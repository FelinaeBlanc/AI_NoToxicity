/*! For license information please see service_worker_ai_logic.bundle.js.LICENSE.txt */
(()=>{var e={570:e=>{e.exports=n;var t=null;try{t=new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0,97,115,109,1,0,0,0,1,13,2,96,0,1,127,96,4,127,127,127,127,1,127,3,7,6,0,1,1,1,1,1,6,6,1,127,1,65,0,11,7,50,6,3,109,117,108,0,1,5,100,105,118,95,115,0,2,5,100,105,118,95,117,0,3,5,114,101,109,95,115,0,4,5,114,101,109,95,117,0,5,8,103,101,116,95,104,105,103,104,0,0,10,191,1,6,4,0,35,0,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,126,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,127,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,128,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,129,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,130,34,4,66,32,135,167,36,0,32,4,167,11])),{}).exports}catch(e){}function n(e,t,n){this.low=0|e,this.high=0|t,this.unsigned=!!n}function s(e){return!0===(e&&e.__isLong__)}n.prototype.__isLong__,Object.defineProperty(n.prototype,"__isLong__",{value:!0}),n.isLong=s;var r={},a={};function i(e,t){var n,s,i;return t?(i=0<=(e>>>=0)&&e<256)&&(s=a[e])?s:(n=l(e,(0|e)<0?-1:0,!0),i&&(a[e]=n),n):(i=-128<=(e|=0)&&e<128)&&(s=r[e])?s:(n=l(e,e<0?-1:0,!1),i&&(r[e]=n),n)}function o(e,t){if(isNaN(e))return t?y:g;if(t){if(e<0)return y;if(e>=d)return v}else{if(e<=-f)return I;if(e+1>=f)return k}return e<0?o(-e,t).neg():l(e%p|0,e/p|0,t)}function l(e,t,s){return new n(e,t,s)}n.fromInt=i,n.fromNumber=o,n.fromBits=l;var u=Math.pow;function c(e,t,n){if(0===e.length)throw Error("empty string");if("NaN"===e||"Infinity"===e||"+Infinity"===e||"-Infinity"===e)return g;if("number"==typeof t?(n=t,t=!1):t=!!t,(n=n||10)<2||36<n)throw RangeError("radix");var s;if((s=e.indexOf("-"))>0)throw Error("interior hyphen");if(0===s)return c(e.substring(1),t,n).neg();for(var r=o(u(n,8)),a=g,i=0;i<e.length;i+=8){var l=Math.min(8,e.length-i),h=parseInt(e.substring(i,i+l),n);if(l<8){var p=o(u(n,l));a=a.mul(p).add(o(h))}else a=(a=a.mul(r)).add(o(h))}return a.unsigned=t,a}function h(e,t){return"number"==typeof e?o(e,t):"string"==typeof e?c(e,t):l(e.low,e.high,"boolean"==typeof t?t:e.unsigned)}n.fromString=c,n.fromValue=h;var p=4294967296,d=p*p,f=d/2,m=i(1<<24),g=i(0);n.ZERO=g;var y=i(0,!0);n.UZERO=y;var b=i(1);n.ONE=b;var x=i(1,!0);n.UONE=x;var w=i(-1);n.NEG_ONE=w;var k=l(-1,2147483647,!1);n.MAX_VALUE=k;var v=l(-1,-1,!0);n.MAX_UNSIGNED_VALUE=v;var I=l(0,-2147483648,!1);n.MIN_VALUE=I;var N=n.prototype;N.toInt=function(){return this.unsigned?this.low>>>0:this.low},N.toNumber=function(){return this.unsigned?(this.high>>>0)*p+(this.low>>>0):this.high*p+(this.low>>>0)},N.toString=function(e){if((e=e||10)<2||36<e)throw RangeError("radix");if(this.isZero())return"0";if(this.isNegative()){if(this.eq(I)){var t=o(e),n=this.div(t),s=n.mul(t).sub(this);return n.toString(e)+s.toInt().toString(e)}return"-"+this.neg().toString(e)}for(var r=o(u(e,6),this.unsigned),a=this,i="";;){var l=a.div(r),c=(a.sub(l.mul(r)).toInt()>>>0).toString(e);if((a=l).isZero())return c+i;for(;c.length<6;)c="0"+c;i=""+c+i}},N.getHighBits=function(){return this.high},N.getHighBitsUnsigned=function(){return this.high>>>0},N.getLowBits=function(){return this.low},N.getLowBitsUnsigned=function(){return this.low>>>0},N.getNumBitsAbs=function(){if(this.isNegative())return this.eq(I)?64:this.neg().getNumBitsAbs();for(var e=0!=this.high?this.high:this.low,t=31;t>0&&!(e&1<<t);t--);return 0!=this.high?t+33:t+1},N.isZero=function(){return 0===this.high&&0===this.low},N.eqz=N.isZero,N.isNegative=function(){return!this.unsigned&&this.high<0},N.isPositive=function(){return this.unsigned||this.high>=0},N.isOdd=function(){return!(1&~this.low)},N.isEven=function(){return!(1&this.low)},N.equals=function(e){return s(e)||(e=h(e)),(this.unsigned===e.unsigned||this.high>>>31!=1||e.high>>>31!=1)&&this.high===e.high&&this.low===e.low},N.eq=N.equals,N.notEquals=function(e){return!this.eq(e)},N.neq=N.notEquals,N.ne=N.notEquals,N.lessThan=function(e){return this.comp(e)<0},N.lt=N.lessThan,N.lessThanOrEqual=function(e){return this.comp(e)<=0},N.lte=N.lessThanOrEqual,N.le=N.lessThanOrEqual,N.greaterThan=function(e){return this.comp(e)>0},N.gt=N.greaterThan,N.greaterThanOrEqual=function(e){return this.comp(e)>=0},N.gte=N.greaterThanOrEqual,N.ge=N.greaterThanOrEqual,N.compare=function(e){if(s(e)||(e=h(e)),this.eq(e))return 0;var t=this.isNegative(),n=e.isNegative();return t&&!n?-1:!t&&n?1:this.unsigned?e.high>>>0>this.high>>>0||e.high===this.high&&e.low>>>0>this.low>>>0?-1:1:this.sub(e).isNegative()?-1:1},N.comp=N.compare,N.negate=function(){return!this.unsigned&&this.eq(I)?I:this.not().add(b)},N.neg=N.negate,N.add=function(e){s(e)||(e=h(e));var t=this.high>>>16,n=65535&this.high,r=this.low>>>16,a=65535&this.low,i=e.high>>>16,o=65535&e.high,u=e.low>>>16,c=0,p=0,d=0,f=0;return d+=(f+=a+(65535&e.low))>>>16,p+=(d+=r+u)>>>16,c+=(p+=n+o)>>>16,c+=t+i,l((d&=65535)<<16|(f&=65535),(c&=65535)<<16|(p&=65535),this.unsigned)},N.subtract=function(e){return s(e)||(e=h(e)),this.add(e.neg())},N.sub=N.subtract,N.multiply=function(e){if(this.isZero())return g;if(s(e)||(e=h(e)),t)return l(t.mul(this.low,this.high,e.low,e.high),t.get_high(),this.unsigned);if(e.isZero())return g;if(this.eq(I))return e.isOdd()?I:g;if(e.eq(I))return this.isOdd()?I:g;if(this.isNegative())return e.isNegative()?this.neg().mul(e.neg()):this.neg().mul(e).neg();if(e.isNegative())return this.mul(e.neg()).neg();if(this.lt(m)&&e.lt(m))return o(this.toNumber()*e.toNumber(),this.unsigned);var n=this.high>>>16,r=65535&this.high,a=this.low>>>16,i=65535&this.low,u=e.high>>>16,c=65535&e.high,p=e.low>>>16,d=65535&e.low,f=0,y=0,b=0,x=0;return b+=(x+=i*d)>>>16,y+=(b+=a*d)>>>16,b&=65535,y+=(b+=i*p)>>>16,f+=(y+=r*d)>>>16,y&=65535,f+=(y+=a*p)>>>16,y&=65535,f+=(y+=i*c)>>>16,f+=n*d+r*p+a*c+i*u,l((b&=65535)<<16|(x&=65535),(f&=65535)<<16|(y&=65535),this.unsigned)},N.mul=N.multiply,N.divide=function(e){if(s(e)||(e=h(e)),e.isZero())throw Error("division by zero");var n,r,a;if(t)return this.unsigned||-2147483648!==this.high||-1!==e.low||-1!==e.high?l((this.unsigned?t.div_u:t.div_s)(this.low,this.high,e.low,e.high),t.get_high(),this.unsigned):this;if(this.isZero())return this.unsigned?y:g;if(this.unsigned){if(e.unsigned||(e=e.toUnsigned()),e.gt(this))return y;if(e.gt(this.shru(1)))return x;a=y}else{if(this.eq(I))return e.eq(b)||e.eq(w)?I:e.eq(I)?b:(n=this.shr(1).div(e).shl(1)).eq(g)?e.isNegative()?b:w:(r=this.sub(e.mul(n)),a=n.add(r.div(e)));if(e.eq(I))return this.unsigned?y:g;if(this.isNegative())return e.isNegative()?this.neg().div(e.neg()):this.neg().div(e).neg();if(e.isNegative())return this.div(e.neg()).neg();a=g}for(r=this;r.gte(e);){n=Math.max(1,Math.floor(r.toNumber()/e.toNumber()));for(var i=Math.ceil(Math.log(n)/Math.LN2),c=i<=48?1:u(2,i-48),p=o(n),d=p.mul(e);d.isNegative()||d.gt(r);)d=(p=o(n-=c,this.unsigned)).mul(e);p.isZero()&&(p=b),a=a.add(p),r=r.sub(d)}return a},N.div=N.divide,N.modulo=function(e){return s(e)||(e=h(e)),t?l((this.unsigned?t.rem_u:t.rem_s)(this.low,this.high,e.low,e.high),t.get_high(),this.unsigned):this.sub(this.div(e).mul(e))},N.mod=N.modulo,N.rem=N.modulo,N.not=function(){return l(~this.low,~this.high,this.unsigned)},N.and=function(e){return s(e)||(e=h(e)),l(this.low&e.low,this.high&e.high,this.unsigned)},N.or=function(e){return s(e)||(e=h(e)),l(this.low|e.low,this.high|e.high,this.unsigned)},N.xor=function(e){return s(e)||(e=h(e)),l(this.low^e.low,this.high^e.high,this.unsigned)},N.shiftLeft=function(e){return s(e)&&(e=e.toInt()),0==(e&=63)?this:e<32?l(this.low<<e,this.high<<e|this.low>>>32-e,this.unsigned):l(0,this.low<<e-32,this.unsigned)},N.shl=N.shiftLeft,N.shiftRight=function(e){return s(e)&&(e=e.toInt()),0==(e&=63)?this:e<32?l(this.low>>>e|this.high<<32-e,this.high>>e,this.unsigned):l(this.high>>e-32,this.high>=0?0:-1,this.unsigned)},N.shr=N.shiftRight,N.shiftRightUnsigned=function(e){if(s(e)&&(e=e.toInt()),0==(e&=63))return this;var t=this.high;return e<32?l(this.low>>>e|t<<32-e,t>>>e,this.unsigned):l(32===e?t:t>>>e-32,0,this.unsigned)},N.shru=N.shiftRightUnsigned,N.shr_u=N.shiftRightUnsigned,N.toSigned=function(){return this.unsigned?l(this.low,this.high,!1):this},N.toUnsigned=function(){return this.unsigned?this:l(this.low,this.high,!0)},N.toBytes=function(e){return e?this.toBytesLE():this.toBytesBE()},N.toBytesLE=function(){var e=this.high,t=this.low;return[255&t,t>>>8&255,t>>>16&255,t>>>24,255&e,e>>>8&255,e>>>16&255,e>>>24]},N.toBytesBE=function(){var e=this.high,t=this.low;return[e>>>24,e>>>16&255,e>>>8&255,255&e,t>>>24,t>>>16&255,t>>>8&255,255&t]},n.fromBytes=function(e,t,s){return s?n.fromBytesLE(e,t):n.fromBytesBE(e,t)},n.fromBytesLE=function(e,t){return new n(e[0]|e[1]<<8|e[2]<<16|e[3]<<24,e[4]|e[5]<<8|e[6]<<16|e[7]<<24,t)},n.fromBytesBE=function(e,t){return new n(e[4]<<24|e[5]<<16|e[6]<<8|e[7],e[0]<<24|e[1]<<16|e[2]<<8|e[3],t)}},391:(e,t,n)=>{var s=n(180),r=n(181),a=n(31),i=n(67),o=n(833),l=n(717),u=n(801);u.alea=s,u.xor128=r,u.xorwow=a,u.xorshift7=i,u.xor4096=o,u.tychei=l,e.exports=u},180:function(e,t,n){var s;!function(e,r){function a(e){var t,n=this,s=(t=4022871197,function(e){e=String(e);for(var n=0;n<e.length;n++){var s=.02519603282416938*(t+=e.charCodeAt(n));s-=t=s>>>0,t=(s*=t)>>>0,t+=4294967296*(s-=t)}return 2.3283064365386963e-10*(t>>>0)});n.next=function(){var e=2091639*n.s0+2.3283064365386963e-10*n.c;return n.s0=n.s1,n.s1=n.s2,n.s2=e-(n.c=0|e)},n.c=1,n.s0=s(" "),n.s1=s(" "),n.s2=s(" "),n.s0-=s(e),n.s0<0&&(n.s0+=1),n.s1-=s(e),n.s1<0&&(n.s1+=1),n.s2-=s(e),n.s2<0&&(n.s2+=1),s=null}function i(e,t){return t.c=e.c,t.s0=e.s0,t.s1=e.s1,t.s2=e.s2,t}function o(e,t){var n=new a(e),s=t&&t.state,r=n.next;return r.int32=function(){return 4294967296*n.next()|0},r.double=function(){return r()+11102230246251565e-32*(2097152*r()|0)},r.quick=r,s&&("object"==typeof s&&i(s,n),r.state=function(){return i(n,{})}),r}r&&r.exports?r.exports=o:n.amdD&&n.amdO?void 0===(s=function(){return o}.call(t,n,t,r))||(r.exports=s):this.alea=o}(0,e=n.nmd(e),n.amdD)},717:function(e,t,n){var s;!function(e,r){function a(e){var t=this,n="";t.next=function(){var e=t.b,n=t.c,s=t.d,r=t.a;return e=e<<25^e>>>7^n,n=n-s|0,s=s<<24^s>>>8^r,r=r-e|0,t.b=e=e<<20^e>>>12^n,t.c=n=n-s|0,t.d=s<<16^n>>>16^r,t.a=r-e|0},t.a=0,t.b=0,t.c=-1640531527,t.d=1367130551,e===Math.floor(e)?(t.a=e/4294967296|0,t.b=0|e):n+=e;for(var s=0;s<n.length+20;s++)t.b^=0|n.charCodeAt(s),t.next()}function i(e,t){return t.a=e.a,t.b=e.b,t.c=e.c,t.d=e.d,t}function o(e,t){var n=new a(e),s=t&&t.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},r.int32=n.next,r.quick=r,s&&("object"==typeof s&&i(s,n),r.state=function(){return i(n,{})}),r}r&&r.exports?r.exports=o:n.amdD&&n.amdO?void 0===(s=function(){return o}.call(t,n,t,r))||(r.exports=s):this.tychei=o}(0,e=n.nmd(e),n.amdD)},181:function(e,t,n){var s;!function(e,r){function a(e){var t=this,n="";t.x=0,t.y=0,t.z=0,t.w=0,t.next=function(){var e=t.x^t.x<<11;return t.x=t.y,t.y=t.z,t.z=t.w,t.w^=t.w>>>19^e^e>>>8},e===(0|e)?t.x=e:n+=e;for(var s=0;s<n.length+64;s++)t.x^=0|n.charCodeAt(s),t.next()}function i(e,t){return t.x=e.x,t.y=e.y,t.z=e.z,t.w=e.w,t}function o(e,t){var n=new a(e),s=t&&t.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},r.int32=n.next,r.quick=r,s&&("object"==typeof s&&i(s,n),r.state=function(){return i(n,{})}),r}r&&r.exports?r.exports=o:n.amdD&&n.amdO?void 0===(s=function(){return o}.call(t,n,t,r))||(r.exports=s):this.xor128=o}(0,e=n.nmd(e),n.amdD)},833:function(e,t,n){var s;!function(e,r){function a(e){var t=this;t.next=function(){var e,n,s=t.w,r=t.X,a=t.i;return t.w=s=s+1640531527|0,n=r[a+34&127],e=r[a=a+1&127],n^=n<<13,e^=e<<17,n^=n>>>15,e^=e>>>12,n=r[a]=n^e,t.i=a,n+(s^s>>>16)|0},function(e,t){var n,s,r,a,i,o=[],l=128;for(t===(0|t)?(s=t,t=null):(t+="\0",s=0,l=Math.max(l,t.length)),r=0,a=-32;a<l;++a)t&&(s^=t.charCodeAt((a+32)%t.length)),0===a&&(i=s),s^=s<<10,s^=s>>>15,s^=s<<4,s^=s>>>13,a>=0&&(i=i+1640531527|0,r=0==(n=o[127&a]^=s+i)?r+1:0);for(r>=128&&(o[127&(t&&t.length||0)]=-1),r=127,a=512;a>0;--a)s=o[r+34&127],n=o[r=r+1&127],s^=s<<13,n^=n<<17,s^=s>>>15,n^=n>>>12,o[r]=s^n;e.w=i,e.X=o,e.i=r}(t,e)}function i(e,t){return t.i=e.i,t.w=e.w,t.X=e.X.slice(),t}function o(e,t){null==e&&(e=+new Date);var n=new a(e),s=t&&t.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},r.int32=n.next,r.quick=r,s&&(s.X&&i(s,n),r.state=function(){return i(n,{})}),r}r&&r.exports?r.exports=o:n.amdD&&n.amdO?void 0===(s=function(){return o}.call(t,n,t,r))||(r.exports=s):this.xor4096=o}(0,e=n.nmd(e),n.amdD)},67:function(e,t,n){var s;!function(e,r){function a(e){var t=this;t.next=function(){var e,n,s=t.x,r=t.i;return e=s[r],n=(e^=e>>>7)^e<<24,n^=(e=s[r+1&7])^e>>>10,n^=(e=s[r+3&7])^e>>>3,n^=(e=s[r+4&7])^e<<7,e=s[r+7&7],n^=(e^=e<<13)^e<<9,s[r]=n,t.i=r+1&7,n},function(e,t){var n,s=[];if(t===(0|t))s[0]=t;else for(t=""+t,n=0;n<t.length;++n)s[7&n]=s[7&n]<<15^t.charCodeAt(n)+s[n+1&7]<<13;for(;s.length<8;)s.push(0);for(n=0;n<8&&0===s[n];++n);for(8==n?s[7]=-1:s[n],e.x=s,e.i=0,n=256;n>0;--n)e.next()}(t,e)}function i(e,t){return t.x=e.x.slice(),t.i=e.i,t}function o(e,t){null==e&&(e=+new Date);var n=new a(e),s=t&&t.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},r.int32=n.next,r.quick=r,s&&(s.x&&i(s,n),r.state=function(){return i(n,{})}),r}r&&r.exports?r.exports=o:n.amdD&&n.amdO?void 0===(s=function(){return o}.call(t,n,t,r))||(r.exports=s):this.xorshift7=o}(0,e=n.nmd(e),n.amdD)},31:function(e,t,n){var s;!function(e,r){function a(e){var t=this,n="";t.next=function(){var e=t.x^t.x>>>2;return t.x=t.y,t.y=t.z,t.z=t.w,t.w=t.v,(t.d=t.d+362437|0)+(t.v=t.v^t.v<<4^e^e<<1)|0},t.x=0,t.y=0,t.z=0,t.w=0,t.v=0,e===(0|e)?t.x=e:n+=e;for(var s=0;s<n.length+64;s++)t.x^=0|n.charCodeAt(s),s==n.length&&(t.d=t.x<<10^t.x>>>4),t.next()}function i(e,t){return t.x=e.x,t.y=e.y,t.z=e.z,t.w=e.w,t.v=e.v,t.d=e.d,t}function o(e,t){var n=new a(e),s=t&&t.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},r.int32=n.next,r.quick=r,s&&("object"==typeof s&&i(s,n),r.state=function(){return i(n,{})}),r}r&&r.exports?r.exports=o:n.amdD&&n.amdO?void 0===(s=function(){return o}.call(t,n,t,r))||(r.exports=s):this.xorwow=o}(0,e=n.nmd(e),n.amdD)},801:function(e,t,n){var s;!function(r,a,i){var o,l=256,u=i.pow(l,6),c=i.pow(2,52),h=2*c,p=255;function d(e,t,n){var s=[],p=y(g((t=1==t?{entropy:!0}:t||{}).entropy?[e,b(a)]:null==e?function(){try{var e;return o&&(e=o.randomBytes)?e=e(l):(e=new Uint8Array(l),(r.crypto||r.msCrypto).getRandomValues(e)),b(e)}catch(e){var t=r.navigator,n=t&&t.plugins;return[+new Date,r,n,r.screen,b(a)]}}():e,3),s),d=new f(s),x=function(){for(var e=d.g(6),t=u,n=0;e<c;)e=(e+n)*l,t*=l,n=d.g(1);for(;e>=h;)e/=2,t/=2,n>>>=1;return(e+n)/t};return x.int32=function(){return 0|d.g(4)},x.quick=function(){return d.g(4)/4294967296},x.double=x,y(b(d.S),a),(t.pass||n||function(e,t,n,s){return s&&(s.S&&m(s,d),e.state=function(){return m(d,{})}),n?(i.random=e,t):e})(x,p,"global"in t?t.global:this==i,t.state)}function f(e){var t,n=e.length,s=this,r=0,a=s.i=s.j=0,i=s.S=[];for(n||(e=[n++]);r<l;)i[r]=r++;for(r=0;r<l;r++)i[r]=i[a=p&a+e[r%n]+(t=i[r])],i[a]=t;(s.g=function(e){for(var t,n=0,r=s.i,a=s.j,i=s.S;e--;)t=i[r=p&r+1],n=n*l+i[p&(i[r]=i[a=p&a+t])+(i[a]=t)];return s.i=r,s.j=a,n})(l)}function m(e,t){return t.i=e.i,t.j=e.j,t.S=e.S.slice(),t}function g(e,t){var n,s=[],r=typeof e;if(t&&"object"==r)for(n in e)try{s.push(g(e[n],t-1))}catch(e){}return s.length?s:"string"==r?e:e+"\0"}function y(e,t){for(var n,s=e+"",r=0;r<s.length;)t[p&r]=p&(n^=19*t[p&r])+s.charCodeAt(r++);return b(t)}function b(e){return String.fromCharCode.apply(0,e)}if(y(i.random(),a),e.exports){e.exports=d;try{o=n(234)}catch(e){}}else void 0===(s=function(){return d}.call(t,n,t,e))||(e.exports=s)}("undefined"!=typeof self?self:this,[],Math)},817:()=>{},590:()=>{},78:()=>{},905:()=>{},637:()=>{},279:()=>{},222:()=>{},234:()=>{}},t={};function n(s){var r=t[s];if(void 0!==r)return r.exports;var a=t[s]={id:s,loaded:!1,exports:{}};return e[s].call(a.exports,a,a.exports,n),a.loaded=!0,a.exports}n.amdD=function(){throw new Error("define cannot be used indirect")},n.amdO={},n.n=e=>{var t=e&&e.__esModule?()=>e.default:()=>e;return n.d(t,{a:t}),t},n.d=(e,t)=>{for(var s in t)n.o(t,s)&&!n.o(e,s)&&Object.defineProperty(e,s,{enumerable:!0,get:t[s]})},n.g=function(){if("object"==typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(e){if("object"==typeof window)return window}}(),n.o=(e,t)=>Object.prototype.hasOwnProperty.call(e,t),n.r=e=>{"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},n.nmd=e=>(e.paths=[],e.children||(e.children=[]),e),(()=>{"use strict";var e={};n.r(e),n.d(e,{assertParamsValid:()=>Di,computeFlatOffset:()=>ji,computeOutShape:()=>Oi,getNormalizedAxes:()=>Bi,isSliceContinous:()=>Hi,maskToAxes:()=>Fi,parseSliceParams:()=>Ki,sliceInfo:()=>qi,startForAxis:()=>Ui,startIndicesWithElidedDims:()=>Pi,stopForAxis:()=>Gi,stopIndicesWithElidedDims:()=>Wi,stridesForAxis:()=>Vi,stridesWithElidedDims:()=>Mi});var t={};n.r(t),n.d(t,{collectGatherOpShapeInfo:()=>ch,computeOutShape:()=>uh,segOpComputeOptimalWindowSize:()=>lh});var s={};n.r(s),n.d(s,{ERF_A1:()=>Tc,ERF_A2:()=>$c,ERF_A3:()=>Ec,ERF_A4:()=>Cc,ERF_A5:()=>Rc,ERF_P:()=>Sc,PARALLELIZE_THRESHOLD:()=>hc,RowPartitionType:()=>ic,SELU_SCALE:()=>Nc,SELU_SCALEALPHA:()=>Ic,applyActivation:()=>pu,assertAndGetBroadcastShape:()=>gi,assertAxesAreInnerMostDims:()=>al,assertParamsConsistent:()=>rc,assignToTypedArray:()=>Mc,axesAreInnerMostDims:()=>tl,calculateShapes:()=>vc,checkEinsumDimSizes:()=>Hc,checkPadOnDimRoundingMode:()=>fo,combineLocations:()=>nl,combineRaggedTensorToTensorShapes:()=>oc,complexWithEvenIndex:()=>Dc,complexWithOddIndex:()=>Fc,computeConv2DInfo:()=>no,computeConv3DInfo:()=>so,computeDefaultPad:()=>ro,computeDilation2DInfo:()=>Qi,computeOptimalWindowSize:()=>pc,computeOutAndReduceShapes:()=>sl,computeOutShape:()=>ac,computePool2DInfo:()=>eo,computePool3DInfo:()=>to,convertConv2DDataFormat:()=>po,decodeEinsumEquation:()=>Uc,eitherStridesOrDilationsAreOne:()=>co,expandShapeToKeepDim:()=>rl,exponent:()=>zc,exponents:()=>Lc,fromStringArrayToUint8:()=>ph,fromUint8ToStringArray:()=>hh,getAxesPermutation:()=>il,getBroadcastDims:()=>fi,getComplexWithIndex:()=>Oc,getEinsumComputePath:()=>jc,getEinsumPermutation:()=>Gc,getFusedBiasGradient:()=>hu,getFusedDyActivation:()=>cu,getImageCenter:()=>dc,getInnerMostAxes:()=>ll,getPermuted:()=>mc,getRaggedRank:()=>uc,getReductionAxes:()=>mi,getReshaped:()=>fc,getReshapedPermuted:()=>gc,getRowPartitionTypesHelper:()=>lc,getSliceBeginCoords:()=>yc,getSliceSize:()=>bc,getSparseFillEmptyRowsIndicesDenseShapeMismatch:()=>Yc,getSparseFillEmptyRowsNegativeIndexErrorMessage:()=>Jc,getSparseFillEmptyRowsOutOfRangeIndexErrorMessage:()=>Zc,getSparseReshapeEmptyTensorZeroOutputDimErrorMessage:()=>th,getSparseReshapeInputOutputMismatchErrorMessage:()=>sh,getSparseReshapeInputOutputMultipleErrorMessage:()=>nh,getSparseReshapeMultipleNegativeOneOutputDimErrorMessage:()=>Qc,getSparseReshapeNegativeOutputDimErrorMessage:()=>eh,getSparseSegmentReductionIndicesOutOfRangeErrorMessage:()=>oh,getSparseSegmentReductionNegativeSegmentIdsErrorMessage:()=>rh,getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage:()=>ah,getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage:()=>ih,getUndoAxesPermutation:()=>ol,isIdentityPermutation:()=>Kc,log:()=>Rs,mergeRealAndImagArrays:()=>Ac,prepareAndValidate:()=>xc,prepareSplitSize:()=>Xc,segment_util:()=>t,shouldFuse:()=>du,slice_util:()=>e,splitRealAndImagArrays:()=>_c,stridesOrDilationsArePositive:()=>ho,tupleValuesAreOne:()=>uo,upcastType:()=>Cr,validateDefaultValueShape:()=>cc,validateInput:()=>kc,validateUpdateShape:()=>wc,warn:()=>Cs});var r={};n.r(r),n.d(r,{mx:()=>Ww,XI:()=>Dk,Nk:()=>Fk,f6:()=>Mk,ct:()=>Mw,YG:()=>Bk,hH:()=>Hk,z3:()=>Cv,sG:()=>Pv,uM:()=>Hv,vS:()=>lI,qB:()=>gI,GG:()=>bI,lg:()=>II,rq:()=>wI,cu:()=>MI,WR:()=>DI,GE:()=>BI,px:()=>WI,jC:()=>nN,He:()=>aN,hE:()=>mN,BF:()=>kv,Dk:()=>SN,cl:()=>DN,_B:()=>jN,ub:()=>XN,_f:()=>ZN,Ku:()=>rS,qy:()=>iS,Zy:()=>bS,bu:()=>kS,zv:()=>$w,dH:()=>Yw,HS:()=>Ck,yH:()=>WS,l3:()=>US,z9:()=>HS,x6:()=>YS,_m:()=>sT,eW:()=>oT,GK:()=>cT,SP:()=>dT,yr:()=>mT,dl:()=>Jv,Dw:()=>kT,xT:()=>ST,_X:()=>sk,wz:()=>_T});var a={};n.r(a),n.d(a,{browserFiles:()=>Hz,browserHTTPRequest:()=>eB,concatenateArrayBuffers:()=>qL,copyModel:()=>Fz,decodeWeights:()=>GL,encodeWeights:()=>UL,fromMemory:()=>rB,fromMemorySync:()=>aB,getLoadHandlers:()=>iz,getModelArtifactsForJSON:()=>ZL,getModelArtifactsForJSONSync:()=>JL,getModelArtifactsInfoForJSON:()=>QL,getSaveHandlers:()=>az,getWeightSpecs:()=>ez,http:()=>Qz,isHTTPScheme:()=>Jz,listModels:()=>_z,loadWeights:()=>qz,moveModel:()=>Oz,registerLoadRouter:()=>rz,registerSaveRouter:()=>sz,removeModel:()=>Dz,weightsLoaderFactory:()=>Xz,withSaveHandler:()=>iB,withSaveHandlerSync:()=>oB});var i={};n.r(i),n.d(i,{conv2d:()=>pU,depthwiseConv2d:()=>mU,matMul:()=>gU});var o={};n.r(o),n.d(o,{json:()=>NG});var l={};n.r(l),n.d(l,{json:()=>SG});var u={};n.r(u),n.d(u,{json:()=>TG});var c={};n.r(c),n.d(c,{json:()=>$G});var h={};n.r(h),n.d(h,{json:()=>EG});var p={};n.r(p),n.d(p,{json:()=>CG});var d={};n.r(d),n.d(d,{json:()=>RG});var f={};n.r(f),n.d(f,{json:()=>AG});var m={};n.r(m),n.d(m,{json:()=>_G});var g={};n.r(g),n.d(g,{json:()=>DG});var y={};n.r(y),n.d(y,{json:()=>FG});var b={};n.r(b),n.d(b,{json:()=>OG});var x={};n.r(x),n.d(x,{json:()=>MG});var w={};n.r(w),n.d(w,{json:()=>LG});var k={};n.r(k),n.d(k,{json:()=>zG});var v={};n.r(v),n.d(v,{json:()=>BG});var I={};n.r(I),n.d(I,{json:()=>PG});var N={};n.r(N),n.d(N,{json:()=>WG});var S={};n.r(S),n.d(S,{json:()=>VG});var T={};n.r(T),n.d(T,{OP_SCOPE_SUFFIX:()=>ML,abs:()=>lB,acos:()=>uB,acosh:()=>cB,add:()=>hB,addN:()=>pB,all:()=>dB,any:()=>fB,argMax:()=>mB,argMin:()=>gB,asin:()=>yB,asinh:()=>bB,atan:()=>xB,atan2:()=>wB,atanh:()=>kB,avgPool:()=>RB,avgPool3d:()=>AB,basicLSTMCell:()=>zB,batchNorm:()=>PB,batchNorm2d:()=>WB,batchNorm3d:()=>VB,batchNorm4d:()=>UB,batchToSpaceND:()=>BB,bincount:()=>GB,booleanMaskAsync:()=>XV,broadcastArgs:()=>HB,broadcastTo:()=>jB,buffer:()=>zz,cast:()=>Bz,ceil:()=>KB,clipByValue:()=>XB,clone:()=>Pz,complex:()=>zL,concat:()=>_B,concat1d:()=>YB,concat2d:()=>JB,concat3d:()=>ZB,concat4d:()=>QB,conv1d:()=>tP,conv2d:()=>eP,conv2dTranspose:()=>sP,conv3d:()=>rP,conv3dTranspose:()=>iP,cos:()=>oP,cosh:()=>lP,cosineWindow:()=>aU,cumprod:()=>uP,cumsum:()=>cP,denseBincount:()=>hP,depthToSpace:()=>pP,depthwiseConv2d:()=>dP,diag:()=>fP,dilation2d:()=>mP,div:()=>yP,divNoNan:()=>vP,dot:()=>IP,dropout:()=>sU,einsum:()=>NP,elu:()=>SP,enclosingPowerOfTwo:()=>rU,equal:()=>xP,erf:()=>TP,euclideanNorm:()=>LP,exp:()=>zP,expandDims:()=>BP,expm1:()=>PP,eye:()=>VP,fft:()=>NV,fill:()=>qB,floor:()=>UP,floorDiv:()=>gP,fused:()=>i,gather:()=>GP,gatherND:()=>nU,greater:()=>HP,greaterEqual:()=>jP,ifft:()=>SV,imag:()=>KP,image:()=>lG,inTopKAsync:()=>iU,irfft:()=>TV,isFinite:()=>qP,isInf:()=>XP,isNaN:()=>YP,leakyRelu:()=>JP,less:()=>ZP,lessEqual:()=>QP,linalg:()=>uG,linspace:()=>eW,localResponseNormalization:()=>tW,log:()=>nW,log1p:()=>sW,logSigmoid:()=>oW,logSoftmax:()=>uW,logSumExp:()=>cW,logicalAnd:()=>hW,logicalNot:()=>pW,logicalOr:()=>dW,logicalXor:()=>fW,losses:()=>cG,lowerBound:()=>yW,matMul:()=>DB,max:()=>EP,maxPool:()=>bW,maxPool3d:()=>xW,maxPoolWithArgmax:()=>wW,maximum:()=>kW,mean:()=>vW,meshgrid:()=>SW,min:()=>CP,minimum:()=>TW,mirrorPad:()=>$W,mod:()=>EW,moments:()=>CW,movingAverage:()=>QV,mul:()=>FB,multiRNNCell:()=>RW,multinomial:()=>AW,neg:()=>aW,norm:()=>MP,notEqual:()=>_W,oneHot:()=>DW,ones:()=>NW,onesLike:()=>FW,op:()=>LL,outerProduct:()=>OW,pad:()=>MW,pad1d:()=>LW,pad2d:()=>zW,pad3d:()=>BW,pad4d:()=>PW,pool:()=>VW,pow:()=>RP,prelu:()=>UW,print:()=>Wz,prod:()=>GW,raggedGather:()=>HW,raggedTensorToTensor:()=>jW,rand:()=>KW,randomGamma:()=>JW,randomNormal:()=>ZW,randomStandardNormal:()=>QW,randomUniform:()=>eV,range:()=>tV,real:()=>nV,reciprocal:()=>sV,relu:()=>rV,relu6:()=>aV,reshape:()=>CB,reverse:()=>iV,reverse1d:()=>oV,reverse2d:()=>lV,reverse3d:()=>uV,reverse4d:()=>cV,rfft:()=>EV,round:()=>hV,rsqrt:()=>pV,scalar:()=>AP,scatterND:()=>eU,searchSorted:()=>gW,selu:()=>dV,separableConv2d:()=>fV,setdiff1dAsync:()=>mV,sigmoid:()=>OB,sign:()=>gV,signal:()=>oG,sin:()=>yV,sinh:()=>bV,slice:()=>MB,slice1d:()=>xV,slice2d:()=>wV,slice3d:()=>kV,slice4d:()=>vV,softmax:()=>IV,softplus:()=>iW,spaceToBatchND:()=>WW,sparse:()=>hG,sparseToDense:()=>tU,spectral:()=>iG,split:()=>$V,sqrt:()=>_P,square:()=>DP,squaredDifference:()=>CV,squeeze:()=>RV,stack:()=>AV,step:()=>_V,stridedSlice:()=>DV,string:()=>pG,sub:()=>lW,sum:()=>FP,tan:()=>FV,tanh:()=>LB,tensor:()=>PL,tensor1d:()=>OV,tensor2d:()=>MV,tensor3d:()=>LV,tensor4d:()=>zV,tensor5d:()=>BV,tensor6d:()=>PV,tile:()=>WP,topk:()=>WV,transpose:()=>ZV,truncatedNormal:()=>VV,unique:()=>UV,unsortedSegmentSum:()=>GV,unstack:()=>HV,upperBound:()=>jV,variable:()=>KV,where:()=>wP,whereAsync:()=>qV,zeros:()=>IW,zerosLike:()=>kP});class ${constructor(e,t){this.backend=e,this.dataMover=t,this.data=new WeakMap,this.dataIdsCount=0}get(e){return this.data.has(e)||this.dataMover.moveData(this.backend,e),this.data.get(e)}set(e,t){this.dataIdsCount++,this.data.set(e,t)}has(e){return this.data.has(e)}delete(e){return this.dataIdsCount--,this.data.delete(e)}numDataIds(){return this.dataIdsCount}}class E{refCount(e){return C("refCount")}incRef(e){return C("incRef")}timerAvailable(){return!0}time(e){return C("time")}read(e){return C("read")}readSync(e){return C("readSync")}readToGPU(e,t){return C("readToGPU")}numDataIds(){return C("numDataIds")}disposeData(e,t){return C("disposeData")}write(e,t,n){return C("write")}move(e,t,n,s,r){return C("move")}createTensorFromGPUData(e,t,n){return C("createTensorFromGPUData")}memory(){return C("memory")}floatPrecision(){return C("floatPrecision")}epsilon(){return 32===this.floatPrecision()?1e-7:1e-4}dispose(){return C("dispose")}}function C(e){throw new Error(`'${e}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`)}function R(e){let t=e.length,n=0;for(;t>0;)n=Math.random()*t|0,t--,D(e,t,n)}function A(e,t,n){return Math.max(e,Math.min(t,n))}function _(e){return e%2==0?e:e+1}function D(e,t,n){const s=e[t];e[t]=e[n],e[n]=s}function F(e,t){if(!e)throw new Error("string"==typeof t?t:t())}function O(e,t,n=""){F(z(e,t),(()=>n+` Shapes ${e} and ${t} must match`))}function M(e){F(null!=e,(()=>"The input to the tensor constructor must be a non-null value."))}function L(e){if(0===e.length)return 1;let t=e[0];for(let n=1;n<e.length;n++)t*=e[n];return t}function z(e,t){if(e===t)return!0;if(null==e||null==t)return!1;if(e.length!==t.length)return!1;for(let n=0;n<e.length;n++)if(e[n]!==t[n])return!1;return!0}function B(e){return e%1==0}function P(e){const t=Math.ceil(Math.sqrt(e));return[t,Math.ceil(e/t)]}function W(e,t){return t<=e.length?e:e+" ".repeat(t-e.length)}function V(e,t=e=>0,n,s){return new Promise(((r,a)=>{let i=0;const o=()=>{if(e())return void r();i++;const l=t(i);null!=n&&i>=n?a():null!=s?s(o,l):setTimeout(o,l)};o()}))}function U(e,t){let n=1,s=-1;for(let t=0;t<e.length;++t)if(e[t]>=0)n*=e[t];else if(-1===e[t]){if(-1!==s)throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${s} and dim ${t}`);s=t}else if(e[t]<0)throw Error(`Shapes can not be < 0. Found ${e[t]} at dim ${t}`);if(-1===s){if(t>0&&t!==n)throw Error(`Size(${t}) must match the product of shape ${e}`);return e}if(0===n)throw Error(`Cannot infer the missing size in [${e}] when there are 0 elements`);if(t%n!=0)throw Error(`The implicit shape can't be a fractional number. Got ${t} / ${n}`);const r=e.slice();return r[s]=t/n,r}function G(e,t){const n=t.length;return F((e=null==e?t.map(((e,t)=>t)):[].concat(e)).every((e=>e>=-n&&e<n)),(()=>`All values in axis param must be in range [-${n}, ${n}) but got axis ${e}`)),F(e.every((e=>B(e))),(()=>`All values in axis param must be integers but got axis ${e}`)),e.map((e=>e<0?n+e:e))}function H(e,t){const n=[],s=[],r=null!=t&&Array.isArray(t)&&0===t.length,a=null==t||r?null:G(t,e).sort();let i=0;for(let t=0;t<e.length;++t){if(null!=a){if(a[i]===t&&1!==e[t])throw new Error(`Can't squeeze axis ${t} since its dim '${e[t]}' is not 1`);(null==a[i]||a[i]>t)&&1===e[t]&&(n.push(e[t]),s.push(t)),a[i]<=t&&i++}1!==e[t]&&(n.push(e[t]),s.push(t))}return{newShape:n,keptDims:s}}function j(e,t){return K(e,t)}function K(e,t){let n=null;if(null==e||"float32"===e)n=new Float32Array(t);else if("int32"===e)n=new Int32Array(t);else if("bool"===e)n=new Uint8Array(t);else{if("string"!==e)throw new Error(`Unknown data type ${e}`);n=new Array(t)}return n}function q(e,t){return!("complex64"===t||"float32"===t&&"complex64"!==e||"int32"===t&&"float32"!==e&&"complex64"!==e||"bool"===t&&"bool"===e)}function X(e){if("float32"===e||"int32"===e)return 4;if("complex64"===e)return 8;if("bool"===e)return 1;throw new Error(`Unknown dtype ${e}`)}function Y(e){return"string"==typeof e||e instanceof String}function J(e){return"number"==typeof e}function Z(e){return Array.isArray(e)?Z(e[0]):e instanceof Float32Array?"float32":e instanceof Int32Array||e instanceof Uint8Array||e instanceof Uint8ClampedArray?"int32":J(e)?"float32":Y(e)?"string":"boolean"==typeof e?"bool":"float32"}function Q(e){return!!(e&&e.constructor&&e.call&&e.apply)}function ee(e,t){for(let n=t;n<e;++n)if(e%n==0)return n;return e}function te(e){const t=e.length;if(t<2)return[];const n=new Array(t-1);n[t-2]=e[t-1];for(let s=t-3;s>=0;--s)n[s]=n[s+1]*e[s+1];return n}function ne(e,t,n,s=!1){const r=new Array;if(1===t.length){const a=t[0]*(s?2:1);for(let t=0;t<a;t++)r[t]=n[e+t]}else{const a=t[0],i=t.slice(1),o=i.reduce(((e,t)=>e*t))*(s?2:1);for(let t=0;t<a;t++)r[t]=ne(e+t*o,i,n,s)}return r}function se(e,t,n=!1){if(0===e.length)return t[0];const s=e.reduce(((e,t)=>e*t))*(n?2:1);if(0===s)return[];if(s!==t.length)throw new Error(`[${e}] does not match the input size ${t.length}${n?" for a complex tensor":""}.`);return ne(0,e,t,n)}function re(e,t){const n=ae(e,t);for(let e=0;e<n.length;e++)n[e]=1;return n}function ae(e,t){if(null==t||"float32"===t||"complex64"===t)return new Float32Array(e);if("int32"===t)return new Int32Array(e);if("bool"===t)return new Uint8Array(e);throw new Error(`Unknown data type ${t}`)}function ie(e,t){const n=e.reduce(((e,t)=>e*t),1);if(null==t||"float32"===t)return se(e,new Float32Array(n));if("int32"===t)return se(e,new Int32Array(n));if("bool"===t)return se(e,new Uint8Array(n));throw new Error(`Unknown data type ${t}`)}function oe(e){e.forEach((t=>{F(Number.isInteger(t)&&t>=0,(()=>`Tensor must have a shape comprised of positive integers but got shape [${e}].`))}))}function le(e,t,n){if(0===t)return 0;if(1===t)return e[0];let s=e[e.length-1];for(let t=0;t<e.length-1;++t)s+=n[t]*e[t];return s}function ue(e,t,n){if(0===t)return[];if(1===t)return[e];const s=new Array(t);for(let t=0;t<s.length-1;++t)s[t]=Math.floor(e/n[t]),e-=s[t]*n[t];return s[s.length-1]=e,s}function ce(e){return e&&e.then&&"function"==typeof e.then}const he="tfjsflags";class pe{constructor(e){this.global=e,this.flags={},this.flagRegistry={},this.urlFlags={},this.getQueryParams=de,this.populateURLFlags()}setPlatform(e,t){null!=this.platform&&(fe().getBool("IS_TEST")||fe().getBool("PROD")||console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${e}.`)),this.platformName=e,this.platform=t}registerFlag(e,t,n){if(this.flagRegistry[e]={evaluationFn:t,setHook:n},null!=this.urlFlags[e]){const t=this.urlFlags[e];fe().getBool("IS_TEST")||fe().getBool("PROD")||console.warn(`Setting feature override from URL ${e}: ${t}.`),this.set(e,t)}}async getAsync(e){return e in this.flags||(this.flags[e]=await this.evaluateFlag(e)),this.flags[e]}get(e){if(e in this.flags)return this.flags[e];const t=this.evaluateFlag(e);if(ce(t))throw new Error(`Flag ${e} cannot be synchronously evaluated. Please use getAsync() instead.`);return this.flags[e]=t,this.flags[e]}getNumber(e){return this.get(e)}getBool(e){return this.get(e)}getString(e){return this.get(e)}getFlags(){return this.flags}get features(){return this.flags}set(e,t){if(null==this.flagRegistry[e])throw new Error(`Cannot set flag ${e} as it has not been registered.`);this.flags[e]=t,null!=this.flagRegistry[e].setHook&&this.flagRegistry[e].setHook(t)}evaluateFlag(e){if(null==this.flagRegistry[e])throw new Error(`Cannot evaluate flag '${e}': no evaluation function found.`);return this.flagRegistry[e].evaluationFn()}setFlags(e){this.flags=Object.assign({},e)}reset(){this.flags={},this.urlFlags={},this.populateURLFlags()}populateURLFlags(){if(void 0===this.global||void 0===this.global.location||void 0===this.global.location.search)return;const e=this.getQueryParams(this.global.location.search);he in e&&e[he].split(",").forEach((e=>{const[t,n]=e.split(":");this.urlFlags[t]=function(e,t){const n=t.toLowerCase();return"true"===n||"false"===n?"true"===n:""+ +n===n?+n:t}(0,n)}))}}function de(e){const t={};return e.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g,((e,...n)=>(function(e,t,n){e[decodeURIComponent(t)]=decodeURIComponent(n||"")}(t,n[0],n[1]),n.join("=")))),t}function fe(){return ge}let me,ge=null;function ye(){if(null==me){let e;if("undefined"!=typeof window)e=window;else if(void 0!==n.g)e=n.g;else if("undefined"!=typeof process)e=process;else{if("undefined"==typeof self)throw new Error("Could not find a global object");e=self}me=e}return me}function be(e,t){const n=function(){const e=ye();return null==e._tfGlobals&&(e._tfGlobals=new Map),e._tfGlobals}();if(n.has(e))return n.get(e);{const s=t();return n.set(e,s),n.get(e)}}const xe="Abs",we="Acos",ke="Acosh",ve="Add",Ie="AddN",Ne="All",Se="Any",Te="ArgMax",$e="ArgMin",Ee="Asin",Ce="Asinh",Re="Atan",Ae="Atanh",_e="Atan2",De="AvgPool",Fe="AvgPoolGrad",Oe="AvgPool3D",Me="AvgPool3DGrad",Le="BatchMatMul",ze="BatchToSpaceND",Be="Bincount",Pe="BitwiseAnd",We="BroadcastArgs",Ve="Cast",Ue="Ceil",Ge="ClipByValue",He="Complex",je="ComplexAbs",Ke="Concat",qe="Conv2D",Xe="Conv2DBackpropFilter",Ye="Conv2DBackpropInput",Je="Conv3D",Ze="Conv3DBackpropFilterV2",Qe="Conv3DBackpropInputV2",et="Cos",tt="Cosh",nt="Cumprod",st="Cumsum",rt="CropAndResize",at="DenseBincount",it="DepthToSpace",ot="DepthwiseConv2dNative",lt="DepthwiseConv2dNativeBackpropFilter",ut="DepthwiseConv2dNativeBackpropInput",ct="Diag",ht="Dilation2D",pt="Dilation2DBackpropInput",dt="Dilation2DBackpropFilter",ft="RealDiv",mt="Einsum",gt="Elu",yt="EluGrad",bt="Erf",xt="Equal",wt="Exp",kt="ExpandDims",vt="Expm1",It="FFT",Nt="Fill",St="FlipLeftRight",Tt="Floor",$t="FloorDiv",Et="FusedBatchNorm",Ct="GatherV2",Rt="GatherNd",At="Greater",_t="GreaterEqual",Dt="Identity",Ft="IFFT",Ot="Imag",Mt="IsFinite",Lt="IsInf",zt="IsNan",Bt="LeakyRelu",Pt="Less",Wt="LessEqual",Vt="LinSpace",Ut="Log",Gt="Log1p",Ht="LogicalAnd",jt="LogicalNot",Kt="LogicalOr",qt="LRN",Xt="LRNGrad",Yt="Max",Jt="Maximum",Zt="MaxPool",Qt="MaxPoolGrad",en="MaxPool3D",tn="MaxPool3DGrad",nn="MaxPoolWithArgmax",sn="Mean",rn="Min",an="Minimum",on="MirrorPad",ln="Mod",un="Multinomial",cn="Multiply",hn="Neg",pn="NotEqual",dn="NonMaxSuppressionV3",fn="NonMaxSuppressionV4",mn="NonMaxSuppressionV5",gn="OnesLike",yn="OneHot",bn="Pack",xn="PadV2",wn="Pow",kn="Prelu",vn="Prod",In="RaggedGather",Nn="RaggedRange",Sn="RaggedTensorToTensor",Tn="Range",$n="Real",En="Reciprocal",Cn="Relu",Rn="Reshape",An="ResizeNearestNeighbor",_n="ResizeNearestNeighborGrad",Dn="ResizeBilinear",Fn="ResizeBilinearGrad",On="Relu6",Mn="Reverse",Ln="Round",zn="Rsqrt",Bn="ScatterNd",Pn="TensorScatterUpdate",Wn="SearchSorted",Vn="Select",Un="Selu",Gn="Slice",Hn="Sin",jn="Sinh",Kn="Sign",qn="Sigmoid",Xn="Softplus",Yn="Sqrt",Jn="Sum",Zn="SpaceToBatchND",Qn="SplitV",es="Softmax",ts="SparseFillEmptyRows",ns="SparseReshape",ss="SparseSegmentMean",rs="SparseSegmentSum",as="SparseToDense",is="SquaredDifference",os="Square",ls="StaticRegexReplace",us="StridedSlice",cs="StringNGrams",hs="StringSplit",ps="StringToHashBucketFast",ds="Sub",fs="Tan",ms="Tanh",gs="Tile",ys="TopK",bs="Transform",xs="Transpose",ws="Unique",ks="Unpack",vs="UnsortedSegmentSum",Is="ZerosLike",Ns="Step",Ss="RotateWithOffset",Ts="_FusedMatMul",$s="FusedConv2D",Es="FusedDepthwiseConv2D";function Cs(...e){fe().getBool("IS_TEST")||fe().getBool("PROD")||console.warn(...e)}function Rs(...e){fe().getBool("IS_TEST")||fe().getBool("PROD")||console.log(...e)}const As=be("kernelRegistry",(()=>new Map)),_s=be("gradRegistry",(()=>new Map));function Ds(e,t){const n=zs(e,t);return As.get(n)}function Fs(e){return _s.get(e)}function Os(e){const t=As.entries(),n=[];for(;;){const{done:s,value:r}=t.next();if(s)break;const[a,i]=r,[o]=a.split("_");o===e&&n.push(i)}return n}function Ms(e){const{kernelName:t,backendName:n}=e,s=zs(t,n);As.has(s)&&Cs(`The kernel '${t}' for backend '${n}' is already registered`),As.set(s,e)}function Ls(e){const{kernelName:t}=e;_s.has(t)&&fe().getBool("DEBUG")&&Cs(`Overriding the gradient for '${t}'`),_s.set(t,e)}function zs(e,t){return`${t}_${e}`}function Bs(e){return e instanceof Float32Array||e instanceof Int32Array||e instanceof Uint8Array||e instanceof Uint8ClampedArray}var Ps=n(570),Ws=n.n(Ps);const Vs=Ws()||Ps;function Us(e){return Vs.fromString(e,!0,16)}const Gs=Us("c3a5c85c97cb3127"),Hs=Us("b492b66fbe98f273"),js=Us("9ae16a3b2f90404f");function Ks(e){return e.xor(e.shru(47))}function qs(e,t,n){const s=e.slice(t,t+n);return Vs.fromBytes(Array.from(s),!0,!0)}function Xs(e,t){return qs(e,t,8)}function Ys(e,t){return qs(e,t,4)}function Js(e,t){return 0===t?e:e.shru(t).or(e.shl(64-t))}function Zs(e,t,n=Us("9ddfea08eb382d69")){let s=e.xor(t).mul(n);s=s.xor(s.shru(47));let r=t.xor(s).mul(n);return r=r.xor(r.shru(47)),r=r.mul(n),r}function Qs(e,t,n,s){return function(e,t,n,s,r,a){r=r.add(e),a=Js(a.add(r).add(s),21);const i=r;return r=(r=r.add(t)).add(n),a=a.add(Js(r,44)),[r.add(s),a.add(i)]}(Xs(e,t),Xs(e,t+8),Xs(e,t+16),Xs(e,t+24),n,s)}function er(e,t=e.length){const n=Vs.fromNumber(81,!0);if(t<=32)return t<=16?function(e,t=e.length){if(t>=8){const n=js.add(2*t),s=Xs(e,0).add(js),r=Xs(e,t-8);return Zs(Js(r,37).mul(n).add(s),Js(s,25).add(r).mul(n),n)}if(t>=4){const n=js.add(2*t);return Zs(Ys(e,0).shl(3).add(t),Ys(e,t-4),n)}if(t>0){const n=e[0]+(e[t>>1]<<8),s=t+(e[t-1]<<2);return Ks(js.mul(n).xor(Gs.mul(s))).mul(js)}return js}(e,t):function(e,t=e.length){const n=js.add(2*t),s=Xs(e,0).mul(Hs),r=Xs(e,8),a=Xs(e,t-8).mul(n),i=Xs(e,t-16).mul(js);return Zs(Js(s.add(r),43).add(Js(a,30)).add(i),s.add(Js(r.add(js),18)).add(a),n)}(e,t);if(t<=64)return function(e,t=e.length){const n=js.add(2*t),s=Xs(e,0).mul(js),r=Xs(e,8),a=Xs(e,t-8).mul(n),i=Xs(e,t-16).mul(js),o=Js(s.add(r),43).add(Js(a,30)).add(i),l=Zs(o,s.add(Js(r.add(js),18)).add(a),n),u=Xs(e,16).mul(n),c=Xs(e,24),h=o.add(Xs(e,t-32)).mul(n),p=l.add(Xs(e,t-24)).mul(n);return Zs(Js(u.add(c),43).add(Js(h,30)).add(p),u.add(Js(c.add(s),18)).add(h),n)}(e,t);let s=n,r=n.mul(Hs).add(113),a=Ks(r.mul(js).add(113)).mul(js),i=[Vs.UZERO,Vs.UZERO],o=[Vs.UZERO,Vs.UZERO];s=s.mul(js).add(Xs(e,0));let l=0;const u=64*(t-1>>6),c=u+(t-1&63)-63;do{s=Js(s.add(r).add(i[0]).add(Xs(e,l+8)),37).mul(Hs),r=Js(r.add(i[1]).add(Xs(e,l+48)),42).mul(Hs),s=s.xor(o[1]),r=r.add(i[0]).add(Xs(e,l+40)),a=Js(a.add(o[0]),33).mul(Hs),i=Qs(e,l,i[1].mul(Hs),s.add(o[0])),o=Qs(e,l+32,a.add(o[1]),r.add(Xs(e,l+16))),[a,s]=[s,a],l+=64}while(l!==u);const h=Hs.add(a.and(255).shl(1));return l=c,o[0]=o[0].add(t-1&63),i[0]=i[0].add(o[0]),o[0]=o[0].add(i[0]),s=Js(s.add(r).add(i[0]).add(Xs(e,l+8)),37).mul(h),r=Js(r.add(i[1]).add(Xs(e,l+48)),42).mul(h),s=s.xor(o[1].mul(9)),r=r.add(i[0].mul(9).add(Xs(e,l+40))),a=Js(a.add(o[0]),33).mul(h),i=Qs(e,l,i[1].mul(h),s.add(o[0])),o=Qs(e,l+32,a.add(o[1]),r.add(Xs(e,l+16))),[a,s]=[s,a],Zs(Zs(i[0],o[0],h).add(Ks(r).mul(Gs)).add(a),Zs(i[1],o[1],h).add(s),h)}function tr(e,t){return"string"===t?rr(e):nr([e],t)}function nr(e,t){if("string"===t)throw new Error("Cannot convert a string[] to a TypedArray");if(Array.isArray(e)&&(e=or(e)),fe().getBool("DEBUG")&&function(e,t){for(let n=0;n<e.length;n++){const s=e[n];if(isNaN(s)||!isFinite(s))throw Error(`A tensor of type ${t} being uploaded contains ${s}.`)}}(e,t),function(e,t){return e instanceof Float32Array&&"float32"===t||e instanceof Int32Array&&"int32"===t||e instanceof Uint8Array&&"bool"===t}(e,t))return e;if(null==t||"float32"===t||"complex64"===t)return new Float32Array(e);if("int32"===t)return new Int32Array(e);if("bool"===t){const t=new Uint8Array(e.length);for(let n=0;n<t.length;++n)0!==Math.round(e[n])&&(t[n]=1);return t}throw new Error(`Unknown data type ${t}`)}function sr(){return fe().platform.now()}function rr(e,t="utf-8"){return t=t||"utf-8",fe().platform.encode(e,t)}function ar(e,t="utf-8"){return t=t||"utf-8",fe().platform.decode(e,t)}function ir(e){return null!=fe().platform.isTypedArray?fe().platform.isTypedArray(e):Bs(e)}function or(e,t=[],n=!1){if(null==t&&(t=[]),"boolean"==typeof e||"number"==typeof e||"string"==typeof e||ce(e)||null==e||ir(e)&&n)t.push(e);else if(Array.isArray(e)||ir(e))for(let s=0;s<e.length;++s)or(e[s],t,n);else{let s=-1;for(const t of Object.keys(e))/^([1-9]+[0-9]*|0)$/.test(t)&&(s=Math.max(s,Number(t)));for(let r=0;r<=s;r++)or(e[r],t,n)}return t}class lr{constructor(e,t){this.backendTimer=e,this.logger=t,null==t&&(this.logger=new cr)}profileKernel(e,t,n){let s;const r=()=>{s=n()};let a;const i=sr();if(this.backendTimer.timerAvailable())a=this.backendTimer.time(r);else{r();for(const e of s)e.dataSync();a=Promise.resolve({kernelMs:sr()-i})}if(fe().getBool("CHECK_COMPUTATION_FOR_ERRORS"))for(let t=0;t<s.length;t++){const n=s[t];n.data().then((t=>{ur(t,n.dtype,e)}))}return{kernelName:e,outputs:s,inputs:t,timeMs:a.then((e=>e.kernelMs)),extraInfo:a.then((e=>null!=e.getExtraProfileInfo?e.getExtraProfileInfo():""))}}logKernelProfile(e){const{kernelName:t,outputs:n,timeMs:s,inputs:r,extraInfo:a}=e;n.forEach((e=>{Promise.all([e.data(),s,a]).then((n=>{this.logger.logKernelProfile(t,e,n[0],n[1],r,n[2])}))}))}}function ur(e,t,n){if("float32"!==t)return!1;for(let t=0;t<e.length;t++){const s=e[t];if(isNaN(s)||!isFinite(s))return console.warn(`Found ${s} in the result of '${n}'`),!0}return!1}class cr{logKernelProfile(e,t,n,s,r,a){const i="number"==typeof s?W(`${s}ms`,9):s.error,o=W(e,25),l=t.rank,u=t.size,c=W(t.shape.toString(),14);let h="";for(const e in r){const n=r[e];if(null!=n){const s=n.shape||t.shape,r=s.length;h+=`${e}: ${r}D ${r>0?s:""} `}}console.log(`%c${o}\t%c${i}\t%c${l}D ${c}\t%c${u}\t%c${h}\t%c${a}`,"font-weight:bold","color:red","color:blue","color: orange","color: green","color: steelblue")}}function hr(e,t,n,s){const r=te(t),a=function(e,t,n,s){const r=L(t),a=s[s.length-1],i=new Array(a).fill(0),o=t.length,l="complex64"===n?mr(e):e;if(o>1)for(let e=0;e<r/a;e++){const t=e*a;for(let e=0;e<a;e++)i[e]=Math.max(i[e],pr(l[t+e],0,n).length)}return i}(e,t,n,r),i=t.length,o=fr(e,t,n,r,a),l=["Tensor"];return s&&(l.push(`  dtype: ${n}`),l.push(`  rank: ${i}`),l.push(`  shape: [${t}]`),l.push("  values:")),l.push(o.map((e=>"    "+e)).join("\n")),l.join("\n")}function pr(e,t,n){let s;return s=Array.isArray(e)?`${parseFloat(e[0].toFixed(7))} + ${parseFloat(e[1].toFixed(7))}j`:Y(e)?`'${e}'`:"bool"===n?dr(e):parseFloat(e.toFixed(7)).toString(),W(s,t)}function dr(e){return 0===e?"false":"true"}function fr(e,t,n,s,r,a=!0){const i="complex64"===n?2:1,o=t[0],l=t.length;if(0===l)return"complex64"===n?[pr(mr(e)[0],0,n)]:"bool"===n?[dr(e[0])]:[e[0].toString()];if(1===l){if(o>20){const t=3*i;let s=Array.from(e.slice(0,t)),a=Array.from(e.slice((o-3)*i,o*i));return"complex64"===n&&(s=mr(s),a=mr(a)),["["+s.map(((e,t)=>pr(e,r[t],n))).join(", ")+", ..., "+a.map(((e,t)=>pr(e,r[o-3+t],n))).join(", ")+"]"]}return["["+("complex64"===n?mr(e):Array.from(e)).map(((e,t)=>pr(e,r[t],n))).join(", ")+"]"]}const u=t.slice(1),c=s.slice(1),h=s[0]*i,p=[];if(o>20){for(let t=0;t<3;t++){const s=t*h,a=s+h;p.push(...fr(e.slice(s,a),u,n,c,r,!1))}p.push("...");for(let t=o-3;t<o;t++){const s=t*h,a=s+h;p.push(...fr(e.slice(s,a),u,n,c,r,t===o-1))}}else for(let t=0;t<o;t++){const s=t*h,a=s+h;p.push(...fr(e.slice(s,a),u,n,c,r,t===o-1))}const d=2===l?",":"";p[0]="["+(o>0?p[0]+d:"");for(let e=1;e<p.length-1;e++)p[e]=" "+p[e]+d;let f=",\n";for(let e=2;e<l;e++)f+="\n";return p[p.length-1]=" "+p[p.length-1]+"]"+(a?"":f),p}function mr(e){const t=[];for(let n=0;n<e.length;n+=2)t.push([e[n],e[n+1]]);return t}class gr{constructor(e,t,n){if(this.dtype=t,this.shape=e.slice(),this.size=L(e),null!=n){const e=n.length;F(e===this.size,(()=>`Length of values '${e}' does not match the size inferred by the shape '${this.size}'.`))}if("complex64"===t)throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");this.values=n||K(t,this.size),this.strides=te(e)}set(e,...t){0===t.length&&(t=[0]),F(t.length===this.rank,(()=>`The number of provided coordinates (${t.length}) must match the rank (${this.rank})`));const n=this.locToIndex(t);this.values[n]=e}get(...e){0===e.length&&(e=[0]);let t=0;for(const n of e){if(n<0||n>=this.shape[t]){const t=`Requested out of range element at ${e}.   Buffer shape=${this.shape}`;throw new Error(t)}t++}let n=e[e.length-1];for(let t=0;t<e.length-1;++t)n+=this.strides[t]*e[t];return this.values[n]}locToIndex(e){if(0===this.rank)return 0;if(1===this.rank)return e[0];let t=e[e.length-1];for(let n=0;n<e.length-1;++n)t+=this.strides[n]*e[n];return t}indexToLoc(e){if(0===this.rank)return[];if(1===this.rank)return[e];const t=new Array(this.shape.length);for(let n=0;n<t.length-1;++n)t[n]=Math.floor(e/this.strides[n]),e-=t[n]*this.strides[n];return t[t.length-1]=e,t}get rank(){return this.shape.length}toTensor(){return yr().makeTensor(this.values,this.shape,this.dtype)}}let yr=null,br=null,xr=null;class wr{constructor(e,t,n,s){this.kept=!1,this.isDisposedInternal=!1,this.shape=e.slice(),this.dtype=t||"float32",this.size=L(e),this.strides=te(e),this.dataId=n,this.id=s,this.rankType=this.rank<5?this.rank.toString():"higher"}get rank(){return this.shape.length}async buffer(){const e=await this.data();return br.buffer(this.shape,this.dtype,e)}bufferSync(){return br.buffer(this.shape,this.dtype,this.dataSync())}async array(){const e=await this.data();return se(this.shape,e,"complex64"===this.dtype)}arraySync(){return se(this.shape,this.dataSync(),"complex64"===this.dtype)}async data(){this.throwIfDisposed();const e=yr().read(this.dataId);if("string"===this.dtype){const t=await e;try{return t.map((e=>ar(e)))}catch(e){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}}return e}dataToGPU(e){return this.throwIfDisposed(),yr().readToGPU(this.dataId,e)}dataSync(){this.throwIfDisposed();const e=yr().readSync(this.dataId);if("string"===this.dtype)try{return e.map((e=>ar(e)))}catch(e){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}return e}async bytes(){this.throwIfDisposed();const e=await yr().read(this.dataId);return"string"===this.dtype?e:new Uint8Array(e.buffer)}dispose(){this.isDisposed||(this.kerasMask&&this.kerasMask.dispose(),yr().disposeTensor(this),this.isDisposedInternal=!0)}get isDisposed(){return this.isDisposedInternal}throwIfDisposed(){if(this.isDisposed)throw new Error("Tensor is disposed.")}print(e=!1){return br.print(this,e)}clone(){return this.throwIfDisposed(),br.clone(this)}toString(e=!1){return hr(this.dataSync(),this.shape,this.dtype,e)}cast(e){return this.throwIfDisposed(),br.cast(this,e)}variable(e=!0,t,n){return this.throwIfDisposed(),yr().makeVariable(this,e,t,n)}}function kr(){return be("Tensor",(()=>wr))}Object.defineProperty(wr,Symbol.hasInstance,{value:e=>!!e&&null!=e.data&&null!=e.dataSync&&null!=e.throwIfDisposed}),kr();class vr extends wr{constructor(e,t,n,s){super(e.shape,e.dtype,e.dataId,s),this.trainable=t,this.name=n}assign(e){if(e.dtype!==this.dtype)throw new Error(`dtype of the new value (${e.dtype}) and previous value (${this.dtype}) must match`);if(!z(e.shape,this.shape))throw new Error(`shape of the new value (${e.shape}) and previous value (${this.shape}) must match`);yr().disposeTensor(this),this.dataId=e.dataId,yr().incRef(this,null)}dispose(){yr().disposeVariable(this),this.isDisposedInternal=!0}}var Ir,Nr,Sr,Tr,$r;Object.defineProperty(vr,Symbol.hasInstance,{value:e=>e instanceof wr&&null!=e.assign&&e.assign instanceof Function}),function(e){e.R0="R0",e.R1="R1",e.R2="R2",e.R3="R3",e.R4="R4",e.R5="R5",e.R6="R6"}(Ir||(Ir={})),function(e){e.float32="float32",e.int32="int32",e.bool="int32",e.complex64="complex64"}(Nr||(Nr={})),function(e){e.float32="float32",e.int32="int32",e.bool="bool",e.complex64="complex64"}(Sr||(Sr={})),function(e){e.float32="float32",e.int32="float32",e.bool="float32",e.complex64="complex64"}(Tr||(Tr={})),function(e){e.float32="complex64",e.int32="complex64",e.bool="complex64",e.complex64="complex64"}($r||($r={}));const Er={float32:Tr,int32:Nr,bool:Sr,complex64:$r};function Cr(e,t){if("string"===e||"string"===t){if("string"===e&&"string"===t)return"string";throw new Error(`Can not upcast ${e} with ${t}`)}return Er[e][t]}function Rr(e){return Cr(e,"int32")}function Ar(e){return null!=e&&"object"==typeof e&&"texture"in e&&e.texture instanceof WebGLTexture}function _r(e){return"undefined"!=typeof GPUBuffer&&null!=e&&"object"==typeof e&&"buffer"in e&&e.buffer instanceof GPUBuffer}function Dr(e,t){if(e.dtype===t.dtype)return[e,t];const n=Cr(e.dtype,t.dtype);return[e.cast(n),t.cast(n)]}function Fr(e,t){return t.some((t=>t.id===e.id))}function Or(e){const t=[];return Mr(e,t,new Set),t}function Mr(e,t,n){if(null==e)return;if(e instanceof wr)return void t.push(e);if(s=e,!Array.isArray(s)&&"object"!=typeof s)return;var s;const r=e;for(const e in r){const s=r[e];n.has(s)||(n.add(s),Mr(s,t,n))}}function Lr(e){return null!=e.kernelName}class zr{constructor(){this.registeredVariables={},this.nextTapeNodeId=0,this.numBytes=0,this.numTensors=0,this.numStringTensors=0,this.numDataBuffers=0,this.gradientDepth=0,this.kernelDepth=0,this.scopeStack=[],this.numDataMovesStack=[],this.nextScopeId=0,this.tensorInfo=new WeakMap,this.profiling=!1,this.activeProfile={newBytes:0,newTensors:0,peakBytes:0,kernels:[],result:null,get kernelNames(){return Array.from(new Set(this.kernels.map((e=>e.name))))}}}dispose(){for(const e in this.registeredVariables)this.registeredVariables[e].dispose()}}class Br{constructor(e){this.ENV=e,this.registry={},this.registryFactory={},this.pendingBackendInitId=0,this.state=new zr}async ready(){if(null!=this.pendingBackendInit)return this.pendingBackendInit.then((()=>{}));if(null!=this.backendInstance)return;const e=this.getSortedBackends();for(let t=0;t<e.length;t++){const n=e[t];if(await this.initializeBackend(n).success)return void await this.setBackend(n)}throw new Error("Could not initialize any backends, all backend initializations failed.")}get backend(){if(null!=this.pendingBackendInit)throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);if(null==this.backendInstance){const{name:e,asyncInit:t}=this.initializeBackendsAndReturnBest();if(t)throw new Error(`The highest priority backend '${e}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);this.setBackend(e)}return this.backendInstance}backendNames(){return Object.keys(this.registryFactory)}findBackend(e){if(!(e in this.registry)){if(!(e in this.registryFactory))return null;{const{asyncInit:t}=this.initializeBackend(e);if(t)return null}}return this.registry[e]}findBackendFactory(e){return e in this.registryFactory?this.registryFactory[e].factory:null}registerBackend(e,t,n=1){return e in this.registryFactory?(Cs(`${e} backend was already registered. Reusing existing backend factory.`),!1):(this.registryFactory[e]={factory:t,priority:n},!0)}async setBackend(e){if(null==this.registryFactory[e])throw new Error(`Backend name '${e}' not found in registry`);if(this.backendName=e,null==this.registry[e]){this.backendInstance=null;const{success:t,asyncInit:n}=this.initializeBackend(e);if(!(n?await t:t))return!1}return this.backendInstance=this.registry[e],this.setupRegisteredKernels(),this.profiler=new lr(this.backendInstance),!0}setupRegisteredKernels(){Os(this.backendName).forEach((e=>{null!=e.setupFunc&&e.setupFunc(this.backendInstance)}))}disposeRegisteredKernels(e){Os(e).forEach((t=>{null!=t.disposeFunc&&t.disposeFunc(this.registry[e])}))}initializeBackend(e){const t=this.registryFactory[e];if(null==t)throw new Error(`Cannot initialize backend ${e}, no registration found.`);try{const n=t.factory();if(!n||n instanceof E||"function"!=typeof n.then)return this.registry[e]=n,{success:!0,asyncInit:!1};{const t=++this.pendingBackendInitId,s=n.then((n=>!(t<this.pendingBackendInitId||(this.registry[e]=n,this.pendingBackendInit=null,0)))).catch((n=>(t<this.pendingBackendInitId||(this.pendingBackendInit=null,Cs(`Initialization of backend ${e} failed`),Cs(n.stack||n.message)),!1)));return this.pendingBackendInit=s,{success:s,asyncInit:!0}}}catch(t){return Cs(`Initialization of backend ${e} failed`),Cs(t.stack||t.message),{success:!1,asyncInit:!1}}}removeBackend(e){if(!(e in this.registryFactory))throw new Error(`${e} backend not found in registry`);this.backendName===e&&null!=this.pendingBackendInit&&this.pendingBackendInitId++,e in this.registry&&(this.disposeRegisteredKernels(e),this.registry[e].dispose(),delete this.registry[e]),delete this.registryFactory[e],this.backendName===e&&(this.pendingBackendInit=null,this.backendName=null,this.backendInstance=null)}getSortedBackends(){if(0===Object.keys(this.registryFactory).length)throw new Error("No backend found in registry.");return Object.keys(this.registryFactory).sort(((e,t)=>this.registryFactory[t].priority-this.registryFactory[e].priority))}initializeBackendsAndReturnBest(){const e=this.getSortedBackends();for(let t=0;t<e.length;t++){const n=e[t],{success:s,asyncInit:r}=this.initializeBackend(n);if(r||s)return{name:n,asyncInit:r}}throw new Error("Could not initialize any backends, all backend initializations failed.")}moveData(e,t){const n=this.state.tensorInfo.get(t),s=n.backend,r=this.readSync(t),a=s.refCount(t);s.disposeData(t,!0),n.backend=e,e.move(t,r,n.shape,n.dtype,a),this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack[this.state.numDataMovesStack.length-1]++}tidy(e,t){let n,s=null;if(null==t){if("function"!=typeof e)throw new Error("Please provide a function to tidy()");t=e}else{if("string"!=typeof e&&!(e instanceof String))throw new Error("When calling with two arguments, the first argument to tidy() must be a string");if("function"!=typeof t)throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");s=e}return this.scopedRun((()=>this.startScope(s)),(()=>this.endScope(n)),(()=>(n=t(),n instanceof Promise&&console.error("Cannot return a Promise inside of tidy."),n)))}scopedRun(e,t,n){e();try{const e=n();return t(),e}catch(e){throw t(),e}}nextTensorId(){return Br.nextTensorId++}nextVariableId(){return Br.nextVariableId++}clone(e){const t=Wr.runKernel(Dt,{x:e}),n={x:e};return this.addTapeNode(this.state.activeScope.name,n,[t],(e=>({x:()=>{const t={x:e};return Wr.runKernel(Ve,t,{dtype:"float32"})}})),[],{}),t}runKernel(e,t,n){if(null==this.backendName&&this.backend,null==Ds(e,this.backendName))throw new Error(`Kernel '${e}' not registered for backend '${this.backendName}'`);return this.runKernelFunc({kernelName:e,inputs:t,attrs:n})}shouldCheckForMemLeaks(){return this.ENV.getBool("IS_TEST")}checkKernelForMemLeak(e,t,n){const s=this.backend.numDataIds();let r=0;n.forEach((e=>{r+="complex64"===e.dtype?3:1}));const a=this.state.numDataMovesStack[this.state.numDataMovesStack.length-1],i=s-t-r-a;if(i>0)throw new Error(`Backend '${this.backendName}' has an internal memory leak (${i} data ids) after running '${e}'`)}runKernelFunc(e){let t,n=[];const s=this.isTapeOn(),r=this.state.numBytes,a=this.state.numTensors;let i,o;this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack.push(0),null==this.backendName&&this.backend;const l=Lr(e)?e.kernelName:null!=this.state.activeScope?this.state.activeScope.name:"";if(Lr(e)){const{kernelName:t,inputs:r,attrs:a}=e;null==this.backendName&&this.backend;const l=Ds(t,this.backendName);F(null!=l,(()=>`Cannot find registered kernel '${t}' for backend '${this.backendName}'`)),i=()=>{const e=this.backend.numDataIds();o=l.kernelFunc({inputs:r,attrs:a,backend:this.backend});const i=Array.isArray(o)?o:[o];this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(t,e,i);const u=i.map((e=>null!=e.rank?e:this.makeTensorFromTensorInfo(e)));if(s){const e=this.getTensorsForGradient(t,r,u);n=this.saveTensorsForBackwardMode(e)}return u}}else{const{forwardFunc:t}=e,r=e=>{s&&(n=e.map((e=>this.keep(this.clone(e)))))};i=()=>{const e=this.backend.numDataIds();o=this.tidy((()=>t(this.backend,r)));const n=Array.isArray(o)?o:[o];return this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(l,e,n),n}}const{inputs:u,attrs:c}=e,h=Lr(e)?null:e.backwardsFunc;let p;return this.scopedRun((()=>this.state.kernelDepth++),(()=>this.state.kernelDepth--),(()=>{this.ENV.getBool("DEBUG")||this.state.profiling?(p=this.profiler.profileKernel(l,u,(()=>i())),this.ENV.getBool("DEBUG")&&this.profiler.logKernelProfile(p),t=p.outputs):t=i()})),s&&this.addTapeNode(l,u,t,h,n,c),this.state.profiling&&this.state.activeProfile.kernels.push({name:l,bytesAdded:this.state.numBytes-r,totalBytesSnapshot:this.state.numBytes,tensorsAdded:this.state.numTensors-a,totalTensorsSnapshot:this.state.numTensors,inputShapes:Object.keys(u).map((e=>null!=u[e]?u[e].shape:null)),outputShapes:t.map((e=>e.shape)),kernelTimeMs:p.timeMs,extraInfo:p.extraInfo}),Array.isArray(o)?t:t[0]}saveTensorsForBackwardMode(e){return e.map((e=>this.keep(this.clone(e))))}getTensorsForGradient(e,t,n){const s=Fs(e);if(null!=s){const e=s.inputsToSave||[],r=s.outputsToSave||[];let a;s.saveAllInputs?(F(Array.isArray(t),(()=>"saveAllInputs is true, expected inputs to be an array.")),a=Object.keys(t).map((e=>t[e]))):a=e.map((e=>t[e]));const i=n.filter(((e,t)=>r[t]));return a.concat(i)}return[]}makeTensor(e,t,n,s){if(null==e)throw new Error("Values passed to engine.makeTensor() are null");n=n||"float32",s=s||this.backend;let r=e;"string"===n&&Y(e[0])&&(r=e.map((e=>rr(e))));const a=s.write(r,t,n),i=new wr(t,n,a,this.nextTensorId());if(this.trackTensor(i,s),"string"===n){const e=this.state.tensorInfo.get(a),t=function(e){if(null==e)return 0;let t=0;return e.forEach((e=>t+=e.length)),t}(r);this.state.numBytes+=t-e.bytes,e.bytes=t}return i}makeTensorFromDataId(e,t,n,s){const r={dataId:e,shape:t,dtype:n=n||"float32"};return this.makeTensorFromTensorInfo(r,s)}makeTensorFromTensorInfo(e,t){const{dataId:n,shape:s,dtype:r}=e,a=new wr(s,r,n,this.nextTensorId());return this.trackTensor(a,t),a}makeVariable(e,t=!0,n,s){n=n||this.nextVariableId().toString(),null!=s&&s!==e.dtype&&(e=e.cast(s));const r=new vr(e,t,n,this.nextTensorId());if(null!=this.state.registeredVariables[r.name])throw new Error(`Variable with name ${r.name} was already registered`);return this.state.registeredVariables[r.name]=r,this.incRef(r,this.backend),r}trackTensor(e,t){this.state.numTensors++,"string"===e.dtype&&this.state.numStringTensors++;let n=0;"complex64"!==e.dtype&&"string"!==e.dtype&&(n=e.size*X(e.dtype)),this.state.numBytes+=n,this.state.tensorInfo.has(e.dataId)||(this.state.numDataBuffers++,this.state.tensorInfo.set(e.dataId,{backend:t||this.backend,dtype:e.dtype,shape:e.shape,bytes:n})),e instanceof vr||this.track(e)}incRef(e,t){this.trackTensor(e,t),this.backend.incRef(e.dataId)}removeDataId(e,t){this.state.tensorInfo.has(e)&&this.state.tensorInfo.get(e).backend===t&&(this.state.tensorInfo.delete(e),this.state.numDataBuffers--)}disposeTensor(e){if(!this.state.tensorInfo.has(e.dataId))return;const t=this.state.tensorInfo.get(e.dataId);if(this.state.numTensors--,"string"===e.dtype&&(this.state.numStringTensors--,this.state.numBytes-=t.bytes),"complex64"!==e.dtype&&"string"!==e.dtype){const t=e.size*X(e.dtype);this.state.numBytes-=t}t.backend.disposeData(e.dataId)&&this.removeDataId(e.dataId,t.backend)}disposeVariables(){for(const e in this.state.registeredVariables){const t=this.state.registeredVariables[e];this.disposeVariable(t)}}disposeVariable(e){this.disposeTensor(e),null!=this.state.registeredVariables[e.name]&&delete this.state.registeredVariables[e.name]}memory(){const e=this.backend.memory();return e.numTensors=this.state.numTensors,e.numDataBuffers=this.state.numDataBuffers,e.numBytes=this.state.numBytes,this.state.numStringTensors>0&&(e.unreliable=!0,null==e.reasons&&(e.reasons=[]),e.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")),e}async profile(e){this.state.profiling=!0;const t=this.state.numBytes,n=this.state.numTensors;this.state.activeProfile.kernels=[],this.state.activeProfile.result=await e(),this.state.profiling=!1,this.state.activeProfile.peakBytes=Math.max(...this.state.activeProfile.kernels.map((e=>e.totalBytesSnapshot))),this.state.activeProfile.newBytes=this.state.numBytes-t,this.state.activeProfile.newTensors=this.state.numTensors-n;for(const e of this.state.activeProfile.kernels)e.kernelTimeMs=await e.kernelTimeMs,e.extraInfo=await e.extraInfo;return this.state.activeProfile}isTapeOn(){return this.state.gradientDepth>0&&0===this.state.kernelDepth}addTapeNode(e,t,n,s,r,a){const i={id:this.state.nextTapeNodeId++,kernelName:e,inputs:t,outputs:n,saved:r},o=Fs(e);null!=o&&(s=o.gradFunc),null!=s&&(i.gradient=e=>(e=e.map(((e,t)=>{if(null==e){const e=n[t],s=ae(e.size,e.dtype);return this.makeTensor(s,e.shape,e.dtype)}return e})),s(e.length>1?e:e[0],r,a))),this.state.activeTape.push(i)}keep(e){return e.kept=!0,e}startTape(){0===this.state.gradientDepth&&(this.state.activeTape=[]),this.state.gradientDepth++}endTape(){this.state.gradientDepth--}startScope(e){const t={track:[],name:"unnamed scope",id:this.state.nextScopeId++};e&&(t.name=e),this.state.scopeStack.push(t),this.state.activeScope=t}endScope(e){const t=Or(e),n=new Set(t.map((e=>e.id)));for(let e=0;e<this.state.activeScope.track.length;e++){const t=this.state.activeScope.track[e];t.kept||n.has(t.id)||t.dispose()}const s=this.state.scopeStack.pop();this.state.activeScope=0===this.state.scopeStack.length?null:this.state.scopeStack[this.state.scopeStack.length-1],t.forEach((e=>{e.kept||e.scopeId!==s.id||this.track(e)}))}gradients(e,t,n,s=!1){if(F(t.length>0,(()=>"gradients() received an empty list of xs.")),null!=n&&"float32"!==n.dtype)throw new Error(`dy must have 'float32' dtype, but has '${n.dtype}'`);const r=this.scopedRun((()=>this.startTape()),(()=>this.endTape()),(()=>this.tidy("forward",e)));F(r instanceof wr,(()=>"The result y returned by f() must be a tensor."));const a=function(e,t,n){const s={},r={};for(let e=0;e<t.length;e++)s[t[e].id]=!0;for(let n=0;n<e.length;n++){const a=e[n],i=a.inputs;for(const e in i){const n=i[e];let o=!1;for(let e=0;e<t.length;e++)if(s[n.id]){a.outputs.forEach((e=>s[e.id]=!0)),o=!0,r[a.id]=!0;break}if(o)break}}const a={};a[n.id]=!0;const i={};for(let t=e.length-1;t>=0;t--){const n=e[t],s=n.inputs;for(let e=0;e<n.outputs.length;e++)if(a[n.outputs[e].id]){for(const e in s)a[s[e].id]=!0,i[n.id]=!0;break}}const o=[];for(let t=0;t<e.length;t++){const n=e[t];if(r[n.id]&&i[n.id]){const e={};for(const t in n.inputs){const r=n.inputs[t];s[r.id]&&(e[t]=r)}const t=Object.assign({},n);t.inputs=e,t.outputs=n.outputs,o.push(t)}}return o}(this.state.activeTape,t,r);if(!s&&0===a.length&&t.length>0)throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");return this.tidy("backward",(()=>{const e={};e[r.id]=null==n?function(e){const t=re(L(e),"float32");return Wr.makeTensor(t,e,"float32")}(r.shape):n,function(e,t,n,s){for(let r=t.length-1;r>=0;r--){const a=t[r],i=[];if(a.outputs.forEach((t=>{const n=e[t.id];null!=n?i.push(n):i.push(null)})),null==a.gradient)throw new Error(`Cannot compute gradient: gradient function not found for ${a.kernelName}.`);const o=a.gradient(i);for(const t in a.inputs){if(!(t in o))throw new Error(`Cannot backprop through input ${t}. Available gradients found: ${Object.keys(o)}.`);const r=n((()=>o[t]()));if("float32"!==r.dtype)throw new Error(`Error in gradient for op ${a.kernelName}. The gradient of input ${t} must have 'float32' dtype, but has '${r.dtype}'`);const i=a.inputs[t];if(!z(r.shape,i.shape))throw new Error(`Error in gradient for op ${a.kernelName}. The gradient of input '${t}' has shape '${r.shape}', which does not match the shape of the input '${i.shape}'`);if(null==e[i.id])e[i.id]=r;else{const t=e[i.id];e[i.id]=s(t,r),t.dispose()}}}}(e,a,(e=>this.tidy(e)),Vr);const s=t.map((t=>e[t.id]));return 0===this.state.gradientDepth&&(this.state.activeTape.forEach((e=>{for(const t of e.saved)t.dispose()})),this.state.activeTape=null),{value:r,grads:s}}))}customGrad(e){return F(Q(e),(()=>"The f passed in customGrad(f) must be a function.")),(...t)=>{let n;F(t.every((e=>e instanceof wr)),(()=>"The args passed in customGrad(f)(x1, x2,...) must all be tensors"));const s={};return t.forEach(((e,t)=>{s[t]=e})),this.runKernelFunc({forwardFunc:(s,r)=>(n=e(...t,r),F(n.value instanceof wr,(()=>"The function f passed in customGrad(f) must return an object where `obj.value` is a tensor")),F(Q(n.gradFunc),(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.")),n.value),backwardsFunc:(e,s)=>{const r=n.gradFunc(e,s),a=Array.isArray(r)?r:[r];F(a.length===t.length,(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).")),F(a.every((e=>e instanceof wr)),(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors."));const i={};return a.forEach(((e,t)=>{i[t]=()=>e})),i},inputs:s})}}readSync(e){return this.state.tensorInfo.get(e).backend.readSync(e)}read(e){return this.state.tensorInfo.get(e).backend.read(e)}readToGPU(e,t){return this.state.tensorInfo.get(e).backend.readToGPU(e,t)}async time(e){const t=sr(),n=await this.backend.time(e);return n.wallMs=sr()-t,n}track(e){return null!=this.state.activeScope&&(e.scopeId=this.state.activeScope.id,this.state.activeScope.track.push(e)),e}get registeredVariables(){return this.state.registeredVariables}reset(){this.pendingBackendInitId++,this.state.dispose(),this.ENV.reset(),this.state=new zr;for(const e in this.registry)this.disposeRegisteredKernels(e),this.registry[e].dispose(),delete this.registry[e];this.backendName=null,this.backendInstance=null,this.pendingBackendInit=null}}function Pr(){const e=ye();if(null==e._tfengine){const t=new pe(e);e._tfengine=new Br(t)}var t;return t=e._tfengine.ENV,ge=t,yr=()=>e._tfengine,e._tfengine}Br.nextTensorId=0,Br.nextVariableId=0;const Wr=Pr();function Vr(e,t){const n={a:e,b:t};return Wr.runKernel(ve,n)}function Ur(e){if(e||"undefined"!=typeof navigator&&null!=navigator){if(e||(e=navigator),"ReactNative"===e.product)return!0;const t=e.userAgent||e.vendor||("undefined"!=typeof window?window.opera:"");if(!t){const t=e;return t.userAgentData&&t.userAgentData.mobile}return/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(t)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(t.substr(0,4))}return!1}function Gr(){return"undefined"!=typeof window&&null!=window.document||"undefined"!=typeof WorkerGlobalScope}const Hr=fe();function jr(e,t){let n=e;if(ir(e))return"string"===t?[]:[e.length];if(Ar(e)){const t=e.channels||"RGBA";return[e.height,e.width*t.length]}if(_r(e))return[e.buffer.size/(null==t?4:X(t))];if(!Array.isArray(e))return[];const s=[];for(;Array.isArray(n)||ir(n)&&"string"!==t;)s.push(n.length),n=n[0];return Array.isArray(e)&&fe().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")&&Kr(e,s,[]),s}function Kr(e,t,n){if(n=n||[],!Array.isArray(e)&&!ir(e))return void F(0===t.length,(()=>`Element arr[${n.join("][")}] is a primitive, but should be an array/TypedArray of ${t[0]} elements`));F(t.length>0,(()=>`Element arr[${n.join("][")}] should be a primitive, but is an array of ${e.length} elements`)),F(e.length===t[0],(()=>`Element arr[${n.join("][")}] should have ${t[0]} elements, but has ${e.length} elements`));const s=t.slice(1);for(let t=0;t<e.length;++t)Kr(e[t],s,n.concat(t))}function qr(e,t,n,s){if("string_or_numeric"!==e){if(null==e)throw new Error("Expected dtype cannot be null.");if("numeric"!==e&&e!==t||"numeric"===e&&"string"===t)throw new Error(`Argument '${n}' passed to '${s}' must be ${e} tensor, but got ${t} tensor`)}}function Xr(e,t,n,s="numeric"){if(e instanceof kr())return qr(s,e.dtype,t,n),e;let r=Z(e);if("string"!==r&&["bool","int32","float32"].indexOf(s)>=0&&(r=s),qr(s,r,t,n),null==e||!ir(e)&&!Array.isArray(e)&&"number"!=typeof e&&"boolean"!=typeof e&&"string"!=typeof e){const s=null==e?"null":e.constructor.name;throw new Error(`Argument '${t}' passed to '${n}' must be a Tensor or TensorLike, but got '${s}'`)}const a=jr(e,r);ir(e)||Array.isArray(e)||(e=[e]);const i="string"!==r?nr(e,r):or(e,[],!0);return Wr.makeTensor(i,a,r)}function Yr(e,t,n,s="numeric"){if(!Array.isArray(e))throw new Error(`Argument ${t} passed to ${n} must be a \`Tensor[]\` or \`TensorLike[]\``);return e.map(((e,r)=>Xr(e,`${t}[${r}]`,n,s)))}function Jr(e){const t=Object.keys(e);if(1!==t.length)throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${t.length} keys.`);let n=t[0];const s=e[n];n.endsWith("_")&&(n=n.substring(0,n.length-1)),n+="__op";const r=(...e)=>{Wr.startScope(n);try{const t=s(...e);return ce(t)&&console.error("Cannot return a Promise inside of tidy."),Wr.endScope(t),t}catch(e){throw Wr.endScope(null),e}};return Object.defineProperty(r,"name",{value:n,configurable:!0}),r}Hr.registerFlag("DEBUG",(()=>!1),(e=>{e&&console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.")})),Hr.registerFlag("IS_BROWSER",(()=>Gr())),Hr.registerFlag("IS_NODE",(()=>"undefined"!=typeof process&&void 0!==process.versions&&void 0!==process.versions.node)),Hr.registerFlag("IS_CHROME",(()=>"undefined"!=typeof navigator&&null!=navigator&&null!=navigator.userAgent&&/Chrome/.test(navigator.userAgent)&&/Google Inc/.test(navigator.vendor))),Hr.registerFlag("IS_SAFARI",(()=>"undefined"!=typeof navigator&&null!=navigator&&null!=navigator.userAgent&&/Safari/.test(navigator.userAgent)&&/Apple/.test(navigator.vendor))),Hr.registerFlag("PROD",(()=>!1)),Hr.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY",(()=>Hr.getBool("DEBUG"))),Hr.registerFlag("DEPRECATION_WARNINGS_ENABLED",(()=>!0)),Hr.registerFlag("IS_TEST",(()=>!1)),Hr.registerFlag("CHECK_COMPUTATION_FOR_ERRORS",(()=>Hr.getBool("DEBUG"))),Hr.registerFlag("WRAP_TO_IMAGEBITMAP",(()=>!1)),Hr.registerFlag("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU",(()=>!1)),Hr.registerFlag("USE_SETTIMEOUTCUSTOM",(()=>!1));const Zr=Jr({complex_:function(e,t){const n=Xr(e,"real","complex"),s=Xr(t,"imag","complex");O(n.shape,s.shape,`real and imag shapes, ${n.shape} and ${s.shape}, must match in call to tf.complex().`);const r={real:n,imag:s};return Wr.runKernel(He,r)}});function Qr(e,t,n,s){if(null==s)s=Z(e);else if("complex64"===s)throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");if(_r(e)||Ar(e)){if("float32"!==s&&"int32"!==s)throw new Error(`Creating tensor from GPU data only supports 'float32'|'int32' dtype, while the dtype is ${s}.`);return Wr.backend.createTensorFromGPUData(e,t||n,s)}if(!ir(e)&&!Array.isArray(e)&&"number"!=typeof e&&"boolean"!=typeof e&&"string"!=typeof e)throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");if(null!=t){oe(t);const e=L(t),s=L(n);F(e===s,(()=>`Based on the provided shape, [${t}], the tensor should have ${e} values but has ${s}`));for(let e=0;e<n.length;++e){const s=n[e],r=e!==n.length-1||s!==L(t.slice(e));F(n[e]===t[e]||!r,(()=>`Error creating a new Tensor. Inferred shape (${n}) does not match the provided shape (${t}). `))}}return ir(e)||Array.isArray(e)||(e=[e]),t=t||n,e="string"!==s?nr(e,s):or(e,[],!0),Wr.makeTensor(e,t,s)}function ea(e,t,n){return Qr(e,t,jr(e,n),n)}const ta={float32:4,float16:2,int32:4,uint16:2,uint8:1,bool:1,complex64:8};class na{static join(e){return new na(e).slice()}constructor(e){if(this.shards=[],this.previousShardIndex=0,null==e)return;if(e instanceof Array||(e=[e]),0===(e=e.map((e=>ir(e)?e.buffer:e))).length)return;this.bufferUniformSize=e[0].byteLength;let t=0;for(let n=0;n<e.length;n++){const s=e[n];n!==e.length-1&&s.byteLength!==this.bufferUniformSize&&(this.bufferUniformSize=void 0);const r=t+s.byteLength;this.shards.push({buffer:s,start:t,end:r}),t=r}0===this.shards.length&&(this.byteLength=0),this.byteLength=this.shards[this.shards.length-1].end}slice(e=0,t=this.byteLength){if(0===this.shards.length)return new ArrayBuffer(0);if(e=isNaN(Number(e))?0:e,t=isNaN(Number(t))?0:t,e=Math.max(0,e),(t=Math.min(this.byteLength,t))<=e)return new ArrayBuffer(0);const n=this.findShardForByte(e);if(-1===n)throw new Error(`Could not find start shard for byte ${e}`);const s=new ArrayBuffer(t-e),r=new Uint8Array(s);let a=0;for(let s=n;s<this.shards.length;s++){const n=this.shards[s],i=e+a-n.start,o=a,l=Math.min(t,n.end)-n.start,u=new Uint8Array(n.buffer,i,l-i);if(r.set(u,o),a+=u.length,t<n.end)break}return s}findShardForByte(e){if(0===this.shards.length||e<0||e>=this.byteLength)return-1;if(null!=this.bufferUniformSize)return this.previousShardIndex=Math.floor(e/this.bufferUniformSize),this.previousShardIndex;function t(t){return e<t.start?-1:e>=t.end?1:0}if(0===t(this.shards[this.previousShardIndex]))return this.previousShardIndex;const n=function(e,t){let n=0,s=e.length;for(;n<=s;){const r=Math.floor((s-n)/2)+n,a=t(e[r]);if(0===a)return r;a<0?s=r:n=r+1}return-1}(this.shards,t);return-1===n?-1:(this.previousShardIndex=n,this.previousShardIndex)}}function sa(){return Wr}function ra(){return Wr.memory()}function aa(e,t){return Wr.tidy(e,t)}function ia(e){Or(e).forEach((e=>e.dispose()))}function oa(e){return Wr.keep(e)}function la(e,t,n=1){return Wr.registerBackend(e,t,n)}async function ua(e,t){const n=[],s=[],r=Array.isArray(e)?e.map((e=>e.name)):Object.keys(e);for(let a=0;a<r.length;++a){const i=r[a],o=Array.isArray(e)?e[a].tensor:e[i];if("float32"!==o.dtype&&"int32"!==o.dtype&&"bool"!==o.dtype&&"string"!==o.dtype&&"complex64"!==o.dtype)throw new Error(`Unsupported dtype in weight '${i}': ${o.dtype}`);const l={name:i,shape:o.shape,dtype:o.dtype};if("string"===o.dtype){const e=new Promise((async e=>{const t=await o.bytes(),n=t.reduce(((e,t)=>e+t.length),0)+4*t.length,s=new Uint8Array(n);let r=0;for(let e=0;e<t.length;e++){const n=t[e],a=new Uint8Array(new Uint32Array([n.length]).buffer);s.set(a,r),r+=4,s.set(n,r),r+=n.length}e(s)}));s.push(e)}else s.push(o.data());null!=t&&(l.group=t),n.push(l)}return{data:pa(await Promise.all(s)),specs:n}}function ca(e,t){const n=L(e.shape);let s;if("quantization"in e){const t=e.quantization;s=ta[t.dtype]}else{if("string"===e.dtype){let e=0;for(let s=0;s<n;s++)e+=4+new Uint32Array(t(e,e+4))[0];return e}s=ta[e.dtype]}return n*s}function ha(e,t){const n=e.name,s=e.dtype,r=e.shape,a=L(r);let i,o=0;if("quantization"in e){const r=e.quantization;if("uint8"===r.dtype||"uint16"===r.dtype){if(!("min"in r)||!("scale"in r))throw new Error(`Weight ${e.name} with quantization ${r.dtype} doesn't have corresponding metadata min and scale.`)}else{if("float16"!==r.dtype)throw new Error(`Weight ${e.name} has unknown quantization dtype ${r.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);if("float32"!==s)throw new Error(`Weight ${e.name} is quantized with ${r.dtype} which only supports weights of type float32 not ${s}.`)}const l=ta[r.dtype],u="uint8"===r.dtype?new Uint8Array(t):new Uint16Array(t);if("float32"===s)if("uint8"===r.dtype||"uint16"===r.dtype){i=new Float32Array(u.length);for(let e=0;e<u.length;e++){const t=u[e];i[e]=t*r.scale+r.min}}else{if("float16"!==r.dtype)throw new Error(`Unsupported quantization type ${r.dtype} for weight type float32.`);{const e=function(){const e=function(){const e=e=>{let t=e<<13,n=0;for(;!(8388608&t);)n-=8388608,t<<=1;return t&=-8388609,n+=947912704,t|n},t=new Uint32Array(2048);t[0]=0;for(let n=1;n<1024;n++)t[n]=e(n);for(let e=1024;e<2048;e++)t[e]=939524096+(e-1024<<13);return t}(),t=function(){const e=new Uint32Array(64);e[0]=0,e[31]=1199570944,e[32]=2147483648,e[63]=3347054592;for(let t=1;t<31;t++)e[t]=t<<23;for(let t=33;t<63;t++)e[t]=2147483648+(t-32<<23);return e}(),n=function(){const e=new Uint32Array(64);for(let t=0;t<64;t++)e[t]=1024;return e[0]=e[32]=0,e}();return s=>{const r=new ArrayBuffer(4*s.length),a=new Uint32Array(r);for(let r=0;r<s.length;r++){const i=s[r],o=e[n[i>>10]+(1023&i)]+t[i>>10];a[r]=o}return new Float32Array(r)}}();i=e(u)}}else{if("int32"!==s)throw new Error(`Unsupported dtype in weight '${n}': ${s}`);if("uint8"!==r.dtype&&"uint16"!==r.dtype)throw new Error(`Unsupported quantization type ${r.dtype} for weight type int32.`);i=new Int32Array(u.length);for(let e=0;e<u.length;e++){const t=u[e];i[e]=Math.round(t*r.scale+r.min)}}o+=a*l}else if("string"===s){const n=L(e.shape);i=[];for(let e=0;e<n;e++){const e=new Uint32Array(t.slice(o,o+4))[0];o+=4;const n=new Uint8Array(t.slice(o,o+e));i.push(n),o+=e}}else{const e=ta[s];if("float32"===s)i=new Float32Array(t);else if("int32"===s)i=new Int32Array(t);else{if("bool"!==s){if("complex64"===s){i=new Float32Array(t);const e=new Float32Array(i.length/2),n=new Float32Array(i.length/2);for(let t=0;t<e.length;t++)e[t]=i[2*t],n[t]=i[2*t+1];const s=ea(e,r,"float32"),a=ea(n,r,"float32"),o=Zr(s,a);return s.dispose(),a.dispose(),o}throw new Error(`Unsupported dtype in weight '${n}': ${s}`)}i=new Uint8Array(t)}o+=a*e}return ea(i,r,s)}function pa(e){if(null===e)throw new Error(`Invalid input value: ${JSON.stringify(e)}`);let t=0;const n=[];e.forEach((e=>{if(t+=e.byteLength,n.push(e.byteLength===e.buffer.byteLength?e:new e.constructor(e)),!(e instanceof Float32Array||e instanceof Int32Array||e instanceof Uint8Array))throw new Error(`Unsupported TypedArray subtype: ${e.constructor.name}`)}));const s=new Uint8Array(t);let r=0;return n.forEach((e=>{s.set(new Uint8Array(e.buffer),r),r+=e.byteLength})),s.buffer}xr=function(e){fe().getBool("DEPRECATION_WARNINGS_ENABLED")&&console.warn(e+" You can disable deprecation warnings with tf.disableDeprecationWarnings().")};const da="undefined"!=typeof Buffer&&("undefined"==typeof Blob||"undefined"==typeof atob||"undefined"==typeof btoa);function fa(e){return da?Buffer.byteLength(e,"utf8"):new Blob([e]).size}function ma(e,t){const n={modelTopology:e.modelTopology,format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy,weightsManifest:t};return null!=e.signature&&(n.signature=e.signature),null!=e.userDefinedMetadata&&(n.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(n.modelInitializer=e.modelInitializer),null!=e.initializerSignature&&(n.initializerSignature=e.initializerSignature),null!=e.trainingConfig&&(n.trainingConfig=e.trainingConfig),n}function ga(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("Expected JSON model topology, received ArrayBuffer.");return{dateSaved:new Date,modelTopologyType:"JSON",modelTopologyBytes:null==e.modelTopology?0:fa(JSON.stringify(e.modelTopology)),weightSpecsBytes:null==e.weightSpecs?0:fa(JSON.stringify(e.weightSpecs)),weightDataBytes:null==e.weightData?0:new na(e.weightData).byteLength}}function ya(e){const t=[];for(const n of e)t.push(...n.weights);return t}class ba{constructor(){this.saveRouters=[],this.loadRouters=[]}static getInstance(){return null==ba.instance&&(ba.instance=new ba),ba.instance}static registerSaveRouter(e){ba.getInstance().saveRouters.push(e)}static registerLoadRouter(e){ba.getInstance().loadRouters.push(e)}static getSaveHandlers(e){return ba.getHandlers(e,"save")}static getLoadHandlers(e,t){return ba.getHandlers(e,"load",t)}static getHandlers(e,t,n){const s=[];return("load"===t?ba.getInstance().loadRouters:ba.getInstance().saveRouters).forEach((t=>{const r=t(e,n);null!==r&&s.push(r)})),s}}const xa="tensorflowjs",wa="models_store",ka="model_info_store";function va(){if(!fe().getBool("IS_BROWSER"))throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");const e="undefined"==typeof window?self:window,t=e.indexedDB||e.mozIndexedDB||e.webkitIndexedDB||e.msIndexedDB||e.shimIndexedDB;if(null==t)throw new Error("The current browser does not appear to support IndexedDB.");return t}function Ia(e){const t=e.result;t.createObjectStore(wa,{keyPath:"modelPath"}),t.createObjectStore(ka,{keyPath:"modelPath"})}class Na{constructor(e){if(this.indexedDB=va(),null==e||!e)throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");this.modelPath=e}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");return this.databaseAction(this.modelPath,e)}async load(){return this.databaseAction(this.modelPath)}databaseAction(e,t){return new Promise(((e,n)=>{const s=this.indexedDB.open(xa,1);s.onupgradeneeded=()=>Ia(s),s.onsuccess=()=>{const r=s.result;if(null==t){const t=r.transaction(wa,"readonly"),s=t.objectStore(wa).get(this.modelPath);s.onsuccess=()=>{if(null==s.result)return r.close(),n(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));e(s.result.modelArtifacts)},s.onerror=e=>(r.close(),n(s.error)),t.oncomplete=()=>r.close()}else{t.weightData=na.join(t.weightData);const s=ga(t),a=r.transaction(ka,"readwrite");let i,o,l=a.objectStore(ka);try{i=l.put({modelPath:this.modelPath,modelArtifactsInfo:s})}catch(e){return n(e)}i.onsuccess=()=>{o=r.transaction(wa,"readwrite");const i=o.objectStore(wa);let u;try{u=i.put({modelPath:this.modelPath,modelArtifacts:t,modelArtifactsInfo:s})}catch(e){return n(e)}u.onsuccess=()=>e({modelArtifactsInfo:s}),u.onerror=e=>{l=a.objectStore(ka);const t=l.delete(this.modelPath);t.onsuccess=()=>(r.close(),n(u.error)),t.onerror=e=>(r.close(),n(u.error))}},i.onerror=e=>(r.close(),n(i.error)),a.oncomplete=()=>{null==o?r.close():o.oncomplete=()=>r.close()}}},s.onerror=e=>n(s.error)}))}}Na.URL_SCHEME="indexeddb://";const Sa=e=>{return fe().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(Na.URL_SCHEME)?(t=e.slice(Na.URL_SCHEME.length),new Na(t)):null;var t};ba.registerSaveRouter(Sa),ba.registerLoadRouter(Sa);class Ta{constructor(){this.indexedDB=va()}async listModels(){return new Promise(((e,t)=>{const n=this.indexedDB.open(xa,1);n.onupgradeneeded=()=>Ia(n),n.onsuccess=()=>{const s=n.result,r=s.transaction(ka,"readonly"),a=r.objectStore(ka).getAll();a.onsuccess=()=>{const t={};for(const e of a.result)t[e.modelPath]=e.modelArtifactsInfo;e(t)},a.onerror=e=>(s.close(),t(a.error)),r.oncomplete=()=>s.close()},n.onerror=e=>t(n.error)}))}async removeModel(e){var t;return e=(t=e).startsWith(Na.URL_SCHEME)?t.slice(Na.URL_SCHEME.length):t,new Promise(((t,n)=>{const s=this.indexedDB.open(xa,1);s.onupgradeneeded=()=>Ia(s),s.onsuccess=()=>{const r=s.result,a=r.transaction(ka,"readwrite"),i=a.objectStore(ka),o=i.get(e);let l;o.onsuccess=()=>{if(null==o.result)return r.close(),n(new Error(`Cannot find model with path '${e}' in IndexedDB.`));{const s=i.delete(e),a=()=>{l=r.transaction(wa,"readwrite");const s=l.objectStore(wa).delete(e);s.onsuccess=()=>t(o.result.modelArtifactsInfo),s.onerror=e=>n(o.error)};s.onsuccess=a,s.onerror=e=>(a(),r.close(),n(o.error))}},o.onerror=e=>(r.close(),n(o.error)),a.oncomplete=()=>{null==l?r.close():l.oncomplete=()=>r.close()}},s.onerror=e=>n(s.error)}))}}const $a="/",Ea="tensorflowjs_models",Ca="info",Ra="model_topology",Aa="weight_specs",_a="weight_data",Da="model_metadata";function Fa(e){return{info:[Ea,e,Ca].join($a),topology:[Ea,e,Ra].join($a),weightSpecs:[Ea,e,Aa].join($a),weightData:[Ea,e,_a].join($a),modelMetadata:[Ea,e,Da].join($a)}}function Oa(e){for(const t of Object.values(e))window.localStorage.removeItem(t)}function Ma(e){const t=e.split($a);if(t.length<3)throw new Error(`Invalid key format: ${e}`);return t.slice(1,t.length-1).join($a)}class La{constructor(e){if(!fe().getBool("IS_BROWSER")||"undefined"==typeof window||void 0===window.localStorage)throw new Error("The current environment does not support local storage.");if(this.LS=window.localStorage,null==e||!e)throw new Error("For local storage, modelPath must not be null, undefined or empty.");this.modelPath=e,this.keys=Fa(this.modelPath)}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");{const t=JSON.stringify(e.modelTopology),n=JSON.stringify(e.weightSpecs),s=ga(e),r=na.join(e.weightData);try{this.LS.setItem(this.keys.info,JSON.stringify(s)),this.LS.setItem(this.keys.topology,t),this.LS.setItem(this.keys.weightSpecs,n),this.LS.setItem(this.keys.weightData,function(e){if(da)return Buffer.from(e).toString("base64");const t=new Uint8Array(e);let n="";for(let e=0,s=t.length;e<s;e++)n+=String.fromCharCode(t[e]);return btoa(n)}(r));const a={format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy,signature:null!=e.signature?e.signature:void 0,userDefinedMetadata:null!=e.userDefinedMetadata?e.userDefinedMetadata:void 0,modelInitializer:null!=e.modelInitializer?e.modelInitializer:void 0,initializerSignature:null!=e.initializerSignature?e.initializerSignature:void 0,trainingConfig:null!=e.trainingConfig?e.trainingConfig:void 0};return this.LS.setItem(this.keys.modelMetadata,JSON.stringify(a)),{modelArtifactsInfo:s}}catch(e){throw Oa(this.keys),new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${s.modelTopologyBytes}, weightSpecsBytes=${s.weightSpecsBytes}, weightDataBytes=${s.weightDataBytes}.`)}}}async load(){const e=JSON.parse(this.LS.getItem(this.keys.info));if(null==e)throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);if("JSON"!==e.modelTopologyType)throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");const t={},n=JSON.parse(this.LS.getItem(this.keys.topology));if(null==n)throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);t.modelTopology=n;const s=JSON.parse(this.LS.getItem(this.keys.weightSpecs));if(null==s)throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);t.weightSpecs=s;const r=this.LS.getItem(this.keys.modelMetadata);if(null!=r){const e=JSON.parse(r);t.format=e.format,t.generatedBy=e.generatedBy,t.convertedBy=e.convertedBy,null!=e.signature&&(t.signature=e.signature),null!=e.userDefinedMetadata&&(t.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(t.modelInitializer=e.modelInitializer),null!=e.initializerSignature&&(t.initializerSignature=e.initializerSignature),null!=e.trainingConfig&&(t.trainingConfig=e.trainingConfig)}const a=this.LS.getItem(this.keys.weightData);if(null==a)throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);return t.weightData=function(e){if(da){const t=Buffer.from(e,"base64");return t.buffer.slice(t.byteOffset,t.byteOffset+t.byteLength)}const t=atob(e),n=new Uint8Array(t.length);for(let e=0;e<t.length;++e)n.set([t.charCodeAt(e)],e);return n.buffer}(a),t}}La.URL_SCHEME="localstorage://";const za=e=>{return fe().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(La.URL_SCHEME)?(t=e.slice(La.URL_SCHEME.length),new La(t)):null;var t};ba.registerSaveRouter(za),ba.registerLoadRouter(za);class Ba{constructor(){F(fe().getBool("IS_BROWSER"),(()=>"Current environment is not a web browser")),F("undefined"==typeof window||void 0!==window.localStorage,(()=>"Current browser does not appear to support localStorage")),this.LS=window.localStorage}async listModels(){const e={},t=Ea+$a,n=$a+Ca;for(let s=0;s<this.LS.length;++s){const r=this.LS.key(s);r.startsWith(t)&&r.endsWith(n)&&(e[Ma(r)]=JSON.parse(this.LS.getItem(r)))}return e}async removeModel(e){var t;const n=Fa(e=(t=e).startsWith(La.URL_SCHEME)?t.slice(La.URL_SCHEME.length):t);if(null==this.LS.getItem(n.info))throw new Error(`Cannot find model at path '${e}'`);const s=JSON.parse(this.LS.getItem(n.info));return Oa(n),s}}class Pa{constructor(){this.managers={}}static getInstance(){return null==Pa.instance&&(Pa.instance=new Pa),Pa.instance}static registerManager(e,t){F(null!=e,(()=>"scheme must not be undefined or null.")),e.endsWith("://")&&(e=e.slice(0,e.indexOf("://"))),F(e.length>0,(()=>"scheme must not be an empty string."));const n=Pa.getInstance();F(null==n.managers[e],(()=>`A model store manager is already registered for scheme '${e}'.`)),n.managers[e]=t}static getManager(e){const t=Pa.getInstance().managers[e];if(null==t)throw new Error(`Cannot find model manager for scheme '${e}'`);return t}static getSchemes(){return Object.keys(Pa.getInstance().managers)}}class Wa{constructor(){this.messageName="setTimeoutCustom",this.functionRefs=[],this.handledMessageCount=0,this.hasEventListener=!1}fetch(e,t){return fetch(e,t)}now(){return performance.now()}encode(e,t){if("utf-8"!==t&&"utf8"!==t)throw new Error(`Browser's encoder only supports utf-8, but got ${t}`);return null==this.textEncoder&&(this.textEncoder=new TextEncoder),this.textEncoder.encode(e)}decode(e,t){return new TextDecoder(t).decode(e)}setTimeoutCustom(e,t){"undefined"!=typeof window&&fe().getBool("USE_SETTIMEOUTCUSTOM")?(this.functionRefs.push(e),setTimeout((()=>{window.postMessage({name:this.messageName,index:this.functionRefs.length-1},"*")}),t),this.hasEventListener||(this.hasEventListener=!0,window.addEventListener("message",(e=>{e.source===window&&e.data.name===this.messageName&&(e.stopPropagation(),(0,this.functionRefs[e.data.index])(),this.handledMessageCount++,this.handledMessageCount===this.functionRefs.length&&(this.functionRefs=[],this.handledMessageCount=0))}),!0))):setTimeout(e,t)}isTypedArray(e){return Bs(e)}}if(fe().get("IS_BROWSER")){fe().setPlatform("browser",new Wa);try{Pa.registerManager(La.URL_SCHEME,new Ba)}catch(e){}try{Pa.registerManager(Na.URL_SCHEME,new Ta)}catch(e){}}let Va;function Ua(e,t="float32",n){return t=t||"float32",oe(e),new gr(e,t,n)}fe().get("IS_NODE")&&!fe().get("IS_BROWSER")&&fe().setPlatform("node",new class{constructor(){this.util=n(905),this.textEncoder=new this.util.TextEncoder}fetch(e,t){return null!=fe().global.fetch?fe().global.fetch(e,t):(null==Va&&(Va=n(78)),Va(e,t))}now(){const e=process.hrtime();return 1e3*e[0]+e[1]/1e6}encode(e,t){if("utf-8"!==t&&"utf8"!==t)throw new Error(`Node built-in encoder only supports utf-8, but got ${t}`);return this.textEncoder.encode(e)}decode(e,t){return 0===e.length?"":new this.util.TextDecoder(t).decode(e)}isTypedArray(e){return this.util.types.isFloat32Array(e)||this.util.types.isInt32Array(e)||this.util.types.isUint8Array(e)||this.util.types.isUint8ClampedArray(e)}});const Ga=Jr({cast_:function(e,t){const n=Xr(e,"x","cast");if(!function(e){return"bool"===e||"complex64"===e||"float32"===e||"int32"===e||"string"===e}(t))throw new Error(`Failed to cast to unknown dtype ${t}`);if("string"===t&&"string"!==n.dtype||"string"!==t&&"string"===n.dtype)throw new Error("Only strings can be casted to strings");const s={x:n},r={dtype:t};return Wr.runKernel(Ve,s,r)}}),Ha=Jr({clone_:function(e){const t={x:Xr(e,"x","clone","string_or_numeric")};return Wr.runKernel(Dt,t)}});Pr(),br={buffer:Ua,cast:Ga,clone:Ha,print:function(e,t=!1){console.log(e.toString(t))}};const ja=Jr({add_:function(e,t){let n=Xr(e,"a","add"),s=Xr(t,"b","add");[n,s]=Dr(n,s);const r={a:n,b:s};return Wr.runKernel(ve,r)}}),Ka=Jr({floorDiv_:function(e,t){let n=Xr(e,"a","floorDiv"),s=Xr(t,"b","floorDiv");[n,s]=Dr(n,s);const r={a:n,b:s};return Wr.runKernel($t,r)}}),qa=Jr({div_:function(e,t){let n=Xr(e,"a","div"),s=Xr(t,"b","div");if([n,s]=Dr(n,s),"int32"===n.dtype&&"int32"===s.dtype)return Ka(n,s);const r={a:n,b:s};return Wr.runKernel(ft,r,{})}}),Xa=Jr({mul_:function(e,t){let n=Xr(e,"a","mul"),s=Xr(t,"b","mul");[n,s]=Dr(n,s);const r={a:n,b:s};return Wr.runKernel(cn,r)}}),Ya=Jr({sqrt_:function(e){const t={x:Xr(e,"x","sqrt","float32")};return Wr.runKernel(Yn,t)}}),Ja=Jr({square_:function(e){const t=Xr(e,"x","square");return Wr.runKernel("Square",{x:t},{})}}),Za=Jr({zerosLike_:function(e){const t={x:Xr(e,"x","zerosLike")};return Wr.runKernel(Is,t)}});function Qa(e){return Wr.customGrad(e)}function ei(e,t){if((ir(e)&&"string"!==t||Array.isArray(e))&&"complex64"!==t)throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");if("string"===t&&ir(e)&&!(e instanceof Uint8Array))throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");return Qr(e,[],[],t)}const ti=new Map,ni=new Map;class si{getClassName(){return this.constructor.className}static fromConfig(e,t){return new e(t)}}class ri{constructor(){this.classNameMap={}}static getMap(){return null==ri.instance&&(ri.instance=new ri),ri.instance}static register(e){ri.getMap().classNameMap[e.className]=[e,e.fromConfig]}}function ai(e,t,n){F(null!=e.className,(()=>"Class being registered does not have the static className property defined.")),F("string"==typeof e.className,(()=>"className is required to be a string, but got type "+typeof e.className)),F(e.className.length>0,(()=>"Class being registered has an empty-string as its className, which is disallowed.")),void 0===t&&(t="Custom"),void 0===n&&(n=e.className);const s=t+">"+n;return ri.register(e),ti.set(s,e),ni.set(e,s),e}class ii extends si{minimize(e,t=!1,n){const{value:s,grads:r}=this.computeGradients(e,n);if(null!=n){const e=n.map((e=>({name:e.name,tensor:r[e.name]})));this.applyGradients(e)}else this.applyGradients(r);return ia(r),t?s:(s.dispose(),null)}get iterations(){return null==this.iterations_&&(this.iterations_=0),this.iterations_}incrementIterations(){this.iterations_=this.iterations+1}computeGradients(e,t){return function(e,t){F(Q(e),(()=>"The f passed in variableGrads(f) must be a function")),F(null==t||Array.isArray(t)&&t.every((e=>e instanceof vr)),(()=>"The varList passed in variableGrads(f, varList) must be an array of variables"));const n=null!=t;if(!n){t=[];for(const e in Wr.registeredVariables)t.push(Wr.registeredVariables[e])}const s=n?t.filter((e=>!e.trainable)):null,r=t.length;F((t=t.filter((e=>e.trainable))).length>0,(()=>`variableGrads() expects at least one of the input variables to be trainable, but none of the ${r} variables is trainable.`));const{value:a,grads:i}=Wr.gradients(e,t,null,!0);F(i.some((e=>null!=e)),(()=>"Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().")),F(0===a.rank,(()=>`The f passed in variableGrads(f) must return a scalar, but it returned a rank-${a.rank} tensor`));const o={};return t.forEach(((e,t)=>{null!=i[t]&&(o[e.name]=i[t])})),null!=s&&s.forEach((e=>o[e.name]=null)),{value:a,grads:o}}(e,t)}dispose(){null!=this.iterations_&&ia(this.iterations_)}async saveIterations(){return null==this.iterations_&&(this.iterations_=0),{name:"iter",tensor:ei(this.iterations_,"int32")}}async getWeights(){throw new Error("getWeights() is not implemented for this optimizer yet.")}async setWeights(e){throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`)}async extractIterations(e){return this.iterations_=(await e[0].tensor.data())[0],e.slice(1)}}Object.defineProperty(ii,Symbol.hasInstance,{value:e=>null!=e.minimize&&null!=e.computeGradients&&null!=e.applyGradients});class oi extends ii{static get className(){return"Adadelta"}constructor(e,t,n=null){super(),this.learningRate=e,this.rho=t,this.epsilon=n,this.accumulatedGrads=[],this.accumulatedUpdates=[],null==n&&(this.epsilon=Wr.backend.epsilon())}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const s=Wr.registeredVariables[t],r=!1;null==this.accumulatedGrads[n]&&(this.accumulatedGrads[n]={originalName:`${t}/accum_grad`,variable:aa((()=>Za(s).variable(r)))}),null==this.accumulatedUpdates[n]&&(this.accumulatedUpdates[n]={originalName:`${t}/accum_var`,variable:aa((()=>Za(s).variable(r)))});const a=Array.isArray(e)?e[n].tensor:e[t];if(null==a)return;const i=this.accumulatedGrads[n].variable,o=this.accumulatedUpdates[n].variable;aa((()=>{const e=ja(Xa(i,this.rho),Xa(Ja(a),1-this.rho)),t=Xa(qa(Ya(ja(o,this.epsilon)),Ya(ja(i,this.epsilon))),a),n=ja(Xa(o,this.rho),Xa(Ja(t),1-this.rho));i.assign(e),o.assign(n);const r=ja(Xa(t,-this.learningRate),s);s.assign(r)}))})),this.incrementIterations()}dispose(){null!=this.accumulatedUpdates&&(ia(this.accumulatedGrads.map((e=>e.variable))),ia(this.accumulatedUpdates.map((e=>e.variable))))}async getWeights(){const e=[...this.accumulatedGrads,...this.accumulatedUpdates];return[await this.saveIterations()].concat(e.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){const t=(e=await this.extractIterations(e)).length/2,n=!1;this.accumulatedGrads=e.slice(0,t).map((e=>({originalName:e.name,variable:e.tensor.variable(n)}))),this.accumulatedUpdates=e.slice(t,2*t).map((e=>({originalName:e.name,variable:e.tensor.variable(n)})))}getConfig(){return{learningRate:this.learningRate,rho:this.rho,epsilon:this.epsilon}}static fromConfig(e,t){return new e(t.learningRate,t.rho,t.epsilon)}}function li(e,t,n){oe(e);const s={shape:e,value:t,dtype:n=n||Z(t)};return Wr.runKernel(Nt,{},s)}class ui extends ii{static get className(){return"Adagrad"}constructor(e,t=.1){super(),this.learningRate=e,this.initialAccumulatorValue=t,this.accumulatedGrads=[]}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const s=Wr.registeredVariables[t];if(null==this.accumulatedGrads[n]){const e=!1;this.accumulatedGrads[n]={originalName:`${t}/accumulator`,variable:aa((()=>li(s.shape,this.initialAccumulatorValue).variable(e)))}}const r=Array.isArray(e)?e[n].tensor:e[t];if(null==r)return;const a=this.accumulatedGrads[n].variable;aa((()=>{const e=ja(a,Ja(r));a.assign(e);const t=ja(Xa(qa(r,Ya(ja(e,Wr.backend.epsilon()))),-this.learningRate),s);s.assign(t)}))})),this.incrementIterations()}dispose(){null!=this.accumulatedGrads&&ia(this.accumulatedGrads.map((e=>e.variable)))}async getWeights(){return[await this.saveIterations()].concat(this.accumulatedGrads.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e),this.accumulatedGrads=e.map((e=>({originalName:e.name,variable:e.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,initialAccumulatorValue:this.initialAccumulatorValue}}static fromConfig(e,t){return new e(t.learningRate,t.initialAccumulatorValue)}}const ci=Jr({pow_:function(e,t){let n=Xr(e,"base","pow"),s=Xr(t,"exp","pow");[n,s]=Dr(n,s);const r={a:n,b:s};return Wr.runKernel(wn,r)}}),hi=Jr({sub_:function(e,t){let n=Xr(e,"a","sub"),s=Xr(t,"b","sub");[n,s]=Dr(n,s);const r={a:n,b:s};return Wr.runKernel(ds,r)}});class pi extends ii{static get className(){return"Adam"}constructor(e,t,n,s=null){super(),this.learningRate=e,this.beta1=t,this.beta2=n,this.epsilon=s,this.accumulatedFirstMoment=[],this.accumulatedSecondMoment=[],aa((()=>{this.accBeta1=ei(t).variable(),this.accBeta2=ei(n).variable()})),null==s&&(this.epsilon=Wr.backend.epsilon())}applyGradients(e){const t=Array.isArray(e)?e.map((e=>e.name)):Object.keys(e);aa((()=>{const n=hi(1,this.accBeta1),s=hi(1,this.accBeta2);t.forEach(((t,r)=>{const a=Wr.registeredVariables[t],i=!1;null==this.accumulatedFirstMoment[r]&&(this.accumulatedFirstMoment[r]={originalName:`${t}/m`,variable:aa((()=>Za(a).variable(i)))}),null==this.accumulatedSecondMoment[r]&&(this.accumulatedSecondMoment[r]={originalName:`${t}/v`,variable:aa((()=>Za(a).variable(i)))});const o=Array.isArray(e)?e[r].tensor:e[t];if(null==o)return;const l=this.accumulatedFirstMoment[r].variable,u=this.accumulatedSecondMoment[r].variable,c=ja(Xa(l,this.beta1),Xa(o,1-this.beta1)),h=ja(Xa(u,this.beta2),Xa(Ja(o),1-this.beta2)),p=qa(c,n),d=qa(h,s);l.assign(c),u.assign(h);const f=ja(Xa(qa(p,ja(Ya(d),this.epsilon)),-this.learningRate),a);a.assign(f)})),this.accBeta1.assign(Xa(this.accBeta1,this.beta1)),this.accBeta2.assign(Xa(this.accBeta2,this.beta2))})),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.accBeta2.dispose(),null!=this.accumulatedFirstMoment&&ia(this.accumulatedFirstMoment.map((e=>e.variable))),null!=this.accumulatedSecondMoment&&ia(this.accumulatedSecondMoment.map((e=>e.variable)))}async getWeights(){const e=[...this.accumulatedFirstMoment,...this.accumulatedSecondMoment];return[await this.saveIterations()].concat(e.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e),aa((()=>{this.accBeta1.assign(ci(this.beta1,this.iterations_+1)),this.accBeta2.assign(ci(this.beta2,this.iterations_+1))}));const t=e.length/2,n=!1;this.accumulatedFirstMoment=e.slice(0,t).map((e=>({originalName:e.name,variable:e.tensor.variable(n)}))),this.accumulatedSecondMoment=e.slice(t,2*t).map((e=>({originalName:e.name,variable:e.tensor.variable(n)})))}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon}}static fromConfig(e,t){return new e(t.learningRate,t.beta1,t.beta2,t.epsilon)}}const di=Jr({abs_:function(e){const t=Xr(e,"x","abs");if("complex64"===t.dtype){const e={x:t};return Wr.runKernel(je,e)}{const e={x:t};return Wr.runKernel(xe,e)}}});function fi(e,t){const n=e.length,s=[];for(let r=0;r<n;r++){const a=n-1-r,i=e[a]||1;(t[t.length-1-r]||1)>1&&1===i&&s.unshift(a)}return s}function mi(e,t){const n=[];for(let s=0;s<t.length;s++){const r=e[e.length-s-1],a=t.length-s-1,i=t[a];(null==r||1===r&&i>1)&&n.unshift(a)}return n}function gi(e,t){const n=Math.max(e.length,t.length),s=new Array(n);for(let r=0;r<n;r++){let a=e[e.length-r-1];null==a&&(a=1);let i=t[t.length-r-1];if(null==i&&(i=1),1===a)s[n-r-1]=i;else if(1===i)s[n-r-1]=a;else{if(a!==i)throw Error(`Operands could not be broadcast together with shapes ${e} and ${t}.`);s[n-r-1]=a}}return s}const yi=Jr({maximum_:function(e,t){let n=Xr(e,"a","maximum"),s=Xr(t,"b","maximum");[n,s]=Dr(n,s),"bool"===n.dtype&&(n=Ga(n,"int32"),s=Ga(s,"int32")),gi(n.shape,s.shape);const r={a:n,b:s};return Wr.runKernel(Jt,r)}});class bi extends ii{static get className(){return"Adamax"}constructor(e,t,n,s=null,r=0){super(),this.learningRate=e,this.beta1=t,this.beta2=n,this.epsilon=s,this.decay=r,this.accumulatedFirstMoment=[],this.accumulatedWeightedInfNorm=[],aa((()=>{this.iteration=ei(0).variable(),this.accBeta1=ei(t).variable()})),null==s&&(this.epsilon=Wr.backend.epsilon())}applyGradients(e){const t=Array.isArray(e)?e.map((e=>e.name)):Object.keys(e);aa((()=>{const n=hi(1,this.accBeta1),s=qa(-this.learningRate,ja(Xa(this.iteration,this.decay),1));t.forEach(((t,r)=>{const a=Wr.registeredVariables[t],i=!1;null==this.accumulatedFirstMoment[r]&&(this.accumulatedFirstMoment[r]={originalName:`${t}/m`,variable:Za(a).variable(i)}),null==this.accumulatedWeightedInfNorm[r]&&(this.accumulatedWeightedInfNorm[r]={originalName:`${t}/v`,variable:Za(a).variable(i)});const o=Array.isArray(e)?e[r].tensor:e[t];if(null==o)return;const l=this.accumulatedFirstMoment[r].variable,u=this.accumulatedWeightedInfNorm[r].variable,c=ja(Xa(l,this.beta1),Xa(o,1-this.beta1)),h=Xa(u,this.beta2),p=di(o),d=yi(h,p);l.assign(c),u.assign(d);const f=ja(Xa(qa(s,n),qa(c,ja(d,this.epsilon))),a);a.assign(f)})),this.iteration.assign(ja(this.iteration,1)),this.accBeta1.assign(Xa(this.accBeta1,this.beta1))})),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.iteration.dispose(),null!=this.accumulatedFirstMoment&&ia(this.accumulatedFirstMoment.map((e=>e.variable))),null!=this.accumulatedWeightedInfNorm&&ia(this.accumulatedWeightedInfNorm.map((e=>e.variable)))}async getWeights(){throw new Error("getWeights() is not implemented for Adamax yet.")}async setWeights(e){throw new Error("setWeights() is not implemented for Adamax yet.")}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon,decay:this.decay}}static fromConfig(e,t){return new e(t.learningRate,t.beta1,t.beta2,t.epsilon,t.decay)}}class xi extends ii{static get className(){return"SGD"}constructor(e){super(),this.learningRate=e,this.setLearningRate(e)}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const s=Array.isArray(e)?e[n].tensor:e[t];if(null==s)return;const r=Wr.registeredVariables[t];aa((()=>{const e=ja(Xa(this.c,s),r);r.assign(e)}))})),this.incrementIterations()}setLearningRate(e){this.learningRate=e,null!=this.c&&this.c.dispose(),this.c=oa(ei(-e))}dispose(){this.c.dispose()}async getWeights(){return[await this.saveIterations()]}async setWeights(e){if(0!==(e=await this.extractIterations(e)).length)throw new Error("SGD optimizer does not have settable weights.")}getConfig(){return{learningRate:this.learningRate}}static fromConfig(e,t){return new e(t.learningRate)}}class wi extends xi{static get className(){return"Momentum"}constructor(e,t,n=!1){super(e),this.learningRate=e,this.momentum=t,this.useNesterov=n,this.accumulations=[],this.m=ei(this.momentum)}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const s=Wr.registeredVariables[t];if(null==this.accumulations[n]){const e=!1;this.accumulations[n]={originalName:`${t}/momentum`,variable:aa((()=>Za(s).variable(e)))}}const r=this.accumulations[n].variable,a=Array.isArray(e)?e[n].tensor:e[t];null!=a&&aa((()=>{let e;const t=ja(Xa(this.m,r),a);e=this.useNesterov?ja(Xa(this.c,ja(a,Xa(t,this.m))),s):ja(Xa(this.c,t),s),r.assign(t),s.assign(e)}))})),this.incrementIterations()}dispose(){this.m.dispose(),null!=this.accumulations&&ia(this.accumulations.map((e=>e.variable)))}setMomentum(e){this.momentum=e}async getWeights(){return[await this.saveIterations()].concat(this.accumulations.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e),this.accumulations=e.map((e=>({originalName:e.name,variable:e.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,momentum:this.momentum,useNesterov:this.useNesterov}}static fromConfig(e,t){return new e(t.learningRate,t.momentum,t.useNesterov)}}class ki extends ii{static get className(){return"RMSProp"}constructor(e,t=.9,n=0,s=null,r=!1){if(super(),this.learningRate=e,this.decay=t,this.momentum=n,this.epsilon=s,this.accumulatedMeanSquares=[],this.accumulatedMoments=[],this.accumulatedMeanGrads=[],this.centered=r,null==s&&(this.epsilon=Wr.backend.epsilon()),null==e)throw new Error("learningRate for RMSPropOptimizer must be defined.")}applyGradients(e){(Array.isArray(e)?e.map((e=>e.name)):Object.keys(e)).forEach(((t,n)=>{const s=Wr.registeredVariables[t],r=!1;null==this.accumulatedMeanSquares[n]&&(this.accumulatedMeanSquares[n]={originalName:`${t}/rms`,variable:aa((()=>Za(s).variable(r)))}),null==this.accumulatedMoments[n]&&(this.accumulatedMoments[n]={originalName:`${t}/momentum`,variable:aa((()=>Za(s).variable(r)))}),null==this.accumulatedMeanGrads[n]&&this.centered&&(this.accumulatedMeanGrads[n]={originalName:`${t}/mg`,variable:aa((()=>Za(s).variable(r)))});const a=Array.isArray(e)?e[n].tensor:e[t];if(null==a)return;const i=this.accumulatedMeanSquares[n].variable,o=this.accumulatedMoments[n].variable;aa((()=>{const e=ja(Xa(i,this.decay),Xa(Ja(a),1-this.decay));if(this.centered){const t=this.accumulatedMeanGrads[n].variable,r=ja(Xa(t,this.decay),Xa(a,1-this.decay)),l=qa(Xa(a,this.learningRate),Ya(hi(e,ja(Ja(r),this.epsilon)))),u=ja(Xa(o,this.momentum),l);i.assign(e),t.assign(r),o.assign(u);const c=hi(s,u);s.assign(c)}else{const e=ja(Xa(i,this.decay),Xa(Ja(a),1-this.decay)),t=ja(Xa(o,this.momentum),qa(Xa(a,this.learningRate),Ya(ja(e,this.epsilon))));i.assign(e),o.assign(t);const n=hi(s,t);s.assign(n)}}))})),this.incrementIterations()}dispose(){null!=this.accumulatedMeanSquares&&ia(this.accumulatedMeanSquares.map((e=>e.variable))),null!=this.accumulatedMeanGrads&&this.centered&&ia(this.accumulatedMeanGrads.map((e=>e.variable))),null!=this.accumulatedMoments&&ia(this.accumulatedMoments.map((e=>e.variable)))}async getWeights(){const e=[...this.accumulatedMeanSquares,...this.accumulatedMoments];return this.centered&&e.push(...this.accumulatedMeanGrads),[await this.saveIterations()].concat(e.map((e=>({name:e.originalName,tensor:e.variable}))))}async setWeights(e){e=await this.extractIterations(e);const t=this.centered?e.length/3:e.length/2,n=!1;this.accumulatedMeanSquares=e.slice(0,t).map((e=>({originalName:e.name,variable:e.tensor.variable(n)}))),this.accumulatedMoments=e.slice(t,2*t).map((e=>({originalName:e.name,variable:e.tensor.variable(n)}))),this.centered&&(this.accumulatedMeanGrads=e.slice(2*t,3*t).map((e=>({originalName:e.name,variable:e.tensor.variable(n)}))))}getConfig(){return{learningRate:this.learningRate,decay:this.decay,momentum:this.momentum,epsilon:this.epsilon,centered:this.centered}}static fromConfig(e,t){return new e(t.learningRate,t.decay,t.momentum,t.epsilon,t.centered)}}const vi=[oi,ui,pi,bi,wi,ki,xi];function Ii(e){return new Promise((e=>setTimeout(e))).then(e)}class Ni{constructor(e){if(!fe().getBool("IS_BROWSER"))throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");e.startsWith(Ni.URL_SCHEME)&&(e=e.slice(Ni.URL_SCHEME.length)),null!=e&&0!==e.length||(e="model"),this.modelJsonFileName=e+".json",this.weightDataFileName=e+".weights.bin"}async save(e){if("undefined"==typeof document)throw new Error("Browser downloads are not supported in this environment since `document` is not present");const t=na.join(e.weightData),n=window.URL.createObjectURL(new Blob([t],{type:"application/octet-stream"}));if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");{const t=ma(e,[{paths:["./"+this.weightDataFileName],weights:e.weightSpecs}]),s=window.URL.createObjectURL(new Blob([JSON.stringify(t)],{type:"application/json"})),r=null==this.modelJsonAnchor?document.createElement("a"):this.modelJsonAnchor;if(r.download=this.modelJsonFileName,r.href=s,await Ii((()=>r.dispatchEvent(new MouseEvent("click")))),null!=e.weightData){const e=null==this.weightDataAnchor?document.createElement("a"):this.weightDataAnchor;e.download=this.weightDataFileName,e.href=n,await Ii((()=>e.dispatchEvent(new MouseEvent("click"))))}return{modelArtifactsInfo:ga(e)}}}}function Si(e,t,n,s){!function(e){F(null!=e&&Array.isArray(e)&&e.length>0,(()=>"promises must be a none empty array"))}(e),function(e,t){F(e>=0&&e<=1,(()=>`Progress fraction must be in range [0, 1], but got startFraction ${e}`)),F(t>=0&&t<=1,(()=>`Progress fraction must be in range [0, 1], but got endFraction ${t}`)),F(t>=e,(()=>`startFraction must be no more than endFraction, but got startFraction ${e} and endFraction ${t}`))}(n=null==n?0:n,s=null==s?1:s);let r=0;return Promise.all(e.map((a=>(a.then((a=>{const i=n+ ++r/e.length*(s-n);return t(i),a})),a))))}async function Ti(e,t){null==t&&(t={});const n=null==t.fetchFunc?fe().platform.fetch:t.fetchFunc,s=e.map((e=>n(e,t.requestInit,{isBinary:!0}))),r=(null==t.onProgress?await Promise.all(s):await Si(s,t.onProgress,0,.5)).map((e=>e.arrayBuffer()));return null==t.onProgress?await Promise.all(r):await Si(r,t.onProgress,.5,1)}Ni.URL_SCHEME="downloads://",ba.registerSaveRouter((e=>fe().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(Ni.URL_SCHEME)?function(e="model"){return new Ni(e)}(e.slice(Ni.URL_SCHEME.length)):null));class $i{constructor(e,t){if(this.DEFAULT_METHOD="POST",null==t&&(t={}),this.weightPathPrefix=t.weightPathPrefix,this.weightUrlConverter=t.weightUrlConverter,null!=t.fetchFunc?(F("function"==typeof t.fetchFunc,(()=>"Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)")),this.fetch=t.fetchFunc):this.fetch=fe().platform.fetch,F(null!=e&&e.length>0,(()=>"URL path for http must not be null, undefined or empty.")),Array.isArray(e)&&F(2===e.length,(()=>`URL paths for http must have a length of 2, (actual length is ${e.length}).`)),this.path=e,null!=t.requestInit&&null!=t.requestInit.body)throw new Error("requestInit is expected to have no pre-existing body, but has one.");this.requestInit=t.requestInit||{},this.loadOptions=t}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");const t=Object.assign({method:this.DEFAULT_METHOD},this.requestInit);t.body=new FormData;const n=ma(e,[{paths:["./model.weights.bin"],weights:e.weightSpecs}]);if(t.body.append("model.json",new Blob([JSON.stringify(n)],{type:"application/json"}),"model.json"),null!=e.weightData){const n=na.join(e.weightData);t.body.append("model.weights.bin",new Blob([n],{type:"application/octet-stream"}),"model.weights.bin")}const s=await this.fetch(this.path,t);if(s.ok)return{modelArtifactsInfo:ga(e),responses:[s]};throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${s.status}.`)}async loadModelJSON(){const e=await this.fetch(this.path,this.requestInit);if(!e.ok)throw new Error(`Request to ${this.path} failed with status code ${e.status}. Please verify this URL points to the model JSON of the model to load.`);let t;try{t=await e.json()}catch(e){let t=`Failed to parse model JSON of response from ${this.path}.`;throw this.path.endsWith(".pb")?t+=" Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.":t+=" Please make sure the server is serving valid JSON for this request.",new Error(t)}const n=t.modelTopology,s=t.weightsManifest;if(null==n&&null==s)throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);return t}async load(){return this.loadOptions.streamWeights?this.loadStream():async function(e,t){let n,s;return null!=e.weightsManifest&&([n,s]=await t(e.weightsManifest)),function(e,t,n){const s={modelTopology:e.modelTopology,format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy};if(null!=e.trainingConfig&&(s.trainingConfig=e.trainingConfig),null!=e.weightsManifest){if(!t)throw new Error("modelJSON has weightsManifest but weightSpecs is null");if(!n)throw new Error("modelJSON has weightsManifest but weightData is null");s.weightSpecs=t,s.weightData=n}return null!=e.signature&&(s.signature=e.signature),null!=e.userDefinedMetadata&&(s.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(s.modelInitializer=e.modelInitializer),null!=e.initializerSignature&&(s.initializerSignature=e.initializerSignature),s}(e,n,s)}(await this.loadModelJSON(),(e=>this.loadWeights(e)))}async loadStream(){const e=await this.loadModelJSON(),t=await this.getWeightUrls(e.weightsManifest),n=ya(e.weightsManifest);return Object.assign(Object.assign({},e),{weightSpecs:n,getWeightStream:()=>function(e,t){var n;const s=null==t.fetchFunc?fe().platform.fetch:t.fetchFunc;let r,a=0;return null===(n=t.onProgress)||void 0===n||n.call(t,0),new ReadableStream({pull:async n=>{for(var i;a<e.length;){if(!r){const n=(await s(e[a],t.requestInit,{isBinary:!0})).body;r=n.getReader()}const{done:o,value:l}=await r.read();if(!o)return void n.enqueue(l);a++,r=void 0,null===(i=t.onProgress)||void 0===i||i.call(t,a/e.length)}n.close()}})}(t,this.loadOptions)})}async getWeightUrls(e){const t=Array.isArray(this.path)?this.path[1]:this.path,[n,s]=function(e){const t=e.lastIndexOf("/"),n=e.lastIndexOf("?");return[e.substring(0,t)+"/",n>t?e.substring(n):""]}(t),r=this.weightPathPrefix||n,a=[],i=[];for(const t of e)for(const e of t.paths)null!=this.weightUrlConverter?i.push(this.weightUrlConverter(e)):a.push(r+e+s);return this.weightUrlConverter&&a.push(...await Promise.all(i)),a}async loadWeights(e){const t=await this.getWeightUrls(e);return[ya(e),await Ti(t,this.loadOptions)]}}function Ei(e){return null!=e.match($i.URL_SCHEME_REGEX)}$i.URL_SCHEME_REGEX=/^https?:\/\//;const Ci=(e,t)=>{if("undefined"==typeof fetch&&(null==t||null==t.fetchFunc))return null;{let n=!0;if(n=Array.isArray(e)?e.every((e=>Ei(e))):Ei(e),n)return Ri(e,t)}return null};function Ri(e,t){return new $i(e,t)}ba.registerSaveRouter(Ci),ba.registerLoadRouter(Ci);const Ai=-2,_i=-1;function Di(e,t,n){const s=e.shape.length;F(s===t.length,(()=>`Error in slice${s}D: Length of begin ${t} must match the rank of the array (${s}).`)),F(s===n.length,(()=>`Error in slice${s}D: Length of size ${n} must match the rank of the array (${s}).`));for(let r=0;r<s;++r)F(t[r]+n[r]<=e.shape[r],(()=>`Error in slice${s}D: begin[${r}] + size[${r}] (${t[r]+n[r]}) would overflow input.shape[${r}] (${e.shape[r]})`))}function Fi(e){const t=[];let n=0;for(;e>0;)1&e&&t.push(n),e/=2,n++;return t}function Oi(e,t,n){const s=[];for(let r=0;r<e.length;r++)s[r]=Math.ceil((t[r]-e[r])/n[r]);return s}function Mi(e,t,n,s){const r=[...e];for(let e=r.length;e<s.length;e++)r.push(1);for(let e=0;e<n;e++)0===e?r[t]=1:(r.splice(t,0,1),r.pop());return r}function Li(e,t,n){return n<=e?n:n-(t-1)}function zi(e,t){const n=[];for(let s=0;s<e;s++)n.push(t+s);return n}function Bi(e,t,n,s,r,a,i,o,l){const u=e.length;let c=new Array(u),h=new Array(u),p=new Array(u);if(t.length&&n>0){const l=t[0],u=n+1;c=Pi(i,l,u,s,e),h=Wi(o,l,u,r,e),p=Mi(a,l,u,e)}else for(let t=0;t<u;t++)c[t]=Ui(i,s,a,e,t,l),h[t]=Gi(o,r,a,e,t,l),p[t]=Vi(a,t,l);return{begin:c,end:h,strides:p}}function Pi(e,t,n,s,r){const a=[...r],i=zi(n,t);for(let r=0;r<a.length;r++)if(i.indexOf(r)>-1)a[r]=0;else{const i=Li(t,n,r);let o=s[i];e&1<<i&&(o=0),a[r]=o}return a}function Wi(e,t,n,s,r){const a=[...r],i=zi(n,t);for(let r=0;r<a.length;r++)if(i.indexOf(r)>-1)a[r]=Number.MAX_SAFE_INTEGER;else{const i=Li(t,n,r);let o=s[i];e&1<<i&&(o=Number.MAX_SAFE_INTEGER),a[r]=o}for(let e=0;e<a.length;e++){const t=r[e];a[e]<0&&(a[e]+=t),a[e]=A(0,a[e],r[e])}return a}function Vi(e,t,n){let s=e[t];return(n&1<<t||null==s)&&(s=1),s}function Ui(e,t,n,s,r,a){let i=t[r];const o=n[r]||1;(e&1<<r||a&1<<r||null==i)&&(i=o>0?Number.MIN_SAFE_INTEGER:Number.MAX_SAFE_INTEGER);const l=s[r];return i<0&&(i+=l),i=A(0,i,l-1),i}function Gi(e,t,n,s,r,a){let i=t[r];const o=n[r]||1;(e&1<<r||a&1<<r||null==i)&&(i=o>0?Number.MAX_SAFE_INTEGER:Number.MIN_SAFE_INTEGER);const l=s[r];return i<0&&(i+=l),i=o>0?A(0,i,l):A(-1,i,l-1),i}function Hi(e,t,n){let s=n.length;for(let e=0;e<n.length;e++)if(n[e]>1){s=e;break}for(let r=s+1;r<n.length;r++)if(t[r]>0||n[r]!==e[r])return!1;return!0}function ji(e,t){let n=e.length>0?e[e.length-1]:1;for(let s=0;s<e.length-1;s++)n+=e[s]*t[s];return n}function Ki(e,t,n){let s;const r=e.shape.length;let a;return s="number"==typeof t?[t,...new Array(r-1).fill(0)]:t.length<r?t.concat(new Array(r-t.length).fill(0)):t.slice(),s.forEach((e=>{F(-1!==e,(()=>"slice() does not support negative begin indexing."))})),a=null==n?new Array(r).fill(-1):"number"==typeof n?[n,...new Array(r-1).fill(-1)]:n.length<r?n.concat(new Array(r-n.length).fill(-1)):n,a=a.map(((t,n)=>t>=0?t:(F(-1===t,(()=>`Negative size values should be exactly -1 but got ${t} for the slice() size at index ${n}.`)),e.shape[n]-s[n]))),[s,a]}function qi(e,t,n,s,r,a,i,o,l){let u;if(null==s?(u=new Array(t.length),u.fill(1)):u=s,null!=i&&i&i-1)throw new Error("Multiple ellipses in slice is not allowed.");let c=!1;const h={dims:u.length,numAddAxisAfterEllipsis:0,begin:t.slice(),end:n.slice(),strides:u.slice(),beginMask:r,endMask:a,ellipsisMask:i,newAxisMask:o,shrinkAxisMask:l};for(let e=0;e<h.dims;e++)c&&1<<e&o&&h.numAddAxisAfterEllipsis++,1<<e&i&&(c=!0);c||(h.ellipsisMask|=1<<h.dims,h.dims++);const p={dims:e.length,beginMask:0,endMask:0,beginValid:!1,endValid:!1};!function(e,t){t.beginMask=0,t.endMask=0,t.shrinkAxisMask=0;let n=0;t.beginValid=null!=e.begin,t.endValid=null!=e.end,t.begin=new Array(t.dims),t.end=new Array(t.dims),t.strides=new Array(t.dims),t.finalShapeGatherIndices=[],t.finalShapeGatherIndicesSparse=[],t.inputShapeGatherIndicesSparse=new Array(t.dims);for(let s=0;s<e.dims;s++)if(1<<s&e.ellipsisMask){const r=Math.min(t.dims-(e.dims-s)+1+e.numAddAxisAfterEllipsis,t.dims);for(;n<r;n++)t.begin[n]=0,t.end[n]=0,t.strides[n]=1,t.beginMask|=1<<n,t.endMask|=1<<n,t.finalShapeGatherIndices.push(n),t.finalShapeGatherIndicesSparse.push(-1),t.inputShapeGatherIndicesSparse[n]=s}else if(1<<s&e.newAxisMask)t.finalShapeGatherIndices.push(Ai),t.finalShapeGatherIndicesSparse.push(-1);else{if(n===t.begin.length)throw Error(`Index out of range using input dim ${n}; input has only ${t.dims} dims, ${t.begin.length}.`);null!=e.begin&&(t.begin[n]=e.begin[s]),null!=e.end&&(t.end[n]=e.end[s]),t.strides[n]=e.strides[s],e.beginMask&1<<s&&(t.beginMask|=1<<n),e.endMask&1<<s&&(t.endMask|=1<<n),e.shrinkAxisMask&1<<s?(t.finalShapeGatherIndices.push(_i),t.finalShapeGatherIndicesSparse.push(-1),t.shrinkAxisMask|=1<<n):(t.finalShapeGatherIndices.push(n),t.finalShapeGatherIndicesSparse.push(s)),t.inputShapeGatherIndicesSparse[n]=s,n++}}(h,p);let d=!0,f=!0,m=!0;const g=[],y=[];for(let t=0;t<e.length;++t){if(0===p.strides[t])throw Error(`strides[${t}] must be non-zero`);const n=!!(p.shrinkAxisMask&1<<t),s=e[t];if(-1===s){g.push(n?1:-1);continue}const r=[p.beginMask&1<<t,p.endMask&1<<t],a=[p.strides[t]>0?0:-1,p.strides[t]>0?s:s-1];if(n&&p.strides[t]<=0)throw Error("only stride 1 allowed on non-range indexing.");m=m&&1===p.strides[t];const i=!!(p.beginMask&1<<t&&p.endMask&1<<t);if(p.beginValid&&p.endValid){if(n){const e=p.begin[t]<0?s+p.begin[t]:p.begin[t];if(p.begin[t]=e,p.end[t]=p.begin[t]+1,e<0||e>=s)throw Error(`slice index ${p.begin[t]} of dimension ${t} out of bounds.`)}else p.begin[t]=Xi(p.begin[t],0,p.strides[t],s,r,a),p.end[t]=Xi(p.end[t],1,p.strides[t],s,r,a);const e=1===p.strides[t]&&0===p.begin[t]&&p.end[t]===s;d=d&&e,f=f&&(0===t&&1===p.strides[t]||e)}else d=d&&1===p.strides[t]&&i,f=f&&(0===t&&1===p.strides[t]||i);let o,l=!1;if(p.beginValid&&p.endValid?(o=p.end[t]-p.begin[t],l=!0):n?(o=1,l=!0):i&&s>=0&&(o=p.strides[t]<0?-s:s,l=!0),l){let e;e=0===o||o<0!=p.strides[t]<0?0:Math.trunc(o/p.strides[t])+(o%p.strides[t]!=0?1:0),g.push(e)}else g.push(-1)}for(let e=0;e<p.finalShapeGatherIndices.length;++e){const t=p.finalShapeGatherIndices[e];t>=0?y.push(g[t]):t===Ai&&y.push(1)}return{finalShapeSparse:y.filter(((e,t)=>p.finalShapeGatherIndices[t]!==Ai)),finalShape:y,isIdentity:d,sliceDim0:f,isSimpleSlice:m,begin:p.begin,end:p.end,strides:p.strides}}function Xi(e,t,n,s,r,a){if(r[t])return n>0?a[t]:a[t+1&1];{const t=e<0?s+e:e;return t<a[0]?a[0]:t>a[1]?a[1]:t}}const Yi=Jr({all_:function(e,t=null,n=!1){const s={x:Xr(e,"x","all","bool")},r={axis:t,keepDims:n};return Wr.runKernel(Ne,s,r)}}),Ji=Jr({any_:function(e,t=null,n=!1){const s={x:Xr(e,"x","any","bool")},r={axis:t,keepDims:n};return Wr.runKernel(Se,s,r)}}),Zi=Jr({argMax_:function(e,t=0){const n={x:Xr(e,"x","argMax")},s={axis:t};return Wr.runKernel(Te,n,s)}});function Qi(e,t,n,s,r="NHWC",a){return no(e,[...t,e[3]],n,a,s,null,null,po(r))}function eo(e,t,n,s,r,a,i="channelsLast"){const[o,l]=ao(t);let u;if("channelsLast"===i)u=[o,l,e[3],e[3]];else{if("channelsFirst"!==i)throw new Error(`Unknown dataFormat ${i}`);u=[o,l,e[1],e[1]]}return no(e,u,n,s,r,a,!1,i)}function to(e,t,n,s,r,a,i="NDHWC"){const[o,l,u]=io(t);let c,h;if("NDHWC"===i)h="channelsLast",c=[o,l,u,e[4],e[4]];else{if("NCDHW"!==i)throw new Error(`Unknown dataFormat ${i}`);h="channelsFirst",c=[o,l,u,e[1],e[1]]}return so(e,c,n,s,r,!1,h,a)}function no(e,t,n,s,r,a,i=!1,o="channelsLast"){let[l,u,c,h]=[-1,-1,-1,-1];if("channelsLast"===o)[l,u,c,h]=e;else{if("channelsFirst"!==o)throw new Error(`Unknown dataFormat ${o}`);[l,h,u,c]=e}const[p,d,,f]=t,[m,g]=ao(n),[y,b]=ao(s),x=oo(p,y),w=oo(d,b),{padInfo:k,outHeight:v,outWidth:I}=function(e,t,n,s,r,a,i,o,l){let u,c,h;if("number"==typeof e){u={top:e,bottom:e,left:e,right:e,type:0===e?"VALID":"NUMBER"};const r=function(e,t,n,s,r){null==s&&(s=ro(e,t,n));const a=e[1];return[lo((e[0]-t+2*s)/n+1,r),lo((a-t+2*s)/n+1,r)]}([t,n],a,s,e,o);c=r[0],h=r[1]}else if("same"===e){c=Math.ceil(t/s),h=Math.ceil(n/r);const e=Math.max(0,(c-1)*s+a-t),o=Math.max(0,(h-1)*r+i-n),l=Math.floor(e/2),p=e-l,d=Math.floor(o/2);u={top:l,bottom:p,left:d,right:o-d,type:"SAME"}}else if("valid"===e)u={top:0,bottom:0,left:0,right:0,type:"VALID"},c=Math.ceil((t-a+1)/s),h=Math.ceil((n-i+1)/r);else{if("object"!=typeof e)throw Error(`Unknown padding parameter: ${e}`);{const p="channelsLast"===l?e[1][0]:e[2][0],d="channelsLast"===l?e[1][1]:e[2][1],f="channelsLast"===l?e[2][0]:e[3][0],m="channelsLast"===l?e[2][1]:e[3][1];u={top:p,bottom:d,left:f,right:m,type:0===p&&0===d&&0===f&&0===m?"VALID":"EXPLICIT"},c=lo((t-a+p+d)/s+1,o),h=lo((n-i+f+m)/r+1,o)}}return{padInfo:u,outHeight:c,outWidth:h}}(r,u,c,m,g,x,w,a,o),N=i?f*h:f;let S;return"channelsFirst"===o?S=[l,N,v,I]:"channelsLast"===o&&(S=[l,v,I,N]),{batchSize:l,dataFormat:o,inHeight:u,inWidth:c,inChannels:h,outHeight:v,outWidth:I,outChannels:N,padInfo:k,strideHeight:m,strideWidth:g,filterHeight:p,filterWidth:d,effectiveFilterHeight:x,effectiveFilterWidth:w,dilationHeight:y,dilationWidth:b,inShape:e,outShape:S,filterShape:t}}function so(e,t,n,s,r,a=!1,i="channelsLast",o){let[l,u,c,h,p]=[-1,-1,-1,-1,-1];if("channelsLast"===i)[l,u,c,h,p]=e;else{if("channelsFirst"!==i)throw new Error(`Unknown dataFormat ${i}`);[l,p,u,c,h]=e}const[d,f,m,,g]=t,[y,b,x]=io(n),[w,k,v]=io(s),I=oo(d,w),N=oo(f,k),S=oo(m,v),{padInfo:T,outDepth:$,outHeight:E,outWidth:C}=function(e,t,n,s,r,a,i,o,l,u,c){let h,p,d,f;if("valid"===e&&(e=0),"number"==typeof e){h={top:e,bottom:e,left:e,right:e,front:e,back:e,type:0===e?"VALID":"NUMBER"};const m=function(e,t,n,s,r,a){null==r&&(r=ro(e,t[0],s[0]));const i=[0,0,0,1];for(let n=0;n<3;n++)e[n]+2*r>=t[n]&&(i[n]=lo((e[n]-t[n]+2*r)/s[n]+1,a));return i}([t,n,s,1],[o,l,u],0,[r,a,i],e,c);p=m[0],d=m[1],f=m[2]}else{if("same"!==e)throw Error(`Unknown padding parameter: ${e}`);{p=Math.ceil(t/r),d=Math.ceil(n/a),f=Math.ceil(s/i);const e=(p-1)*r+o-t,c=(d-1)*a+l-n,m=(f-1)*i+u-s,g=Math.floor(e/2),y=e-g,b=Math.floor(c/2),x=c-b,w=Math.floor(m/2);h={top:b,bottom:x,left:w,right:m-w,front:g,back:y,type:"SAME"}}}return{padInfo:h,outDepth:p,outHeight:d,outWidth:f}}(r,u,c,h,y,b,x,I,N,S,o),R=a?g*p:g;let A;return"channelsFirst"===i?A=[l,R,$,E,C]:"channelsLast"===i&&(A=[l,$,E,C,R]),{batchSize:l,dataFormat:i,inDepth:u,inHeight:c,inWidth:h,inChannels:p,outDepth:$,outHeight:E,outWidth:C,outChannels:R,padInfo:T,strideDepth:y,strideHeight:b,strideWidth:x,filterDepth:d,filterHeight:f,filterWidth:m,effectiveFilterDepth:I,effectiveFilterHeight:N,effectiveFilterWidth:S,dilationDepth:w,dilationHeight:k,dilationWidth:v,inShape:e,outShape:A,filterShape:t}}function ro(e,t,n,s=1){const r=oo(t,s);return Math.floor((e[0]*(n-1)-n+r)/2)}function ao(e){return"number"==typeof e?[e,e,e]:2===e.length?[e[0],e[1],1]:e}function io(e){return"number"==typeof e?[e,e,e]:e}function oo(e,t){return t<=1?e:e+(e-1)*(t-1)}function lo(e,t){if(!t)return Math.trunc(e);switch(t){case"round":return Math.round(e);case"ceil":return Math.ceil(e);case"floor":return Math.floor(e);default:throw new Error(`Unknown roundingMode ${t}`)}}function uo(e){const[t,n,s]=ao(e);return 1===t&&1===n&&1===s}function co(e,t){return uo(e)||uo(t)}function ho(e){return ao(e).every((e=>e>0))}function po(e){if("NHWC"===e)return"channelsLast";if("NCHW"===e)return"channelsFirst";throw new Error(`Unknown dataFormat ${e}`)}function fo(e,t,n){if(null!=n){if("string"==typeof t)throw Error(`Error in ${e}: pad must be an integer when using dimRoundingMode ${n} but got pad ${t}.`);if("number"==typeof t)F(B(t),(()=>`Error in ${e}: pad must be an integer when using dimRoundingMode ${n} but got pad ${t}.`));else{if("object"!=typeof t)throw Error(`Error in ${e}: Unknown padding parameter: ${t}`);t.forEach((t=>{t.forEach((t=>{F(B(t),(()=>`Error in ${e}: pad must be an integer when using dimRoundingMode ${n} but got pad ${t}.`))}))}))}}}const mo=Jr({reshape_:function(e,t){const n={x:Xr(e,"x","reshape","string_or_numeric")},s={shape:t};return Wr.runKernel(Rn,n,s)}}),go=Jr({avgPool_:function(e,t,n,s,r){const a=Xr(e,"x","avgPool","float32");F(co(n,1),(()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`));let i=a,o=!1;3===a.rank&&(o=!0,i=mo(a,[1,a.shape[0],a.shape[1],a.shape[2]])),F(4===i.rank,(()=>`Error in avgPool: x must be rank 4 but got rank ${i.rank}.`)),fo("avgPool",s,r);const l={x:i},u={filterSize:t,strides:n,pad:s,dimRoundingMode:r};let c=Wr.runKernel(De,l,u);return c=Ga(c,a.dtype),o?mo(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),yo=Jr({avgPool3d_:function(e,t,n,s,r,a="NDHWC"){const i=Xr(e,"x","avgPool3d","float32");let o=i,l=!1;4===i.rank&&(l=!0,o=mo(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),F(5===o.rank,(()=>`Error in avgPool3d: x must be rank 5 but got rank ${o.rank}.`)),F("NDHWC"===a,(()=>`Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${a}`)),F("number"==typeof n&&n>0||Array.isArray(n)&&n[0]>0&&n[1]>0&&n[2]>0,(()=>`Error in avgPool3d: Stride must be > 0, but got '${n}'`)),fo("avgPool3d",s,r);const u={x:o},c={filterSize:t,strides:n,pad:s,dimRoundingMode:r,dataFormat:a};let h=Wr.runKernel(Oe,u,c);return h=Ga(h,o.dtype),l?mo(h,[h.shape[1],h.shape[2],h.shape[3],h.shape[4]]):h}}),bo=Jr({batchNorm_:function(e,t,n,s,r,a){null==a&&(a=.001);const i=Xr(e,"x","batchNorm"),o=Xr(t,"mean","batchNorm"),l=Xr(n,"variance","batchNorm");let u,c;null!=r&&(u=Xr(r,"scale","batchNorm")),null!=s&&(c=Xr(s,"offset","batchNorm")),F(o.rank===l.rank,(()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),F(null==c||o.rank===c.rank,(()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),F(null==u||o.rank===u.rank,(()=>"Batch normalization gradient requires mean and scale to have equal ranks."));const h={x:function(e){let t;return t=0===e.rank||1===e.rank?mo(e,[1,1,1,e.size]):2===e.rank?mo(e,[1,1,e.shape[0],e.shape[1]]):3===e.rank?mo(e,[1,e.shape[0],e.shape[1],e.shape[2]]):e,t}(i),scale:u,offset:c,mean:o,variance:l},p={varianceEpsilon:a},d=Wr.runKernel(Et,h,p);return mo(d,i.shape)}}),xo=Jr({batchNorm2d_:function(e,t,n,s,r,a){const i=Xr(e,"x","batchNorm"),o=Xr(t,"mean","batchNorm"),l=Xr(n,"variance","batchNorm");let u,c;return null!=r&&(u=Xr(r,"scale","batchNorm")),null!=s&&(c=Xr(s,"offset","batchNorm")),F(2===i.rank,(()=>`Error in batchNorm2D: x must be rank 2 but got rank ${i.rank}.`)),F(2===o.rank||1===o.rank,(()=>`Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${o.rank}.`)),F(2===l.rank||1===l.rank,(()=>`Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${l.rank}.`)),null!=u&&F(2===u.rank||1===u.rank,(()=>`Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${u.rank}.`)),null!=c&&F(2===c.rank||1===c.rank,(()=>`Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${c.rank}.`)),bo(i,o,l,c,u,a)}}),wo=Jr({batchNorm3d_:function(e,t,n,s,r,a){const i=Xr(e,"x","batchNorm"),o=Xr(t,"mean","batchNorm"),l=Xr(n,"variance","batchNorm");let u,c;return null!=r&&(u=Xr(r,"scale","batchNorm")),null!=s&&(c=Xr(s,"offset","batchNorm")),F(3===i.rank,(()=>`Error in batchNorm3D: x must be rank 3 but got rank ${i.rank}.`)),F(3===o.rank||1===o.rank,(()=>`Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${o.rank}.`)),F(3===l.rank||1===l.rank,(()=>`Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${l.rank}.`)),null!=u&&F(3===u.rank||1===u.rank,(()=>`Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${u.rank}.`)),null!=c&&F(3===c.rank||1===c.rank,(()=>`Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${c.rank}.`)),bo(i,o,l,c,u,a)}}),ko=Jr({batchNorm4d_:function(e,t,n,s,r,a){const i=Xr(e,"x","batchNorm"),o=Xr(t,"mean","batchNorm"),l=Xr(n,"variance","batchNorm");let u,c;return null!=r&&(u=Xr(r,"scale","batchNorm")),null!=s&&(c=Xr(s,"offset","batchNorm")),F(4===i.rank,(()=>`Error in batchNorm4D: x must be rank 4 but got rank ${i.rank}.`)),F(4===o.rank||1===o.rank,(()=>`Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${o.rank}.`)),F(4===l.rank||1===l.rank,(()=>`Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${l.rank}.`)),null!=u&&F(4===u.rank||1===u.rank,(()=>`Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${u.rank}.`)),null!=c&&F(4===c.rank||1===c.rank,(()=>`Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${c.rank}.`)),bo(i,o,l,c,u,a)}}),vo=Jr({broadcastTo_:function(e,t){let n=Xr(e,"broadcastTo","x");const s=n.shape;if(oe(t),t.length<n.rank)throw new Error(`broadcastTo(): shape.length=${t.length} < input.rank=${n.rank}.`);if(t.length>n.rank){const e=n.shape.slice();for(;e.length<t.length;)e.unshift(1);n=mo(n,e)}const r=n.shape,a=Array.from(t);for(let e=t.length-1;e>=0;e--)if(r[e]===t[e])a[e]=1;else if(1!==n.shape[e])throw new Error(`broadcastTo(): [${s}] cannot be broadcast to [${t}].`);if(0===a.map(((e,t)=>e>1?t:-1)).filter((e=>e>=0)).length)return Ha(n);const i={x:n},o={reps:a};return Wr.runKernel(gs,i,o)}}),Io=Jr({clipByValue_:function(e,t,n){const s=Xr(e,"x","clipByValue");if(F(t<=n,(()=>`Error in clip: min (${t}) must be less than or equal to max (${n}).`)),t===n)return li(s.shape,t,s.dtype);const r={x:s},a={clipValueMin:t,clipValueMax:n};return Wr.runKernel(Ge,r,a)}}),No=Jr({concat_:function(e,t=0){F(e.length>=1,(()=>"Pass at least one tensor to concat"));const n=Yr(e,"tensors","concat","string_or_numeric");if("complex64"===n[0].dtype&&n.forEach((e=>{if("complex64"!==e.dtype)throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${e.dtype}. `)})),1===n.length)return Ha(n[0]);const s=n,r={axis:t};return Wr.runKernel(Ke,s,r)}}),So=Jr({concat1d_:function(e){return No(e,0)}}),To=Jr({concat2d_:function(e,t){return No(e,t)}}),$o=Jr({concat3d_:function(e,t){return No(e,t)}}),Eo=Jr({concat4d_:function(e,t){return No(e,t)}}),Co=Jr({conv2d_:function(e,t,n,s,r="NHWC",a=[1,1],i){const o=Xr(e,"x","conv2d","float32"),l=Xr(t,"filter","conv2d","float32");let u=o,c=!1;3===o.rank&&(c=!0,u=mo(o,[1,o.shape[0],o.shape[1],o.shape[2]])),F(4===u.rank,(()=>`Error in conv2d: input must be rank 4, but got rank ${u.rank}.`)),F(4===l.rank,(()=>`Error in conv2d: filter must be rank 4, but got rank ${l.rank}.`)),fo("conv2d",s,i);const h="NHWC"===r?u.shape[3]:u.shape[1];F(h===l.shape[2],(()=>`Error in conv2d: depth of input (${h}) must match input depth for filter ${l.shape[2]}.`)),F(co(n,a),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`)),F(ho(a),(()=>"Error in conv2D: Dilated rates should be larger than 0.")),F(ho(n),(()=>"Error in conv2D: Strides should be larger than 0."));const p={x:u,filter:l},d={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i},f=Wr.runKernel(qe,p,d);return c?mo(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),Ro=Jr({conv1d_:function(e,t,n,s,r="NWC",a=1,i){const o=Xr(e,"x","conv1d"),l=Xr(t,"filter","conv1d");let u=o,c=!1;2===o.rank&&(c=!0,u=mo(o,[1,o.shape[0],o.shape[1]])),F(3===u.rank,(()=>`Error in conv1d: input must be rank 3, but got rank ${u.rank}.`)),F(3===l.rank,(()=>`Error in conv1d: filter must be rank 3, but got rank ${l.rank}.`)),fo("conv1d",s,i),F(u.shape[2]===l.shape[1],(()=>`Error in conv1d: depth of input (${u.shape[2]}) must match input depth for filter ${l.shape[1]}.`)),F(co(n,a),(()=>`Error in conv1D: Either stride or dilation must be 1. Got stride ${n} and dilation '${a}'`)),F(ho(a),(()=>"Error in conv1D: Dilated rates should be larger than 0.")),F(ho(n),(()=>"Error in conv1D: Stride should be larger than 0.")),F("NWC"===r,(()=>`Error in conv1d: got dataFormat of ${r} but only NWC is currently supported.`));const h=mo(l,[1,l.shape[0],l.shape[1],l.shape[2]]),p=mo(u,[u.shape[0],1,u.shape[1],u.shape[2]]),d=Co(p,h,[1,n],s,"NHWC",[1,a],i);return mo(d,c?[d.shape[2],d.shape[3]]:[d.shape[0],d.shape[2],d.shape[3]])}}),Ao=Jr({conv2DBackpropInput_:function(e,t,n,s,r,a="NHWC",i){F(e.length===t.rank,(()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`));let o=e,l=t,u=!1;3===t.rank&&(u=!0,l=mo(t,[1,t.shape[0],t.shape[1],t.shape[2]]),o=[1,e[0],e[1],e[2]]),F(4===o.length,(()=>`Error in conv2dDerInput: inShape must be length 4, but got length ${o.length}.`)),F(4===l.rank,(()=>`Error in conv2dDerInput: dy must be rank 4, but got rank ${l.rank}`)),F(4===n.rank,(()=>`Error in conv2dDerInput: filter must be rank 4, but got rank ${n.rank}`));const c="NHWC"===a?o[3]:o[1],h="NHWC"===a?l.shape[3]:l.shape[1];F(c===n.shape[2],(()=>`Error in conv2dDerInput: depth of input (${c}) must match input depth for filter ${n.shape[2]}.`)),F(h===n.shape[3],(()=>`Error in conv2dDerInput: depth of output (${h}) must match output depth for filter ${n.shape[3]}.`)),fo("conv2dDerInput",r,i);const p={dy:l,filter:n},d={strides:s,pad:r,dataFormat:a,dimRoundingMode:i,inputShape:o},f=Wr.runKernel(Ye,p,d);return u?mo(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),_o=Jr({conv2dTranspose_:function(e,t,n,s,r,a){const i=Xr(e,"x","conv2dTranspose"),o=Xr(t,"filter","conv2dTranspose");return Ao(n,i,o,s,r,"NHWC",a)}}),Do=Jr({conv3d_:function(e,t,n,s,r="NDHWC",a=[1,1,1]){const i=Xr(e,"x","conv3d"),o=Xr(t,"filter","conv3d");let l=i,u=!1;4===i.rank&&(u=!0,l=mo(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),F(5===l.rank,(()=>`Error in conv3d: input must be rank 5, but got rank ${l.rank}.`)),F(5===o.rank,(()=>`Error in conv3d: filter must be rank 5, but got rank ${o.rank}.`)),F(l.shape[4]===o.shape[3],(()=>`Error in conv3d: depth of input (${l.shape[4]}) must match input depth for filter ${o.shape[3]}.`)),F(co(n,a),(()=>`Error in conv3D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`)),F("NDHWC"===r,(()=>`Error in conv3d: got dataFormat of ${r} but only NDHWC is currently supported.`)),F(ho(a),(()=>"Error in conv3D: Dilated rates should be larger than 0.")),F(ho(n),(()=>"Error in conv3D: Strides should be larger than 0."));const c={x:l,filter:o},h={strides:n,pad:s,dataFormat:r,dilations:a},p=Wr.runKernel(Je,c,h);return u?mo(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}}),Fo=Jr({conv3DBackpropInput_:function(e,t,n,s,r){F(e.length===t.rank,(()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`));let a=e,i=t,o=!1;4===t.rank&&(o=!0,i=mo(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]]),a=[1,e[0],e[1],e[2],e[3]]);const l=a[4],u=i.shape[4];F(5===a.length,(()=>`Error in conv3dDerInput: inShape must be length 5, but got length ${a.length}.`)),F(5===i.rank,(()=>`Error in conv3dDerInput: dy must be rank 5, but got rank ${i.rank}`)),F(5===n.rank,(()=>`Error in conv3dDerInput: filter must be rank 5, but got rank ${n.rank}`)),F(l===n.shape[3],(()=>`Error in conv3dDerInput: depth of input (${l}) must match input depth for filter ${n.shape[3]}.`)),F(u===n.shape[4],(()=>`Error in conv3dDerInput: depth of output (${u}) must match output depth for filter ${n.shape[4]}.`));const c={dy:i,filter:n},h={pad:r,strides:s,inputShape:a},p=Wr.runKernel(Qe,c,h);return o?mo(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}}),Oo=Jr({conv3dTranspose_:function(e,t,n,s,r){const a=Xr(e,"x","conv3dTranspose"),i=Xr(t,"filter","conv3dTranspose");return Fo(n,a,i,s,r)}}),Mo=Jr({denseBincount_:function(e,t,n,s=!1){const r=Xr(e,"x","denseBincount"),a=Xr(t,"weights","denseBincount");F("int32"===r.dtype,(()=>`Error in denseBincount: input dtype must be int32, but got ${r.dtype}`)),F(r.rank<=2,(()=>`Error in denseBincount: input must be at most rank 2, but got rank ${r.rank}.`)),F(n>=0,(()=>`size must be non-negative, but got ${n}.`)),F(a.size===r.size||0===a.size,(()=>`Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${r.shape}, weights shape: ${a.shape}.`));const i={x:r,weights:a},o={size:n,binaryOutput:s};return Wr.runKernel(at,i,o)}}),Lo=Jr({depthwiseConv2d_:function(e,t,n,s,r="NHWC",a=[1,1],i){const o=Xr(e,"x","depthwiseConv2d","float32"),l=Xr(t,"filter","depthwiseConv2d","float32");let u=o,c=!1;3===o.rank&&(c=!0,u=mo(o,[1,o.shape[0],o.shape[1],o.shape[2]])),F(4===u.rank,(()=>`Error in depthwiseConv2d: input must be rank 4, but got rank ${u.rank}.`)),F(4===l.rank,(()=>`Error in depthwiseConv2d: filter must be rank 4, but got rank ${l.rank}.`));const h="NHWC"===r?u.shape[3]:u.shape[1];F(h===l.shape[2],(()=>`Error in depthwiseConv2d: number of input channels (${h}) must match the inChannels dimension in filter ${l.shape[2]}.`)),fo("depthwiseConv2d",s,i);const p={x:u,filter:l},d={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i},f=Wr.runKernel(ot,p,d);return c?mo(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),zo=Jr({elu_:function(e){const t={x:Xr(e,"x","elu","float32")};return Wr.runKernel(gt,t)}}),Bo=Jr({equal_:function(e,t){let n=Xr(e,"a","equal","string_or_numeric"),s=Xr(t,"b","equal","string_or_numeric");[n,s]=Dr(n,s),gi(n.shape,s.shape);const r={a:n,b:s};return Wr.runKernel(xt,r)}}),Po=Jr({erf_:function(e){let t=Xr(e,"x","erf");F("int32"===t.dtype||"float32"===t.dtype,(()=>"Input dtype must be `int32` or `float32`.")),"int32"===t.dtype&&(t=Ga(t,"float32"));const n={x:t};return Wr.runKernel(bt,n)}}),Wo=Jr({exp_:function(e){const t={x:Xr(e,"x","exp")};return Wr.runKernel(wt,t)}}),Vo=Jr({expandDims_:function(e,t=0){const n=Xr(e,"x","expandDims","string_or_numeric");F(t<=n.rank,(()=>"Axis must be <= rank of the tensor"));const s={input:n},r={dim:t};return Wr.runKernel(kt,s,r)}}),Uo=Jr({tile_:function(e,t){const n=Xr(e,"x","tile","string_or_numeric");F(n.rank===t.length,(()=>`Error in transpose: rank of input ${n.rank} must match length of reps ${t}.`));const s={x:n},r={reps:t};return Wr.runKernel(gs,s,r)}}),Go=Jr({eye_:function(e,t,n,s="float32"){null==t&&(t=e);const r=Ua([e,t],s),a=e<=t?e:t;for(let e=0;e<a;++e)r.set(1,e,e);const i=mo(r.toTensor(),[e,t]);if(null==n)return i;if(1===n.length)return Uo(Vo(i,0),[n[0],1,1]);if(2===n.length)return Uo(Vo(Vo(i,0),0),[n[0],n[1],1,1]);if(3===n.length)return Uo(Vo(Vo(Vo(i,0),0),0),[n[0],n[1],n[2],1,1]);throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${n.length}D.`)}}),Ho=Jr({floor_:function(e){const t={x:Xr(e,"x","floor","float32")};return Wr.runKernel(Tt,t)}}),jo=Jr({gather_:function(e,t,n=0,s=0){const r={x:Xr(e,"x","gather"),indices:Xr(t,"indices","gather","int32")},a={axis:n,batchDims:s};return Wr.runKernel(Ct,r,a)}}),Ko=Jr({greater_:function(e,t){let n=Xr(e,"a","greater","string_or_numeric"),s=Xr(t,"b","greater","string_or_numeric");[n,s]=Dr(n,s),gi(n.shape,s.shape);const r={a:n,b:s};return Wr.runKernel(At,r)}}),qo=Jr({greaterEqual_:function(e,t){let n=Xr(e,"a","greaterEqual","string_or_numeric"),s=Xr(t,"b","greaterEqual","string_or_numeric");[n,s]=Dr(n,s),gi(n.shape,s.shape);const r={a:n,b:s};return Wr.runKernel(_t,r)}}),Xo=Jr({leakyRelu_:function(e,t=.2){const n={x:Xr(e,"x","leakyRelu")},s={alpha:t};return Wr.runKernel(Bt,n,s)}}),Yo=Jr({log_:function(e){const t={x:Xr(e,"x","log","float32")};return Wr.runKernel(Ut,t)}}),Jo=Jr({log1p_:function(e){const t={x:Xr(e,"x","log1p")};return Wr.runKernel(Gt,t)}}),Zo=Jr({max_:function(e,t=null,n=!1){const s={x:Xr(e,"x","max")},r={reductionIndices:t,keepDims:n};return Wr.runKernel(Yt,s,r)}}),Qo=Jr({sum_:function(e,t=null,n=!1){let s=Xr(e,"x","sum");"bool"===s.dtype&&(s=Ga(s,"int32"));const r={x:s},a={axis:t,keepDims:n};return Wr.runKernel(Jn,r,a)}}),el=Jr({logSoftmax_:function(e,t=-1){const n=Xr(e,"logits","logSoftmax");if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and axis was ${t}`);const s=Qa(((e,n)=>{const s=Zo(e,t,!0),r=hi(e,s),a=hi(Ga(r,"float32"),Yo(Qo(Wo(r),t,!0)));return n([a]),{value:a,gradFunc:(e,n)=>{const[s]=n,r=Wo(s);return hi(e,Xa(Qo(e,t,!0),r))}}}));return s(n)}});function tl(e,t){for(let n=0;n<e.length;++n)if(e[e.length-n-1]!==t-1-n)return!1;return!0}function nl(e,t,n){const s=e.length+t.length,r=[];let a=0,i=0;for(let o=0;o<s;o++)-1===n.indexOf(o)?r.push(e[a++]):r.push(t[i++]);return r}function sl(e,t){const n=[],s=e.length;for(let r=0;r<s;r++)-1===t.indexOf(r)&&n.push(e[r]);return[n,t.map((t=>e[t]))]}function rl(e,t){return nl(e,t.map((e=>1)),t)}function al(e,t,n){F(tl(t,n),(()=>`${e} supports only inner-most axes for now. Got axes ${t} and rank-${n} input.`))}function il(e,t){if(tl(e,t))return null;const n=[];for(let s=0;s<t;++s)-1===e.indexOf(s)&&n.push(s);return e.forEach((e=>n.push(e))),n}function ol(e){return e.map(((e,t)=>[t,e])).sort(((e,t)=>e[1]-t[1])).map((e=>e[0]))}function ll(e,t){const n=[];for(let s=t-e;s<t;++s)n.push(s);return n}const ul=Jr({logSumExp_:function(e,t=null,n=!1){const s=Xr(e,"x","logSumExp"),r=G(t,s.shape),a=Zo(s,r,!0),i=hi(s,a),o=Wo(i),l=Qo(o,r),u=Yo(l),c=ja(mo(a,u.shape),u);if(n){const e=rl(c.shape,r);return mo(c,e)}return c}}),cl=Jr({logicalAnd_:function(e,t){const n=Xr(e,"a","logicalAnd","bool"),s=Xr(t,"b","logicalAnd","bool");gi(n.shape,s.shape);const r={a:n,b:s};return Wr.runKernel(Ht,r)}}),hl=Jr({matMul_:function(e,t,n=!1,s=!1){let r=Xr(e,"a","matMul"),a=Xr(t,"b","matMul");[r,a]=Dr(r,a);const i={a:r,b:a},o={transposeA:n,transposeB:s};return Wr.runKernel(Le,i,o)}}),pl=Jr({maxPool_:function(e,t,n,s,r){const a=Xr(e,"x","maxPool");let i=a,o=!1;3===a.rank&&(o=!0,i=mo(a,[1,a.shape[0],a.shape[1],a.shape[2]])),F(4===i.rank,(()=>`Error in maxPool: input must be rank 4 but got rank ${i.rank}.`)),F(co(n,1),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`)),fo("maxPool",s,r);const l={x:i},u={filterSize:t,strides:n,pad:s,dimRoundingMode:r},c=Wr.runKernel(Zt,l,u);return o?mo(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),dl=Jr({maxPool3d_:function(e,t=[1,1,1],n,s,r,a="NDHWC"){const i=Xr(e,"x","maxPool3d");let o=i,l=!1;4===i.rank&&(l=!0,o=mo(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),F(5===o.rank,(()=>`Error in maxPool3d: x must be rank 5 but got rank ${o.rank}.`)),F("NDHWC"===a,(()=>`Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${a}`)),fo("maxPool3d",s,r);const u={x:o},c={filterSize:t,strides:n,pad:s,dimRoundingMode:r,dataFormat:a},h=Wr.runKernel(en,u,c);return l?mo(h,[h.shape[1],h.shape[2],h.shape[3],h.shape[4]]):h}}),fl=Jr({mean_:function(e,t=null,n=!1){const s={x:Xr(e,"x","mean")},r={axis:t,keepDims:n};return Wr.runKernel(sn,s,r)}}),ml=Jr({min_:function(e,t=null,n=!1){const s={x:Xr(e,"x","min")},r={axis:t,keepDims:n};return Wr.runKernel(rn,s,r)}}),gl=Jr({minimum_:function(e,t){let n=Xr(e,"a","minimum"),s=Xr(t,"b","minimum");[n,s]=Dr(n,s),"bool"===n.dtype&&(n=Ga(n,"int32"),s=Ga(s,"int32")),gi(n.shape,s.shape);const r={a:n,b:s};return Wr.runKernel(an,r)}}),yl=Jr({moments_:function(e,t=null,n=!1){const s=G(t,(e=Xr(e,"x","moments")).shape),r=fl(e,s,n);let a=r.shape;n||(a=rl(r.shape,s));const i=Ja(hi(Ga(e,"float32"),mo(r,a)));return{mean:r,variance:fl(i,s,n)}}}),bl=Jr({neg_:function(e){const t={x:Xr(e,"x","neg")};return Wr.runKernel(hn,t)}}),xl=Jr({notEqual_:function(e,t){let n=Xr(e,"a","notEqual","string_or_numeric"),s=Xr(t,"b","notEqual","string_or_numeric");[n,s]=Dr(n,s),gi(n.shape,s.shape);const r={a:n,b:s};return Wr.runKernel(pn,r)}}),wl=Jr({oneHot_:function(e,t,n=1,s=0,r="int32"){if(t<2)throw new Error(`Error in oneHot: depth must be >=2, but it is ${t}`);const a={indices:Xr(e,"indices","oneHot","int32")},i={dtype:r,depth:t,onValue:n,offValue:s};return Wr.runKernel(yn,a,i)}});function kl(e,t="float32"){if(oe(e),"complex64"===t){const t=kl(e,"float32"),n=kl(e,"float32");return Zr(t,n)}const n=ae(L(e),t);return Wr.makeTensor(n,e,t)}function vl(e,t="float32"){if(oe(e),"complex64"===t){const t=vl(e,"float32"),n=kl(e,"float32");return Zr(t,n)}const n=re(L(e),t);return Wr.makeTensor(n,e,t)}const Il=Jr({onesLike_:function(e){const t={x:Xr(e,"x","onesLike")};return Wr.runKernel(gn,t)}}),Nl=Jr({pad_:function(e,t,n=0){const s=Xr(e,"x","pad");if(0===s.rank)throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");const r={paddings:t,constantValue:n},a={x:s};return Wr.runKernel(xn,a,r)}}),Sl=Jr({prelu_:function(e,t){const n={x:Xr(e,"x","prelu"),alpha:Xr(t,"alpha","prelu")};return Wr.runKernel(kn,n)}});var Tl=n(391);class $l{constructor(e,t,n,s,r){this.mean=e,this.stdDev=t,this.dtype=n,this.nextVal=NaN,this.truncated=s,this.truncated&&(this.upper=this.mean+2*this.stdDev,this.lower=this.mean-2*this.stdDev);const a=r||Math.random();this.random=Tl.alea(a.toString())}nextValue(){if(!isNaN(this.nextVal)){const e=this.nextVal;return this.nextVal=NaN,e}let e,t,n=!1;for(;!n;){let s,r,a;do{s=2*this.random()-1,r=2*this.random()-1,a=s*s+r*r}while(a>=1||0===a);const i=Math.sqrt(-2*Math.log(a)/a);e=this.mean+this.stdDev*s*i,t=this.mean+this.stdDev*r*i,this.truncated&&!this.isValidTruncated(e)||(n=!0)}return this.truncated&&!this.isValidTruncated(t)||(this.nextVal=this.convertValue(t)),this.convertValue(e)}convertValue(e){return null==this.dtype||"float32"===this.dtype?e:Math.round(e)}isValidTruncated(e){return e<=this.upper&&e>=this.lower}}class El{constructor(e=0,t=1,n,s){if(this.canReturnFloat=()=>null==this.dtype||"float32"===this.dtype,this.min=e,this.range=t-e,this.dtype=n,null==s&&(s=Math.random()),"number"==typeof s&&(s=s.toString()),!this.canReturnFloat()&&this.range<=1)throw new Error(`The difference between ${e} - ${t} <= 1 and dtype is not float`);this.random=Tl.alea(s)}convertValue(e){return this.canReturnFloat()?e:Math.round(e)}nextValue(){return this.convertValue(this.min+this.range*this.random())}}const Cl=Jr({randomNormal_:function(e,t=0,n=1,s,r){if(oe(e),null!=s&&"bool"===s)throw new Error(`Unsupported data type ${s}`);const a=new $l(t,n,s,!1,r),i=Ua(e,s);for(let e=0;e<i.values.length;e++)i.values[e]=a.nextValue();return i.toTensor()}}),Rl=Jr({randomUniform_:function(e,t=0,n=1,s="float32",r){oe(e);const a=Ua(e,s),i=new El(t,n,null,r);for(let e=0;e<a.values.length;e++)a.values[e]=i.nextValue();return a.toTensor()}});function Al(e,t,n=1,s="float32"){if(0===n)throw new Error("Cannot have a step of zero");const r={start:e,stop:t,step:n,dtype:s};return Wr.runKernel(Tn,{},r)}const _l=Jr({relu_:function(e){const t={x:Xr(e,"x","relu")};return Wr.runKernel(Cn,t)}}),Dl=Jr({reverse_:function(e,t){const n={x:Xr(e,"x","reverse")},s={dims:t};return Wr.runKernel(Mn,n,s)}}),Fl=Jr({selu_:function(e){const t={x:Xr(e,"x","selu")};return Wr.runKernel(Un,t)}}),Ol=Jr({separableConv2d_:function(e,t,n,s,r,a=[1,1],i="NHWC"){const o=Xr(e,"x","separableConv2d"),l=Xr(t,"depthwiseFilter","separableConv2d"),u=Xr(n,"pointwiseFilter","separableConv2d");let c=o,h=!1;if(3===o.rank&&(h=!0,c=mo(o,[1,o.shape[0],o.shape[1],o.shape[2]])),"NCHW"===i)throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");F(4===c.rank,(()=>`Error in separableConv2d: input must be rank 4, but got rank ${c.rank}.`)),F(4===l.rank,(()=>`Error in separableConv2d: depthwise filter must be rank 4, but got rank ${l.rank}.`)),F(4===u.rank,(()=>`Error in separableConv2d: pointwise filter must be rank 4, but got rank ${l.rank}.`)),F(1===u.shape[0],(()=>`Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${u.shape[0]}.`)),F(1===u.shape[1],(()=>`Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${u.shape[1]}.`));const p=l.shape[2],d=l.shape[3];F(u.shape[2]===p*d,(()=>`Error in separableConv2d: the third dimension of pointwise filter must be ${p*d}, but got ${u.shape[2]}.`));const f=Lo(c,l,s,r,i,a),m=Co(f,u,1,"valid",i);return h?mo(m,[m.shape[1],m.shape[2],m.shape[3]]):m}}),Ml=Jr({sigmoid_:function(e){const t={x:Xr(e,"x","sigmoid","float32")};return Wr.runKernel(qn,t)}}),Ll=Jr({slice_:function(e,t,n){const s=Xr(e,"x","slice","string_or_numeric");if(0===s.rank)throw new Error("Slicing scalar is not possible");const r={x:s},a={begin:t,size:n};return Wr.runKernel(Gn,r,a)}}),zl=Jr({slice1d_:function(e,t,n){const s=Xr(e,"x","slice1d");return F(1===s.rank,(()=>`slice1d expects a rank-1 tensor, but got a rank-${s.rank} tensor`)),Ll(s,[t],[n])}}),Bl=Jr({slice2d_:function(e,t,n){const s=Xr(e,"x","slice2d");return F(2===s.rank,(()=>`slice2d expects a rank-2 tensor, but got a rank-${s.rank} tensor`)),Ll(s,t,n)}}),Pl=Jr({slice3d_:function(e,t,n){const s=Xr(e,"x","slice3d");return F(3===s.rank,(()=>`slice3d expects a rank-3 tensor, but got a rank-${s.rank} tensor`)),Ll(s,t,n)}}),Wl=Jr({slice4d_:function(e,t,n){const s=Xr(e,"x","slice4d");return F(4===s.rank,(()=>`slice4d expects a rank-4 tensor, but got a rank-${s.rank} tensor`)),Ll(s,t,n)}}),Vl=Jr({softmax_:function(e,t=-1){const n=Xr(e,"logits","softmax","float32");if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and dim was ${t}`);const s={logits:n},r={dim:t};return Wr.runKernel(es,s,r)}}),Ul=Jr({softplus_:function(e){const t={x:Xr(e,"x","softplus")};return Wr.runKernel(Xn,t)}}),Gl=Jr({split_:function(e,t,n=0){const s={x:Xr(e,"x","split")},r={numOrSizeSplits:t,axis:n};return Wr.runKernel(Qn,s,r)}}),Hl=Jr({squeeze_:function(e,t){const n=Xr(e,"x","squeeze","string_or_numeric");return mo(n,H(n.shape,t).newShape)}}),jl=Jr({stack_:function(e,t=0){const n=Yr(e,"tensors","stack","string_or_numeric");F(n.length>=1,(()=>"Pass at least one tensor to tf.stack")),n.length>0&&F(t<=n[0].rank,(()=>"Axis must be <= rank of the tensor"));const s=n,r={axis:t};return Wr.runKernel(bn,s,r)}}),Kl=Jr({tanh_:function(e){const t={x:Xr(e,"x","tanh","float32")};return Wr.runKernel(ms,t)}});function ql(e,t){M(e);const n=jr(e,t);if(1!==n.length)throw new Error("tensor1d() requires values to be a flat/TypedArray");return Qr(e,null,n,t)}function Xl(e,t,n){if(M(e),null!=t&&2!==t.length)throw new Error("tensor2d() requires shape to have two numbers");const s=jr(e,n);if(2!==s.length&&1!==s.length)throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");if(1===s.length&&null==t)throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");return Qr(e,t,s,n)}const Yl=Jr({truncatedNormal_:function(e,t=0,n=1,s,r){if(oe(e),null!=s&&"bool"===s)throw new Error("Unsupported data type $ { dtype }");const a=new $l(t,n,s,!0,r),i=Ua(e,s);for(let e=0;e<i.values.length;e++)i.values[e]=a.nextValue();return i.toTensor()}}),Jl=Jr({unstack_:function(e,t=0){const n=Xr(e,"x","unstack","string_or_numeric");F(t>=-n.shape.length&&t<n.shape.length,(()=>`Axis = ${t} is not in [-${n.shape.length}, ${n.shape.length})`));const s={value:n},r={axis:t};return Wr.runKernel(ks,s,r)}}),Zl=Jr({where_:function(e,t,n){const s=Xr(t,"a","where"),r=Xr(n,"b","where"),a=Xr(e,"condition","where","bool"),i=gi(gi(a.shape,s.shape),r.shape),o={condition:vo(a,i),t:vo(s,i),e:vo(r,i)};return Wr.runKernel(Vn,o)}}),Ql=Jr({imag_:function(e){const t={input:Xr(e,"input","imag")};return Wr.runKernel(Ot,t)}}),eu=Jr({real_:function(e){const t={input:Xr(e,"input","real")};return Wr.runKernel($n,t)}}),tu=Jr({transpose_:function(e,t,n){const s=Xr(e,"x","transpose");if(null==t&&(t=s.shape.map(((e,t)=>t)).reverse()),F(s.rank===t.length,(()=>`Error in transpose: rank of input ${s.rank} must match length of perm ${t}.`)),t.forEach((e=>{F(e>=0&&e<s.rank,(()=>"All entries in 'perm' must be between 0 and "+(s.rank-1)+` but got ${t}`))})),s.rank<=1)return s.clone();const r={x:s},a={perm:t};return"complex64"===s.dtype?aa((()=>{let e=eu(s),t=Ql(s);return e=Wr.runKernel(xs,{x:e},a),t=Wr.runKernel(xs,{x:t},a),n&&(t=bl(t)),Zr(e,t)})):Wr.runKernel(xs,r,a)}}),nu=Jr({dropout_:function(e,t,n,s){const r=Xr(e,"x","dropout");if(F("float32"===r.dtype,(()=>`x has to be a floating point tensor since it's going to be scaled, but got a ${r.dtype} tensor instead.`)),F(t>=0&&t<1,(()=>`rate must be a float in the range [0, 1), but got ${t}.`)),0===t)return e instanceof wr?r.clone():r;const a=function(e,t){if(null==t)return e.shape.slice();if(z(e.shape,t))return t;if(e.shape.length===t.length){const n=[];for(let s=0;s<e.shape.length;s++)null==t[s]&&null!=e.shape[s]?n.push(e.shape[s]):n.push(t[s]);return n}return t}(r,n),i=1-t,o=qa(Ho(ja(Rl(a,0,1,"float32",s),i)),i);return Xa(r,o)}}),su=Jr({fft_:function(e){F("complex64"===e.dtype,(()=>`The dtype for tf.spectral.fft() must be complex64 but got ${e.dtype}.`));const t={input:e};return Wr.runKernel(It,t)}}),ru=Jr({rfft_:function(e,t){F("float32"===e.dtype,(()=>`The dtype for rfft() must be real value but got ${e.dtype}`));let n=e.shape[e.shape.length-1];const s=e.size/n;let r;if(null!=t&&t<n){const s=e.shape.map((e=>0)),a=e.shape.map((e=>e));a[e.shape.length-1]=t,r=Ll(e,s,a),n=t}else if(null!=t&&t>n){const s=e.shape.map((e=>e));s[e.shape.length-1]=t-n,r=No([e,kl(s)],e.shape.length-1),n=t}else r=e;const a=Za(r),i=mo(Zr(r,a),[s,n]),o=su(i),l=Math.floor(n/2)+1,u=eu(o),c=Ql(o),h=Gl(u,[l,n-l],u.shape.length-1),p=Gl(c,[l,n-l],c.shape.length-1),d=r.shape.slice();return d[r.shape.length-1]=l,mo(Zr(h[0],p[0]),d)}}),au=Jr({ifft_:function(e){F("complex64"===e.dtype,(()=>`The dtype for tf.spectral.ifft() must be complex64 but got ${e.dtype}.`));const t={input:e};return Wr.runKernel(Ft,t)}}),iu=Jr({irfft_:function(e){const t=e.shape[e.shape.length-1],n=e.size/t;let s;if(t<=2){const r=mo(e,[n,t]);s=au(r)}else{const r=[n,2*(t-1)],a=mo(eu(e),[n,t]),i=mo(Ql(e),[n,t]),o=Dl(Ll(a,[0,1],[n,t-2]),1),l=Xa(Dl(Ll(i,[0,1],[n,t-2]),1),ei(-1)),u=No([a,o],1),c=No([i,l],1),h=mo(Zr(u,c),[r[0],r[1]]);s=au(h)}if(s=eu(s),3===e.rank&&0!==e.shape[0]){const t=s,n=e.shape[0];s=mo(s,[n,s.shape[0]/n,s.shape[1]]),t.dispose()}return s}}),ou=Jr({conv2DBackpropFilter_:function(e,t,n,s,r,a="NHWC",i){let o=e;3===e.rank&&(o=mo(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let l=t;3===l.rank&&(l=mo(t,[1,t.shape[0],t.shape[1],t.shape[2]])),F(4===o.rank,(()=>`Error in conv2dDerFilter: input must be rank 4, but got shape ${o.shape}.`)),F(4===l.rank,(()=>`Error in conv2dDerFilter: dy must be rank 4, but got shape ${l.shape}.`)),F(4===n.length,(()=>`Error in conv2dDerFilter: filterShape must be length 4, but got ${n}.`));const u="NHWC"===a?o.shape[3]:o.shape[1],c="NHWC"===a?l.shape[3]:l.shape[1];F(u===n[2],(()=>`Error in conv2dDerFilter: depth of input ${u}) must match input depth in filter (${n[2]}.`)),F(c===n[3],(()=>`Error in conv2dDerFilter: depth of dy (${c}) must match output depth for filter (${n[3]}).`)),fo("conv2dDerFilter",r,i);const h={x:o,dy:l},p={strides:s,pad:r,dataFormat:a,dimRoundingMode:i,filterShape:n};return Wr.runKernel(Xe,h,p)}}),lu=Jr({relu6_:function(e){const t={x:Xr(e,"x","relu6")};return Wr.runKernel(On,t)}}),uu=Jr({step_:function(e,t=0){const n={x:Xr(e,"x","step")},s={alpha:t};return Wr.runKernel(Ns,n,s)}});function cu(e,t,n){if(null==n||"linear"===n)return e;if("relu"===n)return Xa(e,uu(t));throw new Error(`Cannot compute gradient for fused activation ${n}.`)}function hu(e,t){let n=t;const s=mi(e.shape,t.shape);return s.length>0&&(n=Qo(n,s)),mo(n,e.shape)}function pu(e,t,n,s){if("linear"===t)return e;if("relu"===t)return _l(e);if("elu"===t)return zo(e);if("relu6"===t)return lu(e);if("prelu"===t)return Sl(e,n);if("leakyrelu"===t)return Xo(e,s);if("sigmoid"===t)return Ml(e);throw new Error(`Unknown fused activation ${t}.`)}const du=(e,t)=>!(e>0)||"linear"===t,fu=Jr({fusedConv2d_:function({x:e,filter:t,strides:n,pad:s,dataFormat:r="NHWC",dilations:a=[1,1],dimRoundingMode:i,bias:o,activation:l="linear",preluActivationWeights:u,leakyreluAlpha:c}){if(l=l||"linear",!1===du(Wr.state.gradientDepth,l)){F("NHWC"===r,(()=>`Error in fused conv2d: got dataFormat of ${r} but only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.`));let h=Co(e,t,n,s,r,a,i);return null!=o&&(h=ja(h,o)),pu(h,l,u,c)}const h=Xr(e,"x","conv2d","float32"),p=Xr(t,"filter","conv2d","float32");let d=h,f=!1;3===h.rank&&(f=!0,d=mo(h,[1,h.shape[0],h.shape[1],h.shape[2]])),F(4===d.rank,(()=>`Error in fused conv2d: input must be rank 4, but got rank ${d.rank}.`)),F(4===p.rank,(()=>`Error in fused conv2d: filter must be rank 4, but got rank ${p.rank}.`)),fo("fused conv2d",s,i);const m="NHWC"===r?d.shape[3]:d.shape[1];F(p.shape[2]===m,(()=>`Error in conv2d: depth of input (${m}) must match input depth for filter ${p.shape[2]}.`)),F(co(n,a),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`));const g=no(d.shape,p.shape,n,a,s,i);let y,b;if(null!=o&&(y=Xr(o,"bias","fused conv2d"),[y]=Dr(y,h),"NHWC"===r?gi(g.outShape,y.shape):(F(y.shape.length<=1,(()=>`Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of rank-${y.shape.length}.`)),F(0===y.shape.length||y.shape[0]===g.outChannels||1===y.shape[0],(()=>`Error in fused conv2d: bias shape (${y.shape}) is not compatible with the number of output channels (${g.outChannels})`)))),null!=u){const e=u.shape;if(F(e.length<=1||3===e.length,(()=>`Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of rank-${e.length}.`)),1===e.length)F(1===e[0]||e[0]===g.outChannels,(()=>`Error in fused conv2d: PReLU activation weights (${e}) is not compatible with the number of output channels (${g.outChannels}).`));else if(3===e.length)try{gi(e,g.outShape)}catch(t){const n=`Error in fused conv2d: PReLU activation weights (${e}) is not compatible with the output shape of the conv2d (${g.outShape}).`;throw Error(n)}b=Xr(u,"prelu weights","fused conv2d")}const x=(e,t)=>{F("NHWC"===r,(()=>`Error in gradient of fused conv2D: got dataFormat of ${r} but only NHWC is currently supported.`));const[i,o,u,c]=t,h=cu(e,u,l);F(uo(a),(()=>`Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${a}'`));const p=[Ao(o.shape,h,i,n,s),ou(o,h,i.shape,n,s)];if(null!=c){const e=hu(c,h);p.push(e)}return p},w={x:d,filter:p,bias:y,preluActivationWeights:b},k={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i,activation:l,leakyreluAlpha:c};if(null==o){const e=Qa(((e,t,n)=>{let s=Wr.runKernel($s,w,k);return n([t,e,s]),f&&(s=mo(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:x}}));return e(d,p)}{const e=Qa(((e,t,n,s)=>{let r=Wr.runKernel($s,w,k);return s([t,e,r,n]),f&&(r=mo(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:x}}));return e(d,p,y)}}}),mu=Jr({depthwiseConv2dNativeBackpropFilter_:function(e,t,n,s,r,a=[1,1],i){let o=e;3===e.rank&&(o=mo(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let l=t;3===l.rank&&(l=mo(t,[1,t.shape[0],t.shape[1],t.shape[2]]));const u={x:o,dy:l},c={strides:s,pad:r,dimRoundingMode:i,dilations:a,filterShape:n};return Wr.runKernel(lt,u,c)}}),gu=Jr({depthwiseConv2dNativeBackpropInput_:function(e,t,n,s,r,a=[1,1],i){let o=t,l=!1;3===t.rank&&(l=!0,o=mo(t,[1,t.shape[0],t.shape[1],t.shape[2]]));const u={dy:o,filter:n},c={strides:s,pad:r,dimRoundingMode:i,dilations:a,inputShape:e},h=Wr.runKernel(ut,u,c);return l?mo(h,[h.shape[1],h.shape[2],h.shape[3]]):h}}),yu=Jr({fusedMatMul_:function({a:e,b:t,transposeA:n=!1,transposeB:s=!1,bias:r,activation:a="linear",preluActivationWeights:i,leakyreluAlpha:o=.2}){if(!1===du(Wr.state.gradientDepth,a)){let l=hl(e,t,n,s);return null!=r&&(l=ja(l,r)),pu(l,a,i,o)}let l=Xr(e,"a","fused matMul"),u=Xr(t,"b","fused matMul");[l,u]=Dr(l,u);const c=n?l.shape[l.rank-2]:l.shape[l.rank-1],h=s?u.shape[u.rank-1]:u.shape[u.rank-2],p=n?l.shape[l.rank-1]:l.shape[l.rank-2],d=s?u.shape[u.rank-2]:u.shape[u.rank-1],f=l.shape.slice(0,-2),m=u.shape.slice(0,-2),g=L(f),y=L(m);F(c===h,(()=>`Error in fused matMul: inner shapes (${c}) and (${h}) of Tensors with shapes ${l.shape} and ${u.shape} and transposeA=${n} and transposeB=${s} must match.`));const b=gi(l.shape.slice(0,-2),u.shape.slice(0,-2)).concat([p,d]),x=mo(l,n?[g,c,p]:[g,p,c]),w=mo(u,s?[y,d,h]:[y,h,d]);let k,v;null!=r&&(k=Xr(r,"bias","fused matMul"),[k]=Dr(k,l),gi(b,k.shape)),null!=i&&(v=Xr(i,"prelu weights","fused matMul"));const I=(e,t)=>{const[i,o,l,u]=t,c=cu(mo(e,l.shape),l,a);let h,p;return n||s?!n&&s?(h=hl(c,o,!1,!1),p=hl(c,i,!0,!1)):n&&!s?(h=hl(o,c,!1,!0),p=hl(i,c,!1,!1)):(h=hl(o,c,!0,!0),p=hl(c,i,!0,!0)):(h=hl(c,o,!1,!0),p=hl(i,c,!0,!1)),null!=r?[h,p,hu(u,c)]:[h,p]},N={a:x,b:w,bias:k,preluActivationWeights:v},S={transposeA:n,transposeB:s,activation:a,leakyreluAlpha:o};if(null==r){const e=Qa(((e,t,n)=>{const s=Wr.runKernel(Ts,N,S);return n([e,t,s]),{value:mo(s,b),gradFunc:I}}));return e(x,w)}{const e=Qa(((e,t,n,s)=>{const r=Wr.runKernel(Ts,N,S);return s([e,t,r,n]),{value:mo(r,b),gradFunc:I}}));return e(x,w,k)}}}),bu=Jr({cropAndResize_:function(e,t,n,s,r="bilinear",a=0){const i=Xr(e,"image","cropAndResize"),o=Xr(t,"boxes","cropAndResize","float32"),l=Xr(n,"boxInd","cropAndResize","int32"),u=o.shape[0];F(4===i.rank,(()=>`Error in cropAndResize: image must be rank 4,but got rank ${i.rank}.`)),F(2===o.rank&&4===o.shape[1],(()=>`Error in cropAndResize: boxes must be have size [${u},4] but had shape ${o.shape}.`)),F(1===l.rank&&l.shape[0]===u,(()=>`Error in cropAndResize: boxInd must be have size [${u}] but had shape ${o.shape}.`)),F(2===s.length,(()=>`Error in cropAndResize: cropSize must be of length 2, but got length ${s.length}.`)),F(s[0]>=1&&s[1]>=1,(()=>`cropSize must be atleast [1,1], but was ${s}`)),F("bilinear"===r||"nearest"===r,(()=>`method must be bilinear or nearest, but was ${r}`));const c={image:i,boxes:o,boxInd:l},h={method:r,extrapolationValue:a,cropSize:s};return Wr.runKernel(rt,c,h)}}),xu=Jr({flipLeftRight_:function(e){const t=Xr(e,"image","flipLeftRight","float32");F(4===t.rank,(()=>`Error in flipLeftRight: image must be rank 4,but got rank ${t.rank}.`));const n={image:t};return Wr.runKernel(St,n,{})}}),wu=Jr({grayscaleToRGB_:function(e){const t=Xr(e,"image","grayscaleToRGB"),n=t.rank-1,s=t.shape[n];F(t.rank>=2,(()=>`Error in grayscaleToRGB: images must be at least rank 2, but got rank ${t.rank}.`)),F(1===s,(()=>`Error in grayscaleToRGB: last dimension of a grayscale image should be size 1, but got size ${s}.`));const r=new Array(t.rank);return r.fill(1,0,n),r[n]=3,Uo(t,r)}}),ku=Jr({einsum_:function(e,...t){const n=t.map(((e,t)=>Xr(e,`tensors${t}`,"einsum"))),s={equation:e};return Wr.runKernel(mt,n,s)}}),vu=Jr({rgbToGrayscale_:function(e){const t=Xr(e,"image","RGBToGrayscale"),n=t.rank-1,s=t.shape[n];F(t.rank>=2,(()=>`Error in RGBToGrayscale: images must be at least rank 2, but got rank ${t.rank}.`)),F(3===s,(()=>`Error in RGBToGrayscale: last dimension of an RGB image should be size 3, but got size ${s}.`));const r=t.dtype,a=Ga(t,"float32"),i=ql([.2989,.587,.114]);let o;switch(t.rank){case 2:o=ku("ij,j->i",a,i);break;case 3:o=ku("ijk,k->ij",a,i);break;case 4:o=ku("ijkl,l->ijk",a,i);break;case 5:o=ku("ijklm,m->ijkl",a,i);break;case 6:o=ku("ijklmn,n->ijklm",a,i);break;default:throw new Error("Not a valid tensor rank.")}return o=Vo(o,-1),Ga(o,r)}}),Iu=Jr({rotateWithOffset_:function(e,t,n=0,s=.5){const r=Xr(e,"image","rotateWithOffset","float32");F(4===r.rank,(()=>`Error in rotateWithOffset: image must be rank 4,but got rank ${r.rank}.`));const a={image:r},i={radians:t,fillValue:n,center:s};return Wr.runKernel(Ss,a,i)}});function Nu(e,t,n,s,r,a){null==s&&(s=.5),null==r&&(r=Number.NEGATIVE_INFINITY),null==a&&(a=0);const i=e.shape[0];return n=Math.min(n,i),F(0<=s&&s<=1,(()=>`iouThreshold must be in [0, 1], but was '${s}'`)),F(2===e.rank,(()=>`boxes must be a 2D tensor, but was of rank '${e.rank}'`)),F(4===e.shape[1],(()=>`boxes must have 4 columns, but 2nd dimension was ${e.shape[1]}`)),F(1===t.rank,(()=>"scores must be a 1D tensor")),F(t.shape[0]===i,(()=>`scores has incompatible shape with boxes. Expected ${i}, but was ${t.shape[0]}`)),F(0<=a&&a<=1,(()=>`softNmsSigma must be in [0, 1], but was '${a}'`)),{maxOutputSize:n,iouThreshold:s,scoreThreshold:r,softNmsSigma:a}}const Su=Jr({nonMaxSuppression_:function(e,t,n,s=.5,r=Number.NEGATIVE_INFINITY){const a=Xr(e,"boxes","nonMaxSuppression","float32"),i=Xr(t,"scores","nonMaxSuppression","float32"),o=Nu(a,i,n,s,r),l={maxOutputSize:n=o.maxOutputSize,iouThreshold:s=o.iouThreshold,scoreThreshold:r=o.scoreThreshold};return Wr.runKernel(dn,{boxes:a,scores:i},l)}});function Tu(e,t,n){const s=function(e,t,n){return function(e,t,n){let s=0,r=e.length,a=0,i=!1;for(;s<r;){a=s+(r-s>>>1);const o=n(t,e[a]);o>0?s=a+1:(r=a,i=!o)}return i?s:-s-1}(e,t,n||$u)}(e,t,n),r=s<0?-(s+1):s;e.splice(r,0,t)}function $u(e,t){return e>t?1:e<t?-1:0}function Eu(e,t,n,s,r){return Au(e,t,n,s,r,0)}function Cu(e,t,n,s,r,a){return Au(e,t,n,s,r,0,!1,a,!0)}function Ru(e,t,n,s,r,a){return Au(e,t,n,s,r,a,!0)}function Au(e,t,n,s,r,a,i=!1,o=!1,l=!1){const u=[];for(let e=0;e<t.length;e++)t[e]>r&&u.push({score:t[e],boxIndex:e,suppressBeginIndex:0});u.sort(Fu);const c=a>0?-.5/a:0,h=[],p=[];for(;h.length<n&&u.length>0;){const t=u.pop(),{score:n,boxIndex:a,suppressBeginIndex:i}=t;if(n<r)break;let o=!1;for(let n=h.length-1;n>=i;--n){const i=_u(e,a,h[n]);if(i>=s){o=!0;break}if(t.score=t.score*Du(s,c,i),t.score<=r)break}t.suppressBeginIndex=h.length,o||(t.score===n?(h.push(a),p.push(t.score)):t.score>r&&Tu(u,t,Fu))}const d=h.length,f=n-d;o&&f>0&&(h.push(...new Array(f).fill(0)),p.push(...new Array(f).fill(0)));const m={selectedIndices:h};return i&&(m.selectedScores=p),l&&(m.validOutputs=d),m}function _u(e,t,n){const s=e.subarray(4*t,4*t+4),r=e.subarray(4*n,4*n+4),a=Math.min(s[0],s[2]),i=Math.min(s[1],s[3]),o=Math.max(s[0],s[2]),l=Math.max(s[1],s[3]),u=Math.min(r[0],r[2]),c=Math.min(r[1],r[3]),h=Math.max(r[0],r[2]),p=Math.max(r[1],r[3]),d=(o-a)*(l-i),f=(h-u)*(p-c);if(d<=0||f<=0)return 0;const m=Math.max(a,u),g=Math.max(i,c),y=Math.min(o,h),b=Math.min(l,p),x=Math.max(y-m,0)*Math.max(b-g,0);return x/(d+f-x)}function Du(e,t,n){const s=Math.exp(t*n*n);return n<=e?s:0}function Fu(e,t){return e.score-t.score||e.score===t.score&&t.boxIndex-e.boxIndex}const Ou=Jr({nonMaxSuppressionWithScore_:function(e,t,n,s=.5,r=Number.NEGATIVE_INFINITY,a=0){const i=Xr(e,"boxes","nonMaxSuppression"),o=Xr(t,"scores","nonMaxSuppression"),l=Nu(i,o,n,s,r,a),u={boxes:i,scores:o},c={maxOutputSize:n=l.maxOutputSize,iouThreshold:s=l.iouThreshold,scoreThreshold:r=l.scoreThreshold,softNmsSigma:a=l.softNmsSigma},h=Wr.runKernel(mn,u,c);return{selectedIndices:h[0],selectedScores:h[1]}}}),Mu=Jr({nonMaxSuppressionPadded_:function(e,t,n,s=.5,r=Number.NEGATIVE_INFINITY,a=!1){const i=Xr(e,"boxes","nonMaxSuppression"),o=Xr(t,"scores","nonMaxSuppression"),l=Nu(i,o,n,s,r,null),u={boxes:i,scores:o},c={maxOutputSize:l.maxOutputSize,iouThreshold:l.iouThreshold,scoreThreshold:l.scoreThreshold,padToMaxOutputSize:a},h=Wr.runKernel(fn,u,c);return{selectedIndices:h[0],validOutputs:h[1]}}}),Lu=Jr({resizeBilinear_:function(e,t,n=!1,s=!1){const r=Xr(e,"images","resizeBilinear");F(3===r.rank||4===r.rank,(()=>`Error in resizeBilinear: x must be rank 3 or 4, but got rank ${r.rank}.`)),F(2===t.length,(()=>`Error in resizeBilinear: new shape must 2D, but got shape ${t}.`)),F(!1===s||!1===n,(()=>"Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false."));let a=r,i=!1;3===r.rank&&(i=!0,a=mo(r,[1,r.shape[0],r.shape[1],r.shape[2]]));const[]=t,o={images:a},l={alignCorners:n,halfPixelCenters:s,size:t},u=Wr.runKernel(Dn,o,l);return i?mo(u,[u.shape[1],u.shape[2],u.shape[3]]):u}}),zu=Jr({resizeNearestNeighbor_:function(e,t,n=!1,s=!1){const r=Xr(e,"images","resizeNearestNeighbor");F(3===r.rank||4===r.rank,(()=>`Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${r.rank}.`)),F(2===t.length,(()=>`Error in resizeNearestNeighbor: new shape must 2D, but got shape ${t}.`)),F("float32"===r.dtype||"int32"===r.dtype,(()=>"`images` must have `int32` or `float32` as dtype")),F(!1===s||!1===n,(()=>"Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false."));let a=r,i=!1;3===r.rank&&(i=!0,a=mo(r,[1,r.shape[0],r.shape[1],r.shape[2]]));const[]=t,o={images:a},l={alignCorners:n,halfPixelCenters:s,size:t},u=Wr.runKernel(An,o,l);return i?mo(u,[u.shape[1],u.shape[2],u.shape[3]]):u}}),Bu=Jr({bincount_:function(e,t,n){const s=Xr(e,"x","bincount"),r=Xr(t,"weights","bincount");F("int32"===s.dtype,(()=>`Error in bincount: input dtype must be int32, but got ${s.dtype}`)),F(n>=0,(()=>`size must be non-negative, but got ${n}.`)),F(r.size===s.size||0===r.size,(()=>`Error in bincount: weights must have the same size as input or0-length, but got input shape: ${s.shape}, weights shape: ${r.shape}.`));const a={x:s,weights:r},i={size:n};return Wr.runKernel(Be,a,i)}}),Pu=Jr({lessEqual_:function(e,t){let n=Xr(e,"a","lessEqual","string_or_numeric"),s=Xr(t,"b","lessEqual","string_or_numeric");[n,s]=Dr(n,s),gi(n.shape,s.shape);const r={a:n,b:s};return Wr.runKernel(Wt,r)}}),Wu=Jr({round_:function(e){const t={x:Xr(e,"x","round")};return Wr.runKernel(Ln,t)}}),Vu=Jr({threshold_:function(e,t="binary",n=!1,s=.5){const r=Xr(e,"image","threshold"),a=r.shape[0]*r.shape[1];let i,o,l,u,c=Xa(ql([s]),255);if(F(3===r.rank,(()=>`Error in threshold: image must be rank 3,but got rank ${r.rank}.`)),F(3===r.shape[2]||1===r.shape[2],(()=>`Error in threshold: image color channel must be equal to 3 or 1but got ${r.shape[2]}.`)),F("int32"===r.dtype||"float32"===r.dtype,(()=>`Error in dtype: image dtype must be int32 or float32,but got dtype ${r.dtype}.`)),F("otsu"===t||"binary"===t,(()=>`Method must be binary or otsu, but was ${t}`)),3===r.shape[2]){[i,o,l]=Gl(r,[1,1,1],-1);const e=Xa(i,.2989),t=Xa(o,.587),n=Xa(l,.114);u=ja(ja(e,t),n)}else u=e;"otsu"===t&&(c=function(e,t){let n,s,r,a,i,o,l=ql([-1]),u=ql([0]),c=ql([0]);for(let h=0;h<e.size-1;h++){n=Ll(e,0,h+1),s=Ll(e,h+1),i=qa(Qo(n),t),o=qa(Qo(s),t);const p=Qo(Xa(n,Al(0,n.size)));r=qa(p,Qo(n));const d=li(s.shape,n.size),f=ja(Al(0,s.size),d),m=Xa(s,f);a=qa(Qo(m),Qo(s));const g=hi(r,a),y=hi(r,a),b=Xa(i,o);c=Xa(Xa(b,g),y);const x=Ko(c,u);u=Zl(x,c,u),l=Zl(x,ql([h]),l)}return l}(Bu(Ga(Wu(u),"int32"),ea([]),256),a));const h=n?Pu(u,c):Ko(u,c);return Ga(Xa(h,255),"int32")}}),Uu=Jr({transform_:function(e,t,n="nearest",s="constant",r=0,a){const i=Xr(e,"image","transform","float32"),o=Xr(t,"transforms","transform","float32");F(4===i.rank,(()=>`Error in transform: image must be rank 4,but got rank ${i.rank}.`)),F(2===o.rank&&(o.shape[0]===i.shape[0]||1===o.shape[0])&&8===o.shape[1],(()=>"Error in transform: Input transform should be batch x 8 or 1 x 8")),F(null==a||2===a.length,(()=>`Error in transform: outputShape must be [height, width] or null, but got ${a}.`));const l={image:i,transforms:o},u={interpolation:n,fillMode:s,fillValue:r,outputShape:a};return Wr.runKernel(bs,l,u)}}),Gu=Jr({less_:function(e,t){let n=Xr(e,"a","less","string_or_numeric"),s=Xr(t,"b","less","string_or_numeric");[n,s]=Dr(n,s),gi(n.shape,s.shape);const r={a:n,b:s};return Wr.runKernel(Pt,r)}}),Hu=Jr({bandPart_:function(e,t,n){const s=Xr(e,"a","bandPart");F(s.rank>=2,(()=>`bandPart(): Rank must be at least 2, got ${s.rank}.`));const r=s.shape,[a,i]=s.shape.slice(-2);let o,l;"number"==typeof t?(F(t%1==0,(()=>`bandPart(): numLower must be an integer, got ${t}.`)),F(t<=a,(()=>`bandPart(): numLower (${t}) must not be greater than the number of rows (${a}).`)),o=Xr(t<0?a:t,"numLower","bandPart")):(F("int32"===t.dtype,(()=>"bandPart(): numLower's dtype must be an int32.")),o=Zl(Gu(t,0),a,gl(t,a))),"number"==typeof n?(F(n%1==0,(()=>`bandPart(): numUpper must be an integer, got ${n}.`)),F(n<=i,(()=>`bandPart(): numUpper (${n}) must not be greater than the number of columns (${i}).`)),l=Xr(n<0?i:n,"numUpper","bandPart")):(F("int32"===n.dtype,(()=>"bandPart(): numUpper's dtype must be an int32.")),l=Zl(Gu(n,0),i,gl(n,i)));const u=mo(Al(0,a,1,"int32"),[-1,1]),c=Al(0,i,1,"int32"),h=hi(u,c),p=cl(Pu(h,o),qo(h,bl(l))),d=kl([a,i],s.dtype);return mo(jl(Jl(mo(s,[-1,a,i])).map((e=>Zl(p,e,d)))),r)}});function ju(e,t,n=null){if(0===e.rank)return di(e);if(1!==e.rank&&null===n)return ju(mo(e,[-1]),t,n);if(1===e.rank||"number"==typeof n||Array.isArray(n)&&1===n.length){if(1===t)return Qo(di(e),n);if(t===1/0)return Zo(di(e),n);if(t===-1/0)return ml(di(e),n);if("euclidean"===t||2===t)return Ya(Qo(ci(di(e),ei(2,"int32")),n));throw new Error(`Error in norm: invalid ord value: ${t}`)}if(Array.isArray(n)&&2===n.length){if(1===t)return Zo(Qo(di(e),n[0]),n[1]-1);if(t===1/0)return Zo(Qo(di(e),n[1]),n[0]);if(t===-1/0)return ml(Qo(di(e),n[1]),n[0]);if("fro"===t||"euclidean"===t)return Ya(Qo(Ja(e),n));throw new Error(`Error in norm: invalid ord value: ${t}`)}throw new Error(`Error in norm: invalid axis: ${n}`)}const Ku=Jr({norm_:function(e,t="euclidean",n=null,s=!1){const r=ju(e=Xr(e,"x","norm"),t,n);let a=r.shape;if(s){const t=G(n,e.shape);a=rl(r.shape,t)}return mo(r,a)}}),qu=Jr({gramSchmidt_:function(e){let t;if(Array.isArray(e)){t=!1,F(null!=e&&e.length>0,(()=>"Gram-Schmidt process: input must not be null, undefined, or empty"));const n=e[0].shape[0];for(let t=1;t<e.length;++t)F(e[t].shape[0]===n,(()=>`Gram-Schmidt: Non-unique lengths found in the input vectors: (${e[t].shape[0]} vs. ${n})`))}else t=!0,e=Gl(e,e.shape[0],0).map((e=>Hl(e,[0])));F(e.length<=e[0].shape[0],(()=>`Gram-Schmidt: Number of vectors (${e.length}) exceeds number of dimensions (${e[0].shape[0]}).`));const n=[],s=e;for(let t=0;t<e.length;++t)n.push(Wr.tidy((()=>{let e=s[t];if(t>0)for(let s=0;s<t;++s){const t=Xa(Qo(Xa(n[s],e)),n[s]);e=hi(e,t)}return qa(e,Ku(e,"euclidean"))})));return t?jl(n,0):n}});function Xu(e,t=!1){return Wr.tidy((()=>{F(2===e.shape.length,(()=>`qr2d() requires a 2D Tensor, but got a ${e.shape.length}D Tensor.`));const n=e.shape[0],s=e.shape[1];let r=Go(n),a=Ha(e);const i=Xl([[1]],[1,1]);let o=Ha(i);const l=n>=s?s:n;for(let e=0;e<l;++e){const t=a,l=o,u=r;[o,a,r]=Wr.tidy((()=>{const t=Ll(a,[e,e],[n-e,1]),l=Ku(t),u=Ll(a,[e,e],[1,1]),c=Zl(Ko(u,0),Xl([[-1]]),Xl([[1]])),h=hi(u,Xa(c,l)),p=qa(t,h);o=1===p.shape[0]?Ha(i):No([i,Ll(p,[1,0],[p.shape[0]-1,p.shape[1]])],0);const d=bl(qa(hl(c,h),l)),f=Ll(a,[e,0],[n-e,s]),m=Xa(d,o),g=tu(o);if(0===e)a=hi(f,hl(m,hl(g,f)));else{const t=hi(f,hl(m,hl(g,f)));a=No([Ll(a,[0,0],[e,s]),t],0)}const y=tu(m),b=Ll(r,[0,e],[n,r.shape[1]-e]);if(0===e)r=hi(b,hl(hl(b,o),y));else{const t=hi(b,hl(hl(b,o),y));r=No([Ll(r,[0,0],[n,e]),t],1)}return[o,a,r]})),ia([t,l,u])}return!t&&n>s&&(r=Ll(r,[0,0],[n,s]),a=Ll(a,[0,0],[s,s])),[r,a]}))}const Yu=Jr({qr_:function(e,t=!1){if(F(e.rank>=2,(()=>`qr() requires input tensor to have a rank >= 2, but got rank ${e.rank}`)),2===e.rank)return Xu(e,t);{const n=e.shape.slice(0,e.shape.length-2).reduce(((e,t)=>e*t)),s=Jl(mo(e,[n,e.shape[e.shape.length-2],e.shape[e.shape.length-1]]),0),r=[],a=[];return s.forEach((e=>{const[n,s]=Xu(e,t);r.push(n),a.push(s)})),[mo(jl(r,0),e.shape),mo(jl(a,0),e.shape)]}}});var Ju;!function(e){e[e.NONE=0]="NONE",e[e.MEAN=1]="MEAN",e[e.SUM=2]="SUM",e[e.SUM_BY_NONZERO_WEIGHTS=3]="SUM_BY_NONZERO_WEIGHTS"}(Ju||(Ju={}));const Zu=Jr({squaredDifference_:function(e,t){let n=Xr(e,"a","squaredDifference"),s=Xr(t,"b","squaredDifference");[n,s]=Dr(n,s),gi(n.shape,s.shape);const r={a:n,b:s};return Wr.runKernel(is,r,{})}}),Qu={flipLeftRight:xu,grayscaleToRGB:wu,resizeNearestNeighbor:zu,resizeBilinear:Lu,rgbToGrayscale:vu,rotateWithOffset:Iu,cropAndResize:bu,nonMaxSuppression:Su,nonMaxSuppressionAsync:async function(e,t,n,s=.5,r=Number.NEGATIVE_INFINITY){const a=Xr(e,"boxes","nonMaxSuppressionAsync"),i=Xr(t,"scores","nonMaxSuppressionAsync"),o=Nu(a,i,n,s,r);n=o.maxOutputSize,s=o.iouThreshold,r=o.scoreThreshold;const l=await Promise.all([a.data(),i.data()]),u=l[0],c=l[1],{selectedIndices:h}=Eu(u,c,n,s,r);return a!==e&&a.dispose(),i!==t&&i.dispose(),ql(h,"int32")},nonMaxSuppressionWithScore:Ou,nonMaxSuppressionWithScoreAsync:async function(e,t,n,s=.5,r=Number.NEGATIVE_INFINITY,a=0){const i=Xr(e,"boxes","nonMaxSuppressionAsync"),o=Xr(t,"scores","nonMaxSuppressionAsync"),l=Nu(i,o,n,s,r,a);n=l.maxOutputSize,s=l.iouThreshold,r=l.scoreThreshold,a=l.softNmsSigma;const u=await Promise.all([i.data(),o.data()]),c=u[0],h=u[1],{selectedIndices:p,selectedScores:d}=Ru(c,h,n,s,r,a);return i!==e&&i.dispose(),o!==t&&o.dispose(),{selectedIndices:ql(p,"int32"),selectedScores:ql(d)}},nonMaxSuppressionPadded:Mu,nonMaxSuppressionPaddedAsync:async function(e,t,n,s=.5,r=Number.NEGATIVE_INFINITY,a=!1){const i=Xr(e,"boxes","nonMaxSuppressionAsync"),o=Xr(t,"scores","nonMaxSuppressionAsync"),l=Nu(i,o,n,s,r,null),u=l.maxOutputSize,c=l.iouThreshold,h=l.scoreThreshold,[p,d]=await Promise.all([i.data(),o.data()]),{selectedIndices:f,validOutputs:m}=Cu(p,d,u,c,h,a);return i!==e&&i.dispose(),o!==t&&o.dispose(),{selectedIndices:ql(f,"int32"),validOutputs:ei(m,"int32")}},threshold:Vu,transform:Uu},ec={bandPart:Hu,gramSchmidt:qu,qr:Yu},tc=class{static sgd(e){return new xi(e)}static momentum(e,t,n=!1){return new wi(e,t,n)}static rmsprop(e,t=.9,n=0,s=null,r=!1){return new ki(e,t,n,s,r)}static adam(e=.001,t=.9,n=.999,s=null){return new pi(e,t,n,s)}static adadelta(e=.001,t=.95,n=null){return new oi(e,t,n)}static adamax(e=.002,t=.9,n=.999,s=null,r=0){return new bi(e,t,n,s,r)}static adagrad(e,t=.1){return new ui(e,t)}},nc="undefined"!=typeof requestAnimationFrame?requestAnimationFrame:"undefined"!=typeof setImmediate?setImmediate:e=>e();function sc(){return new Promise((e=>nc((()=>e()))))}function rc(e,t){const n=e[0].length;e.forEach(((e,t)=>{F(e.length===n,(()=>`Error in concat${n}D: rank of tensors[${t}] must be the same as the rank of the rest (${n})`))})),F(t>=0&&t<n,(()=>`Error in concat${n}D: axis must be between 0 and ${n-1}.`));const s=e[0];e.forEach(((e,r)=>{for(let a=0;a<n;a++)F(a===t||e[a]===s[a],(()=>`Error in concat${n}D: Shape of tensors[${r}] (${e}) does not match the shape of the rest (${s}) along the non-concatenated axis ${r}.`))}))}function ac(e,t){const n=e[0].slice();for(let s=1;s<e.length;s++)n[t]+=e[s][t];return n}var ic;function oc(e,t,n){let s=new Array;if(null==n&&null==t)return s;if(null==t)for(;s.length<e+n.length;)s.push(-1);else s=t.slice();if(null==n)return s;if(e+n.length!==s.length)throw new Error(`rt input.shape and shape=${t} are incompatible: rt input.rank = ${e+n.length}, but shape.rank = ${s.length}`);for(let r=1;r<n.length;++r){const a=n[r],i=s[s.length-n.length+r],o=s[i];if(a>=0)if(o>=0){if(o!==a)throw new Error(`rt input.shape and shape=${t} are incompatible: rt input.shape[${r+e}] = ${a} but shape[${r+e}] = ${o}`)}else s[i]=a}return s}function lc(e){const t={FIRST_DIM_SIZE:ic.FIRST_DIM_SIZE,VALUE_ROWIDS:ic.VALUE_ROWIDS,ROW_LENGTHS:ic.ROW_LENGTHS,ROW_SPLITS:ic.ROW_SPLITS,ROW_LIMITS:ic.ROW_LIMITS,ROW_STARTS:ic.ROW_STARTS},n=[];for(const s of e){if(!(s in t))break;n.push(t[s])}return n}function uc(e){return 0===e.length?0:e[0]===ic.FIRST_DIM_SIZE?e.length-1:e.length}function cc(e,t){if(null==e||null==t)return;const n=e.length,s=t.length;if(n>=s)throw new Error(`defaultValue.shape=${e} and ragged tensor flatValues.shape=${t}, are incompatible: defaultValue.rank = ${n} must be less than ragged tensor input flatValues.rank = ${s})`);for(let r=0;r<Math.min(n,s-1);++r){const n=e[r],s=t[r+1];if(n>=0&&s>=0&&1!==n&&n!==s)throw new Error(`defaultValue.shape=${e}, and ragged tensor input flatValues.shape=${t} are incompatible: defaultValue.shape[${r-e.length}] = ${n} but ragged tensor input.flatValues.shape[${r-e.length}] = ${s}`)}}!function(e){e[e.FIRST_DIM_SIZE=0]="FIRST_DIM_SIZE",e[e.VALUE_ROWIDS=1]="VALUE_ROWIDS",e[e.ROW_LENGTHS=2]="ROW_LENGTHS",e[e.ROW_SPLITS=3]="ROW_SPLITS",e[e.ROW_LIMITS=4]="ROW_LIMITS",e[e.ROW_STARTS=5]="ROW_STARTS"}(ic||(ic={}));const hc=30;function pc(e){return e<=hc?e:ee(e,Math.floor(Math.sqrt(e)))}function dc(e,t,n){return[n*("number"==typeof e?e:e[0]),t*("number"==typeof e?e:e[1])]}function fc(e,t,n,s=!0){let r=[];if(s)r=r.concat(t.slice(0)),r.push(e[0]/n),r=r.concat(e.slice(1));else{r=r.concat(e[0]);const n=t.length;for(let s=0;s<n;++s)r=r.concat([e[s+1]/t[s],t[s]]);r=r.concat(e.slice(n+1))}return r}function mc(e,t,n=!0){const s=[];if(n){s.push(t);for(let n=t+1;n<e;++n)n<=2*t?(s.push(n),s.push(n-(t+1))):s.push(n)}else{const n=[],r=[];for(let s=1;s<e;++s)s>=2*t+1||s%2==1?r.push(s):n.push(s);s.push(...n),s.push(0),s.push(...r)}return s}function gc(e,t,n,s=!0){const r=[];s?r.push(e[0]/n):r.push(e[0]*n);for(let n=1;n<e.length;++n)n<=t.length?s?r.push(t[n-1]*e[n]):r.push(e[n]/t[n-1]):r.push(e[n]);return r}function yc(e,t){const n=[0];for(let s=0;s<t;++s)n.push(e[s][0]);return n}function bc(e,t,n){const s=e.slice(0,1);for(let r=0;r<n;++r)s.push(e[r+1]-t[r][0]-t[r][1]);return s}function xc(e,t){const n=e.shape.length,s=t.shape.length;if(n<1)throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${n}.`);if(s<1)throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${s}.`);if("int32"!==t.dtype)throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${t.dtype}.`);if(t.shape[s-1]>n)throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${t.shape[s-1]} vs. ${n}`);if(0===L(e.shape))throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${e.shape}.`);const r=t.shape,a=r[r.length-1];let i=1;for(let e=0;e<r.length-1;++e)i*=r[e];const o=e.shape,l=r.slice();l.pop();let u=1;for(let e=a;e<n;++e)u*=o[e],l.push(o[e]);const c=[...te(e.shape).map((e=>e/u)),1].slice(0,a);return[l,i,u,c]}function wc(e,t,n){const s=t.rank>1?t.shape[t.rank-1]:1,r=t.rank>1?t.rank-1:1,a=`Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${n.shape}, indices.shape: ${t.shape}, shape: ${e}, sliceDim: ${s}, and batchDim: ${r}.`;if(n.rank<r)throw new Error(a+` update.rank < ${r}. `);if(e.length<s+(n.rank-r))throw new Error(a+` Output shape length < ${s+(n.rank-r)}`);if(n.rank!==r+e.length-s)throw new Error(a+" update.rank != "+(r+e.length-s));for(let e=0;e<r;++e)if(n.shape[e]!==t.shape[e])throw new Error(a+` updates.shape[${e}] (${n.shape[e]}) != indices.shape[${e}] (${t.shape[e]}).`);for(let t=0;t<n.rank-r;++t)if(n.shape[t+r]!==e[t+s])throw new Error(a+` updates.shape[${t+r}] (${n.shape[t+r]}) != shape[${t+r}] (${e[t+r]})`)}function kc(e,t,n){if(t.rank<1)throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${t.rank}.`);if(e.rank<1)throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${e.rank}.`);if("int32"!==t.dtype)throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${t.dtype}`);if(n.length<1)throw new Error(`Output rank must be greater or equal to 1, but got shape: ${n}`);if(0===n.length){if(0===t.size)throw new Error(`Indices specified for empty output. indices shape: ${t.shape}`);if(0===e.size)throw new Error(`Updates specified for empty output. updates shape: ${e.shape}`)}wc(n,t,e)}function vc(e,t,n){const s=t.shape.length,r=s>1?t.shape[s-1]:1,a=n.length;let i=1;for(let e=r;e<a;++e)i*=n[e];const o=r<1?1:r;return{sliceRank:r,numUpdates:L(t.shape)/o,sliceSize:i,strides:[...te(n.slice(0,r)),1],outputSize:L(n)}}const Ic=1.7580993408473768,Nc=1.0507009873554805,Sc=.3275911,Tc=.254829592,$c=-.284496736,Ec=1.421413741,Cc=-1.453152027,Rc=1.061405429;function Ac(e,t){if(e.length!==t.length)throw new Error(`Cannot merge real and imag arrays of different lengths. real:${e.length}, imag: ${t.length}.`);const n=new Float32Array(2*e.length);for(let s=0;s<n.length;s+=2)n[s]=e[s/2],n[s+1]=t[s/2];return n}function _c(e){const t=new Float32Array(e.length/2),n=new Float32Array(e.length/2);for(let s=0;s<e.length;s+=2)t[s/2]=e[s],n[s/2]=e[s+1];return{real:t,imag:n}}function Dc(e){const t=Math.ceil(e.length/4),n=new Float32Array(t),s=new Float32Array(t);for(let t=0;t<e.length;t+=4)n[Math.floor(t/4)]=e[t],s[Math.floor(t/4)]=e[t+1];return{real:n,imag:s}}function Fc(e){const t=Math.floor(e.length/4),n=new Float32Array(t),s=new Float32Array(t);for(let t=2;t<e.length;t+=4)n[Math.floor(t/4)]=e[t],s[Math.floor(t/4)]=e[t+1];return{real:n,imag:s}}function Oc(e,t){return{real:e[2*t],imag:e[2*t+1]}}function Mc(e,t,n,s){e[2*s]=t,e[2*s+1]=n}function Lc(e,t){const n=new Float32Array(e/2),s=new Float32Array(e/2);for(let r=0;r<Math.ceil(e/2);r++){const a=(t?2:-2)*Math.PI*(r/e);n[r]=Math.cos(a),s[r]=Math.sin(a)}return{real:n,imag:s}}function zc(e,t,n){const s=(n?2:-2)*Math.PI*(e/t);return{real:Math.cos(s),imag:Math.sin(s)}}const Bc="->",Pc=/->/g,Wc=",",Vc="...";function Uc(e,t){const n=((e=e.replace(/\s/g,"")).length-e.replace(Pc,"").length)/Bc.length;if(n<1)throw new Error("Equations without an arrow are not supported.");if(n>1)throw new Error(`Equation must contain exactly one arrow ("${Bc}").`);const[s,r]=e.split(Bc);F(-1===s.indexOf(Vc),(()=>`The ellipsis notation ("${Vc}") is not supported yet.`));const a=s.split(Wc),i=a.length;if(t!==i)throw new Error(`Expected ${i} input tensors, received ${t}`);if(i>2)throw new Error("Support for more than 2 input tensors is not implemented yet.");const o=[];for(let e=0;e<r.length;++e){const t=r[e];if(!a.some((e=>-1!==e.indexOf(t))))throw new Error(`Output subscripts contain the label ${t} not present in the input subscripts.`);-1===o.indexOf(t)&&o.push(t)}for(let e=0;e<s.length;++e){const t=s[e];-1===o.indexOf(t)&&t!==Wc&&o.push(t)}const l=new Array(a.length);for(let e=0;e<i;++e){if(new Set(a[e].split("")).size!==a[e].length)throw new Error(`Found duplicate axes in input component ${a[e]}. Support for duplicate axes in input is not implemented yet.`);l[e]=[];for(let t=0;t<a[e].length;++t)l[e].push(o.indexOf(a[e][t]))}const u=o.length,c=[];for(let e=r.length;e<u;++e)c.push(e);return{allDims:o,summedDims:c,idDims:l}}function Gc(e,t){let n=new Array(e);n.fill(-1);for(let e=0;e<t.length;++e)n[t[e]]=e;const s=[];for(let t=0;t<e;++t)-1===n[t]&&s.push(t);return n=n.filter((e=>-1!==e)),{permutationIndices:n,expandDims:s}}function Hc(e,t,n){const s=new Array(e);for(let e=0;e<n.length;++e){const r=n[e].shape;for(let n=0;n<t[e].length;++n)void 0===s[t[e][n]]?s[t[e][n]]=r[n]:F(s[t[e][n]]===r[n],(()=>`Expected dimension ${s[t[e][n]]} at axis ${n} of input shaped ${JSON.stringify(r)}, but got dimension ${r[n]}`))}}function jc(e,t){const n=e,s=[];let r=0;0===e.length&&n.push(-1),r=e.length+1;for(let e=0;e<r;++e)s.push([]);const a=[];for(let e=0;e<n.length;++e){const r=qc(t,n[e]);for(const t of r)-1===a.indexOf(t)&&(s[e].push(t),a.push(t))}return{path:n,steps:s}}function Kc(e){return e.every(((e,t)=>e===t))}function qc(e,t){const n=[];for(let s=0;s<e.length;++s)0!==e[s].length&&-1===e[s].indexOf(t)&&-1!==t||n.push(s);return n}function Xc(e,t,n=0){let s=[];if("number"==typeof t)F(e.shape[n]%t==0,(()=>"Number of splits must evenly divide the axis.")),s=new Array(t).fill(e.shape[n]/t);else{const r=t.reduce(((e,t)=>(-1===t&&(e+=1),e)),0);F(r<=1,(()=>"There should be only one negative value in split array."));const a=t.indexOf(-1);if(-1!==a){const s=t.reduce(((e,t)=>t>0?e+t:e));t[a]=e.shape[n]-s}F(e.shape[n]===t.reduce(((e,t)=>e+t)),(()=>"The sum of sizes must match the size of the axis dimension.")),s=t}return s}function Yc(e){return`Received SparseTensor with denseShape[0] = 0 but\n  indices.shape[0] = ${e}`}function Jc(e,t){return`indices(${e}, 0) is invalid: ${t} < 0`}function Zc(e,t,n){return`indices(${e}, 0) is invalid: ${t} >= ${n}`}function Qc(e,t){return`only one output dimension may be -1, not both ${e} and ${t}`}function eh(e,t){return`size ${e} must be non-negative, not ${t}`}function th(){return"reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero"}function nh(e,t){return`Input to reshape is a SparseTensor with ${L(e)}\n  dense values, but the requested shape requires a multiple of ${L(t)}. inputShape=${e} outputShape= ${t}`}function sh(e,t){return`Input to reshape is a tensor with ${L(e)} dense values, but the requested shape has ${L(t)}. inputShape=${e} outputShape=${t}`}function rh(){return"segment ids must be >= 0"}function ah(){return"segment ids are not increasing"}function ih(e,t){return`Segment id ${e} out of range [0, ${t}), possibly because segmentIds input is not sorted.`}function oh(e,t,n){return`Bad: indices[${e}] == ${t} out of range [0, ${n})`}function lh(e,t){let n,s=!1;for(e<=hc?(n=e,s=!0):n=ee(e,Math.floor(Math.sqrt(e)));!s;)n>t||n===e?s=!0:n=ee(e,n+1);return n}function uh(e,t,n){const s=[],r=e.length;for(let a=0;a<r;a++)a!==t?s.push(e[a]):s.push(n);return s}function ch(e,t,n,s){const r=t.shape.length,a=e.shape.length;if(0!==s&&(s<-r||s>r))throw new Error(`Expect batchDims in the range of [-${r}, ${r}], but got ${s}`);if(s<0&&(s+=r),s>a)throw new Error(`batchDims (${s}) must be less than rank(x) (\n    ${a}).`);if(n<s)throw new Error(`batchDims (${s}) must be less than or equal to axis (${n}).`);for(let n=0;n<s;++n)if(e.shape[n]!==t.shape[n])throw new Error(`x.shape[${n}]: ${e.shape[n]} should be equal to indices.shape[${n}]: ${t.shape[n]}.`);const i=e.shape[n],o=[];let l=1,u=1,c=1;for(let t=0;t<s;++t)o.push(e.shape[t]),l*=e.shape[t];for(let t=s;t<n;t++)o.push(e.shape[t]),u*=e.shape[t];for(let e=s;e<r;e++)o.push(t.shape[e]);for(let t=n+1;t<a;t++)o.push(e.shape[t]),c*=e.shape[t];return{batchSize:l,sliceSize:c,outerSize:u,dimSize:i,outputShape:o}}function hh(e){try{return e.map((e=>ar(e)))}catch(e){throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${e}`)}}function ph(e){return e.map((e=>rr(e)))}function dh(e,t){const n=[];for(let e=0;e<t.length;e++)t[e]&&n.push(e);const s=Ua(e,"int32"),r=Ua([n.length,e.length],"int32");for(let t=0;t<n.length;t++){const a=s.indexToLoc(n[t]),i=t*e.length;r.values.set(a,i)}return r.toTensor()}!function(){for(const e of vi)ai(e)}();const fh={kernelName:xe,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Xa(e,uu(Ga(n,"float32"),-1))}}},mh={kernelName:we,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>{const t=Ja(Ga(n,"float32")),s=Ya(hi(ei(1),t));return bl(qa(e,s))}}}},gh={kernelName:ke,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>{const t=Ya(hi(Ja(Ga(n,"float32")),1));return qa(e,t)}}}},yh={kernelName:ve,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,s]=t,r=gi(n.shape,s.shape);return{a:()=>{let t=e;const s=mi(n.shape,r);return s.length>0&&(t=Qo(t,s)),mo(t,n.shape)},b:()=>{let t=e;const n=mi(s.shape,r);return n.length>0&&(t=Qo(t,n)),mo(t,s.shape)}}}},bh={kernelName:Ie,saveAllInputs:!0,gradFunc:(e,t)=>{const n={};return t.forEach(((t,s)=>{n[s]=()=>e.clone()})),n}},xh={kernelName:Te,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Za(n)}}},wh={kernelName:$e,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Za(n)}}},kh={kernelName:Ee,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>qa(e,Ya(hi(ei(1),Ja(Ga(n,"float32")))))}}},vh={kernelName:Ce,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>{const t=Ya(ja(ei(1),Ja(Ga(n,"float32"))));return qa(e,t)}}}},Ih={kernelName:_e,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,s]=t,r=gi(n.shape,s.shape);return{a:()=>{const t=ja(Ja(n),Ja(s));let a=Xa(e,qa(s,t));const i=mi(n.shape,r);return i.length>0&&(a=Qo(a,i)),mo(a,n.shape)},b:()=>{const t=ja(Ja(n),Ja(s));let a=bl(Xa(e,qa(n,t)));const i=mi(s.shape,r);return i.length>0&&(a=Qo(a,i)),mo(a,s.shape)}}}},Nh={kernelName:Re,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>qa(e,ja(Ja(Ga(n,"float32")),1))}}},Sh={kernelName:Ae,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>qa(e,hi(ei(1),Ja(Ga(n,"float32"))))}}},Th=Jr({avgPool3dGrad_:function(e,t,n,s,r,a){const i=Xr(e,"dy","avgPool3dGrad"),o=Xr(t,"input","avgPool3dGrad");let l=i,u=o,c=!1;4===o.rank&&(c=!0,l=mo(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]]),u=mo(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),F(5===l.rank,(()=>`Error in avgPool3dGrad: dy must be rank 5 but got rank ${l.rank}.`)),F(5===u.rank,(()=>`Error in avgPool3dGrad: input must be rank 5 but got rank ${u.rank}.`)),fo("avgPool3dGrad",r,a);const h={dy:l,input:u},p={filterSize:n,strides:s,pad:r,dimRoundingMode:a},d=Wr.runKernel(Me,h,p);return c?mo(d,[d.shape[1],d.shape[2],d.shape[3],d.shape[4]]):d}}),$h={kernelName:Oe,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[s]=t,{filterSize:r,strides:a,pad:i,dimRoundingMode:o}=n;return{x:()=>Th(e,s,r,a,i,o)}}},Eh=Jr({avgPoolGrad_:function(e,t,n,s,r){const a=Xr(e,"dy","avgPoolGrad"),i=Xr(t,"input","avgPoolGrad");F(i.rank===a.rank,(()=>`Rank of input (${i.rank}) does not match rank of dy (${a.rank})`));let o=i,l=a,u=!1;3===i.rank&&(u=!0,o=mo(i,[1,i.shape[0],i.shape[1],i.shape[2]]),l=mo(a,[1,a.shape[0],a.shape[1],a.shape[2]])),F(4===l.rank,(()=>`Error in avgPoolGrad: dy must be rank 4 but got rank ${l.rank}.`)),F(4===o.rank,(()=>`Error in avgPoolGrad: input must be rank 4 but got rank ${o.rank}.`));const c={dy:l,input:o},h={filterSize:n,strides:s,pad:r},p=Wr.runKernel(Fe,c,h);return u?mo(p,[p.shape[1],p.shape[2],p.shape[3]]):p}}),Ch={kernelName:De,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[s]=t,{filterSize:r,strides:a,pad:i}=n;return{x:()=>Eh(e,s,r,a,i)}}},Rh={kernelName:Le,inputsToSave:["a","b"],gradFunc:(e,t,n)=>{const[s,r]=t,{transposeA:a,transposeB:i}=n;return a||i?!a&&i?{a:()=>hl(e,r,!1,!1),b:()=>hl(e,s,!0,!1)}:a&&!i?{a:()=>hl(r,e,!1,!0),b:()=>hl(s,e,!1,!1)}:{a:()=>hl(r,e,!0,!0),b:()=>hl(e,s,!0,!0)}:{a:()=>hl(e,r,!1,!0),b:()=>hl(s,e,!0,!1)}}},Ah=Jr({spaceToBatchND_:function(e,t,n){const s=Xr(e,"x","spaceToBatchND");F(s.rank>=1+t.length,(()=>`input rank ${s.rank} should be > than [blockShape] ${t.length}`)),F(n.length===t.length,(()=>`paddings.shape[0] ${n.length} must be equal to [blockShape] ${t.length}`)),F(s.shape.reduce(((e,s,r)=>r>0&&r<=t.length?e&&(s+n[r-1][0]+n[r-1][1])%t[r-1]==0:e),!0),(()=>`input spatial dimensions ${s.shape.slice(1)} with paddings ${n.toString()} must be divisible by blockShapes ${t.toString()}`));const r={x:s},a={blockShape:t,paddings:n};return Wr.runKernel(Zn,r,a)}}),_h={kernelName:ze,gradFunc:(e,t,n)=>{const{blockShape:s,crops:r}=n;return{x:()=>Ah(e,s,r)}}},Dh={kernelName:"BroadcastTo",gradFunc:(e,t,n)=>{const s=n,r=s.inputShape,a=s.shape,i=Array.from(a);for(let e=r.length-1;e>=0;e--)if(r[e]===a[e])i[e]=1;else if(1!==r[e])throw new Error(`broadcastTo(): [${r}] cannot be broadcast to [${a}].`);const o=[];for(let e=0;e<i.length;e++)i[e]>1&&o.push(e);return{x:()=>Qo(e,o,!0)}}},Fh={kernelName:Ve,gradFunc:e=>({x:()=>e.clone()})},Oh={kernelName:Ue,gradFunc:e=>({x:()=>Za(e)})},Mh={kernelName:Ge,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[s]=t,{clipValueMin:r,clipValueMax:a}=n;return{x:()=>Zl(cl(qo(s,r),Pu(s,a)),e,Za(e))}}},Lh={kernelName:je,inputsToSave:["x"],gradFunc:fh.gradFunc},zh={kernelName:Ke,saveAllInputs:!0,gradFunc:(e,t,n)=>{const s=t.map((e=>e.shape)),{axis:r}=n,a=G(r,t[0].shape)[0],i=s.map((e=>e[a]));return Gl(e,i,a).map((e=>()=>e))}},Bh={kernelName:qe,inputsToSave:["x","filter"],gradFunc:(e,t,n)=>{const[s,r]=t,{dilations:a,strides:i,pad:o,dataFormat:l}=n;return F(uo(a),(()=>`Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${a}'`)),{x:()=>Ao(s.shape,e,r,i,o,l),filter:()=>ou(s,e,r.shape,i,o,l)}}},Ph={kernelName:Ye,inputsToSave:["dy","filter"],gradFunc:(e,t,n)=>{const[s,r]=t,{strides:a,pad:i,dataFormat:o,dimRoundingMode:l}=n;return{dy:()=>Co(e,r,a,i,o,1,l),filter:()=>ou(e,s,r.shape,a,i,o,l)}}},Wh=Jr({conv3DBackpropFilter_:function(e,t,n,s,r){let a=e;4===e.rank&&(a=mo(e,[1,e.shape[0],e.shape[1],e.shape[2],e.shape[3]]));let i=t;4===i.rank&&(i=mo(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]])),F(5===a.rank,(()=>`Error in conv3dDerFilter: input must be rank 5, but got shape ${a.shape}.`)),F(5===i.rank,(()=>`Error in conv3dDerFilter: dy must be rank 5, but got shape ${i.shape}.`)),F(5===n.length,(()=>`Error in conv3dDerFilter: filterShape must be length 5, but got ${n}.`)),F(a.shape[4]===n[3],(()=>`Error in conv3dDerFilter: depth of input ${a.shape[4]}) must match input depth in filter (${n[3]}.`)),F(i.shape[4]===n[4],(()=>`Error in conv3dDerFilter: depth of dy (${i.shape[4]}) must match output depth for filter (${n[4]}).`));const o={x:a,dy:i},l={strides:s,pad:r,filterShape:n};return Wr.runKernel(Ze,o,l)}}),Vh={kernelName:Je,inputsToSave:["x","filter"],gradFunc:(e,t,n)=>{const{dilations:s,strides:r,pad:a}=n;F(uo(s),(()=>`Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${s}'`));const[i,o]=t;return{x:()=>Fo(i.shape,e,o,r,a),filter:()=>Wh(i,e,o.shape,r,a)}}},Uh=Jr({sin_:function(e){const t={x:Xr(e,"x","sin","float32")};return Wr.runKernel(Hn,t)}}),Gh={kernelName:et,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Xa(bl(Uh(Ga(n,"float32"))),e)}}},Hh=Jr({sinh_:function(e){const t={x:Xr(e,"x","sinh")};return Wr.runKernel(jn,t)}}),jh={kernelName:tt,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Xa(Hh(Ga(n,"float32")),e)}}},Kh=Jr({cumsum_:function(e,t=0,n=!1,s=!1){const r={x:Xr(e,"x","cumsum")},a={axis:t,exclusive:n,reverse:s};return Wr.runKernel(st,r,a)}}),qh={kernelName:st,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[s]=t,{axis:r,exclusive:a,reverse:i}=n;return{x:()=>{const t=il([r],s.rank);let n=Kh(e,r,a,!i);return null!=t&&(n=tu(n,t)),n}}}},Xh={kernelName:ot,inputsToSave:["x","filter"],gradFunc:(e,t,n)=>{const{dilations:s,strides:r,pad:a,dimRoundingMode:i}=n,o=null==s?[1,1]:s;F(uo(o),(()=>`Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${o}'`));const[l,u]=t;return F(4===l.rank,(()=>`Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${l.rank}.`)),F(4===u.rank,(()=>`Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${u.rank}.`)),F(l.shape[3]===u.shape[2],(()=>`Error in gradient of depthwiseConv2d: number of input channels (${l.shape[3]}) must match the inChannels dimension in filter ${u.shape[2]}.`)),F(co(r,o),(()=>`Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${r} and dilations '${o}'.`)),fo("depthwiseConv2d",a,i),{x:()=>gu(l.shape,e,u,r,a,o,i),filter:()=>mu(l,e,u.shape,r,a,o,i)}}},Yh={kernelName:ht,inputsToSave:["x","filter"],gradFunc:(e,t,n)=>{const[s,r]=t,a={x:s,filter:r,dy:e},i={x:s,filter:r,dy:e};return{x:()=>Wr.runKernel(pt,a,n),filter:()=>Wr.runKernel(dt,i,n)}}},Jh={kernelName:gt,outputsToSave:[!0],gradFunc:(e,t)=>{const[n]=t,s={dy:e,y:n};return{x:()=>Wr.runKernel(yt,s)}}},Zh={kernelName:bt,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t,s=Xa(Wo(bl(Ja(n))),2/Math.sqrt(Math.PI));return{x:()=>Xa(e,s)}}},Qh={kernelName:wt,outputsToSave:[!0],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Xa(e,n)}}},ep={kernelName:kt,inputsToSave:["input"],gradFunc:(e,t)=>{const[n]=t;return{input:()=>mo(e,n.shape)}}},tp={kernelName:vt,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Xa(e,Wo(n))}}},np={kernelName:Tt,gradFunc:e=>({x:()=>Za(e)})},sp={kernelName:$t,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,s]=t,r=gi(n.shape,s.shape);return{a:()=>{const t=qa(e,Ga(s,"float32")),a=mi(n.shape,r);return a.length>0?mo(Qo(t,a),n.shape):t},b:()=>{let t=Xa(e,Ga(n,"float32"));const a=mi(s.shape,r);a.length>0&&(t=mo(Qo(t,a),s.shape));const i=Ja(s);return bl(qa(t,Ga(i,"float32")))}}}},rp=Jr({rsqrt_:function(e){const t={x:Xr(e,"x","rsqrt","float32")};return Wr.runKernel(zn,t)}}),ap={kernelName:Et,inputsToSave:["x","mean","variance","scale"],gradFunc:(e,t,n)=>{const{varianceEpsilon:s}=n,[r,a,i,o]=t,l=null==o?ei(1):o,u=mi(a.shape,r.shape),c=[];if(1===a.rank){for(let e=0;e<r.shape.length-1;++e)c.push(r.shape[e]);c.push(1)}const h=hi(r,a),p=Xa(e,l),d=rp(ja(i,ei(s))),f=Xa(Xa(Xa(d,d),d),ei(-.5));return{x:()=>1===a.rank?mo(Xa(Xa(e,Uo(mo(d,[1,1,1,a.shape[0]]),c)),l),r.shape):mo(Xa(Xa(e,d),l),r.shape),mean:()=>{let e=Xa(Xa(d,ei(-1)),p);return 1===a.rank&&(e=Qo(e,u)),mo(e,a.shape)},variance:()=>{let e=Xa(Xa(f,h),p);return 1===a.rank&&(e=Qo(e,u)),mo(e,a.shape)},scale:()=>{const t=Xa(h,d);let n=Xa(e,t);return 1===a.rank&&(n=Qo(n,u)),mo(n,a.shape)},offset:()=>{let t=e;return 1===a.rank&&(t=Qo(t,u)),mo(t,a.shape)}}}},ip=Jr({unsortedSegmentSum_:function(e,t,n){const s=Xr(e,"x","unsortedSegmentSum"),r=Xr(t,"segmentIds","unsortedSegmentSum","int32");F(B(n),(()=>"numSegments must be of dtype int"));const a={x:s,segmentIds:r},i={numSegments:n};return Wr.runKernel(vs,a,i)}}),op={kernelName:Ct,inputsToSave:["x","indices"],gradFunc:(e,t,n)=>{const[s,r]=t,{axis:a,batchDims:i}=n,o=G(a,s.shape)[0],l=(e,t,n)=>()=>{const s=e.shape,r=t.size,i=s.slice(0,o),l=i.length,u=s.slice(a,s.length).slice(1),c=u.length,h=lp(0,l),p=lp(l+1,l+1+c),d=up([i,[r],u]),f=mo(n,d),m=mo(t,[r]),g=up([[l],h,p]),y=tu(f,g);let b=ip(y,m,e.shape[o]);const x=ol(g);return b=tu(b,x),b};if(1===i){const t=s.shape[0],n=s.split(t,0);return{x:()=>{const t=jl(n.map(((t,n)=>l(t,r.slice(n,1),e.slice(n,1))())));return t.reshape(s.shape)},indices:()=>r}}return{x:l(s,r,e),indices:()=>r}}};function lp(e,t){const n=[];for(let s=e;s<t;++s)n.push(s);return n}function up(e){const t=[];for(let n=0;n<e.length;++n)for(let s=0;s<e[n].length;++s)t.push(e[n][s]);return t}const cp={kernelName:_t,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,s]=t;return{a:()=>Za(n),b:()=>Za(s)}}},hp={kernelName:Dt,gradFunc:e=>({x:()=>Ga(e,"float32")})},pp={kernelName:Mt,gradFunc:e=>({x:()=>Za(e)})},dp={kernelName:Lt,gradFunc:e=>({x:()=>Za(e)})},fp={kernelName:zt,gradFunc:e=>({x:()=>Za(e)})},mp={kernelName:Bt,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[s]=t,{alpha:r}=n,a=Ko(s,0);return{x:()=>Zl(a,e,Xa(e,r))}}},gp={kernelName:Gt,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>qa(e,ja(n,1))}}},yp={kernelName:Ut,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>qa(e,Ga(n,"float32"))}}},bp={kernelName:"LogSoftmax",inputsToSave:[],outputsToSave:[!0],gradFunc:(e,t,n)=>{const[s]=t,{axis:r}=n;return{logits:()=>{const t=Wo(s);return hi(e,Xa(Qo(e,r,!0),t))}}}},xp=Jr({localResponseNormalizationBackprop_:function(e,t,n,s=5,r=1,a=1,i=.5){const o={x:e,y:t,dy:n},l={depthRadius:s,bias:r,alpha:a,beta:i};return Wr.runKernel(Xt,o,l)}}),wp={kernelName:qt,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const[s,r]=t,{depthRadius:a,bias:i,alpha:o,beta:l}=n;return{x:()=>xp(s,r,e,a,i,o,l)}}};function kp(e,t,n,s){return t.rank<n.rank&&(t=mo(t,rl(t.shape,s))),e.rank<n.rank&&(e=mo(e,rl(e.shape,s))),{x:()=>Xa(e,Ga(Bo(n,t),e.dtype))}}const vp={kernelName:Yt,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const s=n,{reductionIndices:r}=s,a=t[0],i=kp(e,t[1],a,G(r,a.shape));return{x:()=>i.x()}}},Ip={kernelName:Jt,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,s]=t;return{a:()=>Xa(e,Ga(qo(n,s),"float32")),b:()=>Xa(e,Ga(Gu(n,s),"float32"))}}},Np=Jr({maxPool3dGrad_:function(e,t,n,s,r,a,i){const o=Xr(e,"dy","maxPool3dGrad"),l=Xr(t,"input","maxPool3dGrad"),u=Xr(n,"output","maxPool3dGrad");let c=o,h=l,p=u,d=!1;4===l.rank&&(d=!0,c=mo(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]]),h=mo(l,[1,l.shape[0],l.shape[1],l.shape[2],l.shape[3]]),p=mo(u,[1,u.shape[0],u.shape[1],u.shape[2],u.shape[3]])),F(5===c.rank,(()=>`Error in maxPool3dGrad: dy must be rank 5 but got rank ${c.rank}.`)),F(5===h.rank,(()=>`Error in maxPool3dGrad: input must be rank 5 but got rank ${h.rank}.`)),F(5===p.rank,(()=>`Error in maxPool3dGrad: output must be rank 5 but got rank ${p.rank}.`)),fo("maxPool3dGrad",a,i);const f={dy:c,input:h,output:p},m={filterSize:s,strides:r,pad:a,dimRoundingMode:i},g=Wr.runKernel(tn,f,m);return d?mo(g,[g.shape[1],g.shape[2],g.shape[3],g.shape[4]]):g}}),Sp={kernelName:en,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const[s,r]=t,{filterSize:a,strides:i,pad:o,dimRoundingMode:l}=n;return{x:()=>Np(e,s,r,a,i,o,l)}}},Tp=Jr({maxPoolGrad_:function(e,t,n,s,r,a,i){const o=Xr(e,"dy","maxPoolGrad"),l=Xr(t,"input","maxPoolGrad"),u=Xr(n,"output","maxPoolGrad");F(l.rank===o.rank,(()=>`Rank of input (${l.rank}) does not match rank of dy (${o.rank})`)),F(4===o.rank,(()=>`Error in maxPoolGrad: dy must be rank 4 but got rank ${o.rank}.`)),F(4===l.rank,(()=>`Error in maxPoolGrad: input must be rank 4 but got rank ${l.rank}.`)),fo("maxPoolGrad",a,i);const c={dy:o,input:l,output:u},h={filterSize:s,strides:r,pad:a,dimRoundingMode:i};return Wr.runKernel(Qt,c,h)}}),$p={kernelName:Zt,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const[s,r]=t,{filterSize:a,strides:i,pad:o}=n;return{x:()=>Tp(e,s,r,a,i,o)}}},Ep={kernelName:sn,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[s]=t,{axis:r}=n,a=G(r,s.shape),i=L(sl(s.shape,a)[1]);return{x:()=>{const t=s.shape.slice();a.forEach((e=>{t[e]=1}));const n=mo(e,t);return qa(Xa(n,vl(s.shape,"float32")),i)}}}},Cp={kernelName:rn,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const s=n,{axis:r}=s,[a,i]=t,o=kp(e,i,a,G(r,a.shape));return{x:()=>o.x()}}},Rp={kernelName:an,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,s]=t;return{a:()=>Xa(e,Ga(Pu(n,s),"float32")),b:()=>Xa(e,Ga(Ko(n,s),"float32"))}}},Ap={kernelName:on,inputsToSave:["x"],gradFunc:(e,t,n)=>{const s=t[0],{paddings:r}=n,a=r.map((e=>e[0]));return{x:()=>Ll(e,a,s.shape)}}},_p={kernelName:ln,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,s]=t,r=gi(n.shape,s.shape);return{a:()=>{const t=mi(n.shape,r);return t.length>0?mo(Qo(e,t),n.shape):e},b:()=>{const t=Xa(e,bl(Ho(qa(n,s)))),a=mi(s.shape,r);return a.length>0?mo(Qo(t,a),s.shape):t}}}},Dp={kernelName:cn,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,s]=t,r=gi(n.shape,s.shape);return{a:()=>{const t=Xa(e,Ga(s,"float32")),a=mi(n.shape,r);return a.length>0?mo(Qo(t,a),n.shape):t},b:()=>{const t=Xa(e,Ga(n,"float32")),a=mi(s.shape,r);return a.length>0?mo(Qo(t,a),s.shape):t}}}},Fp={kernelName:hn,gradFunc:e=>({x:()=>bl(e)})},Op={kernelName:yn,inputsToSave:["indices"],gradFunc:(e,t)=>{const n=t[0];return{indices:()=>kl(n.shape,"float32")}}},Mp={kernelName:gn,gradFunc:e=>({x:()=>Za(e)})},Lp={kernelName:bn,saveAllInputs:!0,gradFunc:(e,t,n)=>{const{axis:s}=n;return Jl(e,s).map((e=>()=>e))}},zp={kernelName:xn,inputsToSave:["x"],gradFunc:(e,t,n)=>{const s=t[0],{paddings:r}=n,a=r.map((e=>e[0]));return{x:()=>Ll(e,a,s.shape)}}},Bp={kernelName:wn,inputsToSave:["a","b"],outputsToSave:[!0],gradFunc:(e,t)=>{const[n,s,r]=t,a=n,i=s,o=gi(a.shape,i.shape);return{a:()=>{const t=Ga(i,"float32");let n=Xa(e,Xa(t,ci(a,hi(t,ei(1)))));const s=mi(a.shape,o);return s.length>0&&(n=Qo(n,s)),mo(n,a.shape)},b:()=>{const t=Ko(a,0),n=Zl(t,Yo(a),Za(a));let s=Xa(e,Xa(r,n));const l=mi(i.shape,o);return l.length>0&&(s=Qo(s,l)),mo(s,i.shape)}}}},Pp={kernelName:kn,inputsToSave:["x","alpha"],gradFunc:(e,t)=>{const[n,s]=t,r=Ko(n,0);return{x:()=>Zl(r,e,Xa(e,s)),alpha:()=>{let t=Zl(r,Za(e),Xa(e,n));const a=mi(s.shape,e.shape);return a.length>0&&(t=Qo(t,a)),mo(t,s.shape)}}}},Wp=Jr({cumprod_:function(e,t=0,n=!1,s=!1){const r={x:Xr(e,"x","cumprod")},a={axis:t,exclusive:n,reverse:s};return Wr.runKernel(nt,r,a)}});const Vp={kernelName:vn,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[s]=t,{axis:r}=n;let a=[];return a=null==r?s.shape.map(((e,t)=>t)):"number"==typeof r?[r]:r,{x:()=>function(e,t,n){const s=e.shape.length,r=s-n.length,a=il(n,s);let i=e;null!=a&&(i=tu(e,a));const o=i.shape.slice(),l=o.splice(s-n.length,n.length).reduce(((e,t)=>e*t),1);o.push(l);let u=function(e,t,n){const s=e.shape.slice();s[n]=1;const r=mo(t,s),a=Wp(e,n,!0,!1),i=Wp(e,n,!0,!0),o=Xa(a,i);return Xa(r,o)}(i.reshape(o),t,r);if(u=u.reshape(i.shape),null!=a){const e=ol(a);u=tu(u,e)}return u}(s,e,a)}}},Up={kernelName:ft,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,s]=t,r=gi(n.shape,s.shape);return{a:()=>{const t=qa(e,Ga(s,"float32")),a=mi(n.shape,r);return a.length>0?mo(Qo(t,a),n.shape):t},b:()=>{let t=Xa(e,Ga(n,"float32"));const a=mi(s.shape,r);a.length>0&&(t=mo(Qo(t,a),s.shape));const i=Ja(s);return bl(qa(t,Ga(i,"float32")))}}}},Gp={kernelName:En,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>qa(e,bl(Ja(n)))}}},Hp={kernelName:On,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t,s=Xa(Pu(n,6),uu(n));return{x:()=>Xa(e,Ga(s,"float32"))}}},jp={kernelName:Cn,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Xa(e,Ga(uu(n),"float32"))}}},Kp={kernelName:Rn,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mo(e,n.shape)}}},qp={kernelName:Dn,inputsToSave:["images"],gradFunc:(e,t,n)=>{const[s]=t,r={dy:e,images:s};return{images:()=>Wr.runKernel(Fn,r,n)}}},Xp={kernelName:An,inputsToSave:["images"],gradFunc:(e,t,n)=>{const[s]=t,r={dy:e,images:s};return{images:()=>Wr.runKernel(_n,r,n)}}},Yp={kernelName:Mn,gradFunc:(e,t,n)=>{const{dims:s}=n,r=G(s,e.shape);return{x:()=>Dl(e,r)}}},Jp={kernelName:Ln,gradFunc:e=>({x:()=>Za(e)})},Zp={kernelName:zn,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>bl(qa(e,Xa(ci(n,1.5),2)))}}},Qp=Jr({logicalNot_:function(e){const t={x:Xr(e,"x","logicalNot","bool")};return Wr.runKernel(jt,t)}}),ed={kernelName:Vn,inputsToSave:["condition"],gradFunc:(e,t)=>{const[n]=t;return{condition:()=>Ga(Za(n),"float32"),t:()=>Xa(e,Ga(n,e.dtype)),e:()=>Xa(e,Ga(Qp(n),e.dtype))}}},td={kernelName:Un,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>{const t=Ko(n,ei(0)),s=ei(Ic),r=ei(Nc),a=Xa(e,r),i=Xa(Xa(e,s),Wo(Ga(n,"float32")));return Zl(t,a,i)}}}},nd={kernelName:qn,outputsToSave:[!0],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Xa(e,Xa(n,hi(ei(1),n)))}}},sd={kernelName:Kn,gradFunc:e=>({x:()=>Za(e)})},rd=Jr({cos_:function(e){const t={x:Xr(e,"x","cos","float32")};return Wr.runKernel(et,t)}}),ad={kernelName:Hn,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Xa(rd(Ga(n,"float32")),e)}}},id=Jr({cosh_:function(e){const t={x:Xr(e,"x","cosh","float32")};return Wr.runKernel(tt,t)}}),od={kernelName:jn,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Xa(id(Ga(n,"float32")),e)}}},ld={kernelName:Gn,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[s]=t,{begin:r,size:a}=n,i=s.shape,[o,l]=Ki(s,r,a),u=[];for(let t=0;t<e.rank;t++)u.push([o[t],i[t]-o[t]-l[t]]);return{x:()=>Nl(e,u)}}},ud={kernelName:es,outputsToSave:[!0],gradFunc:(e,t,n)=>{const[s]=t,{dim:r}=n,a=Xa(e,s);return{logits:()=>hi(a,Xa(Qo(a,[r],!0),s))}}},cd={kernelName:Xn,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Xa(e,Ml(n))}}},hd=Jr({batchToSpaceND_:function(e,t,n){const s=Xr(e,"x","batchToSpaceND"),r=t.reduce(((e,t)=>e*t));F(s.rank>=1+t.length,(()=>`input rank is ${s.rank} but should be > than blockShape.length ${t.length}`)),F(n.length===t.length,(()=>`crops.length is ${n.length} but should be equal to blockShape.length  ${t.length}`)),F(s.shape[0]%r==0,(()=>`input tensor batch is ${s.shape[0]} but is not divisible by the product of the elements of blockShape ${t.join(" * ")} === ${r}`));const a={x:s},i={blockShape:t,crops:n};return Wr.runKernel(ze,a,i)}}),pd={kernelName:Zn,gradFunc:(e,t,n)=>{const{blockShape:s,paddings:r}=n;return{x:()=>hd(e,s,r)}}},dd={kernelName:Qn,gradFunc:(e,t,n)=>{const{axis:s}=n;return{x:()=>No(e,s)}}},fd=[fh,mh,gh,yh,bh,xh,wh,kh,vh,Ih,Nh,Sh,$h,Ch,Rh,_h,Dh,Fh,Oh,Mh,Lh,zh,Ph,Bh,Vh,Gh,jh,qh,Xh,Yh,Up,Jh,Zh,Qh,ep,tp,sp,np,ap,op,cp,hp,pp,dp,fp,mp,gp,yp,bp,wp,vp,vp,Ip,Sp,$p,Ep,Cp,Rp,Ap,_p,Dp,Fp,Op,Mp,Lp,zp,zp,Bp,Pp,Vp,Gp,Hp,jp,Kp,qp,Xp,Yp,Jp,Zp,ed,td,nd,sd,ad,od,ld,ud,cd,pd,pd,dd,dd,{kernelName:Yn,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>qa(e,Xa(Ya(Ga(n,"float32")),2))}}},{kernelName:is,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,s]=t,r=ei(2);return{a:()=>Xa(e,Xa(r,hi(n,s))),b:()=>Xa(e,Xa(r,hi(s,n)))}}},{kernelName:os,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Xa(e,Xa(Ga(n,"float32"),2))}}},{kernelName:Ns,gradFunc:e=>({x:()=>Za(e)})},{kernelName:ds,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,s]=t,r=gi(n.shape,s.shape);return{a:()=>{let t=e;const s=mi(n.shape,r);return s.length>0&&(t=Qo(t,s)),mo(t,n.shape)},b:()=>{let t=e;const n=mi(s.shape,r);return n.length>0&&(t=Qo(t,n)),mo(bl(t),s.shape)}}}},{kernelName:Jn,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[s]=t,r=s.shape.slice(),{axis:a}=n;G(a,s.shape).forEach((e=>{r[e]=1}));const i=mo(e,r),o=Xa(i,vl(s.shape,"float32"));return{x:()=>o}}},{kernelName:fs,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>qa(e,Ja(rd(n)))}}},{kernelName:ms,outputsToSave:[!0],gradFunc:(e,t)=>{const[n]=t;return{x:()=>Xa(hi(ei(1),Ja(n)),e)}}},{kernelName:gs,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[s]=t,{reps:r}=n;return{x:()=>{let t=Za(s);if(1===s.rank)for(let n=0;n<r[0];++n)t=ja(t,Ll(e,[n*s.shape[0]],[s.shape[0]]));else if(2===s.rank)for(let n=0;n<r[0];++n)for(let a=0;a<r[1];++a)t=ja(t,Ll(e,[n*s.shape[0],a*s.shape[1]],[s.shape[0],s.shape[1]]));else if(3===s.rank)for(let n=0;n<r[0];++n)for(let a=0;a<r[1];++a)for(let i=0;i<r[2];++i)t=ja(t,Ll(e,[n*s.shape[0],a*s.shape[1],i*s.shape[2]],[s.shape[0],s.shape[1],s.shape[2]]));else{if(4!==s.rank)throw new Error(`Gradient for tile operation is not implemented for rank-${s.rank} tensors yet.`);for(let n=0;n<r[0];++n)for(let a=0;a<r[1];++a)for(let i=0;i<r[2];++i)for(let o=0;o<r[3];++o)t=ja(t,Ll(e,[n*s.shape[0],a*s.shape[1],i*s.shape[2],o*s.shape[3]],[s.shape[0],s.shape[1],s.shape[2],s.shape[3]]))}return t}}}},{kernelName:xs,gradFunc:(e,t,n)=>{const s=n,{perm:r}=s,a=ol(r);return{x:()=>tu(e,a)}}},{kernelName:ks,gradFunc:(e,t,n)=>{const s=n,{axis:r}=s;return{value:()=>jl(e,r)}}},{kernelName:vs,inputsToSave:["segmentIds"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>function(e,t){const n=yi(t,Za(t)),s=jo(e,n);let r=qo(t,ei(0,"int32"));const a=s.rank-r.rank;for(let e=0;e<a;++e)r=Vo(r,e+1);r=cl(r,vl(s.shape,"bool"));const i=Za(s);return Zl(r,s,i)}(e,n)}}},{kernelName:Is,gradFunc:e=>({x:()=>Za(e)})}];for(const e of fd)Ls(e);kr().prototype.abs=function(){return this.throwIfDisposed(),di(this)};const md=Jr({acos_:function(e){const t={x:Xr(e,"x","acos")};return Wr.runKernel(we,t)}});kr().prototype.acos=function(){return this.throwIfDisposed(),md(this)};const gd=Jr({acosh_:function(e){const t={x:Xr(e,"x","acosh")};return Wr.runKernel(ke,t)}});kr().prototype.acosh=function(){return this.throwIfDisposed(),gd(this)},kr().prototype.add=function(e){return this.throwIfDisposed(),ja(this,e)},kr().prototype.all=function(e,t){return this.throwIfDisposed(),Yi(this,e,t)},kr().prototype.any=function(e,t){return this.throwIfDisposed(),Ji(this,e,t)},kr().prototype.argMax=function(e){return this.throwIfDisposed(),Zi(this,e)};const yd=Jr({argMin_:function(e,t=0){const n={x:Xr(e,"x","argMin")},s={axis:t};return Wr.runKernel($e,n,s)}});kr().prototype.argMin=function(e){return this.throwIfDisposed(),yd(this,e)},kr().prototype.asScalar=function(){return this.throwIfDisposed(),F(1===this.size,(()=>"The array must have only 1 element.")),mo(this,[])},kr().prototype.asType=function(e){return this.throwIfDisposed(),Ga(this,e)},kr().prototype.as1D=function(){return this.throwIfDisposed(),mo(this,[this.size])},kr().prototype.as2D=function(e,t){return this.throwIfDisposed(),mo(this,[e,t])},kr().prototype.as3D=function(e,t,n){return this.throwIfDisposed(),mo(this,[e,t,n])},kr().prototype.as4D=function(e,t,n,s){return this.throwIfDisposed(),mo(this,[e,t,n,s])},kr().prototype.as5D=function(e,t,n,s,r){return this.throwIfDisposed(),mo(this,[e,t,n,s,r])};const bd=Jr({asin_:function(e){const t={x:Xr(e,"x","asin")};return Wr.runKernel(Ee,t)}});kr().prototype.asin=function(){return this.throwIfDisposed(),bd(this)};const xd=Jr({asinh_:function(e){const t={x:Xr(e,"x","asinh")};return Wr.runKernel(Ce,t)}});kr().prototype.asinh=function(){return this.throwIfDisposed(),xd(this)};const wd=Jr({atan_:function(e){const t={x:Xr(e,"x","atan")};return Wr.runKernel(Re,t)}});kr().prototype.atan=function(){return this.throwIfDisposed(),wd(this)};const kd=Jr({atan2_:function(e,t){let n=Xr(e,"a","atan2"),s=Xr(t,"b","atan2");[n,s]=Dr(n,s);const r={a:n,b:s};return Wr.runKernel(_e,r)}});kr().prototype.atan2=function(e){return this.throwIfDisposed(),kd(this,e)};const vd=Jr({atanh_:function(e){const t={x:Xr(e,"x","atanh")};return Wr.runKernel(Ae,t)}});kr().prototype.atanh=function(){return this.throwIfDisposed(),vd(this)},kr().prototype.avgPool=function(e,t,n,s){return this.throwIfDisposed(),go(this,e,t,n,s)},kr().prototype.batchToSpaceND=function(e,t){return this.throwIfDisposed(),hd(this,e,t)},kr().prototype.batchNorm=function(e,t,n,s,r){return this.throwIfDisposed(),bo(this,e,t,n,s,r)},kr().prototype.broadcastTo=function(e){return this.throwIfDisposed(),vo(this,e)},kr().prototype.cast=function(e){return this.throwIfDisposed(),Ga(this,e)};const Id=Jr({ceil_:function(e){const t={x:Xr(e,"x","ceil","float32")};return Wr.runKernel(Ue,t)}});kr().prototype.ceil=function(){return this.throwIfDisposed(),Id(this)},kr().prototype.clipByValue=function(e,t){return this.throwIfDisposed(),Io(this,e,t)},kr().prototype.concat=function(e,t){return this.throwIfDisposed(),e instanceof wr&&(e=[e]),No([this,...e],t)},kr().prototype.conv1d=function(e,t,n,s,r,a){return this.throwIfDisposed(),Ro(this,e,t,n,s,r,a)},kr().prototype.conv2dTranspose=function(e,t,n,s,r){return this.throwIfDisposed(),_o(this,e,t,n,s,r)},kr().prototype.conv2d=function(e,t,n,s,r,a){return this.throwIfDisposed(),Co(this,e,t,n,s,r,a)},kr().prototype.cos=function(){return this.throwIfDisposed(),rd(this)},kr().prototype.cosh=function(){return this.throwIfDisposed(),id(this)},kr().prototype.cumprod=function(e,t,n){return this.throwIfDisposed(),Wp(this,e,t,n)},kr().prototype.cumsum=function(e,t,n){return this.throwIfDisposed(),Kh(this,e,t,n)};const Nd=Jr({depthToSpace_:function(e,t,n="NHWC"){const s=Xr(e,"x","depthToSpace","float32"),r="NHWC"===n?s.shape[1]:s.shape[2],a="NHWC"===n?s.shape[2]:s.shape[3],i="NHWC"===n?s.shape[3]:s.shape[1];F(t>1,(()=>`blockSize should be > 1 for depthToSpace, but was: ${t}`)),F(r*t>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${r} and ${t}  for depthToSpace with input shape\n    ${s.shape}`)),F(a*t>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${a} and ${t} for depthToSpace with input shape\n        ${s.shape}`)),F(i%(t*t)==0,(()=>`Dimension size must be evenly divisible by ${t*t} but is ${i} for depthToSpace with input shape ${s.shape}`));const o={x:s},l={blockSize:t,dataFormat:n};return Wr.runKernel(it,o,l)}});kr().prototype.depthToSpace=function(e,t){return this.throwIfDisposed(),Nd(this,e,t)},kr().prototype.depthwiseConv2d=function(e,t,n,s,r,a){return this.throwIfDisposed(),Lo(this,e,t,n,s,r,a)};const Sd=Jr({dilation2d_:function(e,t,n,s,r=[1,1],a="NHWC"){const i=Xr(e,"x","dilation2d"),o=Xr(t,"filter","dilation2d");F(3===i.rank||4===i.rank,(()=>`Error in dilation2d: input must be rank 3 or 4, but got rank ${i.rank}.`)),F(3===o.rank,(()=>`Error in dilation2d: filter must be rank 3, but got rank ${o.rank}.`)),F("NHWC"===a,(()=>`Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${a}`));let l=i,u=!1;3===i.rank&&(l=mo(i,[1,i.shape[0],i.shape[1],i.shape[2]]),u=!0),F(l.shape[3]===o.shape[2],(()=>`Error in dilation2d:  input and filter must have the same depth: ${l.shape[3]} vs ${o.shape[2]}`));const c={x:l,filter:o},h={strides:n,pad:s,dilations:r},p=Wr.runKernel(ht,c,h);return u?mo(p,[p.shape[1],p.shape[2],p.shape[3]]):p}});kr().prototype.dilation2d=function(e,t,n,s,r){return this.throwIfDisposed(),Sd(this,e,t,n,s,r)};const Td=Jr({divNoNan_:function(e,t){let n=Xr(e,"a","div"),s=Xr(t,"b","div");[n,s]=Dr(n,s);const r=qa(n,s),a=Za(r),i=Bo(s,a);return Zl(i,a,r)}});kr().prototype.divNoNan=function(e){return this.throwIfDisposed(),Td(this,e)},kr().prototype.div=function(e){return this.throwIfDisposed(),qa(this,e)};const $d=Jr({dot_:function(e,t){const n=Xr(e,"t1","dot"),s=Xr(t,"t2","dot");F(!(1!==n.rank&&2!==n.rank||1!==s.rank&&2!==s.rank),(()=>`Error in dot: inputs must all be rank 1 or 2, but got ranks ${n.rank} and ${s.rank}.`));const r=1===n.rank?n.size:n.shape[1],a=1===s.rank?s.size:s.shape[0];if(F(r===a,(()=>`Error in dot: inner dimensions of inputs must match, but got ${r} and ${a}.`)),1===n.rank&&1===s.rank){const e=mo(n,[1,-1]),t=mo(s,[-1,1]),r=hl(e,t);return mo(r,[])}if(1===n.rank&&2===s.rank){const e=mo(n,[1,-1]),t=mo(s,[s.shape[0],s.shape[1]]),r=hl(e,t);return mo(r,[r.size])}if(2===n.rank&&1===s.rank){const e=mo(s,[-1,1]),t=hl(n,e);return mo(t,[t.size])}{const e=mo(s,[s.shape[0],s.shape[1]]);return hl(n,e)}}});kr().prototype.dot=function(e){return this.throwIfDisposed(),$d(this,e)},kr().prototype.elu=function(){return this.throwIfDisposed(),zo(this)},kr().prototype.equal=function(e){return this.throwIfDisposed(),Bo(this,e)},kr().prototype.erf=function(){return this.throwIfDisposed(),Po(this)};const Ed=Jr({euclideanNorm_:function(e,t=null,n=!1){return Ku(e,"euclidean",t,n)}});kr().prototype.euclideanNorm=function(e,t){return this.throwIfDisposed(),Ed(this,e,t)},kr().prototype.exp=function(){return this.throwIfDisposed(),Wo(this)},kr().prototype.expandDims=function(e){return this.throwIfDisposed(),Vo(this,e)};const Cd=Jr({expm1_:function(e){const t={x:Xr(e,"x","expm1")};return Wr.runKernel(vt,t)}});kr().prototype.expm1=function(){return this.throwIfDisposed(),Cd(this)},kr().prototype.fft=function(){return this.throwIfDisposed(),su(this)},kr().prototype.flatten=function(){return this.throwIfDisposed(),mo(this,[this.size])},kr().prototype.floor=function(){return this.throwIfDisposed(),Ho(this)},kr().prototype.floorDiv=function(e){return this.throwIfDisposed(),Ka(this,e)},kr().prototype.gather=function(e,t,n){return this.throwIfDisposed(),jo(this,e,t,n)},kr().prototype.greaterEqual=function(e){return this.throwIfDisposed(),qo(this,e)},kr().prototype.greater=function(e){return this.throwIfDisposed(),Ko(this,e)},kr().prototype.ifft=function(){return this.throwIfDisposed(),au(this)},kr().prototype.irfft=function(){return this.throwIfDisposed(),iu(this)};const Rd=Jr({isFinite_:function(e){const t={x:Xr(e,"x","isFinite")};return Wr.runKernel(Mt,t)}});kr().prototype.isFinite=function(){return this.throwIfDisposed(),Rd(this)};const Ad=Jr({isInf_:function(e){const t={x:Xr(e,"x","isInf")};return Wr.runKernel(Lt,t)}});kr().prototype.isInf=function(){return this.throwIfDisposed(),Ad(this)};const _d=Jr({isNaN_:function(e){const t={x:Xr(e,"x","isNaN")};return Wr.runKernel(zt,t)}});kr().prototype.isNaN=function(){return this.throwIfDisposed(),_d(this)},kr().prototype.leakyRelu=function(e){return this.throwIfDisposed(),Xo(this,e)},kr().prototype.lessEqual=function(e){return this.throwIfDisposed(),Pu(this,e)},kr().prototype.less=function(e){return this.throwIfDisposed(),Gu(this,e)};const Dd=Jr({localResponseNormalization_:function(e,t=5,n=1,s=1,r=.5){const a=Xr(e,"x","localResponseNormalization");F(4===a.rank||3===a.rank,(()=>`Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ${a.rank}.`)),F(B(t),(()=>`Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${t}.`));let i=a,o=!1;3===a.rank&&(o=!0,i=mo(a,[1,a.shape[0],a.shape[1],a.shape[2]]));const l={x:i},u={depthRadius:t,bias:n,alpha:s,beta:r},c=Wr.runKernel(qt,l,u);return o?mo(c,[c.shape[1],c.shape[2],c.shape[3]]):c}});kr().prototype.localResponseNormalization=function(e,t,n,s){return this.throwIfDisposed(),Dd(this,e,t,n,s)};const Fd=Jr({logSigmoid_:function(e){const t=Xr(e,"x","logSigmoid");return Qa((e=>({value:bl(Ul(bl(e))),gradFunc:t=>Xa(t,Ml(bl(e)))})))(t)}});kr().prototype.logSigmoid=function(){return this.throwIfDisposed(),Fd(this)},kr().prototype.logSoftmax=function(e){return this.throwIfDisposed(),el(this,e)},kr().prototype.logSumExp=function(e,t){return this.throwIfDisposed(),ul(this,e,t)},kr().prototype.log=function(){return this.throwIfDisposed(),Yo(this)},kr().prototype.log1p=function(){return this.throwIfDisposed(),Jo(this)},kr().prototype.logicalAnd=function(e){return this.throwIfDisposed(),cl(this,e)},kr().prototype.logicalNot=function(){return this.throwIfDisposed(),Qp(this)};const Od=Jr({logicalOr_:function(e,t){const n=Xr(e,"a","logicalOr","bool"),s=Xr(t,"b","logicalOr","bool");gi(n.shape,s.shape);const r={a:n,b:s};return Wr.runKernel(Kt,r)}});kr().prototype.logicalOr=function(e){return this.throwIfDisposed(),Od(this,e)};const Md=Jr({logicalXor_:function(e,t){const n=Xr(e,"a","logicalXor","bool"),s=Xr(t,"b","logicalXor","bool");return gi(n.shape,s.shape),cl(Od(e,t),Qp(cl(e,t)))}});kr().prototype.logicalXor=function(e){return this.throwIfDisposed(),Md(this,e)},kr().prototype.matMul=function(e,t,n){return this.throwIfDisposed(),hl(this,e,t,n)},kr().prototype.maxPool=function(e,t,n,s){return this.throwIfDisposed(),pl(this,e,t,n,s)},kr().prototype.max=function(e,t){return this.throwIfDisposed(),Zo(this,e,t)},kr().prototype.maximum=function(e){return this.throwIfDisposed(),yi(this,e)},kr().prototype.mean=function(e,t){return this.throwIfDisposed(),fl(this,e,t)},kr().prototype.min=function(e,t){return this.throwIfDisposed(),ml(this,e,t)},kr().prototype.minimum=function(e){return this.throwIfDisposed(),gl(this,e)};const Ld=Jr({mirrorPad_:function(e,t,n){F("reflect"===n||"symmetric"===n,(()=>`Invalid mode. Mode must be either reflect or symmetric. Got ${n}.`));const s=Xr(e,"x","mirrorPad");if(0===s.rank)throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");F(t.length===s.rank,(()=>`Padding doesn't match input. Must be ${s.rank}. Got ${t.length}.`));const r="reflect"===n?1:0;for(let e=0;e<s.rank;e++)F(2===t[e].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),F(t[e][0]>=0&&t[e][0]<=s.shape[e]-r&&t[e][1]>=0&&t[e][1]<=s.shape[e]-r,(()=>`Padding in dimension ${e} cannot be greater than or equal to ${s.shape[e]-r} or less than 0 for input of shape ${s.shape}`));const a={paddings:t,mode:n},i={x:s};return Wr.runKernel(on,i,a)}});kr().prototype.mirrorPad=function(e,t){return this.throwIfDisposed(),Ld(this,e,t)};const zd=Jr({mod_:function(e,t){let n=Xr(e,"a","mod"),s=Xr(t,"b","mod");[n,s]=Dr(n,s);const r={a:n,b:s};return Wr.runKernel(ln,r)}});kr().prototype.mod=function(e){return this.throwIfDisposed(),zd(this,e)},kr().prototype.mul=function(e){return this.throwIfDisposed(),Xa(this,e)},kr().prototype.neg=function(){return this.throwIfDisposed(),bl(this)},kr().prototype.norm=function(e,t,n){return this.throwIfDisposed(),Ku(this,e,t,n)},kr().prototype.notEqual=function(e){return this.throwIfDisposed(),xl(this,e)},kr().prototype.oneHot=function(e,t=1,n=0){return this.throwIfDisposed(),wl(this,e,t,n)},kr().prototype.onesLike=function(){return this.throwIfDisposed(),Il(this)},kr().prototype.pad=function(e,t){return this.throwIfDisposed(),Nl(this,e,t)};const Bd=Jr({pool_:function(e,t,n,s,r,a,i){null==r&&(r=[1,1]),null==a&&(a=1),0===s&&(s="valid");const o=Xr(e,"x","maxPool");let l=o,u=!1;3===o.rank&&(u=!0,l=mo(o,[1,o.shape[0],o.shape[1],o.shape[2]])),F(co(a,r),(()=>`Error in pool: Either strides or dilations must be 1. Got strides ${a} and dilations '${r}'`));const c=eo(l.shape,t,a,r,s),h=[c.dilationHeight,c.dilationWidth];let p;p="same"===s?function(e,t){const n=e.map(((e,n)=>e+(e-1)*(t[n]-1))).map((e=>e-1)),s=n.map((e=>Math.floor(e/2))),r=n.map(((e,t)=>e-s[t]));return n.map(((e,t)=>[s[t],r[t]]))}([c.filterHeight,c.filterWidth],h):[[0,0],[0,0]];const d=1===h[0]&&1===h[1],[f,m]=function(e,t,n){const s=n.map((e=>e[0])),r=n.map((e=>e[1])),a=e.concat(s,r),i=t.map(((e,t)=>(e-a[t]%e)%e)),o=r.map(((e,t)=>e+i[t]));return[t.map(((e,t)=>[s[t],o[t]])),t.map(((e,t)=>[0,i[t]]))]}([c.inHeight,c.inWidth],h,p),g=d?s:"valid",y=d?l:Ah(l,h,f),b=("avg"===n?()=>go(y,t,a,g,i):()=>pl(y,t,a,g,i))(),x=d?b:hd(b,h,m);return u?mo(x,[x.shape[1],x.shape[2],x.shape[3]]):x}});kr().prototype.pool=function(e,t,n,s,r,a){return this.throwIfDisposed(),Bd(this,e,t,n,s,r,a)},kr().prototype.pow=function(e){return this.throwIfDisposed(),ci(this,e)},kr().prototype.prelu=function(e){return this.throwIfDisposed(),Sl(this,e)};const Pd=Jr({prod_:function(e,t=null,n=!1){let s=Xr(e,"x","prod");"bool"===s.dtype&&(s=Ga(s,"int32"));const r={x:s},a={axis:t,keepDims:n};return Wr.runKernel(vn,r,a)}});kr().prototype.prod=function(e,t){return this.throwIfDisposed(),Pd(this,e,t)};const Wd=Jr({reciprocal_:function(e){const t={x:Xr(e,"x","reciprocal")};return Wr.runKernel(En,t)}});kr().prototype.reciprocal=function(){return this.throwIfDisposed(),Wd(this)},kr().prototype.relu=function(){return this.throwIfDisposed(),_l(this)},kr().prototype.relu6=function(){return this.throwIfDisposed(),lu(this)},kr().prototype.reshapeAs=function(e){return this.throwIfDisposed(),mo(this,e.shape)},kr().prototype.reshape=function(e){return this.throwIfDisposed(),mo(this,e)},kr().prototype.resizeBilinear=function(e,t,n){return this.throwIfDisposed(),Lu(this,e,t,n)},kr().prototype.resizeNearestNeighbor=function(e,t,n){return this.throwIfDisposed(),zu(this,e,t,n)},kr().prototype.reverse=function(e){return this.throwIfDisposed(),Dl(this,e)},kr().prototype.rfft=function(){return this.throwIfDisposed(),ru(this)},kr().prototype.round=function(){return this.throwIfDisposed(),Wu(this)},kr().prototype.rsqrt=function(){return this.throwIfDisposed(),rp(this)},kr().prototype.selu=function(){return this.throwIfDisposed(),Fl(this)},kr().prototype.separableConv2d=function(e,t,n,s,r,a){return this.throwIfDisposed(),Ol(this,e,t,n,s,r,a)},kr().prototype.sigmoid=function(){return this.throwIfDisposed(),Ml(this)};const Vd=Jr({sign_:function(e){const t={x:Xr(e,"x","sign")};return Wr.runKernel(Kn,t)}});kr().prototype.sign=function(){return this.throwIfDisposed(),Vd(this)},kr().prototype.sin=function(){return this.throwIfDisposed(),Uh(this)},kr().prototype.sinh=function(){return this.throwIfDisposed(),Hh(this)},kr().prototype.slice=function(e,t){return this.throwIfDisposed(),Ll(this,e,t)},kr().prototype.softmax=function(e){return this.throwIfDisposed(),Vl(this,e)},kr().prototype.softplus=function(){return this.throwIfDisposed(),Ul(this)},kr().prototype.spaceToBatchND=function(e,t){return this.throwIfDisposed(),Ah(this,e,t)},kr().prototype.split=function(e,t){return this.throwIfDisposed(),Gl(this,e,t)},kr().prototype.sqrt=function(){return this.throwIfDisposed(),Ya(this)},kr().prototype.square=function(){return this.throwIfDisposed(),Ja(this)},kr().prototype.squaredDifference=function(e){return this.throwIfDisposed(),Zu(this,e)},kr().prototype.squeeze=function(e){return this.throwIfDisposed(),Hl(this,e)},kr().prototype.stack=function(e,t){this.throwIfDisposed();const n=e instanceof wr?[this,e]:[this,...e];return jl(n,t)},kr().prototype.step=function(e){return this.throwIfDisposed(),uu(this,e)};const Ud=Jr({stridedSlice_:function(e,t,n,s,r=0,a=0,i=0,o=0,l=0){const u={x:Xr(e,"x","stridedSlice","string_or_numeric")},c={begin:t,end:n,strides:s,beginMask:r,endMask:a,ellipsisMask:i,newAxisMask:o,shrinkAxisMask:l};return Wr.runKernel(us,u,c)}});kr().prototype.stridedSlice=function(e,t,n,s,r,a,i,o){return this.throwIfDisposed(),Ud(this,e,t,n,s,r,a,i,o)},kr().prototype.sub=function(e){return this.throwIfDisposed(),hi(this,e)},kr().prototype.sum=function(e,t){return this.throwIfDisposed(),Qo(this,e,t)};const Gd=Jr({tan_:function(e){const t={x:Xr(e,"x","tan","float32")};return Wr.runKernel(fs,t)}});kr().prototype.tan=function(){return this.throwIfDisposed(),Gd(this)},kr().prototype.tanh=function(){return this.throwIfDisposed(),Kl(this)},kr().prototype.tile=function(e){return this.throwIfDisposed(),Uo(this,e)},kr().prototype.toBool=function(){return this.throwIfDisposed(),Ga(this,"bool")},kr().prototype.toFloat=function(){return this.throwIfDisposed(),Ga(this,"float32")},kr().prototype.toInt=function(){return this.throwIfDisposed(),Ga(this,"int32")};const Hd=Jr({topk_:function(e,t=1,n=!0){const s=Xr(e,"x","topk");if(0===s.rank)throw new Error("topk() expects the input to be of rank 1 or higher");const r=s.shape[s.shape.length-1];if(t<0)throw new Error(`'k' passed to topk() must be >= 0 but got ${t}`);if(t>r)throw new Error(`'k' passed to topk() must be <= the last dimension (${r}) but got ${t}`);const a={x:s},i={k:t,sorted:n},[o,l]=Wr.runKernel(ys,a,i);return{values:o,indices:l}}});kr().prototype.topk=function(e,t){return this.throwIfDisposed(),Hd(this,e,t)},kr().prototype.transpose=function(e){return this.throwIfDisposed(),tu(this,e)};const jd=Jr({unique_:function(e,t=0){const n=Xr(e,"x","unique","string_or_numeric");F(n.rank>0,(()=>"The input tensor must be at least 1D"));const s={x:n},r={axis:t},[a,i]=Wr.runKernel(ws,s,r);return{values:a,indices:i}}});kr().prototype.unique=function(e){return this.throwIfDisposed(),jd(this,e)},kr().prototype.unsortedSegmentSum=function(e,t){return this.throwIfDisposed(),ip(this,e,t)},kr().prototype.unstack=function(e){return this.throwIfDisposed(),Jl(this,e)},kr().prototype.where=function(e,t){return this.throwIfDisposed(),Zl(e,this,t)},kr().prototype.zerosLike=function(){return this.throwIfDisposed(),Za(this)};class Kd extends Error{constructor(e){super(e),Object.setPrototypeOf(this,Kd.prototype)}}class qd extends Error{constructor(e){super(e),Object.setPrototypeOf(this,qd.prototype)}}class Xd extends Error{constructor(e){super(e),Object.setPrototypeOf(this,Xd.prototype)}}class Yd extends Error{constructor(e){super(e),Object.setPrototypeOf(this,Yd.prototype)}}class Jd extends Error{constructor(e){super(e),Object.setPrototypeOf(this,Jd.prototype)}}Error;class Zd{constructor(e){this.maxEntries=e||100,this.cache=new Map}get(e){let t;return this.cache.has(e)&&(t=this.cache.get(e),this.cache.delete(e),this.cache.set(e,t)),t}put(e,t){if(this.cache.has(e))this.cache.delete(e);else if(this.cache.size>=this.maxEntries){const e=this.cache.keys().next().value;this.cache.delete(e)}this.cache.set(e,t)}getMaxEntries(){return this.maxEntries}setMaxEntries(e){if(e<0)throw new Error(`The maxEntries of LRU caches must be at least 0, but got ${e}.`);if(this.maxEntries>e)for(let t=0;t<this.maxEntries-e;t++){const e=this.cache.keys().next().value;this.cache.delete(e)}this.maxEntries=e}}function Qd(e,t){if(Array.isArray(e)){let n=[];for(let s=0;s<t;s++)n=n.concat(e);return n}{const n=new Array(t);return n.fill(e),n}}function ef(e,t){if(!e)throw new Jd(t)}function tf(e,t){let n=0;for(const s of e)s===t&&n++;return n}function nf(e){return 1===e.length?e[0]:e}function sf(e){return Array.isArray(e)?e:[e]}function rf(e){const t=e.replace(/(.)([A-Z][a-z0-9]+)/g,"$1_$2").replace(/([a-z])([A-Z])/g,"$1_$2").toLowerCase();return"_"!==t[0]?t:"private"+t}function af(e){return e.length<=1||-1===e.indexOf("_")?e:e.replace(/[_]+(\w|$)/g,((e,t)=>t.toUpperCase()))}let of={};function lf(e){if(null==e)return null;const t={};return t.className=e.getClassName(),t.config=e.getConfig(),t}function uf(e){if(null!=e&&"object"==typeof e)if(Array.isArray(e))e.forEach((e=>uf(e)));else{const t=Object.keys(e);for(const n of t){const t=e[n];null!=t&&"object"==typeof t&&(Array.isArray(t)||"ndarray"!==t.type||"number"!=typeof t.value?uf(t):e[n]=t.value)}}}function cf(e,t={},n={},s="object",r=!1){if("string"==typeof e){const r=e;let a;if(r in n)a=n[r];else if(r in of)a=of[r];else if(a=t[r],null==a)throw new Xd(`Unknown ${s}: ${e}. This may be due to one of the following reasons:\n1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);return a}{const a=e;if(null==a.className||null==a.config)throw new Xd(`${s}: Improper config format: ${JSON.stringify(a)}.\n'className' and 'config' must set.`);const i=a.className;let o,l;if(i in n?[o,l]=n[i]:i in of?[o,l]=of.className:i in t&&([o,l]=t[i]),null==o)throw new Xd(`Unknown ${s}: ${i}. This may be due to one of the following reasons:\n1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);if(null!=l){const e={};for(const t of Object.keys(of))e[t]=of[t];for(const t of Object.keys(n))e[t]=n[t];a.config.customObjects=e;const t=Object.assign({},of);for(const e of Object.keys(n))of[e]=n[e];uf(a.config);const s=l(o,a.config,n,r);return of=Object.assign({},t),s}{const e=Object.assign({},of);for(const e of Object.keys(n))of[e]=n[e];const t=new o(a.config);return of=Object.assign({},e),t}}}function hf(e,t){return-1*function(e,t){return e<t?-1:e>t?1:0}(e,t)}function pf(e){if(null==e)return e;const t=[];for(const n of e)-1===t.indexOf(n)&&t.push(n);return t}function df(e){if(null==e)throw new Xd(`Invalid value in obj: ${JSON.stringify(e)}`);for(const t in e)if(e.hasOwnProperty(t))return!1;return!0}function ff(e,t,n){if(null!=n&&e.indexOf(n)<0)throw new Xd(`${n} is not a valid ${t}.  Valid values are ${e} or null/undefined.`)}function mf(e,t,n=0,s=1/0){return ef(n>=0),ef(s>=n),Array.isArray(e)&&e.length>=n&&e.length<=s&&e.every((e=>typeof e===t))}function gf(e,t){Array.isArray(e)?(F(e.length>0,(()=>`${t} is unexpectedly an empty array.`)),e.forEach(((e,n)=>gf(e,`element ${n+1} of ${t}`)))):F(Number.isInteger(e)&&e>0,(()=>`Expected ${t} to be a positive integer, but got ${yf(e)}.`))}function yf(e){return null===e?"null":Array.isArray(e)?"["+e.map((e=>yf(e))).join(",")+"]":"string"==typeof e?`"${e}"`:`${e}`}function bf(e){return"relu"===e?"relu":"linear"===e?"linear":"elu"===e?"elu":null}let xf=0;function wf(){return xf++}const kf={};function vf(e=""){return e in kf||(kf[e]=0),kf[e]+=1,e+kf[e].toString()}const If=["channelsFirst","channelsLast"],Nf=["nearest","bilinear"],Sf=["valid","same","causal"],Tf=["max","avg"],$f=["sum","mul","concat","ave"],Ef=new Map;function Cf(e){ff(If,"DataFormat",e)}function Rf(e){ff(Sf,"PaddingMode",e)}function Af(e){ff(Tf,"PoolMode",e)}const _f=[];function Df(e,t){_f.push(e);try{const e=t();return _f.pop(),e}catch(e){throw _f.pop(),e}}function Ff(e){if(!Lf(e))throw new Error("Not a valid tensor name: '"+e+"'");return(0===_f.length?"":_f.join("/")+"/")+e}function Of(e){if(!Lf(e))throw new Error("Not a valid tensor name: '"+e+"'");Ef.has(e)||Ef.set(e,0);const t=Ef.get(e);if(Ef.set(e,Ef.get(e)+1),t>0){const n=`${e}_${t}`;return Ef.set(n,1),n}return e}const Mf=new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);function Lf(e){return!!e.match(Mf)}function zf(e,t,n){null==t&&(t=0),null==n&&(n=e.length);let s=1;for(let r=t;r<n;++r)s*=e[r];return s}function Bf(e){if(0===e.length)return Number.NaN;let t=Number.POSITIVE_INFINITY;for(let n=0;n<e.length;n++){const s=e[n];s<t&&(t=s)}return t}function Pf(e){if(0===e.length)return Number.NaN;let t=Number.NEGATIVE_INFINITY;for(let n=0;n<e.length;n++){const s=e[n];s>t&&(t=s)}return t}function Wf(e,t){if(t<e)throw new Xd(`end (${t}) < begin (${e}) is forbidden.`);const n=[];for(let s=e;s<t;++s)n.push(s);return n}let Vf;function Uf(){return null==Vf&&(Vf=Wr.backend.epsilon()),Vf}function Gf(e,t){return Ga(e,t)}function Hf(e,t=-1){const n=e.shape.slice();return t<0&&(t=n.length+t+1),n.splice(t,0,1),mo(e,n)}function jf(e,t,n){return aa((()=>{switch(e.rank){case 1:return zl(e,t,n);case 2:return Bl(e,[t,0],[n,e.shape[1]]);case 3:return Pl(e,[t,0,0],[n,e.shape[1],e.shape[2]]);case 4:return Wl(e,[t,0,0,0],[n,e.shape[1],e.shape[2],e.shape[3]]);case 5:return Ll(e,[t,0,0,0,0],[n,e.shape[1],e.shape[2],e.shape[3],e.shape[4]]);case 6:return Ll(e,[t,0,0,0,0,0],[n,e.shape[1],e.shape[2],e.shape[3],e.shape[4],e.shape[5]]);default:throw new Xd(`sliceAlongFirstAxis() received an unsupported tensor rank: ${e.rank}`)}}))}function Kf(e,t,n){return aa((()=>{switch(e.rank){case 1:return zl(e,t,n);case 2:return Bl(e,[0,t],[e.shape[0],n]);case 3:return Pl(e,[0,0,t],[e.shape[0],e.shape[1],n]);case 4:return Wl(e,[0,0,0,t],[e.shape[0],e.shape[1],e.shape[2],n]);default:throw new Xd(`sliceAlongLastAxis() received an unsupported tensor rank: ${e.rank}`)}}))}function qf(e,t,n,s){return aa((()=>{switch(e.rank){case 1:return zl(e,t,n);case 2:switch(s){case 1:return jf(e,t,n);case 2:return Kf(e,t,n);default:throw new Xd(`The axis is not within the rank of the tensor ${s}`)}case 3:switch(s){case 1:return jf(e,t,n);case 2:return Pl(e,[0,t,0],[e.shape[0],n,e.shape[2]]);case 3:return Kf(e,t,n);default:throw new Xd(`The axis is not within the rank of the tensor ${s}`)}case 4:switch(s){case 1:return jf(e,t,n);case 2:return Wl(e,[0,t,0,0],[e.shape[0],n,e.shape[2],e.shape[3]]);case 3:return Wl(e,[0,0,t,0],[e.shape[0],e.shape[1],n,e.shape[3]]);case 4:return Kf(e,t,n);default:throw new Xd(`The axis is not within the rank of the tensor ${s}`)}default:throw new Xd(`sliceAlongLastAxis() received an unsupported tensor rank: ${e.rank}`)}}))}function Xf(e,t=-1){let n;return t<0&&(n=e[0].rank,t=0!==n?n:0),t===e[0].rank&&(t=-1),No(e,t)}function Yf(e,t){switch(e.rank){case 1:return So([e,t]);case 2:return To([e,t],0);case 3:return $o([e,t],0);case 4:return Eo([e,t],0);default:throw new Xd(`concatAlongFirstAxis() received an unsupported tensor rank: ${e.rank}`)}}function Jf(e,t){if(Array.isArray(t)||(t=[t]),e.rank!==t.length)throw new Xd(`The length of input n (${t.length}) does not match the number of dimensions in input x (${e.rank})`);return Uo(e,t)}function Zf(e,t=0,n=1,s,r){return Cl(e,t,n,s,r)}function Qf(e,t,n,s){if(e.rank<2||t.rank<2)throw new Yd(`dot requires both inputs to be rank >= 2 but got x shape = ${e.shape} and y shape = ${t.shape}`);if(t.rank>=3&&e.shape.slice(-1)[0]!==t.shape.slice(-2)[0])throw new Yd(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${e.shape} and  y shape = ${t.shape}`);if(2===e.rank&&2===t.rank)return yu({a:e,b:t,transposeA:!1,transposeB:!1,bias:s?nm(e.rank,s,"channelsLast"):null,activation:n});{const r=e.shape.slice(),a=r.pop();e=mo(e,[-1,a]);const i=t.shape.slice(),o=i.pop(),l=i.pop(),u=[...i,o],c=Array.from({length:t.rank},((e,n)=>0===n?t.rank-2:n<=t.rank-2?n-1:n));t=mo(tu(t,c),[l,-1]);const h=[...r,...u];return mo(yu({a:e,b:t,transposeA:!1,transposeB:!1,bias:s?nm(e.rank,s,"channelsLast"):null,activation:n}),h)}}function em(e,t,n){return aa((()=>(t=Array.isArray(t)?ql(t,"int32"):Ga(t,"int32"),jo(e,t,n))))}function tm(e){return Xa(e,e)}function nm(e,t,n){const s=t.shape;if(1!==t.rank&&t.rank!==e)throw new Xd(`Unexpected bias dimensions: ${t.rank}; expected it to be 1 or ${e}`);if(5===e){if("channelsFirst"===n)return 1===s.length?mo(t,[1,s[0],1,1,1]):mo(t,[1,s[3],s[0],s[1],s[2]]);if("channelsLast"===n)return 1===s.length?mo(t,[1,1,1,1,s[0]]):mo(t,[1].concat(s))}else if(4===e){if("channelsFirst"===n)return 1===s.length?mo(t,[1,s[0],1,1]):mo(t,[1,s[2],s[0],s[1]]);if("channelsLast"===n)return 1===s.length?mo(t,[1,1,1,s[0]]):mo(t,[1].concat(s))}else if(3===e){if("channelsFirst"===n)return 1===s.length?mo(t,[1,s[0],1]):mo(t,[1,s[1],s[0]]);if("channelsLast"===n)return 1===s.length?mo(t,[1,1,s[0]]):mo(t,[1].concat(s))}else if(e<3)return t;throw new Xd(`Unsupported input rank by biasAdd: ${t.rank}`)}function sm(e,t,n){return aa((()=>(null==n&&(n="channelsLast"),Cf(n),ja(e,nm(e.rank,t,n)))))}function rm(e,t,n,s){return aa((()=>nu(e,t,n,s)))}function am(e,t,n=!1){return n?e():t()}const im=["fanIn","fanOut","fanAvg"],om=["normal","uniform","truncatedNormal"];class lm extends si{fromConfigUsesCustomObjects(){return!1}getConfig(){return{}}}class um extends lm{apply(e,t){return kl(e,t)}}um.className="Zeros",ai(um);class cm extends lm{apply(e,t){return vl(e,t)}}cm.className="Ones",ai(cm);class hm extends lm{constructor(e){if(super(),"object"!=typeof e)throw new Xd(`Expected argument of type ConstantConfig but got ${e}`);if(void 0===e.value)throw new Xd(`config must have value set but got ${e}`);this.value=e.value}apply(e,t){return aa((()=>Xa(ei(this.value),vl(e,t))))}getConfig(){return{value:this.value}}}hm.className="Constant",ai(hm);class pm extends lm{constructor(e){super(),this.DEFAULT_MINVAL=-.05,this.DEFAULT_MAXVAL=.05,this.minval=e.minval||this.DEFAULT_MINVAL,this.maxval=e.maxval||this.DEFAULT_MAXVAL,this.seed=e.seed}apply(e,t){return Rl(e,this.minval,this.maxval,t,this.seed)}getConfig(){return{minval:this.minval,maxval:this.maxval,seed:this.seed}}}pm.className="RandomUniform",ai(pm);class dm extends lm{constructor(e){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=e.mean||this.DEFAULT_MEAN,this.stddev=e.stddev||this.DEFAULT_STDDEV,this.seed=e.seed}apply(e,t){if("float32"!==(t=t||"float32")&&"int32"!==t)throw new Yd(`randomNormal does not support dType ${t}.`);return Zf(e,this.mean,this.stddev,t,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}dm.className="RandomNormal",ai(dm);class fm extends lm{constructor(e){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=e.mean||this.DEFAULT_MEAN,this.stddev=e.stddev||this.DEFAULT_STDDEV,this.seed=e.seed}apply(e,t){if("float32"!==(t=t||"float32")&&"int32"!==t)throw new Yd(`truncatedNormal does not support dType ${t}.`);return Yl(e,this.mean,this.stddev,t,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}fm.className="TruncatedNormal",ai(fm);class mm extends lm{constructor(e){super(),this.gain=null!=e.gain?e.gain:1}apply(e,t){return aa((()=>{if(2!==e.length||e[0]!==e[1])throw new Xd("Identity matrix initializer can only be used for 2D square matrices.");return Xa(this.gain,Go(e[0]))}))}getConfig(){return{gain:this.gain}}}mm.className="Identity",ai(mm);class gm extends lm{constructor(e){if(super(),e.scale<0)throw new Xd(`scale must be a positive float. Got: ${e.scale}`);var t;this.scale=null==e.scale?1:e.scale,this.mode=null==e.mode?"fanIn":e.mode,t=this.mode,ff(im,"FanMode",t),this.distribution=null==e.distribution?"normal":e.distribution,function(e){ff(om,"Distribution",e)}(this.distribution),this.seed=e.seed}apply(e,t){const n=function(e,t="channelsLast"){let n,s;if(Cf(t),2===e.length)n=e[0],s=e[1];else if(-1!==[3,4,5].indexOf(e.length)){if("channelsFirst"===t){const t=zf(e,2);n=e[1]*t,s=e[0]*t}else if("channelsLast"===t){const t=zf(e,0,e.length-2);n=e[e.length-2]*t,s=e[e.length-1]*t}}else{const t=zf(e);n=Math.sqrt(t),s=Math.sqrt(t)}return[n,s]}(e),s=n[0],r=n[1];let a=this.scale;if("fanIn"===this.mode?a/=Math.max(1,s):"fanOut"===this.mode?a/=Math.max(1,r):a/=Math.max(1,(s+r)/2),"normal"===this.distribution){const n=Math.sqrt(a);if("float32"!==(t=t||"float32")&&"int32"!==t)throw new Yd(`${this.getClassName()} does not support dType ${t}.`);return Yl(e,0,n,t,this.seed)}{const n=Math.sqrt(3*a);return Rl(e,-n,n,t,this.seed)}}getConfig(){return{scale:this.scale,mode:this.mode,distribution:this.distribution,seed:this.seed}}}gm.className="VarianceScaling",ai(gm);class ym extends gm{constructor(e){super({scale:1,mode:"fanAvg",distribution:"uniform",seed:null==e?null:e.seed})}getClassName(){return gm.className}}ym.className="GlorotUniform",ai(ym);class bm extends gm{constructor(e){super({scale:1,mode:"fanAvg",distribution:"normal",seed:null==e?null:e.seed})}getClassName(){return gm.className}}bm.className="GlorotNormal",ai(bm);class xm extends gm{constructor(e){super({scale:2,mode:"fanIn",distribution:"normal",seed:null==e?null:e.seed})}getClassName(){return gm.className}}xm.className="HeNormal",ai(xm);class wm extends gm{constructor(e){super({scale:2,mode:"fanIn",distribution:"uniform",seed:null==e?null:e.seed})}getClassName(){return gm.className}}wm.className="HeUniform",ai(wm);class km extends gm{constructor(e){super({scale:1,mode:"fanIn",distribution:"normal",seed:null==e?null:e.seed})}getClassName(){return gm.className}}km.className="LeCunNormal",ai(km);class vm extends gm{constructor(e){super({scale:1,mode:"fanIn",distribution:"uniform",seed:null==e?null:e.seed})}getClassName(){return gm.className}}vm.className="LeCunUniform",ai(vm);class Im extends lm{constructor(e){super(),this.DEFAULT_GAIN=1,this.ELEMENTS_WARN_SLOW=2e3,this.gain=null==e.gain?this.DEFAULT_GAIN:e.gain,this.seed=e.seed}apply(e,t){return aa((()=>{if(e.length<2)throw new Yd("Shape must be at least 2D.");if("int32"!==t&&"float32"!==t&&void 0!==t)throw new TypeError(`Unsupported data type ${t}.`);const n=L(e.slice(0,-1)),s=e[e.length-1],r=n*s;r>this.ELEMENTS_WARN_SLOW&&console.warn(`Orthogonal initializer is being called on a matrix with more than ${this.ELEMENTS_WARN_SLOW} (${r}) elements: Slowness may result.`);const a=Zf([Math.max(s,n),Math.min(s,n)],0,1,t,this.seed),i=ec.qr(a,!1);let o=i[0];const l=i[1].flatten().stridedSlice([0],[Math.min(s,n)*Math.min(s,n)],[Math.min(s,n)+1]);return o=Xa(o,l.sign()),n<s&&(o=o.transpose()),Xa(ei(this.gain),o.reshape(e))}))}getConfig(){return{gain:this.gain,seed:this.seed}}}Im.className="Orthogonal",ai(Im);const Nm={constant:"Constant",glorotNormal:"GlorotNormal",glorotUniform:"GlorotUniform",heNormal:"HeNormal",heUniform:"HeUniform",identity:"Identity",leCunNormal:"LeCunNormal",leCunUniform:"LeCunUniform",ones:"Ones",orthogonal:"Orthogonal",randomNormal:"RandomNormal",randomUniform:"RandomUniform",truncatedNormal:"TruncatedNormal",varianceScaling:"VarianceScaling",zeros:"Zeros"};function Sm(e,t={}){return cf(e,ri.getMap().classNameMap,t,"initializer")}function Tm(e){return lf(e)}function $m(e){if("string"==typeof e){const t=e in Nm?Nm[e]:e;if("GlorotNormal"===t)return new bm;if("GlorotUniform"===t)return new ym;if("HeNormal"===t)return new xm;if("HeUniform"===t)return new wm;if("LeCunNormal"===t)return new km;if("LeCunUniform"===t)return new vm;{const e={};return e.className=t,e.config={},Sm(e)}}return e instanceof lm?e:Sm(e)}function Em(e){return Array.isArray(e)&&Array.isArray(e[0])}function Cm(e){return 0===e.length?[]:Array.isArray(e[0])?e:[e]}function Rm(e){let t;if(Array.isArray(e)){if(1!==e.length)throw new Xd(`Expected Tensor length to be 1; got ${e.length}`);t=e[0]}else t=e;return t}function Am(e){if(Array.isArray(e)&&Array.isArray(e[0])){if(1===e.length)return e[0];throw new Xd(`Expected exactly 1 Shape; got ${e.length}`)}return e}function _m(e){let t=0;for(const n of e)0===n.shape.length?t+=1:t+=n.shape.reduce(((e,t)=>e*t));return t}const Dm="Variable";class Fm{constructor(e,t="float32",n=Dm,s=!0,r=null){this.dtype=null==t?"float32":t,this.shape=e.shape,this.id=wf(),n=null==n?Dm:n,this.originalName=Ff(n),this.name=Of(this.originalName),this.trainable_=s,this.constraint=r,this.val=function(e,t=!0,n,s){return Wr.makeVariable(e,t,n,s)}(e,this.trainable_,this.name,this.dtype)}read(){return this.assertNotDisposed(),this.val}write(e){return this.assertNotDisposed(),function(e,t){if(e.shape.toString()!==t.shape.toString())throw new Error("Shape mismatch: "+JSON.stringify(e.shape)+" vs. "+JSON.stringify(t.shape))}(this.val,e),this.val.id!==e.id&&(this.val.assign(e),null!=this.constraint&&this.val.assign(this.constraint.apply(this.val))),this}dispose(){this.assertNotDisposed(),this.val.dispose()}assertNotDisposed(){if(this.val.isDisposed)throw new Error(`LayersVariable ${this.name} is already disposed.`)}get trainable(){return this.trainable_}set trainable(e){this.trainable_=e,this.val.trainable=e}}function Om(e){return e.map((e=>e.read()))}function Mm(e){e.forEach((e=>{e[0].write(e[1])}))}class Lm{constructor(e){this.dtype=e.dtype,this.shape=e.shape,null!=e.shape?this.ndim=e.shape.length:this.ndim=e.ndim,this.maxNDim=e.maxNDim,this.minNDim=e.minNDim,this.axes=e.axes||{}}}class zm{constructor(e,t,n,s,r,a,i){this.dtype=e,this.shape=t,this.sourceLayer=n,this.inputs=s,this.callArgs=r,this.outputTensorIndex=i,this.id=wf(),null!=a&&(this.originalName=Ff(a),this.name=Of(this.originalName)),this.rank=t.length}}let Bm=0;class Pm{constructor(e,t){this.callArgs=t,this.id=Bm++,this.outboundLayer=e.outboundLayer,this.inboundLayers=e.inboundLayers,this.nodeIndices=e.nodeIndices,this.tensorIndices=e.tensorIndices,this.inputTensors=e.inputTensors,this.outputTensors=e.outputTensors,this.inputMasks=e.inputMasks,this.outputMasks=e.outputMasks,this.inputShapes=e.inputShapes,this.outputShapes=e.outputShapes;for(const t of e.inboundLayers)null!=t&&t.outboundNodes.push(this);e.outboundLayer.inboundNodes.push(this)}getConfig(){const e=[];for(const t of this.inboundLayers)null!=t?e.push(t.name):e.push(null);return{outboundLayer:this.outboundLayer?this.outboundLayer.name:null,inboundLayers:e,nodeIndices:this.nodeIndices,tensorIndices:this.tensorIndices}}}let Wm=0;class Vm extends si{constructor(e={}){super(),this._callHook=null,this._addedWeightNames=[],this._stateful=!1,this.id=Wm++,this.activityRegularizer=null,this.inputSpec=null,this.supportsMasking=!1,this._trainableWeights=[],this._nonTrainableWeights=[],this._losses=[],this._updates=[],this._built=!1,this.inboundNodes=[],this.outboundNodes=[];let t=e.name;if(!t){const e=this.getClassName();t=rf(e)+"_"+vf(e)}if(this.name=t,this.trainable_=null==e.trainable||e.trainable,null!=e.inputShape||null!=e.batchInputShape){let t;if(null!=e.batchInputShape)t=e.batchInputShape;else if(null!=e.inputShape){let n=null;null!=e.batchSize&&(n=e.batchSize),t=[n].concat(e.inputShape)}this.batchInputShape=t;let n=e.dtype;null==n&&(n=e.inputDType),null==n&&(n="float32"),this.dtype=n}null!=e.weights?this.initialWeights=e.weights:this.initialWeights=null,this._refCount=null,this.fastWeightInitDuringBuild=!1}static nodeKey(e,t){return e.name+"_ib-"+t.toString()}getNodeAtIndex(e,t){if(0===this.inboundNodes.length)throw new qd(`The layer has never been called and thus has no defined ${t}.`);if(this.inboundNodes.length<=e)throw new Xd(`Asked to get ${t} at node ${e}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);return this.inboundNodes[e]}getInputAt(e){return nf(this.getNodeAtIndex(e,"input").inputTensors)}getOutputAt(e){return nf(this.getNodeAtIndex(e,"output").outputTensors)}get input(){if(this.inboundNodes.length>1)throw new Kd(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);if(0===this.inboundNodes.length)throw new Kd(`Layer ${this.name} is not connected, no input to return.`);return nf(this.getNodeAtIndex(0,"input").inputTensors)}get output(){if(0===this.inboundNodes.length)throw new Kd(`Layer ${this.name} has no inbound nodes.`);if(this.inboundNodes.length>1)throw new Kd(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);return nf(this.getNodeAtIndex(0,"output").outputTensors)}get losses(){return this._losses}calculateLosses(){return this.losses.map((e=>e()))}get updates(){return this._updates}get built(){return this._built}set built(e){this._built=e}get trainable(){return this.trainable_}set trainable(e){this._trainableWeights.forEach((t=>t.trainable=e)),this.trainable_=e}get trainableWeights(){return this.trainable_?this._trainableWeights.filter((e=>e.trainable)):[]}set trainableWeights(e){this._trainableWeights=e}get nonTrainableWeights(){return this.trainable?this._trainableWeights.filter((e=>!e.trainable)).concat(this._nonTrainableWeights):this._trainableWeights.concat(this._nonTrainableWeights)}set nonTrainableWeights(e){this._nonTrainableWeights=e}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}get stateful(){return this._stateful}resetStates(){if(!this.stateful)throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.")}assertInputCompatibility(e){const t=sf(e);if(null==this.inputSpec||0===this.inputSpec.length)return;const n=sf(this.inputSpec);if(t.length!==n.length)throw new Xd(`Layer ${this.name} expects ${n.length} inputs, but it received ${t.length} input tensors. Input received: ${e}`);for(let e=0;e<t.length;e++){const s=t[e],r=n[e];if(null==r)continue;const a=s.rank;if(null!=r.ndim&&a!==r.ndim)throw new Xd(`Input ${e} is incompatible with layer ${this.name}: expected ndim=${r.ndim}, found ndim=${a}`);if(null!=r.maxNDim&&a>r.maxNDim)throw new Xd(`Input ${e} is incompatible with layer ${this.name}: expected max_ndim=${r.maxNDim}, found ndim=${a}`);if(null!=r.minNDim&&a<r.minNDim)throw new Xd(`Input ${e} is incompatible with layer ${this.name}: expected min_ndim=${r.minNDim}, found ndim=${a}.`);if(null!=r.dtype&&s.dtype!==r.dtype)throw new Xd(`Input ${e} is incompatible with layer ${this.name} : expected dtype=${r.dtype}, found dtype=${s.dtype}.`);if(r.axes){const t=s.shape;for(const n in r.axes){const s=Number(n),a=r.axes[n],i=s>=0?t[s]:t[t.length+s];if(null!=a&&-1===[a,null].indexOf(i))throw new Xd(`Input ${e} is incompatible with layer ${this.name}: expected axis ${s} of input shape to have value ${a} but got shape ${t}.`)}}if(null!=r.shape)for(let t=0;t<r.shape.length;++t){const n=r.shape[t],a=s.shape[t];if(null!=n&&null!=a&&n!==a)throw new Xd(`Input ${e} is incompatible with layer ${this.name}: expected shape=${r.shape}, found shape=${s.shape}.`)}}}call(e,t){return e}invokeCallHook(e,t){null!=this._callHook&&this._callHook(e,t)}setCallHook(e){this._callHook=e}clearCallHook(){this._callHook=null}apply(e,t){t=t||{},this.assertNotDisposed();const n=sf(e),s=function(e){let t=!0;for(const n of sf(e))if(!(n instanceof zm)){t=!1;break}return t}(e),r=function(e){let t=!0;for(const n of sf(e))if(n instanceof zm){t=!1;break}return t}(e);if(s===r)throw new Xd("Arguments to apply() must be all SymbolicTensors or all Tensors");return Df(this.name,(()=>{if(!this.built){this.assertInputCompatibility(e);const t=[];for(const n of sf(e))t.push(n.shape);this.build(nf(t)),this.built=!0,this.initialWeights&&this.setWeights(this.initialWeights),null===this._refCount&&r&&(this._refCount=1)}if(this.assertInputCompatibility(e),r){let s=this.call(e,t);this.supportsMasking&&this.setMaskMetadata(e,s);const r=sf(s),a=[];for(let e of r)-1!==n.indexOf(e)&&(e=e.clone()),a.push(e);if(s=nf(a),null!=this.activityRegularizer)throw new Yd("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return s}{const n=function(e){e=sf(e);const t=[];for(const n of e)t.push(n.shape);return nf(t)}(e),s=this.computeOutputShape(n);let r;const a="float32";if(this.warnOnIncompatibleInputShape(Array.isArray(e)?n[0]:n),r=null!=s&&s.length>0&&Array.isArray(s[0])?s.map(((n,s)=>new zm(a,n,this,sf(e),t,this.name,s))):new zm(a,s,this,sf(e),t,this.name),this.addInboundNode(e,r,null,null,n,s,t),this._refCount++,null!=this.activityRegularizer)throw new Yd("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return r}}))}warnOnIncompatibleInputShape(e){if(null!=this.batchInputShape)if(e.length!==this.batchInputShape.length)console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(e)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);else{let t=!1;this.batchInputShape.forEach(((n,s)=>{null!=n&&null!=e[s]&&e[s]!==n&&(t=!0)})),t&&console.warn(`The shape of the input tensor (${JSON.stringify(e)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`)}}get outputShape(){if(null==this.inboundNodes||0===this.inboundNodes.length)throw new Kd(`The layer ${this.name} has never been called and thus has no defined output shape.`);const e=[];for(const t of this.inboundNodes){const n=JSON.stringify(t.outputShapes);-1===e.indexOf(n)&&e.push(n)}if(1===e.length){const e=this.inboundNodes[0].outputShapes;return Array.isArray(e)&&Array.isArray(e[0])&&1===e.length?e[0]:e}throw new Kd(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`)}countParams(){if(!this.built)throw new qd(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);return _m(this.weights)}build(e){this.built=!0}getWeights(e=!1){return Om(e?this.trainableWeights:this.weights)}setWeights(e){aa((()=>{const t=this.weights;if(t.length!==e.length)throw new Xd(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${e.length}, but the layer was expecting ${t.length} weights. Provided weights: ${e}...`);if(0===t.length)return;const n=[],s=Om(t);for(let r=0;r<s.length;++r){const a=s[r],i=t[r],o=e[r];if(!z(a.shape,o.shape))throw new Xd(`Layer weight shape ${a.shape} not compatible with provided weight shape ${o.shape}`);n.push([i,o])}Mm(n)}))}addWeight(e,t,n,s,r,a,i,o){if(-1!==this._addedWeightNames.indexOf(e))throw new Xd(`Duplicate weight name ${e} for layer ${this.name}`);this._addedWeightNames.push(e),null==n&&(n="float32"),this.fastWeightInitDuringBuild&&(s=null!=o?o():$m("zeros"));const l=s.apply(t,n),u=new Fm(l,n,e,a,i);return l.dispose(),null!=r&&this.addLoss((()=>r.apply(u.read()))),null==a&&(a=!0),a?this._trainableWeights.push(u):this._nonTrainableWeights.push(u),u}setFastWeightInitDuringBuild(e){this.fastWeightInitDuringBuild=e}addLoss(e){null==e||Array.isArray(e)&&0===e.length||(e=sf(e),void 0!==this._losses&&null!==this._losses&&this.losses.push(...e))}computeOutputShape(e){return e}computeMask(e,t){if(!this.supportsMasking){if(null!=t){if(!Array.isArray(t))throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);t.forEach((e=>{if(null!=e)throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`)}))}return null}return t}setMaskMetadata(e,t,n){if(!this.supportsMasking)return;const s=this.computeMask(e,n),r=sf(t),a=sf(s);if(r.length!==a.length)throw new Error(`${this.name} outputs ${r.length} tensors but ${r.length} masks for those tensors`);for(let e=0;e<r.length;e++)r[e].kerasMask=a[e]}addInboundNode(e,t,n,s,r,a,i=null){const o=sf(e);t=sf(t),n=sf(n),s=sf(s),r=Cm(r),a=Cm(a);const l=[],u=[],c=[];for(const e of o)l.push(e.sourceLayer),u.push(e.nodeIndex),c.push(e.tensorIndex);new Pm({outboundLayer:this,inboundLayers:l,nodeIndices:u,tensorIndices:c,inputTensors:o,outputTensors:t,inputMasks:n,outputMasks:s,inputShapes:r,outputShapes:a},i);for(let e=0;e<t.length;e++)t[e].sourceLayer=this,t[e].nodeIndex=this.inboundNodes.length-1,t[e].tensorIndex=e}getConfig(){const e={name:this.name,trainable:this.trainable};return null!=this.batchInputShape&&(e.batchInputShape=this.batchInputShape),null!=this.dtype&&(e.dtype=this.dtype),e}disposeWeights(){return this.weights.forEach((e=>e.dispose())),this.weights.length}assertNotDisposed(){if(0===this._refCount)throw new Error(`Layer '${this.name}' is already disposed.`)}dispose(){if(!this.built)throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);if(null===this._refCount)throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);this.assertNotDisposed();let e=0;return 0==--this._refCount&&(e=this.disposeWeights()),{refCountAfterDispose:this._refCount,numDisposedVariables:e}}}function Um(e,t,n){if((null==t||null!=n&&n>0)&&(t=e.sourceLayer,n=e.nodeIndex),0===t.inboundNodes.length)return[e];{const e=t.inboundNodes[n];if(0===e.inboundLayers.length)return e.inputTensors;{const t=[];for(let n=0;n<e.inboundLayers.length;n++){const s=Um(e.inputTensors[n],e.inboundLayers[n],e.nodeIndices[n]);for(const e of s)-1===t.indexOf(e)&&t.push(e)}return t}}}class Gm extends Vm{constructor(e){if(super({dtype:e.dtype,name:null!=e.name?e.name:vf("input").toString()}),null==e.batchSize&&(e.batchSize=null),null==e.sparse&&(e.sparse=!1),this.trainable=!1,this.built=!0,this.sparse=e.sparse,null!=e.inputShape&&null!=e.batchInputShape)throw new Xd("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");let t=e.batchInputShape;if(null==t){if(null==e.inputShape)throw new Xd("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");t=[e.batchSize].concat(e.inputShape)}else if(null!=e.batchSize)throw new Xd("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");const n=e.dtype||"float32";this.batchInputShape=t,this.dtype=n,this.inputSpec=[{shape:t}];const s=new zm(this.dtype,this.batchInputShape,this,[],{},this.name);s.nodeIndex=0,s.tensorIndex=0,new Pm({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:[s],outputTensors:[s],inputMasks:[null],outputMasks:[null],inputShapes:[t],outputShapes:[t]})}apply(e,t){throw new Xd(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`)}dispose(){return{refCountAfterDispose:this._refCount,numDisposedVariables:0}}getConfig(){return{batchInputShape:this.batchInputShape,dtype:this.dtype,sparse:this.sparse,name:this.name}}}Gm.className="InputLayer",ai(Gm);class Hm{constructor(e){if(this.id2Value={},this.id2Mask={},this.name2Id={},e instanceof Hm)for(const t in e.id2Value)this.id2Value[t]=e.id2Value[t],t in e.id2Mask&&(this.id2Mask[t]=e.id2Mask[t]);else{if(null==e)return;for(const t of e)this.add(t.key,t.value)}}add(e,t,n){if(null!=this.id2Value[e.id])throw new Xd(`Duplicate key: name=${e.name}, id=${e.id}`);return this.id2Value[e.id]=function(e,t){if(null==e.dtype||e.dtype===t.dtype)return t;try{return Ga(t,e.dtype)}catch(n){throw new Xd(`The dtype of the feed (${t.dtype}) can not be cast to the dtype of the key '${e.name}' (${e.dtype}).`)}}(e,t),this.name2Id[e.name]=e.id,null!=n&&(this.id2Mask[e.id]=n),this}addFeed(e){this.add(e.key,e.value)}hasKey(e){return null!=this.id2Value[e.id]}names(){return Object.keys(this.name2Id)}getValue(e){if(e instanceof zm){if(null==this.id2Value[e.id])throw new Xd(`Nonexistent key: ${e.name}`);return this.id2Value[e.id]}{const t=this.name2Id[e];if(null==t)throw new Xd(`Feed dict has no SymbolicTensor name: ${e}`);return this.id2Value[t]}}getMask(e){if(e instanceof zm){if(null==this.id2Value[e.id])throw new Xd(`Nonexistent key: ${e.name}`);return this.id2Mask[e.id]}{const t=this.name2Id[e];if(null==t)throw new Xd(`Feed dict has no SymbolicTensor name: ${e}`);return this.id2Mask[t]}}disposeMasks(){null!=this.id2Mask&&ia(this.id2Mask)}}const jm=new Zd,Km=new Zd;function qm(e,t,n,s){const r=null!=n&&n.training,a=Array.isArray(e),i=a?e:[e],o=i.map((e=>e.name)),l=[],u=t.names();for(const e of o)-1!==u.indexOf(e)?l.push(t.getValue(e)):l.push(null);null!=s&&(s.maxNumTensors=-1/0,s.minNumTensors=1/0);const c=o.join(",")+"|"+t.names().sort().join(",");let h,p=jm.get(c);if(null==p){const e=function(e,t){F(null!=e&&e.length>0,(()=>"Expected at least one fetch, got none"));let n=[],s={};if(1===e.length){const r=Ym(e[0],t);n=r.sorted,s=r.recipientMap}else{const r=new Set;for(const a of e){const{sorted:e,recipientMap:i}=Ym(a,t);for(const t of e)r.has(t.name)||(n.push(t),r.add(t.name));for(const e in i)null==s[e]&&(s[e]=new Set),i[e].forEach((t=>s[e].add(t)))}}return{sorted:n,recipientCounts:Xm(s)}}(i,t);p=e.sorted,h=e.recipientCounts,jm.put(c,p),Km.put(c,h)}h={},r||Object.assign(h,Km.get(c));const d=new Hm(t);for(let e=0;e<p.length;++e){if(null!=s){const e=ra().numTensors;e>s.maxNumTensors&&(s.maxNumTensors=e),e<s.minNumTensors&&(s.minNumTensors=e)}const a=p[e],i=a.sourceLayer;if(i instanceof Gm)continue;const u=[],c=[],f=[];let m=!1;for(const e of a.inputs){const n=d.getValue(e),s=d.getMask(e);u.push(n),c.push(s),null!=s&&(m=!0),r||(h[e.name]--,0!==h[e.name]||t.hasKey(e)||-1!==o.indexOf(e.name)||n.isDisposed||!0===e.sourceLayer.stateful||f.push(n))}m&&((n=n||{}).mask=c[0]);const g=sf(i.apply(u,n));let y=null;i.supportsMasking&&(y=i.computeMask(u,c));const b=Jm(a),x=Array.isArray(b)?b:[b];for(let e=0;e<x.length;++e){d.hasKey(x[e])||d.add(x[e],g[e],Array.isArray(y)?y[0]:y);const t=o.indexOf(x[e].name);-1!==t&&(l[t]=g[e])}r||ia(f)}return d.disposeMasks(),a?l:l[0]}function Xm(e){const t={};for(const n in e)t[n]=e[n].size;return t}function Ym(e,t){const n=new Set,s=[],r={};for(const e of t.names())n.add(e);const a=[],i=[];for(a.push(e);a.length>0;){const e=a[a.length-1];if(n.has(e.name)){a.pop();continue}const t=i[i.length-1]===a.length-1;if(0===e.inputs.length||t)a.pop(),s.push(e),n.add(e.name),t&&i.pop();else{i.push(a.length-1);for(const t of e.inputs)null==r[t.name]&&(r[t.name]=new Set),r[t.name].add(e.name),n.has(t.name)||a.push(t)}}return{sorted:s,recipientMap:r}}function Jm(e){let t;if(1===e.sourceLayer.inboundNodes.length)t=e.sourceLayer.output;else{let n=null;for(let t=0;t<e.sourceLayer.inboundNodes.length;++t)for(const s of e.sourceLayer.inboundNodes[t].outputTensors)if(s.id===e.id){n=t;break}t=e.sourceLayer.getOutputAt(n)}return t}function Zm(e,t){return aa((()=>Ya(Qo(Xa(e,e),t,!0))))}fe().registerFlag("TOPOLOGICAL_SORT_CACHE_MAX_ENTRIES",(()=>100),(function(e){null!=jm&&jm.setMaxEntries(e),null!=Km&&Km.setMaxEntries(e)}));class Qm extends si{getConfig(){return{}}}class eg extends Qm{constructor(e){super(),this.defaultMaxValue=2,this.defaultAxis=0,this.maxValue=null!=e.maxValue?e.maxValue:this.defaultMaxValue,this.axis=null!=e.axis?e.axis:this.defaultAxis}apply(e){return aa((()=>{const t=Zm(e,this.axis),n=Io(t,0,this.maxValue);return Xa(e,qa(n,ja(Uf(),t)))}))}getConfig(){return{maxValue:this.maxValue,axis:this.axis}}}eg.className="MaxNorm",ai(eg);class tg extends Qm{constructor(e){super(),this.defaultAxis=0,this.axis=null!=e.axis?e.axis:this.defaultAxis}apply(e){return aa((()=>qa(e,ja(Uf(),Zm(e,this.axis)))))}getConfig(){return{axis:this.axis}}}tg.className="UnitNorm",ai(tg);class ng extends Qm{apply(e){return _l(e)}}ng.className="NonNeg",ai(ng);class sg extends Qm{constructor(e){super(),this.defaultMinValue=0,this.defaultMaxValue=1,this.defaultRate=1,this.defaultAxis=0,this.minValue=null!=e.minValue?e.minValue:this.defaultMinValue,this.maxValue=null!=e.maxValue?e.maxValue:this.defaultMaxValue,this.rate=null!=e.rate?e.rate:this.defaultRate,this.axis=null!=e.axis?e.axis:this.defaultAxis}apply(e){return aa((()=>{const t=Zm(e,this.axis),n=ja(Xa(this.rate,Io(t,this.minValue,this.maxValue)),Xa(1-this.rate,t));return Xa(e,qa(n,ja(Uf(),t)))}))}getConfig(){return{minValue:this.minValue,maxValue:this.maxValue,rate:this.rate,axis:this.axis}}}sg.className="MinMaxNorm",ai(sg);const rg={maxNorm:"MaxNorm",minMaxNorm:"MinMaxNorm",nonNeg:"NonNeg",unitNorm:"UnitNorm"};function ag(e){return lf(e)}function ig(e,t={}){return cf(e,ri.getMap().classNameMap,t,"constraint")}function og(e){return null==e?null:"string"==typeof e?ig({className:e in rg?rg[e]:e,config:{}}):e instanceof Qm?e:ig(e)}async function lg(e){if(null==e)return;const t=[],n=[],s=[];for(const r in e){const a=e[r];if("number"!=typeof a){const e=a;t.push(e.data()),n.push(r),s.push(e)}}if(t.length>0){const r=await Promise.all(t);for(let t=0;t<r.length;++t)e[n[t]]=r[t][0];ia(s)}}function ug(e){if(null!=e)for(const t in e){const n=e[t];"number"!=typeof n&&n.dispose()}}var cg;!function(e){e[e.SILENT=0]="SILENT",e[e.VERBOSE=1]="VERBOSE"}(cg||(cg={}));class hg{constructor(){this.validationData=null}setParams(e){this.params=e}async onEpochBegin(e,t){}async onEpochEnd(e,t){}async onBatchBegin(e,t){}async onBatchEnd(e,t){}async onTrainBegin(e){}async onTrainEnd(e){}setModel(e){}}class pg{constructor(e,t=10){null==e&&(e=[]),this.callbacks=e,this.queueLength=t}append(e){this.callbacks.push(e)}setParams(e){for(const t of this.callbacks)t.setParams(e)}setModel(e){for(const t of this.callbacks)t.setModel(e)}async onEpochBegin(e,t){null==t&&(t={});for(const n of this.callbacks)await n.onEpochBegin(e,t)}async onEpochEnd(e,t){null==t&&(t={});for(const n of this.callbacks)await n.onEpochEnd(e,t)}async onBatchBegin(e,t){null==t&&(t={});for(const n of this.callbacks)await n.onBatchBegin(e,t)}async onBatchEnd(e,t){null==t&&(t={});for(const n of this.callbacks)await n.onBatchEnd(e,t)}async onTrainBegin(e){null==e&&(e={});for(const t of this.callbacks)await t.onTrainBegin(e)}async onTrainEnd(e){null==e&&(e={});for(const t of this.callbacks)await t.onTrainEnd(e)}}class dg extends hg{constructor(){super()}async onEpochBegin(e){this.seen=0,this.totals={}}async onBatchEnd(e,t){null==t&&(t={});const n=null==t.size?0:t.size;this.seen+=n;for(const e in t){const s=t[e];if("number"==typeof s)this.totals.hasOwnProperty(e)||(this.totals[e]=0),this.totals[e]=this.totals[e]+s*n;else{let t;e in this.totals?t=this.totals[e]:this.totals[e]=0;const r=aa((()=>ja(this.totals[e],Xa(s,n))));this.totals[e]=r,null!=t&&t.dispose()}}}async onEpochEnd(e,t){if(null!=t)for(const e of this.params.metrics)null!=this.totals[e]&&("number"==typeof this.totals[e]?t[e]=this.totals[e]/this.seen:aa((()=>{const n=Xa(qa(1,this.seen),this.totals[e]);t[e]=n,this.totals[e].dispose(),oa(t[e])})))}}class fg extends hg{async onTrainBegin(e){this.epoch=[],this.history={}}async onEpochEnd(e,t){null==t&&(t={}),this.epoch.push(e);for(const e in t)null==this.history[e]&&(this.history[e]=[]),this.history[e].push(t[e])}async syncData(){const e=[],t=[],n=[];for(const s in this.history){const r=this.history[s];for(let a=0;a<r.length;++a)if("number"!=typeof r[a]){const i=r[a];e.push(i.data()),t.push(s),n.push(a)}}const s=await Promise.all(e);for(let e=0;e<s.length;++e)this.history[t[e]][n[e]].dispose(),this.history[t[e]][n[e]]=s[e][0]}}class mg extends hg{constructor(e,t){if(super(),this.currentEpoch=0,this.nowFunc=e.nowFunc,this.nextFrameFunc=e.nextFrameFunc||sc,this.yieldEvery=t||"auto","auto"===this.yieldEvery&&(this.yieldEvery=125),"never"===this.yieldEvery&&null!=e.onYield)throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");J(this.yieldEvery)&&(this.maybeWait=function(e,t,n){let s,r=null!=n?n():sr();return(...a)=>{const i=null!=n?n():sr();return i-r<t||(r=i,s=e(...a)),s}}(this.maybeWait.bind(this),this.yieldEvery,this.nowFunc)),this.trainBegin=e.onTrainBegin,this.trainEnd=e.onTrainEnd,this.epochBegin=e.onEpochBegin,this.epochEnd=e.onEpochEnd,this.batchBegin=e.onBatchBegin,this.batchEnd=e.onBatchEnd,this.yield=e.onYield}async maybeWait(e,t,n){const s=[];null!=this.yield&&(await lg(n),s.push(this.yield(e,t,n))),s.push(this.nextFrameFunc()),await Promise.all(s)}async onEpochBegin(e,t){this.currentEpoch=e,null!=this.epochBegin&&(await lg(t),await this.epochBegin(e,t))}async onEpochEnd(e,t){const n=[];null!=this.epochEnd&&(await lg(t),n.push(this.epochEnd(e,t))),"epoch"===this.yieldEvery&&n.push(this.nextFrameFunc()),await Promise.all(n)}async onBatchBegin(e,t){null!=this.batchBegin&&(await lg(t),await this.batchBegin(e,t))}async onBatchEnd(e,t){const n=[];null!=this.batchEnd&&(await lg(t),n.push(this.batchEnd(e,t))),"batch"===this.yieldEvery?n.push(this.nextFrameFunc()):J(this.yieldEvery)&&n.push(this.maybeWait(this.currentEpoch,e,t)),await Promise.all(n)}async onTrainBegin(e){null!=this.trainBegin&&(await lg(e),await this.trainBegin(e))}async onTrainEnd(e){null!=this.trainEnd&&(await lg(e),await this.trainEnd(e))}}function gg(e,t){return null==e&&(e={}),e instanceof hg?[e]:Array.isArray(e)&&e[0]instanceof hg?e:sf(e).map((e=>new mg(e,t)))}class yg{constructor(){}static registerCallbackConstructor(e,t){F(e>=0&&Number.isInteger(e),(()=>`Verbosity level is expected to be an integer >= 0, but got ${e}`)),yg.checkForDuplicate(t),null==yg.constructors[e]&&(yg.constructors[e]=[]),yg.constructors[e].push(t)}static checkForDuplicate(e){for(const t in yg.constructors)yg.constructors[+t].forEach((t=>{if(t===e)throw new Xd("Duplicate callback constructor.")}))}static clear(){yg.constructors={}}static createCallbacks(e){const t=[];for(const n in yg.constructors){const s=+n;e>=s&&t.push(...yg.constructors[s])}return t.map((e=>new e))}}function bg(e,t,n,s,r,a,i,o,l){const u=new fg,c=[new dg,...yg.createCallbacks(t)];null!=e&&c.push(...e),c.push(u);const h=new pg(c);return h.setParams({epochs:n,initialEpoch:s,samples:r,steps:a,batchSize:i,verbose:t,doValidation:o,metrics:l}),{callbackList:h,history:u}}function xg(e,t={},n=!1){return cf(e,ri.getMap().classNameMap,t,"layer",n)}function wg(e,t){return aa((()=>{"float32"!==e.dtype&&(e=Ga(e,"float32"));const n=Qo(tm(e),t,!0),s=li(n.shape,Uf()),r=Ya(yi(n,s));return qa(e,r)}))}function kg(e,t){return aa((()=>fl(tm(hi(t,e)),-1)))}function vg(e,t){return aa((()=>fl(di(hi(t,e)),-1)))}function Ig(e,t){return aa((()=>{const n=hi(e,t),s=Io(di(e),Uf(),Number.MAX_VALUE),r=di(qa(n,s));return Xa(100,fl(r,-1))}))}function Ng(e,t,n=!1){return aa((()=>{if(n)t=Vl(t);else{const e=Qo(t,t.shape.length-1,!0);t=qa(t,e)}return t=Io(t,Uf(),1-Uf()),bl(Qo(Xa(Ga(e,"float32"),Yo(t)),t.shape.length-1))}))}function Sg(e,t,n=!1){return aa((()=>{const s=Ga(Ho(function(e){const t=[zf(e.shape)];return mo(e,t)}(e)),"int32"),r=(t=Io(t,Uf(),1-Uf())).shape;return Ng(mo(wl(s,r[r.length-1]),r),t,n)}))}function Tg(e,t){return aa((()=>{let n;return n=Io(t,Uf(),1-Uf()),n=Yo(qa(n,hi(1,n))),fl(function(e,t){if(!z(e.shape,t.shape))throw new Xd(`logits and labels must have the same shape, but got shapes ${JSON.stringify(e.shape)} and ${JSON.stringify(t.shape)}`);return aa((()=>{const n=_l(t),s=bl(di(t));return ja(hi(n,Xa(t,e)),Jo(Wo(s)))}))}(e,n),-1)}))}function $g(e,t){return aa((()=>{const n=wg(e,-1),s=wg(t,-1),r=Xa(n,s);return bl(Qo(r,-1))}))}yg.constructors={};const Eg={meanSquaredError:kg,meanAbsoluteError:vg,meanAbsolutePercentageError:Ig,meanSquaredLogarithmicError:function(e,t){return aa((()=>{const n=Io(t,Uf(),Number.MAX_VALUE),s=Yo(ja(1,n)),r=Io(e,Uf(),Number.MAX_VALUE),a=Yo(ja(1,r));return fl(tm(hi(s,a)),-1)}))},squaredHinge:function(e,t){return aa((()=>{const n=yi(0,hi(1,Xa(e,t)));return fl(tm(n),-1)}))},hinge:function(e,t){return aa((()=>{const n=yi(0,hi(1,Xa(e,t)));return fl(n,-1)}))},categoricalHinge:function(e,t){return aa((()=>{const n=Qo(Xa(e,t),-1),s=Zo(Xa(hi(1,e),t),-1);return yi(0,ja(1,hi(s,n)))}))},logcosh:function(e,t){return aa((()=>{const n=Math.log(2),s=hi(t,e),r=hi(ja(s,Ul(Xa(-2,s))),n);return fl(r,-1)}))},categoricalCrossentropy:Ng,sparseCategoricalCrossentropy:Sg,binaryCrossentropy:Tg,kullbackLeiblerDivergence:function(e,t){return aa((()=>{const n=Io(e,Uf(),1),s=Io(t,Uf(),1);return Qo(Xa(e,Yo(qa(n,s))),-1)}))},poisson:function(e,t){return aa((()=>{const n=Yo(ja(Uf(),t));return fl(hi(t,Xa(e,n)),-1)}))},cosineProximity:$g};function Cg(e){if("string"==typeof e){if(e in Eg)return Eg[e];let t=`Unknown loss ${e}`;throw e.toLowerCase().includes("softmaxcrossentropy")&&(t=`Unknown loss ${e}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`),new Xd(t)}return e}function Rg(e,t){return aa((()=>{const n=Xa(.5,Il(t)),s=Gf(Ko(t,n),e.dtype);return fl(Bo(e,s),-1)}))}function Ag(e,t){return aa((()=>Gf(Bo(Zi(e,-1),Zi(t,-1)),"float32")))}function _g(e,t){return Tg(e,t)}function Dg(e,t){return e.rank===t.rank&&(e=Hl(e,[e.rank-1])),(t=Zi(t,-1)).dtype!==e.dtype&&(t=Ga(t,e.dtype)),Ga(Bo(e,t),"float32")}const Fg=Ng,Og=Sg,Mg={binaryAccuracy:Rg,categoricalAccuracy:Ag,precision:function(e,t){return aa((()=>{const n=function(e,t){return aa((()=>Ga(Qo(cl(Bo(e,1),Bo(t,1))),"float32")))}(e,t),s=function(e,t){return aa((()=>Ga(Qo(cl(Bo(e,0),Bo(t,1))),"float32")))}(e,t),r=ja(n,s);return Ga(Zl(Ko(r,0),qa(n,r),0),"float32")}))},categoricalCrossentropy:Fg,sparseCategoricalCrossentropy:Og,mse:kg,MSE:kg,mae:vg,MAE:vg,mape:Ig,MAPE:Ig,cosine:$g};function Lg(e){if("string"==typeof e&&e in Mg)return Mg[e];if("string"!=typeof e&&null!=e)return e;throw new Xd(`Unknown metric ${e}`)}function zg(e){if(ef(null!==e,`Unknown LossOrMetricFn ${e}`),"string"==typeof e)return e;{let t;for(const n of Object.keys(Eg))if(Eg[n]===e){t=n;break}if(void 0!==t)return t;for(const n of Object.keys(Mg))if(Mg[n]===e){t=n;break}return void 0!==t?t:e.name}}function Bg(e,t,n=!1){if(null==e||"object"!=typeof e||Object.getPrototypeOf(e)!==Object.prototype||!Pg(e))throw new Error("User-defined metadata is expected to be a JSON object, but is not.");if(n){const n=JSON.stringify(e);n.length>1048576&&console.warn(`User-defined metadata of model "${t}" is too large in size (length=${n.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= 1048576.`)}}function Pg(e){if(null===e)return!0;if("object"==typeof e){if(Object.getPrototypeOf(e)===Object.prototype){const t=Object.keys(e);for(const n of t){if("string"!=typeof n)return!1;if(!Pg(e[n]))return!1}return!0}if(Array.isArray(e)){for(const t of e)if(!Pg(t))return!1;return!0}return!1}{const t=typeof e;return"string"===t||"number"===t||"boolean"===t}}function Wg(e,t,n=console.log){let s="";for(let n=0;n<e.length;++n)n>0&&(s=s.slice(0,s.length-1)+" "),s+=e[n],s=s.slice(0,t[n]),s+=" ".repeat(t[n]-s.length);n(s)}function Vg(e,t,n){let s,r;try{r=e.inboundNodes.map((e=>JSON.stringify(e.inputShapes))).join(",")}catch(e){r="multiple"}try{s=JSON.stringify(e.outputShape)}catch(e){s="multiple"}Wg([`${e.name} (${e.getClassName()})`,r,s,e.countParams().toString()],t,n)}function Ug(e,t,n,s){let r,a;try{a=e.inboundNodes.map((e=>JSON.stringify(e.inputShapes))).join(",")}catch(e){a="multiple"}try{r=JSON.stringify(e.outputShape)}catch(e){r="multiple"}const i=[];for(const t of e.inboundNodes)if(!(null!=n&&n.length>0&&-1===n.indexOf(t)))for(let e=0;e<t.inboundLayers.length;++e){const n=t.inboundLayers[e].name,s=t.nodeIndices[e],r=t.tensorIndices[e];i.push(`${n}[${s}][${r}]`)}const o=e.name,l=e.getClassName(),u=0===i.length?"":i[0];Wg([`${o} (${l})`,a,r,e.countParams().toString(),u],t,s);for(let e=1;e<i.length;++e)Wg(["","","","",i[e]],t,s)}function Gg(e,t,n){return("inboundNodes"===e||"outputLayers"===e||"inputLayers"===e)&&0===t&&"string"==typeof n}function Hg(e,t){if(null===e)return null;if("string"==typeof e)return af(e);if("number"==typeof e||"boolean"==typeof e)return e;if(e instanceof Array){const n=[],s=e.length;for(let r=0;r<s;++r){const s=e[r];Gg(t,r,s)?n.push(s):n.push(Hg(s,t))}return n}{const t={};for(const n of Object.keys(e)){const s=e[n];if("name"===n&&"string"==typeof s)t[n]=s;else{const e=af(n);t[e]=Hg(s,e)}}return t}}function jg(e,t){if(null==e)return null;if("string"==typeof e)return rf(e);if("number"==typeof e||"boolean"==typeof e)return e;if(e instanceof Array){const n=[],s=e.length;for(let r=0;r<s;++r){const s=e[r];Gg(t,r,s)?n.push(s):n.push(jg(s,t))}return n}{const t={};for(const n of Object.keys(e)){const s=e[n];t[rf(n)]="name"!==n&&"className"!==n||"string"!=typeof s?jg(s,n):s}return t}}const Kg="4.22.0";class qg extends Vm{constructor(e){if(super({}),this.containerNodes=new Set,this.name=e.name,null==this.name){const e=this.getClassName().toLowerCase();this.name=vf(e)}if(this.supportsMasking=!1,this.trainable_=!0,Array.isArray(e.inputs)?this.inputs=e.inputs.slice():this.inputs=[e.inputs],Array.isArray(e.outputs)?this.outputs=e.outputs.slice():this.outputs=[e.outputs],pf(this.inputs).length!==this.inputs.length)throw new Xd(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map((e=>e.name))}`);pf(this.outputs).length!==this.outputs.length&&console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map((e=>e.name))}`),this.inputLayers=[],this.inputLayersNodeIndices=[],this.inputLayersTensorIndices=[],this.outputLayers=[],this.outputLayersNodeIndices=[],this.outputLayersTensorIndices=[],this.layers=[],this.internalContainerRefs=[];for(const e of this.outputs){const t=e.sourceLayer,n=e.nodeIndex,s=e.tensorIndex;this.outputLayers.push(t),this.outputLayersNodeIndices.push(n),this.outputLayersTensorIndices.push(s)}for(const e of this.inputs){const t=e.sourceLayer,n=e.nodeIndex,s=e.tensorIndex;ef(0===n,"input layer has >1 nodes"),ef(0===s,"input layer has >1 tensors"),this.inputLayers.push(t),this.inputLayersNodeIndices.push(n),this.inputLayersTensorIndices.push(s)}this.inputNames=[],this.outputNames=[],this.feedInputShapes=[],this.feedInputNames=[],this.feedOutputNames=[];for(let t=0;t<this.inputLayers.length;t++){const n=this.inputLayers[t];if(!(n instanceof Gm))throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${e.inputs}. Input ${t} (0-based) originates from layer type ${n.getClassName()}.`);this.inputNames.push(n.name),this.feedInputShapes.push(n.batchInputShape),this.feedInputNames.push(n.name)}for(const e of this.outputLayers)this.outputNames.push(e.name);this.internalInputShapes=this.inputs.map((e=>e.shape)),this.internalOutputShapes=this.outputs.map((e=>e.shape));const t={},n={},s={},r={},a={},i=[],o=(e,t,n,s,r,l)=>{null!=s&&null!=r&&null!=l||(s=e.sourceLayer,r=e.nodeIndex,l=e.tensorIndex);const u=s.inboundNodes[r];if(-1!==n.indexOf(u))throw new qd(`The tensor ${e.name} at layer "${s.name}" is part of a cycle.`);if(-1!==t.indexOf(u))return;this.containerNodes.add(qg.nodeKey(s,r)),s.id in a||(a[s.id]=Object.keys(a).length),-1===n.indexOf(u)&&n.push(u);const c=u.inboundLayers.length;for(let e=0;e<c;e++){const s=u.inputTensors[e],r=u.inboundLayers[e],a=u.nodeIndices[e],i=u.tensorIndices[e];o(s,t,n,r,a,i)}for(t.push(u);n.indexOf(u)>=0;)n.splice(n.indexOf(u),1);i.push(u)},l=[],u=[];for(const e of this.outputs)o(e,l,u);const c=i.slice().reverse();for(const e of c){n[e.id]=e,e.id in t||(t[e.id]=0);let a=t[e.id];const i=null==s[e.outboundLayer.id]?0:s[e.outboundLayer.id];a=Math.max(a,i),s[e.outboundLayer.id]=a,r[e.outboundLayer.id]=e.outboundLayer,t[e.id]=a;for(let s=0;s<e.inboundLayers.length;s++){const r=e.inboundLayers[s],i=e.nodeIndices[s],o=r.inboundNodes[i],l=null==t[o.id]?0:t[o.id];t[o.id]=Math.max(a+1,l),n[o.id]=o}}const h={};for(const e in t){const s=t[e];s in h||(h[s]=[]),h[s].push(n[e])}const p={};for(const e in s){const t=s[e];t in p||(p[t]=[]),p[t].push(r[e])}let d=Object.keys(p).map((e=>parseInt(e,10))).sort(hf);this.layers=[];for(const e of d){const t=p[e];t.sort(((e,t)=>{const n=a[e.id],s=a[t.id];return n<s?-1:n>s?1:0}));for(const e of t)e instanceof qg&&this.internalContainerRefs.push(e),this.layers.push(e)}this.layersByDepth=p,d=Object.keys(h).map((e=>parseInt(e,10))).sort(hf);const f=this.inputs.slice(),m=[];for(const e of d)for(const t of h[e]){const e=t.outboundLayer;if(null!=e){for(const n of t.inputTensors)if(-1===f.indexOf(n))throw new qd(`Graph disconnected: cannot obtain value for tensor ${n} at layer "${e.name}". The following previous layers were accessed without issue: ${m}`);for(const e of t.outputTensors)f.push(e);m.push(e.name)}}this.nodesByDepth=h;const g=this.layers.map((e=>e.name));for(const e of g){const t=g.filter((t=>t===e)).length;if(1!==t)throw new qd(`The name "${e}" is used ${t} times in the model. All layer names should be unique. Layer names: `+JSON.stringify(g))}this.outboundNodes=[],this.inboundNodes=[],new Pm({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:this.inputs.map((e=>null)),outputMasks:this.outputs.map((e=>null)),inputShapes:this.inputs.map((e=>e.shape)),outputShapes:this.outputs.map((e=>e.shape))}),this.built=!0,this._refCount=1}assertNotDisposed(){if(0===this._refCount)throw new Error(`Container '${this.name}' is already disposed.`)}dispose(){this.assertNotDisposed();const e={refCountAfterDispose:null,numDisposedVariables:0};if(0==--this._refCount){for(const t of this.layers)e.numDisposedVariables+=t.dispose().numDisposedVariables;for(const t of this.internalContainerRefs)e.numDisposedVariables+=t.dispose().numDisposedVariables}return e.refCountAfterDispose=this._refCount,e}get trainable(){return this.trainable_}set trainable(e){this.layers.forEach((t=>{t._trainableWeights.forEach((t=>t.trainable=e))})),this.trainable_=e}get trainableWeights(){if(this._trainableWeights.length>0)throw new Xd("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");if(!this.trainable)return[];let e=[];for(const t of this.layers)e=e.concat(t.trainableWeights);return e}get nonTrainableWeights(){const e=[];for(const t of this.layers)e.push(...t.nonTrainableWeights);if(!this.trainable){const t=[];for(const e of this.layers)t.push(...e.trainableWeights);return t.concat(e)}return e}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}loadWeights(e,t=!0){const n={};let s=0;const r=(e=>{const t=Object.keys(e);if(0===t.length)return!1;const n=t[0].split("/");return!isNaN(parseInt(n[n.length-1],10))})(e);r&&this.parseWeights(e);for(const e of this.layers)for(const[t,a]of e.weights.entries()){const e=r?`${a.name.split("/").slice(0,-1).join("/")+"/"}${t}`:a.originalName;if(null!=n[e])throw new Xd(`Duplicate weight name: ${e}`);n[e]=a,s++}const a=[];for(const s in e){let r=s;if(null==n[s]){const e=s.split("/");r=e.slice(0,-2).concat([e[e.length-1]]).join("/")}if(null!=n[r])a.push([n[r],e[s]]);else if(t)throw new Xd(`Provided weight data has no target variable: ${s}`);delete n[r]}if(t){const e=[];for(const t in n)e.push(t);if(e.length>0)throw new Xd(`${e.length} of ${s} weights are not set: ${e}`)}Mm(a)}parseWeights(e){for(const t in Object.keys(e)){const n=t.split("/"),s=["vars","layer_checkpoint_dependencies"],r=n.map((e=>e.startsWith("_")?e.slice(1):e)).filter((e=>!s.includes(e))).join("/");r!==t&&(e[r]=e[t],delete e[t])}}updatedConfig(){const e=this.getConfig(),t={};return t.className=this.getClassName(),t.config=e,t.kerasVersion=`tfjs-layers ${Kg}`,t.backend="TensorFlow.js",t}toJSON(e,t=!0){const n=jg(this.updatedConfig());return t?JSON.stringify(n):n}call(e,t){return aa((()=>{e=sf(e);const n=new Hm;for(let t=0;t<this.inputs.length;++t)n.add(this.inputs[t],e[t]);return qm(this.outputs,n,t)}))}computeMask(e,t){return aa((()=>{let n;return e=sf(e),n=null==t?Qd(null,e.length):sf(t),this.runInternalGraph(e,n)[1]}))}computeOutputShape(e){const t=Cm(e);if(t.length!==this.inputLayers.length)throw new Xd(`Invalid inputShape argument ${e}: model has ${this.inputLayers.length} tensor inputs.`);const n={};for(let e=0;e<t.length;e++){const s=this.inputLayers[e],r=t[e];n[s.name+"_0_0"]=r}const s=Object.keys(this.nodesByDepth).map((e=>parseInt(e,10))).sort(hf);if(s.length>1)for(const e of s){const t=this.nodesByDepth[e];for(const e of t){const t=e.outboundLayer;if(-1!==this.inputLayers.map((e=>e.id)).indexOf(t.id))continue;const s=[];for(let t=0;t<e.inboundLayers.length;t++){const r=e.inboundLayers[t],a=e.nodeIndices[t],i=e.tensorIndices[t],o=n[`${r.name}_${a}_${i}`];s.push(o)}const r=Cm(t.computeOutputShape(nf(s))),a=t.inboundNodes.indexOf(e);for(let e=0;e<r.length;e++)n[`${t.name}_${a}_${e}`]=r[e]}}const r=[],a=[];for(let e=0;e<this.outputLayers.length;e++){const t=this.outputLayers[e],n=this.outputLayersNodeIndices[e],s=this.outputLayersTensorIndices[e],r=`${t.name}_${n}_${s}`;a.push(r)}for(let e=0;e<a.length;e++){const t=a[e];ef(t in n),r.push(n[t])}return nf(r)}runInternalGraph(e,t){null==t&&(t=Qd(null,e.length));const n={};for(let s=0;s<this.inputs.length;++s){const r=this.inputs[s],a=e[s],i=t[s];n[r.id]=[a,i]}const s=Object.keys(this.nodesByDepth).map((e=>parseInt(e,10))).sort(hf);for(const e of s){const t=this.nodesByDepth[e];for(const e of t){const t=e.outboundLayer,s=e.inputTensors,r=e.outputTensors,a=new Array;for(const e of s)e.id in n&&a.push(n[e.id]);if(a.length===s.length){let s,i,o,l,u={};if(null!=e.callArgs&&(u=e.callArgs),1===a.length){const[e,n]=a[0];null==u.mask&&(u.mask=n),o=sf(t.call(e,u)),l=sf(t.computeMask(e,n)),s=[e],i=[n]}else s=a.map((e=>e[0])),i=a.map((e=>e[1])),null==u.mask&&(u.mask=i),o=sf(t.call(s,u)),l=sf(t.computeMask(s,i));if(t.activityRegularizer)throw new Yd("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");for(let e=0;e<r.length;++e){const t=r[e],s=o[e],a=l[e];n[t.id]=[s,a]}}}}const r=[],a=[],i=[];for(const e of this.outputs){ef(e.id in n,`Could not compute output ${e.name} : ${e.id}`);const[t,s]=n[e.id];i.push(t.shape),r.push(t),a.push(s)}return[r,a,i]}buildNodeConversionMap(e){const t={};let n;for(const e of this.layers){n=e instanceof qg?1:0;for(let s=0;s<e.inboundNodes.length;s++){const r=qg.nodeKey(e,s);this.containerNodes.has(r)&&(t[r]=n,n+=1)}}return t}getLayer(e,t){if(null!=t)return this.findLayer(t);if(null==e)throw new Xd("Provide either a layer name or layer index");if("number"==typeof e)return this.findLayer(e);for(const t of this.layers)if(t.name===e)return t;throw new Xd(`No such layer: ${e}`)}findLayer(e){if(this.layers.length<=e)throw new Xd(`Was asked to retrieve layer at index ${e}, but model only has ${this.layers.length} layer(s).`);return this.layers[e]}calculateLosses(){return aa((()=>{const e=[];for(const t of this.layers)for(let n=0;n<t.inboundNodes.length;++n){const s=qg.nodeKey(t,n);this.containerNodes.has(s)&&e.push(...t.calculateLosses())}return e}))}getConfig(){const e={name:this.name},t=this.buildNodeConversionMap(this.layers),n=[];for(const e of this.layers){const s=e.getClassName(),r=e.getConfig(),a=[];for(let n=0;n<e.inboundNodes.length;n++){const s=e.inboundNodes[n],r=qg.nodeKey(e,n);let i={};if(this.containerNodes.has(r)){if(s.callArgs)try{JSON.stringify(s.callArgs),i=s.callArgs}catch(t){console.warn(`Layer ${e.name} was passed non-serializable keyword arguments: ${s.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`),i={}}if(s.inboundLayers.length>0){const e=[];for(let n=0;n<s.inboundLayers.length;n++){const r=s.inboundLayers[n],a=s.nodeIndices[n],o=s.tensorIndices[n];let l=t[qg.nodeKey(r,a)];null==l&&(l=0),e.push([r.name,l,o,i])}a.push(e)}}}const i={};i.name=e.name,i.className=s,i.config=r,i.inboundNodes=a,n.push(i)}e.layers=n;const s=[];for(let e=0;e<this.inputLayers.length;e++){const n=this.inputLayers[e],r=this.inputLayersNodeIndices[e],a=qg.nodeKey(n,r);if(!this.containerNodes.has(a))continue;let i=t[a];null==i&&(i=0);const o=this.inputLayersTensorIndices[e];s.push([n.name,i,o])}e.inputLayers=s;const r=[];for(let e=0;e<this.outputLayers.length;e++){const n=this.outputLayers[e],s=this.outputLayersNodeIndices[e],a=qg.nodeKey(n,s);if(!this.containerNodes.has(a))continue;let i=t[a];null==i&&(i=0);const o=this.outputLayersTensorIndices[e];r.push([n.name,i,o])}return e.outputLayers=r,e}static fromConfig(e,t,n={},s=!1){const r={},a={};function i(e,t){e.name in a?a[e.name].push(t):a[e.name]=[t]}function o(e,t){const n=[];let s;for(const a of t){const o=a[0],l=a[1],u=a[2];if(s=null==a[3]?{}:a[3],!(o in r))return void i(e,t);const c=r[o];if(c.inboundNodes.length<=l)return void i(e,t);const h=c.inboundNodes[l];n.push(h.outputTensors[u])}n.length>0&&e.apply(nf(n),s)}function l(e){const n=e.name,a=xg(e,null!=t.customObjects?t.customObjects:{});a.setFastWeightInitDuringBuild(s),r[n]=a,e.inboundNodes.forEach((e=>{if(!(e instanceof Array))throw new Xd(`Corrupted configuration, expected array for nodeData: ${e}`);i(a,e)}))}const u=t.name,c=t.layers;for(const e of c)l(e);for(;!df(a);)for(const e of c){const t=r[e.name];if(t.name in a){const e=a[t.name];delete a[t.name];for(const n of e)o(t,n)}}const h=[],p=[],d=t.inputLayers;for(const e of d){const t=e[0],n=e[1],s=e[2];ef(t in r);const a=r[t].inboundNodes[n].outputTensors;h.push(a[s])}const f=t.outputLayers;for(const e of f){const t=e[0],n=e[1],s=e[2];ef(t in r);const a=r[t].inboundNodes[n].outputTensors;p.push(a[s])}return new e({inputs:h,outputs:p,name:u})}get stateful(){if(this._stateful)throw new Xd("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");for(const e of this.layers)if(e.stateful)return!0;return!1}resetStates(){aa((()=>{this.layers.forEach((e=>{e.stateful&&e.resetStates()}))}))}}function Xg(e,t){return function(e,t,n){const s=t.length;if(null==e||Array.isArray(e)&&0===e.length)return t.map((e=>null));if(1===s)return Array.isArray(e)&&1===e.length?e:"object"==typeof e&&t[0]in e?[e[t[0]]]:[e];if(Array.isArray(e)){if(e.length!==s)throw new Error(`Provided ${n} is an array of ${e.length} element(s), but the model has ${s} outputs. Make sure a set of weights is provided for each model output.`);return e}if("object"==typeof e&&Object.keys(e).length>0&&"object"==typeof e[Object.keys(e)[0]]){const n=[];return t.forEach((t=>{t in e?n.push(e[t]):n.push(null)})),n}throw new Error(`The model has multiple (${s}) outputs, so ${n} must be either an array with ${s} elements or an object with ${t} keys. Provided ${n} not understood: ${JSON.stringify(e)}`)}(e,t,"classWeight")}async function Yg(e,t,n,s){if(null!=t||null!=s)throw new Error("Support sampleWeight is not implemented yet");if(null!=n){const t=aa((()=>{if(1===e.shape.length)return Ha(e);if(2===e.shape.length){if(e.shape[1]>1)return Zi(e,1);if(1===e.shape[1])return mo(e,[e.shape[0]]);throw new Error(`Encountered unexpected last-dimension size (${e.shape[1]}) during handling of class weights. The size is expected to be >= 1.`)}throw new Error(`Unexpected rank of target (y) tensor (${e.rank}) during handling of class weights. The rank is expected to be 1 or 2.`)})),s=Array.from(await t.data());ia(t);const r=[];return s.forEach((e=>{if(null==n[e])throw new Error(`classWeight must contain all classes in the training data. The class ${e} exists in the data but not in classWeight`);r.push(n[e])})),ql(r,"float32")}return null}function Jg(e,t){return Xa(e,t)}function Zg(e,t){let n,s;const r=t;n=r.xs,s=r.ys,F(null!=n&&null!=s,(()=>`A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${t}`));const a=Qg("input",e.inputNames,n),i=Qg("output",e.outputNames,s),o=a[0].shape[0];F(a.length===e.inputs.length,(()=>`LayersModel has ${e.inputs.length} inputs, but the dataset provides ${a.length} inputs.  (Expected input keys: ${JSON.stringify(e.inputNames)})`)),F(i.length===e.outputs.length,(()=>`LayersModel has ${e.outputs.length} outputs, but the dataset provides ${i.length} outputs.  (Expected output keys: ${JSON.stringify(e.outputNames)})`));for(let t=0;t<a.length;t++)F(a[t].shape[0]===o,(()=>`Batch size mismatch: input ${e.inputNames[t]} has ${a[t].shape[0]}; expected  ${o} based on input ${e.inputNames[0]}.`));for(let t=0;t<i.length;t++)F(i[t].shape[0]===o,(()=>`Batch size mismatch: output ${e.outputNames[t]} has ${i[t].shape[0]}; expected  ${o} based on input ${e.inputNames[0]}.`));return{xs:a,ys:i}}function Qg(e,t,n){if(n instanceof wr)return[n];if(Array.isArray(n))return F(n.length===t.length,(()=>`Received an array of ${n.length} Tensors, but expected ${t.length} to match the ${e} keys ${t}.`)),n;{const s=[];for(const r of t){if(null==n[r])throw new Xd(`The feature data generated by the dataset lacks the required ${e} key '${r}'.`);s.push(n[r])}return s}}function ey(e){return"function"==typeof e.iterator}function ty(e){F(e>0&&Number.isInteger(e),(()=>`batchSize is required to be a positive integer, but got ${e}`))}function ny(e,t,n){return null==e?[null]:Array.isArray(e)?e.map((e=>jf(e,t,n-t))):jf(e,t,n-t)}function sy(e,t){return aa((()=>null==e?null:Array.isArray(e)?e.map((e=>sy(e,t))):em(e,"int32"===t.dtype?t:Ga(t,"int32"))))}function ry(e,t){const n=[];let s=0,r=null;for(;s<e;)r=s+t,r>=e&&(r=e),n.push([s,r]),s=r;return n}function ay(e){const t=[];e instanceof wr&&(e=[e]);for(let n=0;n<e.length;++n){const s=e[n];if(1===s.rank)t.push(Hf(s,1));else{if(0===s.rank)throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");t.push(s)}}return t}function iy(e,t){if(null==e)return;const n=[];if(t instanceof wr)n.push(t.id);else if(Array.isArray(t))t.forEach((e=>n.push(e.id)));else if(null!=t)for(const e in t){const s=t[e];n.push(s.id)}const s=[];if(e instanceof wr)-1===n.indexOf(e.id)&&s.push(e);else if(Array.isArray(e))e.forEach((e=>{-1===n.indexOf(e.id)&&s.push(e)}));else if(null!=e)for(const t in e){const r=e[t];-1===n.indexOf(r.id)&&s.push(r)}s.forEach((e=>{e.isDisposed||e.dispose()}))}function oy(e){return Array.isArray(e)}function ly(e){return!function(e){return e instanceof wr}(e)&&!oy(e)}function uy(e,t,n,s=!0,r=""){if(null==t||0===t.length){if(null!=e){let t=!1;if(oy(e)&&e.length>0)t=!0;else if(ly(e)){for(const n in e)if(e.hasOwnProperty(n)){t=!0;break}}else t=!0;if(t)throw new Xd(`Error when checking model ${r} expected no data, but got ${e}`)}return[]}if(null==e)return t.map((e=>null));let a;if(ly(e)){a=[];for(const n of t){if(null==e[n])throw new Xd(`No data provided for "${n}". Need data for each key in: ${t}`);a.push(e[n])}}else if(oy(e)){if(e.length!==t.length)throw new Xd(`Error when checking model ${r}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${t.length} Tensor(s), but instead got the following list of Tensor(s): ${e}`);a=e}else{if(t.length>1)throw new Xd(`The model ${r} expects ${t.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${e.shape}`);a=[e]}if(a=ay(a),null!=n)for(let e=0;e<t.length;++e){if(null==n[e])continue;const i=a[e];if(i.shape.length!==n[e].length)throw new Xd(`Error when checking ${r}: expected ${t[e]} to have ${n[e].length} dimension(s). but got array with shape ${i.shape}`);for(let t=0;t<n[e].length;++t){if(0===t&&!s)continue;const a=i.shape[t],o=n[e][t];if(null!=o&&o>=0&&a!==o)throw new Xd(`${r} expected a batch of elements where each example has shape [${n[e].slice(1,n[e].length)}] (i.e.,tensor shape [*,${n[e].slice(1,n[e].length)}]) but the ${r} received an input with ${i.shape[0]} examples, each with shape [${i.shape.slice(1,i.shape.length)}] (tensor shape [${i.shape}])`)}}return a}function cy(e,t,n,s=!0,r=""){let a;if(Array.isArray(e)){if(e.length!==t.length)throw new Xd(`Error when checking model ${r}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${t.length} Tensor(s), but instead got ${e.length} Tensors(s).`);a=e}else{if(t.length>1)throw new Xd(`The model expects ${t.length} ${r} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(e.shape)}.`);a=[e]}if(null!=n)for(let e=0;e<t.length;++e){if(null==n[e])continue;const i=a[e];if(i.shape.length!==n[e].length)throw new Xd(`Error when checking ${r}: expected ${t[e]} to have ${n[e].length} dimension(s), but got array with shape ${JSON.stringify(i.shape)}`);for(let a=0;a<n[e].length;++a){if(0===a&&!s)continue;const o=i.shape[a],l=n[e][a];if(null!=l&&l!==o)throw new Xd(`Error when checking ${r}: expected ${t[e]} to have shape ${JSON.stringify(n[e])} but got array with shape ${JSON.stringify(i.shape)}.`)}}}class hy extends qg{constructor(e){super(e),this.isTraining=!1}summary(e,t,n=console.log){if(!this.built)throw new Xd("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");!function(e,t,n,s=console.log){const r=function(e){let t=!0;const n=[],s=[];for(const t in e.nodesByDepth)n.push(e.nodesByDepth[t]);for(const e of n){if(e.length>1||1===e.length&&e[0].inboundLayers.length>1){t=!1;break}s.push(...e)}if(t)for(const n of e.layers){let e=!1;for(const r of n.inboundNodes)if(-1!==s.indexOf(r)){if(e){t=!1;break}e=!0}if(!t)break}return t}(e),a=["Layer (type)","Input Shape","Output shape","Param #"];let i;if(r?(t=t||90,n=n||[.32,.61,.89,1]):(t=t||115,n=n||[.24,.48,.7,.8,1]),n[n.length-1]<=1&&(n=n.map((e=>Math.floor(t*e)))),!r){a.push("Receives inputs"),i=[];for(const t in e.nodesByDepth)i.push(...e.nodesByDepth[t])}s("_".repeat(t)),Wg(a,n,s),s("=".repeat(t));const o=e.layers;for(let e=0;e<o.length;++e)r?Vg(o[e],n,s):Ug(o[e],n,i,s),s((e===o.length-1?"=":"_").repeat(t));e.checkTrainableWeightsConsistency();const l=function(e){let t;return t=null!=e.collectedTrainableWeights?_m(e.collectedTrainableWeights):_m(e.trainableWeights),t}(e),u=_m(e.nonTrainableWeights);s(`Total params: ${l+u}`),s(`Trainable params: ${l}`),s(`Non-trainable params: ${u}`),s("_".repeat(t))}(this,e,t,n)}compile(e){if(null==e.loss&&(e.loss=[]),this.loss=e.loss,"string"==typeof e.optimizer)this.optimizer_=function(e){const t={Adagrad:()=>tc.adagrad(.01),Adadelta:()=>tc.adadelta(1,.95,Uf()),Adam:()=>tc.adam(.001,.9,.999,Uf()),Adamax:()=>tc.adamax(.002,.9,.999,Uf(),0),RMSProp:()=>tc.rmsprop(.001,.9,0,Uf()),SGD:()=>tc.sgd(.01)};if(t.adagrad=t.Adagrad,t.adadelta=t.Adadelta,t.adam=t.Adam,t.adamax=t.Adamax,t.rmsprop=t.RMSProp,t.sgd=t.SGD,e in t)return t[e]();throw new Xd(`Unknown Optimizer ${e}`)}(e.optimizer),this.isOptimizerOwned=!0;else{if(!(e.optimizer instanceof ii))throw new Xd("User-defined optimizer must be an instance of tf.Optimizer.");this.optimizer_=e.optimizer,this.isOptimizerOwned=!1}let t=[];if(Array.isArray(e.loss)||"string"==typeof e.loss||"function"==typeof e.loss)if(Array.isArray(e.loss)){if(e.loss.length!==this.outputs.length)throw new Xd(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${e.loss}.`);const n=e.loss;t=n.map((e=>Cg(e)))}else{const n=Cg(e.loss);this.outputs.forEach((e=>{t.push(n)}))}else{e.loss=e.loss;for(const t in e.loss)if(-1===this.outputNames.indexOf(t))throw new Xd(`Unknown entry in loss dictionary: "${t}". Only expected the following keys: ${this.outputNames}`);for(const n of this.outputNames)null==e.loss[n]&&console.warn(`Output "${n}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${n} during training`),t.push(Cg(e.loss[n]))}this.lossFunctions=t,this.feedOutputNames=[],this.feedOutputShapes=[],this.feedLossFns=[];for(let e=0;e<this.outputs.length;++e){const t=this.internalOutputShapes[e],n=this.outputNames[e];this.feedOutputNames.push(n),this.feedOutputShapes.push(t),this.feedLossFns.push(this.lossFunctions[e])}const n=[];this.metrics=e.metrics,this.metricsNames=["loss"],this.metricsTensors=[],Df("loss",(()=>{for(let e=0;e<this.outputs.length;++e){if(-1!==n.indexOf(e))continue;const t=this.lossFunctions[e];this.outputs.length>1&&(this.metricsTensors.push([t,e]),this.metricsNames.push(this.outputNames[e]+"_loss"))}}));const s=function(e,t){if(null==e||Array.isArray(e)&&0===e.length)return t.map((e=>[]));let n;if("string"==typeof e||"function"==typeof e)n=[e];else{if(!Array.isArray(e)&&"object"!=typeof e)throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${e}`);n=e}if(Array.isArray(n))return t.map((e=>n));{const e=[];for(const s of t){let t=n.hasOwnProperty(s)?n[s]:[];Array.isArray(t)||(t=[t]),e.push(t)}return e}}(e.metrics,this.outputNames),r=(e,t,n)=>{this.outputNames.length>1&&(t=this.outputNames[e]+"_"+t),this.metricsNames.push(t),this.metricsTensors.push([n,e])};Df("metric",(()=>{for(let e=0;e<this.outputs.length;++e)-1===n.indexOf(e)&&(t=>{let n,s,a;for(const i of t){if("string"==typeof i&&-1!==["accuracy","acc","crossentropy","ce"].indexOf(i)){const t=this.internalOutputShapes[e];let r;1===t[t.length-1]||this.lossFunctions[e]===Tg?-1!==["accuracy","acc"].indexOf(i)?s=Rg:-1!==["crossentropy","ce"].indexOf(i)&&(s=_g):this.lossFunctions[e]===Sg?-1!==["accuracy","acc"].indexOf(i)?s=Dg:-1!==["crossentropy","ce"].indexOf(i)&&(s=Og):-1!==["accuracy","acc"].indexOf(i)?s=Ag:-1!==["crossentropy","ce"].indexOf(i)&&(s=Fg),-1!==["accuracy","acc"].indexOf(i)?r="acc":-1!==["crossentropy","ce"].indexOf(i)&&(r="ce"),a=s,n=""+r}else{const e=Lg(i);a=e,n=""+zg(i)}let t;Df(n,(()=>{t=a})),r(e,n,t)}})(s[e])})),this.collectedTrainableWeights=this.trainableWeights}checkTrainableWeightsConsistency(){null!=this.collectedTrainableWeights&&this.trainableWeights.length!==this.collectedTrainableWeights.length&&console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?")}evaluate(e,t,n={}){const s=null==n.batchSize?32:n.batchSize;ty(s);const r=this.standardizeUserDataXY(e,t,!0,s);try{const e=r[0].concat(r[1]);this.makeTestFunction();const t=this.testFunction;return nf(this.testLoop(t,e,s,n.verbose,n.steps))}finally{iy(r[0],e),iy(r[1],t)}}async evaluateDataset(e,t){return this.makeTestFunction(),async function(e,t,n){const s=null!=(n=n||{}).batches,r=e.testFunction;let a=[];if(n.verbose>0)throw new Yd("Verbose mode is not implemented yet.");F(!s||n.batches>0&&Number.isInteger(n.batches),(()=>`Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(n.batches)}`));const i="function"==typeof t.next?t:await t.iterator();let o=0,l=0;for(;!s||l<n.batches;){const t=await i.next();if(a=aa((()=>{if(t.value){const{xs:n,ys:s}=Zg(e,t.value),i=n.concat(s),u=aa((()=>r(i)));if(ia(i),0===l)for(let e=0;e<u.length;++e)a.push(ei(0));const c=i[0].shape[0];for(let e=0;e<u.length;++e){const t=u[e],n=a[e];a[e]=aa((()=>ja(a[e],Xa(c,t)))),l>0&&ia(n)}ia(u),o+=c,++l}return a})),t.done){s&&console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${n.batches} batches). You may need to use the repeat() function when building your dataset.`);break}}for(let e=0;e<a.length;++e){const t=a[e];a[e]=qa(a[e],o),ia(t)}return nf(a)}(this,e,t)}checkNumSamples(e,t,n,s="steps"){let r;if(null!=n){if(r=null,null!=t)throw new Xd(`If ${s} is set, batchSize must be null or undefined.Got batchSize = ${t}`)}else{if(null==e)throw new Xd(`Either the input data should have a defined shape, or ${s} shoud be specified.`);r=Array.isArray(e)?e[0].shape[0]:e.shape[0]}return r}execute(e,t){if(Array.isArray(t)&&0===t.length)throw new Xd("`outputs` is an empty Array, which is not allowed.");const n=Array.isArray(t),s=n?t:[t],r=this.retrieveSymbolicTensors(s),a=new Hm;if(e instanceof wr&&(e=[e]),Array.isArray(e)){if(e.length!==this.inputs.length)throw new Xd(`The number of inputs provided (${e.length}) does not match the number of inputs of this model (${this.inputs.length}).`);for(let t=0;t<this.inputs.length;++t)a.add(this.inputs[t],e[t])}else for(const t of this.inputs){const n=e[t.name];if(null==n)throw new Xd(`No value is provided for the model's input ${t.name}`);a.add(t,n)}const i=qm(r,a);return n?i:i[0]}retrieveSymbolicTensors(e){const t=Qd(null,e.length);let n=e.length;for(const s of this.layers){const r=Array.isArray(s.output)?s.output:[s.output],a=r.map((e=>e.name));for(let s=0;s<e.length;++s){const i=a.indexOf(e[s]);if(-1!==i&&(t[s]=r[i],n--),0===n)break}if(0===n)break}if(n>0){const n=[];throw t.forEach(((t,s)=>{null==t&&n.push(e[s])})),new Xd(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(n)}`)}return t}predictLoop(e,t=32,n=!1){return aa((()=>{const s=this.checkNumSamples(e);if(n)throw new Yd("Verbose predictLoop() is not implemented yet.");const r=ry(s,t),a=this.outputs.map((e=>[]));for(let t=0;t<r.length;++t)aa((()=>{const n=r[t][0],s=r[t][1],a=ny(e,n,s),i=[];if(Array.isArray(a))for(let e=0;e<a.length;++e)i.push({key:this.inputs[e],value:a[e]});else i.push({key:this.inputs[0],value:a});const o=new Hm(i);return qm(this.outputs,o)})).forEach(((e,t)=>a[t].push(e)));return nf(a.map((e=>No(e,0))))}))}predict(e,t={}){const n=ay(e);cy(n,this.inputNames,this.feedInputShapes,!1);try{const e=null==t.batchSize?32:t.batchSize;return ty(e),this.predictLoop(n,e)}finally{iy(n,e)}}predictOnBatch(e){cy(e,this.inputNames,this.feedInputShapes,!0);const t=(Array.isArray(e)?e[0]:e).shape[0];return this.predictLoop(e,t)}standardizeUserDataXY(e,t,n=!0,s){if(null==this.optimizer_)throw new qd("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");const r=[];for(let e=0;e<this.feedOutputShapes.length;++e){const t=this.feedOutputShapes[e];this.feedLossFns[e]===Sg?r.push(t.slice(0,t.length-1).concat([1])):r.push(t)}if(function(e,t){const n=pf(e.map((e=>e.shape[0])));n.sort();const s=pf(t.map((e=>e.shape[0])));if(s.sort(),n.length>1)throw new Xd(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(e.map((e=>e.shape)))}`);if(s.length>1)throw new Xd(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(t.map((e=>e.shape)))}`);if(n.length>0&&s.length>0&&!z(n,s))throw new Xd(`Input Tensors should have the same number of samples as target Tensors. Found ${n[0]} input sample(s) and ${s[0]} target sample(s).`)}(e=uy(e,this.feedInputNames,this.feedInputShapes,!1,"input"),t=uy(t,this.feedOutputNames,r,!1,"target")),function(e,t,n){const s=[kg,Tg,Ng];for(let r=0;r<e.length;++r){const a=e[r],i=t[r],o=n[r];if(null!=i){if(i===Ng&&1===a.shape[a.shape.length-1])throw new Xd(`You are passing a target array of shape ${a.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);if(-1!==s.indexOf(i)){const e=a.shape.slice(1),t=o.slice(1);for(let n=0;n<e.length;++n){const s=e[n],r=t[n];if(null!=r&&s!==r)throw new Xd(`A target Tensor with shape ${a.shape} was passed for an output of shape ${o}, while using a loss function that expects targets to have the same shape as the output.`)}}}}}(t,this.feedLossFns,this.feedOutputShapes),this.stateful&&null!=s&&s>0&&e[0].shape[0]%s!=0)throw new Xd(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${s}. Found: ${e[0].shape[0]} sample(s).`);return[e,t]}async standardizeUserData(e,t,n,s,r=!0,a){const[i,o]=this.standardizeUserDataXY(e,t,r,a);if(null!=n)throw new Error("sample weight is not supported yet.");let l=null;if(null!=s){const e=Xg(s,this.outputNames);l=[];for(let t=0;t<e.length;++t)l.push(await Yg(o[t],null,e[t]))}return[i,o,l]}testLoop(e,t,n,s=0,r){return aa((()=>{const a=this.checkNumSamples(t,n,r,"steps"),i=[];if(s>0)throw new Yd("Verbose mode is not implemented yet.");if(null!=r)throw new Yd("steps mode in testLoop() is not implemented yet");{const s=ry(a,n),r=ql(Wf(0,a));for(let n=0;n<s.length;++n){const a=s[n][0],o=s[n][1],l=jf(r,a,o-a),u=sy(t,l),c=e(u);if(0===n)for(let e=0;e<c.length;++e)i.push(ei(0));for(let e=0;e<c.length;++e){const t=c[e];i[e]=ja(i[e],Xa(o-a,t))}}for(let e=0;e<i.length;++e)i[e]=qa(i[e],a)}return i}))}getDedupedMetricsNames(){const e=this.metricsNames,t=[];for(let n=0;n<e.length;++n){const s=e[n];let r=s;tf(e,s)>1&&(r+=`_${tf(e.slice(0,n),s)}`),t.push(r)}return t}makeTrainFunction(){return e=>{const t=[],n=e.slice(0,this.inputs.length),s=e.slice(this.inputs.length,this.inputs.length+this.outputs.length),r=e.slice(this.inputs.length+this.outputs.length,this.inputs.length+2*this.outputs.length),a=[],i=this.collectedTrainableWeights.map((e=>e.read()));return[this.optimizer_.minimize((()=>{const e=[];for(let t=0;t<this.inputs.length;++t)e.push({key:this.inputs[t],value:n[t]});const i=new Hm(e),o=qm(this.outputs,i,{training:!0});let l;for(let e=0;e<this.lossFunctions.length;++e){let n=(0,this.lossFunctions[e])(s[e],o[e]);null!=r[e]&&(n=Jg(n,r[e]));const a=fl(n);t.push(a),l=0===e?n:ja(l,n)}for(let e=0;e<this.metricsTensors.length;++e){let n;if(this.outputs.length>1&&e<this.outputs.length)n=t[e];else{const t=this.metricsTensors[e][0],r=this.metricsTensors[e][1];n=fl(t(s[r],o[r]))}oa(n),a.push(n)}return l=fl(l),this.calculateLosses().forEach((e=>{l=ja(l,e)})),l}),!0,i)].concat(a)}}makeTestFunction(){this.testFunction=e=>aa((()=>{const t=[];let n;const s=e.slice(0,this.inputs.length),r=e.slice(this.inputs.length,this.inputs.length+this.outputs.length),a=[];for(let e=0;e<this.inputs.length;++e)a.push({key:this.inputs[e],value:s[e]});const i=new Hm(a),o=qm(this.outputs,i);for(let e=0;e<this.lossFunctions.length;++e){const s=this.lossFunctions[e],a=fl(s(r[e],o[e]));n=0===e?a:ja(n,a),t.push(n)}for(let e=0;e<this.metricsTensors.length;++e){const n=this.metricsTensors[e][0],s=this.metricsTensors[e][1],a=fl(n(r[s],o[s]));t.push(a)}return t}))}async fit(e,t,n={}){if(this.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");let s,r,a,i,o,l,u,c,h;this.isTraining=!0;try{const p=null==n.batchSize?32:n.batchSize;ty(p);const d=!1,f=await this.standardizeUserData(e,t,n.sampleWeight,n.classWeight,d,p);s=f[0],r=f[1],h=f[2];let m,g=!1;if(null!=n.validationData&&n.validationData.length>0){if(g=!0,2!==n.validationData.length)throw 3===n.validationData.length?new Yd("validationData including sample weights is not supported yet."):new Xd(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${n.validationData} is invalid.`);o=n.validationData[0],l=n.validationData[1];const e=!0,t=await this.standardizeUserData(o,l,null,null,e,p);u=t[0],c=t[1],m=u.concat(c)}else if(null!=n.validationSplit&&n.validationSplit>0&&n.validationSplit<1){g=!0;const e=Math.floor(s[0].shape[0]*(1-n.validationSplit)),t=s[0].shape[0];u=ny(s,e,t),a=s,s=ny(s,0,e),c=ny(r,e,t),i=r,r=ny(r,0,e),m=u.concat(c)}else null!=n.validationSteps&&(g=!0);const y=s.concat(r).concat(h);this.checkTrainableWeightsConsistency();const b=this.makeTrainFunction(),x=this.getDedupedMetricsNames();let w,k;g?(this.makeTestFunction(),w=this.testFunction,k=x.slice().concat(x.map((e=>"val_"+e)))):(w=null,m=[],k=x.slice());const v=gg(n.callbacks,n.yieldEvery);return await this.fitLoop(b,y,x,p,n.epochs,n.verbose,v,w,m,n.shuffle,k,n.initialEpoch,null,null)}finally{this.isTraining=!1,iy(s,e),iy(r,t),iy(a,e),iy(i,t),iy(u,o),iy(c,l),null!=h&&ia(h)}}async fitLoop(e,t,n,s,r,a,i,o,l,u,c,h,p,d){null==s&&(s=32),null==r&&(r=1),null==u&&(u=!0),null==h&&(h=0);let f=!1;if(null!=o&&null!=l&&(f=!0),null!=d&&(f=!0,null==p))throw new Xd("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");const m=this.checkNumSamples(t,s,p,"steps_per_epoch");let g;null!=m&&(g=Wf(0,m)),null==a&&(a=1);const{callbackList:y,history:b}=bg(i,a,r,h,m,p,s,f,c);y.setModel(this),this.history=b,await y.onTrainBegin(),this.stopTraining_=!1;for(let a=h;a<r;++a){await y.onEpochBegin(a);const r={};if(null!=p)throw new Yd("stepsPerEpoch mode is not implemented yet.");{if("batch"===u)throw new Yd("batch shuffling is not implemneted yet");u&&R(g);const a=ql(g),i=ry(m,s);for(let u=0;u<i.length;++u){const c={};if(await y.onBatchBegin(u,c),aa((()=>{const h=i[u][0],p=i[u][1],d=jf(a,h,p-h);c.batch=u,c.size=p-h;const m=sy(t,d),g=e(m);for(let e=0;e<n.length;++e){const t=n[e],s=g[e];c[t]=s,oa(s)}if(u===i.length-1&&f){const e=this.testLoop(o,l,s);for(let t=0;t<n.length;++t){const s=n[t],a=e[t];oa(a),r["val_"+s]=a}}})),await y.onBatchEnd(u,c),ug(c),this.stopTraining_)break}a.dispose()}if(await y.onEpochEnd(a,r),this.stopTraining_)break}return await y.onTrainEnd(),await this.history.syncData(),this.history}async fitDataset(e,t){return async function(e,t,n){const s=null!=n.batchesPerEpoch;if(F(null!=e.optimizer,(()=>"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig).")),F(null!=n,(()=>"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call.")),F(null!=n.epochs&&n.epochs>0&&Number.isInteger(n.epochs),(()=>`For fitDataset(), config.epochs is expected to be a positive integer, but got ${n.epochs}`)),F(!s||n.batchesPerEpoch>0&&Number.isInteger(n.batchesPerEpoch),(()=>`For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${n.batchesPerEpoch}`)),F(null==n.validationSplit,(()=>"`validationSplit` is not supported by `fitDataset()`. Use validationData instead.")),e.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");e.isTraining=!0;try{const r=null!=n.validationData;let a,i;if(r)if(ey(n.validationData))F(null==n.validationBatches||n.validationBatches>0&&Number.isInteger(n.validationBatches),(()=>`For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${n.validationBatches}`));else{const e=function(e){if(3===e.length)throw new Yd("Validation with sample weights is not implemented yet.");return{xs:e[0],ys:e[1]}}(n.validationData);a=e.xs,i=e.ys}const o=e.makeTrainFunction(),l=e.getDedupedMetricsNames();let u;u=r?l.slice().concat(l.map((e=>"val_"+e))):l.slice();const c=gg(n.callbacks,n.yieldEvery),h=null==n.verbose?1:n.verbose,{callbackList:p,history:d}=bg(c,h,n.epochs,null,null,function(e,t){let n=null;return null!=t.batchesPerEpoch?n=t.batchesPerEpoch:Number.isFinite(e.size)&&(n=e.size),n}(t,n),null,r,u);p.setModel(e),e.history=d,await p.onTrainBegin(),e.stopTraining_=!1;let f=null==n.initialEpoch?0:n.initialEpoch,m=await t.iterator();for(;f<n.epochs;){const u={};await p.onEpochBegin(f);let c=0,h=0;for(s||(m=await t.iterator());!s||c<n.batchesPerEpoch;){const t=await m.next();if(s&&t.done){console.warn(`You provided \`batchesPerEpoch\` as ${n.batchesPerEpoch}, but your dataset iterator ran out of data after ${c} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, `+n.batchesPerEpoch*n.epochs+" batches). You may need to use the repeat() function when building your dataset.");break}if(null!=t.value){const{xs:s,ys:r}=Zg(e,t.value),a={};a.batch=h,a.size=s[0].shape[0],await p.onBatchBegin(h,a);const i=[];if(null!=n.classWeight){const t=Xg(n.classWeight,e.outputNames);for(let e=0;e<t.length;++e)i.push(await Yg(r[e],null,t[e]))}const u=s.concat(r).concat(i),d=o(u);ia(u);for(let e=0;e<l.length;++e){const t=l[e],n=d[e];a[t]=n,oa(n)}await p.onBatchEnd(h,a),ug(a),h++,c++}if(s?c>=n.batchesPerEpoch:t.done){if(r){let t;t=ey(n.validationData)?sf(await e.evaluateDataset(n.validationData,{batches:n.validationBatches})):sf(e.evaluate(a,i,{batchSize:null==n.validationBatchSize?32:n.validationBatchSize,verbose:0}));for(let n=0;n<e.metricsNames.length;++n)u[`val_${e.metricsNames[n]}`]=t[n]}break}if(e.stopTraining_)break}if(await p.onEpochEnd(f,u),f++,e.stopTraining_)break}return await p.onTrainEnd(),await e.history.syncData(),e.history}finally{e.isTraining=!1}}(this,e,t)}async trainOnBatch(e,t){const n=await this.standardizeUserData(e,t),s=n[0],r=n[1],a=this.makeTrainFunction()(s.concat(r)),i=[];for(const e of a){const t=await e.data();i.push(t[0])}return ia(a),iy(n[0],e),iy(n[1],t),nf(i)}getNamedWeights(e){const t=[],n=null!=e&&e.trainableOnly,s=n?this.trainableWeights:this.weights,r=this.getWeights(n);for(let e=0;e<s.length;++e)n&&!s[e].trainable||t.push({name:s[e].originalName,tensor:r[e]});return t}set stopTraining(e){this.stopTraining_=e}get stopTraining(){return this.stopTraining_}get optimizer(){return this.optimizer_}set optimizer(e){this.optimizer_!==e&&(this.optimizer_=e,this.isOptimizerOwned=!1)}dispose(){const e=super.dispose();if(0===e.refCountAfterDispose&&null!=this.optimizer&&this.isOptimizerOwned){const t=ra().numTensors;this.optimizer_.dispose(),e.numDisposedVariables+=t-ra().numTensors}return e}getLossIdentifiers(){let e;if("string"==typeof this.loss)e=rf(this.loss);else if(Array.isArray(this.loss)){for(const e of this.loss)if("string"!=typeof e)throw new Error("Serialization of non-string loss is not supported.");e=this.loss.map((e=>rf(e)))}else{const t=Object.keys(this.loss);e={};const n=this.loss;for(const s of t){if("string"!=typeof n[s])throw new Error("Serialization of non-string loss is not supported.");e[s]=rf(n[s])}}return e}getMetricIdentifiers(){if("string"==typeof this.metrics||"function"==typeof this.metrics)return[rf(zg(this.metrics))];if(Array.isArray(this.metrics))return this.metrics.map((e=>rf(zg(e))));{const e={};for(const t in this.metrics)e[t]=rf(zg(this.metrics[t]));return e}}getTrainingConfig(){return{loss:this.getLossIdentifiers(),metrics:this.getMetricIdentifiers(),optimizer_config:{class_name:this.optimizer.getClassName(),config:this.optimizer.getConfig()}}}loadTrainingConfig(e){if(null!=e.weighted_metrics)throw new Error("Loading weight_metrics is not supported yet.");if(null!=e.loss_weights)throw new Error("Loading loss_weights is not supported yet.");if(null!=e.sample_weight_mode)throw new Error("Loading sample_weight_mode is not supported yet.");const t=xg(Hg(e.optimizer_config));let n,s;if("string"==typeof e.loss)n=af(e.loss);else if(Array.isArray(e.loss))n=e.loss.map((e=>af(e)));else if(null!=e.loss){n={};for(const t in e.loss)n[t]=af(e.loss[t])}if(Array.isArray(e.metrics))s=e.metrics.map((e=>af(e)));else if(null!=e.metrics){s={};for(const t in e.metrics)s[t]=af(e.metrics[t])}this.compile({loss:n,metrics:s,optimizer:t})}async save(e,t){if("string"==typeof e){const t=(n=e,ba.getSaveHandlers(n));if(0===t.length)throw new Xd(`Cannot find any save handlers for URL '${e}'`);if(t.length>1)throw new Xd(`Found more than one (${t.length}) save handlers for URL '${e}'`);e=t[0]}var n;if(null==e.save)throw new Xd("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");const s=await ua(this.getNamedWeights(t)),r={modelTopology:this.toJSON(null,!1),format:"layers-model",generatedBy:`TensorFlow.js tfjs-layers v${Kg}`,convertedBy:null};if(null!=t&&t.includeOptimizer&&null!=this.optimizer){r.trainingConfig=this.getTrainingConfig();const e="optimizer",{data:t,specs:n}=await ua(await this.optimizer.getWeights(),e);s.specs.push(...n),s.data=(a=[s.data,t],na.join(a))}var a;if(null!=this.userDefinedMetadata){const e=!0;Bg(this.userDefinedMetadata,this.name,e),r.userDefinedMetadata=this.userDefinedMetadata}return r.weightData=s.data,r.weightSpecs=s.specs,e.save(r)}setUserDefinedMetadata(e){Bg(e,this.name),this.userDefinedMetadata=e}getUserDefinedMetadata(){return this.userDefinedMetadata}}hy.className="Model",ai(hy);class py extends hy{}async function dy(e,t){if(null==t&&(t={}),"string"==typeof e){const r=(n=e,s=t,ba.getLoadHandlers(n,s));if(0===r.length)r.push(function(e,t){return Ri(e,t)}(e,t));else if(r.length>1)throw new Xd(`Found more than one (${r.length}) load handlers for URL '${e}'`);e=r[0]}var n,s;return async function(e,t,n){if(null==n&&(n={}),null==e.load)throw new Xd("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const s=await e.load();let r=s.modelTopology;null!=r.model_config&&(r=r.model_config);const a=null==n.strict||n.strict,i=null!=s.weightData&&null!=s.weightSpecs&&a,o=xg(Hg(r),void 0,i),l=s.trainingConfig;if(null!=l&&o.loadTrainingConfig(l),null!=s.userDefinedMetadata&&o.setUserDefinedMetadata(s.userDefinedMetadata),null!=s.weightData){if(null==s.weightSpecs)throw new Xd("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");const{modelWeights:e,optimizerWeights:t}=function(e,t){const n=function(e,t){const n=new na(e),s={};let r=0;for(const e of t){const t=ca(e,((e,t)=>n.slice(r+e,r+t)));s[e.name]=ha(e,n.slice(r,r+t)),r+=t}return s}(e,t),s={},r=[];return t.forEach((e=>{"optimizer"===e.group?r.push({name:e.name,tensor:n[e.name]}):s[e.name]=n[e.name]})),{modelWeights:s,optimizerWeights:r}}(s.weightData,s.weightSpecs);o.loadWeights(e,a),null!=o.optimizer&&t.length>0&&await o.optimizer.setWeights(t),ia(e),ia(t.map((e=>e.tensor)))}return o}(e,0,t)}py.className="Functional",ai(py);class fy extends hy{constructor(e){if(super({inputs:[],outputs:[]}),e=e||{},this.trainable=!0,this.built=!1,this.name=null!=e.name?e.name:vf("sequential_"),null!=e.layers)for(const t of e.layers)this.add(t)}checkShape(e){if(e.inboundNodes[0].outputTensors[0].shape.some((e=>e<0)))throw new Xd(`Negative dimension size caused by adding layer ${e.name} with input shape [${e.inboundNodes[0].inputTensors[0].shape}]`)}add(e){const t=e instanceof fy||e instanceof hy;let n;if(t){if(n=e,1!==n.outputs.length)throw new Xd("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");if(1!==n.inputs.length)throw new Xd("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.")}if(0===this.outputs.length){if(0===e.inboundNodes.length){if(null==e.batchInputShape)throw new Xd("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");const t=function(e){if(null==e.batchShape&&null==e.shape)throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");if(null!=e.batchShape&&null!=e.shape)throw new Xd("Please provide either a `shape` or `batchShape` argument to Input, but not both.");let t=e.batchShape;null!=e.shape&&null==t&&(t=[null].concat(e.shape));let n=e.dtype;return null==n&&(n="float32"),new Gm({batchInputShape:t,name:e.name,dtype:n,sparse:e.sparse}).inboundNodes[0].outputTensors[0]}({batchShape:e.batchInputShape,dtype:e.dtype,name:e.name+"_input"});e.apply(t)}if(t)this.outputs=n.outputs,this.inputs=n.inputs;else{if(1!==e.inboundNodes.length)throw new Xd(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${e.name} which has ${e.inboundNodes.length} pre-existing inbound connections.`);if(1!==e.inboundNodes[0].outputTensors.length)throw new Xd("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(e),this.outputs=[e.inboundNodes[0].outputTensors[0]],this.inputs=Um(this.outputs[0])}this.inboundNodes=[],new Pm({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:Qd(null,this.inputs.length),outputMasks:[null],inputShapes:this.inputs.map((e=>e.shape)),outputShapes:this.outputs[0].shape})}else{const t=e.apply(this.outputs[0]);if(Array.isArray(t))throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(e),this.outputs=[t],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}this.layers.push(e),this.built=!1}pop(){if(0===this.layers.length)throw new TypeError("There are no layers in the model.");if(this.layers.pop(),0===this.layers.length)this.outputs=[],this.inboundNodes=[],this.outboundNodes=[];else{const e=this.layers.length-1;this.layers[e].outboundNodes=[],this.outputs=[this.layers[e].output],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}}call(e,t){return null==this.model&&this.build(),this.model.call(e,t)}build(e){if(Am(e),0===this.inputs.length||0===this.outputs.length)throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");this.model=new hy({inputs:this.inputs,outputs:this.outputs[0],name:this.name+"_model"}),this.model.trainable=this.trainable,this.supportsMasking=this.model.supportsMasking,this.inputLayers=this.model.inputLayers,this.inputLayersNodeIndices=this.model.inputLayersNodeIndices,this.inputLayersTensorIndices=this.model.inputLayersTensorIndices,this.outputLayers=this.model.outputLayers,this.outputLayersNodeIndices=this.model.outputLayersNodeIndices,this.outputLayersTensorIndices=this.model.outputLayersTensorIndices,this.nodesByDepth=this.model.nodesByDepth,this.containerNodes=this.model.containerNodes,this.outputNames=this.model.outputNames,this.inputNames=this.model.inputNames,this.built=!0}countParams(){return this.built||this.build(),super.countParams()}summary(e,t,n=console.log){this.built||this.build(),super.summary(e,t,n)}setWeights(e){null==this.model&&this.build(),this.model.setWeights(e)}evaluate(e,t,n={}){if(!this.built)throw new qd("The model needs to be compiled before being used.");return this.model.evaluate(e,t,n)}async evaluateDataset(e,t){if(!this.built)throw new qd("The model needs to be compiled before being used.");return this.model.evaluateDataset(e,t)}predict(e,t={}){return null==this.model&&this.build(),this.model.predict(e,t)}predictOnBatch(e){return null==this.model&&this.build(),this.model.predictOnBatch(e)}compile(e){this.build(),this.model.compile(e),this.optimizer_=this.model.optimizer,this.isOptimizerOwned=this.model.isOptimizerOwned,this.loss=this.model.loss,this.metrics=this.model.metrics,this.metricsTensors=this.model.metricsTensors,this.metricsNames=this.model.metricsNames}get optimizer(){return null==this.model?void 0:this.model.optimizer}set optimizer(e){this.model.optimizer=e}async fit(e,t,n={}){if(!this.built)throw new qd("The model needs to be compiled before being used.");return this.model.fit(e,t,n)}async fitDataset(e,t){if(!this.built)throw new qd("The model needs to be compiled before being used.");return this.model.fitDataset(e,t)}async trainOnBatch(e,t){return this.model.trainOnBatch(e,t)}static fromConfig(e,t,n={},s=!1){let r,a={};if(t instanceof Array){if(null==t[0].className||"Merge"===t[0].className)throw new Xd("Legacy serialization format not supported yet.");r=t}else F(null!=t.layers,(()=>"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field.")),r=t.layers,delete t.layers,a=t;const i=new e(a);if(!(i instanceof fy))throw new Yd(`Sequential.fromConfig called on non-Sequential input: ${i}`);for(const e of r){const t=xg(e,void 0,s);s&&t.setFastWeightInitDuringBuild(!0),i.add(t)}return i}set stopTraining(e){if(null==this.model)throw new Xd("Cannot set the stopTraining property of a sequential model before it is compiled.");this.model.stopTraining=e}get stopTraining(){if(null==this.model)throw new Xd("Cannot get the stopTraining property of a sequential model before it is compiled.");return this.model.stopTraining}getConfig(){const e=[];for(const t of this.layers){const n={};n.className=t.getClassName(),n.config=t.getConfig(),e.push(n)}return{name:this.name,layers:e}}}fy.className="Sequential",ai(fy);class my extends si{getConfig(){return{}}}class gy extends my{apply(e,t=1){return function(e,t=1){if(1!==t)throw new Yd(`Support for alpha values other than 1 (${t}) is not implemented yet.`);return zo(e)}(e,t)}}gy.className="elu",ai(gy);class yy extends my{apply(e){return Fl(e)}}yy.className="selu",ai(yy);class by extends my{apply(e){return _l(e)}}by.className="relu",ai(by);class xy extends my{apply(e){return aa((()=>gl(6,_l(e))))}}xy.className="relu6",ai(xy);class wy extends my{apply(e){return e}}wy.className="linear",ai(wy);class ky extends my{apply(e){return Ml(e)}}ky.className="sigmoid",ai(ky);class vy extends my{apply(e){return function(e){return aa((()=>{const t=ja(.5,Xa(.2,e));return Io(t,0,1)}))}(e)}}vy.className="hardSigmoid",ai(vy);class Iy extends my{apply(e){return Ul(e)}}Iy.className="softplus",ai(Iy);class Ny extends my{apply(e){return function(e){return aa((()=>qa(e,ja(di(e),1))))}(e)}}Ny.className="softsign",ai(Ny);class Sy extends my{apply(e){return Kl(e)}}Sy.className="tanh",ai(Sy);class Ty extends my{apply(e,t=-1){return Vl(e,t)}}Ty.className="softmax",ai(Ty);class $y extends my{apply(e,t=-1){return el(e,t)}}$y.className="logSoftmax",ai($y);class Ey extends my{apply(e){return aa((()=>aa((()=>{const t=Math.sqrt(2),n=Xa(.5,ja(1,Po(qa(e,t))));return Xa(e,n)}))))}}Ey.className="gelu",ai(Ey);class Cy extends my{apply(e){return aa((()=>Xa(.5,Xa(e,ja(1,Kl(Xa(Ya(qa(2,Math.PI)),ja(e,Xa(.044715,ci(e,3))))))))))}}Cy.className="gelu_new",ai(Cy);class Ry extends my{apply(e){return aa((()=>Xa(e,Kl(Ul(e)))))}}Ry.className="mish",ai(Ry);class Ay extends my{apply(e,t=1){return aa((()=>Xa(Ml(Xa(e,t)),e)))}}function _y(e){return e.getClassName()}function Dy(e,t={}){return cf(e,ri.getMap().classNameMap,t,"activation")}function Fy(e){if(null==e){return Dy({className:"linear",config:{}})}if("string"==typeof e){const t={};return t.className=e,t.config={},Dy(t)}return e instanceof my?e:Dy(e)}Ay.className="swish",ai(Ay);class Oy extends si{}class My extends Oy{constructor(e){super(),function(e){if(null!=e&&"object"!=typeof e)throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${e}`)}(e),this.l1=null==e||null==e.l1?.01:e.l1,this.l2=null==e||null==e.l2?.01:e.l2,this.hasL1=0!==this.l1,this.hasL2=0!==this.l2}apply(e){return aa((()=>{let t=kl([1]);return this.hasL1&&(t=ja(t,Qo(Xa(this.l1,di(e))))),this.hasL2&&(t=ja(t,Qo(Xa(this.l2,tm(e))))),mo(t,[])}))}getConfig(){return{l1:this.l1,l2:this.l2}}static fromConfig(e,t){return new e({l1:t.l1,l2:t.l2})}}My.className="L1L2",ai(My);const Ly={l1l2:"L1L2"};function zy(e){return lf(e)}function By(e,t={}){return cf(e,ri.getMap().classNameMap,t,"regularizer")}function Py(e){return null==e?null:"string"==typeof e?By({className:e in Ly?Ly[e]:e,config:{}}):e instanceof Oy?e:By(e)}class Wy extends Vm{constructor(e){super(null==e?{}:e),this.supportsMasking=!0,null!=e&&(this.maxValue=e.maxValue)}call(e,t){e=Rm(e);let n=_l(e);return null!=this.maxValue&&(n=Io(n,0,this.maxValue)),n}computeOutputShape(e){return e}getConfig(){const e={maxValue:this.maxValue},t=super.getConfig();return Object.assign(e,t),e}}Wy.className="ReLU",ai(Wy);class Vy extends Vm{constructor(e){super(null==e?{}:e),this.DEFAULT_ALPHA=.3,null==e&&(e={}),this.alpha=null==e.alpha?this.DEFAULT_ALPHA:e.alpha}call(e,t){const n=Rm(e);return Xo(n,this.alpha)}computeOutputShape(e){return e}getConfig(){const e={alpha:this.alpha},t=super.getConfig();return Object.assign(e,t),e}}Vy.className="LeakyReLU",ai(Vy);class Uy extends Vm{constructor(e){if(super(null==e?{}:e),this.DEFAULT_ALPHA_INITIALIZER="zeros",null==e&&(e={}),this.supportsMasking=!0,this.alphaInitializer=$m(e.alphaInitializer||this.DEFAULT_ALPHA_INITIALIZER),this.alphaRegularizer=Py(e.alphaRegularizer),this.alphaConstraint=og(e.alphaConstraint),null==e.sharedAxes)this.sharedAxes=null;else if(Array.isArray(e.sharedAxes))this.sharedAxes=e.sharedAxes;else{if("number"!=typeof e.sharedAxes)throw new Xd(`Expected sharedAxes to be a number or an array of numbers, but got ${e.sharedAxes}`);this.sharedAxes=[e.sharedAxes]}}build(e){const t=(e=Am(e)).slice(1);if(null!=this.sharedAxes)for(const e of this.sharedAxes)t[e-1]=1;this.alpha=this.addWeight("alpha",t,"float32",this.alphaInitializer,this.alphaRegularizer,!0,this.alphaConstraint);const n={};if(null!=this.sharedAxes)for(let t=1;t<e.length;++t)n[t]=e[t];this.inputSpec=[new Lm({ndim:e.length,axes:n})],this.built=!0}call(e,t){return e=Rm(e),Sl(e,this.alpha.read())}getConfig(){const e={alphaInitializer:Tm(this.alphaInitializer),alphaRegularizer:zy(this.alphaRegularizer),alphaConstraint:ag(this.alphaConstraint),sharedAxes:this.sharedAxes},t=super.getConfig();return Object.assign(e,t),e}}Uy.className="PReLU",ai(Uy);class Gy extends Vm{constructor(e){if(super(null==e?{}:e),this.DEFAULT_ALPHA=1,null==e&&(e={}),null!=e.alpha&&e.alpha!==this.DEFAULT_ALPHA)throw new Yd(`Non-default alpha value (${e.alpha}) is not supported by the ELU layer yet.`);this.alpha=null==e.alpha?this.DEFAULT_ALPHA:e.alpha}call(e,t){const n=Rm(e);return zo(n)}computeOutputShape(e){return e}getConfig(){const e={alpha:this.alpha},t=super.getConfig();return Object.assign(e,t),e}}Gy.className="ELU",ai(Gy);class Hy extends Vm{constructor(e){super(null==e?{}:e),this.DEFAULT_THETA=1,null==e&&(e={}),this.theta=null==e.theta?this.DEFAULT_THETA:e.theta}call(e,t){const n=Rm(e);return Xa(n,Ga(Ko(n,this.theta),"float32"))}computeOutputShape(e){return e}getConfig(){const e={theta:this.theta},t=super.getConfig();return Object.assign(e,t),e}}Hy.className="ThresholdedReLU",ai(Hy);class jy extends Vm{constructor(e){super(null==e?{}:e),this.DEFAULT_AXIS=1,null==e&&(e={}),this.softmax=(new Ty).apply,this.axis=null==e.axis?this.DEFAULT_AXIS:e.axis}call(e,t){return aa((()=>{let n=Rm(e);const s=t.mask;if(null!=s){const e=Xa(hi(vl(n.shape),Ga(s,n.dtype)),ei(-1e9));n=ja(n,e)}return this.axis instanceof Array?this.axis.length>1?Wo(hi(n,ul(n,this.axis,!0))):this.softmax(n,this.axis[0]):this.softmax(n,this.axis)}))}computeOutputShape(e){return e}getConfig(){const e={axis:this.axis},t=super.getConfig();return Object.assign(e,t),e}}function Ky(e,t,n){if("number"==typeof e)return Qd(e,t);if(e.length!==t)throw new Xd(`The ${n} argument must be an integer or tuple of ${t} integers. Received: ${e.length} elements.`);for(let r=0;r<t;++r){const a=e[r];if((s=a)!==parseInt(s.toString(),10))throw new Xd(`The ${n} argument must be an integer or tuple of ${t} integers. Received: ${JSON.stringify(e)} including a non-integer number ${a}`)}return e;var s}function qy(e,t,n,s,r=1){if(null==e)return e;let a;return a="same"===n?e:e-(t+(t-1)*(r-1))+1,Math.floor((a+s-1)/s)}function Xy(e,t,n,s){if(null==e)return null;if("valid"===s)e=e*t+Pf([n-t,0]);else{if("same"!==s)throw new Xd(`Unsupport padding mode: ${s}.`);e*=t}return e}function Yy(e,t){return aa((()=>(Cf(t),"channelsFirst"===t?tu(e,[0,2,3,1]):e)))}function Jy(e,t){return aa((()=>(Cf(t),"channelsFirst"===t?tu(e,[0,2,3,4,1]):e)))}function Zy(e,t,n,s=[1,1],r="valid",a,i,o=null){return aa((()=>{if(null==a&&(a="channelsLast"),Cf(a),3!==e.rank&&4!==e.rank)throw new Xd(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${e.rank}.`);if(3!==t.rank&&4!==t.rank)throw new Xd(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${e.rank}.`);let l=Yy(e,a);if("causal"===r)throw new Yd("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return l=fu({x:l,filter:t,strides:s,pad:"same"===r?"same":"valid",dilations:i,dataFormat:"NHWC",bias:n,activation:o}),"channelsFirst"===a&&(l=tu(l,[0,3,1,2])),l}))}jy.className="Softmax",ai(jy);class Qy extends Vm{constructor(e,t){if(super(t),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",Qy.verifyArgs(t),this.rank=e,gf(this.rank,"rank"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new Yd(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=Ky(t.kernelSize,e,"kernelSize"),this.strides=Ky(null==t.strides?1:t.strides,e,"strides"),this.padding=null==t.padding?"valid":t.padding,Rf(this.padding),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,Cf(this.dataFormat),this.activation=Fy(t.activation),this.useBias=null==t.useBias||t.useBias,this.biasInitializer=$m(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=og(t.biasConstraint),this.biasRegularizer=Py(t.biasRegularizer),this.activityRegularizer=Py(t.activityRegularizer),this.dilationRate=Ky(null==t.dilationRate?1:t.dilationRate,e,"dilationRate"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new Xd(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);if(2===this.rank){if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new Xd(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`)}else if(3===this.rank)if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new Xd(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`)}static verifyArgs(e){if(ef("kernelSize"in e,"required key 'kernelSize' not in config"),"number"!=typeof e.kernelSize&&!mf(e.kernelSize,"number",1,3))throw new Xd(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(e.kernelSize)}.`)}getConfig(){const e={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:_y(this.activation),useBias:this.useBias,biasInitializer:Tm(this.biasInitializer),biasRegularizer:zy(this.biasRegularizer),activityRegularizer:zy(this.activityRegularizer),biasConstraint:ag(this.biasConstraint)},t=super.getConfig();return Object.assign(e,t),e}}class eb extends Qy{constructor(e,t){super(e,t),this.kernel=null,eb.verifyArgs(t),this.filters=t.filters,gf(this.filters,"filters"),this.kernelInitializer=$m(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=og(t.kernelConstraint),this.kernelRegularizer=Py(t.kernelRegularizer)}build(e){e=Am(e);const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t])throw new Xd(`The channel dimension of the input should be defined. Found ${e[t]}`);const n=e[t],s=this.kernelSize.concat([n,this.filters]);this.kernel=this.addWeight("kernel",s,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[t]:n}}],this.built=!0}call(e,t){return aa((()=>{let t;e=Rm(e);const n=null==this.bias?null:this.bias.read(),s=bf(this.activation.getClassName());if(null!=s&&2===this.rank)t=Zy(e,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate,s);else{if(1===this.rank)t=function(e,t,n,s=1,r="valid",a,i=1){return aa((()=>{if(null==a&&(a="channelsLast"),Cf(a),3!==e.shape.length)throw new Xd(`The input of a conv1dWithBias operation should be 3, but is ${e.shape.length} instead.`);if(3!==t.shape.length)throw new Xd(`The kernel for a conv1dWithBias operation should be 3, but is ${t.shape.length} instead`);if(null!=n&&1!==n.shape.length)throw new Xd(`The bias for a conv1dWithBias operation should be 1, but is ${n.shape.length} instead`);if("channelsFirst"===a&&(e=tu(e,[0,2,1])),"causal"===r)throw new Yd("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let o=Ro(e,t,s,"same"===r?"same":"valid","NWC",i);return null!=n&&(o=sm(o,n)),o}))}(e,this.kernel.read(),n,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)t=Zy(e,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate);else{if(3!==this.rank)throw new Yd("convolutions greater than 3D are not implemented yet.");t=function(e,t,n,s=[1,1,1],r="valid",a,i){return aa((()=>{if(null==a&&(a="channelsLast"),Cf(a),4!==e.rank&&5!==e.rank)throw new Xd(`conv3dWithBias expects input to be of rank 4 or 5, but received ${e.rank}.`);if(4!==t.rank&&5!==t.rank)throw new Xd(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${e.rank}.`);let o=Jy(e,a);if("causal"===r)throw new Yd("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return o=Do(o,t,s,"same"===r?"same":"valid","NDHWC",i),null!=n&&(o=sm(o,n)),"channelsFirst"===a&&(o=tu(o,[0,4,1,2,3])),o}))}(e,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate)}null!=this.activation&&(t=this.activation.apply(t))}return t}))}computeOutputShape(e){e=Am(e);const t=[],n="channelsLast"===this.dataFormat?e.slice(1,e.length-1):e.slice(2);for(let e=0;e<n.length;++e){const s=qy(n[e],this.kernelSize[e],this.padding,this.strides[e],"number"==typeof this.dilationRate?this.dilationRate:this.dilationRate[e]);t.push(s)}let s=[e[0]];return"channelsLast"===this.dataFormat?(s=s.concat(t),s.push(this.filters)):(s.push(this.filters),s=s.concat(t)),s}getConfig(){const e={filters:this.filters,kernelInitializer:Tm(this.kernelInitializer),kernelRegularizer:zy(this.kernelRegularizer),kernelConstraint:ag(this.kernelConstraint)},t=super.getConfig();return Object.assign(e,t),e}static verifyArgs(e){if(!("filters"in e)||"number"!=typeof e.filters||e.filters<1)throw new Xd(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(e.filters)}`)}}class tb extends eb{constructor(e){super(2,e),tb.verifyArgs(e)}getConfig(){const e=super.getConfig();return delete e.rank,e}static verifyArgs(e){if("number"!=typeof e.kernelSize&&!mf(e.kernelSize,"number",1,2))throw new Xd(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(e.kernelSize)}.`)}}tb.className="Conv2D",ai(tb);class nb extends eb{constructor(e){super(3,e),nb.verifyArgs(e)}getConfig(){const e=super.getConfig();return delete e.rank,e}static verifyArgs(e){if("number"!=typeof e.kernelSize&&(!Array.isArray(e.kernelSize)||1!==e.kernelSize.length&&3!==e.kernelSize.length))throw new Xd(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(e.kernelSize)}.`)}}nb.className="Conv3D",ai(nb);class sb extends tb{constructor(e){if(super(e),this.inputSpec=[new Lm({ndim:4})],"same"!==this.padding&&"valid"!==this.padding)throw new Xd(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(e){if(4!==(e=Am(e)).length)throw new Xd("Input should have rank 4; Received input shape: "+JSON.stringify(e));const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t])throw new Xd("The channel dimension of the inputs should be defined. Found `None`.");const n=e[t],s=this.kernelSize.concat([this.filters,n]);this.kernel=this.addWeight("kernel",s,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new Lm({ndim:4,axes:{[t]:n}})],this.built=!0}call(e,t){return aa((()=>{let t=Rm(e);if(4!==t.shape.length)throw new Xd(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${t.shape.length}`);const n=t.shape,s=n[0];let r,a;"channelsFirst"===this.dataFormat?(r=2,a=3):(r=1,a=2);const i=n[r],o=n[a],l=this.kernelSize[0],u=this.kernelSize[1],c=this.strides[0],h=this.strides[1],p=[s,Xy(i,c,l,this.padding),Xy(o,h,u,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(t=tu(t,[0,2,3,1]));let d=_o(t,this.kernel.read(),p,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(d=tu(d,[0,3,1,2])),null!=this.bias&&(d=sm(d,this.bias.read(),this.dataFormat)),null!=this.activation&&(d=this.activation.apply(d)),d}))}computeOutputShape(e){const t=(e=Am(e)).slice();let n,s,r;"channelsFirst"===this.dataFormat?(n=1,s=2,r=3):(n=3,s=1,r=2);const a=this.kernelSize[0],i=this.kernelSize[1],o=this.strides[0],l=this.strides[1];return t[n]=this.filters,t[s]=Xy(t[s],o,a,this.padding),t[r]=Xy(t[r],l,i,this.padding),t}getConfig(){const e=super.getConfig();return delete e.dilationRate,e}}sb.className="Conv2DTranspose",ai(sb);class rb extends nb{constructor(e){if(super(e),this.inputSpec=[new Lm({ndim:5})],"same"!==this.padding&&"valid"!==this.padding)throw new Xd(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(e){if(5!==(e=Am(e)).length)throw new Xd("Input should have rank 5; Received input shape: "+JSON.stringify(e));const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t])throw new Xd("The channel dimension of the inputs should be defined. Found `None`.");const n=e[t],s=this.kernelSize.concat([this.filters,n]);this.kernel=this.addWeight("kernel",s,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new Lm({ndim:5,axes:{[t]:n}})],this.built=!0}call(e,t){return aa((()=>{let t=Rm(e);if(5!==t.shape.length)throw new Xd(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${t.shape.length}`);const n=t.shape,s=n[0];let r,a,i;"channelsFirst"===this.dataFormat?(i=2,r=3,a=4):(i=1,r=2,a=3);const o=n[i],l=n[r],u=n[a],c=this.kernelSize[0],h=this.kernelSize[1],p=this.kernelSize[2],d=this.strides[0],f=this.strides[1],m=this.strides[2],g=[s,Xy(o,d,c,this.padding),Xy(l,f,h,this.padding),Xy(u,m,p,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(t=tu(t,[0,2,3,4,1]));let y=Oo(t,this.kernel.read(),g,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(y=tu(y,[0,4,1,2,3])),null!==this.bias&&(y=sm(y,this.bias.read(),this.dataFormat)),null!==this.activation&&(y=this.activation.apply(y)),y}))}computeOutputShape(e){const t=(e=Am(e)).slice();let n,s,r,a;"channelsFirst"===this.dataFormat?(n=1,s=2,r=3,a=4):(n=4,s=1,r=2,a=3);const i=this.kernelSize[0],o=this.kernelSize[1],l=this.kernelSize[2],u=this.strides[0],c=this.strides[1],h=this.strides[2];return t[n]=this.filters,t[s]=Xy(t[s],u,i,this.padding),t[r]=Xy(t[r],c,o,this.padding),t[a]=Xy(t[a],h,l,this.padding),t}getConfig(){const e=super.getConfig();return delete e.dilationRate,e}}rb.className="Conv3DTranspose",ai(rb);class ab extends eb{constructor(e,t){if(super(e,t),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,null==t.filters)throw new Xd("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(null!=t.kernelInitializer||null!=t.kernelRegularizer||null!=t.kernelConstraint)throw new Xd("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(null!=t.padding&&"same"!==t.padding&&"valid"!==t.padding)throw new Xd(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(t.padding)}`);this.depthMultiplier=null==t.depthMultiplier?1:t.depthMultiplier,this.depthwiseInitializer=$m(t.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=Py(t.depthwiseRegularizer),this.depthwiseConstraint=og(t.depthwiseConstraint),this.pointwiseInitializer=$m(t.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=Py(t.pointwiseRegularizer),this.pointwiseConstraint=og(t.pointwiseConstraint)}build(e){if((e=Am(e)).length<this.rank+2)throw new Xd(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank+2}, but received input shape: ${JSON.stringify(e)}`);const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t]||e[t]<0)throw new Xd(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(e[t])}`);const n=e[t],s=this.kernelSize.concat([n,this.depthMultiplier]),r=[];for(let e=0;e<this.rank;++e)r.push(1);r.push(n*this.depthMultiplier,this.filters);const a=!0;this.depthwiseKernel=this.addWeight("depthwise_kernel",s,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,a,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",r,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,a,this.pointwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,a,this.biasConstraint):this.bias=null,this.inputSpec=[new Lm({ndim:this.rank+2,axes:{[t]:n}})],this.built=!0}call(e,t){return aa((()=>{let t;if(e=Rm(e),1===this.rank)throw new Yd("1D separable convolution is not implemented yet.");return 2===this.rank&&("channelsFirst"===this.dataFormat&&(e=tu(e,[0,2,3,1])),t=Ol(e,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(t=sm(t,this.bias.read(),this.dataFormat)),null!=this.activation&&(t=this.activation.apply(t)),"channelsFirst"===this.dataFormat&&(t=tu(t,[0,3,1,2])),t}))}getConfig(){const e=super.getConfig();return delete e.rank,delete e.kernelInitializer,delete e.kernelRegularizer,delete e.kernelConstraint,e.depthwiseInitializer=Tm(this.depthwiseInitializer),e.pointwiseInitializer=Tm(this.pointwiseInitializer),e.depthwiseRegularizer=zy(this.depthwiseRegularizer),e.pointwiseRegularizer=zy(this.pointwiseRegularizer),e.depthwiseConstraint=ag(this.depthwiseConstraint),e.pointwiseConstraint=ag(this.pointwiseConstraint),e}}ab.className="SeparableConv";class ib extends ab{constructor(e){super(2,e)}}ib.className="SeparableConv2D",ai(ib);class ob extends eb{constructor(e){super(1,e),ob.verifyArgs(e),this.inputSpec=[{ndim:3}]}getConfig(){const e=super.getConfig();return delete e.rank,delete e.dataFormat,e}static verifyArgs(e){if("number"!=typeof e.kernelSize&&!mf(e.kernelSize,"number",1,1))throw new Xd(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(e.kernelSize)}.`)}}ob.className="Conv1D",ai(ob);class lb extends Vm{constructor(e){super(e),"number"==typeof e.cropping?this.cropping=[[e.cropping,e.cropping],[e.cropping,e.cropping]]:"number"==typeof e.cropping[0]?this.cropping=[[e.cropping[0],e.cropping[0]],[e.cropping[1],e.cropping[1]]]:this.cropping=e.cropping,this.dataFormat=void 0===e.dataFormat?"channelsLast":e.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(e){return"channelsFirst"===this.dataFormat?[e[0],e[1],e[2]-this.cropping[0][0]-this.cropping[0][1],e[3]-this.cropping[1][0]-this.cropping[1][1]]:[e[0],e[1]-this.cropping[0][0]-this.cropping[0][1],e[2]-this.cropping[1][0]-this.cropping[1][1],e[3]]}call(e,t){return aa((()=>{if(e=Rm(e),"channelsLast"===this.dataFormat){const t=qf(e,this.cropping[0][0],e.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return qf(t,this.cropping[1][0],e.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{const t=qf(e,this.cropping[0][0],e.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return qf(t,this.cropping[1][0],e.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}}))}getConfig(){const e={cropping:this.cropping,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}lb.className="Cropping2D",ai(lb);class ub extends Vm{constructor(e){var t;super(e),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==e.size?this.DEFAULT_SIZE:e.size,this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,Cf(this.dataFormat),this.interpolation=null==e.interpolation?"nearest":e.interpolation,t=this.interpolation,ff(Nf,"InterpolationFormat",t)}computeOutputShape(e){if("channelsFirst"===this.dataFormat){const t=null==e[2]?null:this.size[0]*e[2],n=null==e[3]?null:this.size[1]*e[3];return[e[0],e[1],t,n]}{const t=null==e[1]?null:this.size[0]*e[1],n=null==e[2]?null:this.size[1]*e[2];return[e[0],t,n,e[3]]}}call(e,t){return aa((()=>{let t=Rm(e);const n=t.shape;if("channelsFirst"===this.dataFormat){t=tu(t,[0,2,3,1]);const e=this.size[0]*n[2],s=this.size[1]*n[3],r="nearest"===this.interpolation?Qu.resizeNearestNeighbor(t,[e,s]):Qu.resizeBilinear(t,[e,s]);return tu(r,[0,3,1,2])}{const e=this.size[0]*n[1],s=this.size[1]*n[2];return"nearest"===this.interpolation?Qu.resizeNearestNeighbor(t,[e,s]):Qu.resizeBilinear(t,[e,s])}}))}getConfig(){const e={size:this.size,dataFormat:this.dataFormat,interpolation:this.interpolation},t=super.getConfig();return Object.assign(e,t),e}}ub.className="UpSampling2D",ai(ub);class cb extends Qy{constructor(e){super(2,e),this.depthwiseKernel=null,this.depthMultiplier=null==e.depthMultiplier?1:e.depthMultiplier,this.depthwiseInitializer=$m(e.depthwiseInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.depthwiseConstraint=og(e.depthwiseConstraint),this.depthwiseRegularizer=Py(e.depthwiseRegularizer)}build(e){if((e=Am(e)).length<4)throw new Xd(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(e)}.`);const t="channelsFirst"===this.dataFormat?1:3;if(null==e[t]||e[t]<0)throw new Xd(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${e[t]}).`);const n=e[t],s=[this.kernelSize[0],this.kernelSize[1],n,this.depthMultiplier];this.depthwiseKernel=this.addWeight("depthwise_kernel",s,null,this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[n*this.depthMultiplier],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(e,t){return aa((()=>{let t=function(e,t,n=[1,1],s="valid",r,a){return aa((()=>{null==r&&(r="channelsLast"),Cf(r);let i=Yy(e,r);if(4!==e.rank)throw new Xd(`Input for depthwiseConv2d is required to be 4-D, but is instead ${e.rank}-D`);if(4!==t.rank)throw new Xd(`depthwiseKernel is required to be 4-D, but is instead ${t.rank}-D`);return i=Lo(i,t,n,"same"===s?"same":"valid","NHWC",a),"channelsFirst"===r&&(i=tu(i,[0,3,1,2])),i}))}(e=Rm(e),this.depthwiseKernel.read(),this.strides,this.padding,this.dataFormat,null);return this.useBias&&(t=sm(t,this.bias.read(),this.dataFormat)),null!=this.activation&&(t=this.activation.apply(t)),t}))}computeOutputShape(e){e=Am(e);const t="channelsFirst"===this.dataFormat?e[2]:e[1],n="channelsFirst"===this.dataFormat?e[3]:e[2],s="channelsFirst"===this.dataFormat?e[1]*this.depthMultiplier:e[3]*this.depthMultiplier,r=qy(t,this.kernelSize[0],this.padding,this.strides[0]),a=qy(n,this.kernelSize[1],this.padding,this.strides[1]);return"channelsFirst"===this.dataFormat?[e[0],s,r,a]:[e[0],r,a,s]}getConfig(){const e=super.getConfig();return e.depthMultiplier=this.depthMultiplier,e.depthwiseInitializer=Tm(this.depthwiseInitializer),e.depthwiseRegularizer=zy(this.depthwiseRegularizer),e.depthwiseConstraint=ag(this.depthwiseRegularizer),e}}function hb(e,t,n,s){if(Array.isArray(e)){if(null!=t||null!=n)throw new Xd("When inputs is an array, neither initialState or constants should be provided");null!=s&&(n=e.slice(e.length-s,e.length),e=e.slice(0,e.length-s)),e.length>1&&(t=e.slice(1,e.length)),e=e[0]}function r(e){return null==e||Array.isArray(e)?e:[e]}return{inputs:e,initialState:t=r(t),constants:n=r(n)}}function pb(e,t,n,s=!1,r,a,i=!1,o=!1){return aa((()=>{const l=t.shape.length;if(l<3)throw new Xd(`Input should be at least 3D, but is ${l}D.`);const u=[1,0].concat(Wf(2,l));if(t=tu(t,u),null!=a)throw new Yd("The rnn() functoin of the deeplearn.js backend does not support constants yet.");i&&console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."),null!=r&&((r=Ga(Ga(r,"bool"),"float32")).rank===l-1&&(r=Vo(r,-1)),r=tu(r,u)),s&&(t=Dl(t,0),null!=r&&(r=Dl(r,0)));const c=[];let h,p=n;const d=t.shape[0],f=Jl(t);let m,g;null!=r&&(m=Jl(r));for(let t=0;t<d;++t){const n=f[t],s=aa((()=>e(n,p)));if(null==r)h=s[0],p=s[1];else{const e=aa((()=>{const e=m[t],n=hi(Il(e),e);return{output:ja(Xa(s[0],e),Xa(p[0],n)),newStates:p.map(((t,r)=>ja(Xa(s[1][r],e),Xa(t,n))))}}));h=e.output,p=e.newStates}o&&c.push(h)}return o&&(g=jl(c,1)),[h,g,p]}))}cb.className="DepthwiseConv2D",ai(cb);class db extends Vm{constructor(e){let t;if(super(e),null==e.cell)throw new Xd("cell property is missing for the constructor of RNN.");if(t=Array.isArray(e.cell)?new kb({cells:e.cell}):e.cell,null==t.stateSize)throw new Xd("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");this.cell=t,this.returnSequences=null!=e.returnSequences&&e.returnSequences,this.returnState=null!=e.returnState&&e.returnState,this.goBackwards=null!=e.goBackwards&&e.goBackwards,this._stateful=null!=e.stateful&&e.stateful,this.unroll=null!=e.unroll&&e.unroll,this.supportsMasking=!0,this.inputSpec=[new Lm({ndim:3})],this.stateSpec=null,this.states_=null,this.numConstants=null,this.keptStates=[]}getStates(){return null==this.states_?Wf(0,Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1).map((e=>null)):this.states_}setStates(e){this.states_=e}computeOutputShape(e){Em(e)&&(e=e[0]);let t=this.cell.stateSize;Array.isArray(t)||(t=[t]);const n=t[0];let s;if(s=this.returnSequences?[e[0],e[1],n]:[e[0],n],this.returnState){const n=[];for(const s of t)n.push([e[0],s]);return[s].concat(n)}return s}computeMask(e,t){return aa((()=>{Array.isArray(t)&&(t=t[0]);const e=this.returnSequences?t:null;if(this.returnState){const t=this.states.map((e=>null));return[e].concat(t)}return e}))}get states(){if(null==this.states_){const e=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1,t=[];for(let n=0;n<e;++n)t.push(null);return t}return this.states_}set states(e){this.states_=e}build(e){if(null!=this.numConstants)throw new Yd("Constants support is not implemented in RNN yet.");Em(e)&&(e=e[0]);const t=this.stateful?e[0]:null,n=e.slice(2);this.inputSpec[0]=new Lm({shape:[t,null,...n]});const s=[e[0]].concat(e.slice(2));let r;if(this.cell.build(s),r=Array.isArray(this.cell.stateSize)?this.cell.stateSize:[this.cell.stateSize],null!=this.stateSpec){if(!z(this.stateSpec.map((e=>e.shape[e.shape.length-1])),r))throw new Xd(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`)}else this.stateSpec=r.map((e=>new Lm({shape:[null,e]})));this.stateful&&this.resetStates()}resetStates(e,t=!1){aa((()=>{if(!this.stateful)throw new Kd("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape[0];if(null==n)throw new Xd("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.states_)Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((e=>kl([n,e]))):this.states_=[kl([n,this.cell.stateSize])];else if(null==e)ia(this.states_),null!=this.keptStates&&(ia(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((e=>kl([n,e]))):this.states_[0]=kl([n,this.cell.stateSize]);else{if(Array.isArray(e)||(e=[e]),e.length!==this.states_.length)throw new Xd(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${e.length} state value(s). Input received: ${e}`);!0===t?this.keptStates.push(this.states_.slice()):ia(this.states_);for(let t=0;t<this.states_.length;++t){const s=e[t],r=Array.isArray(this.cell.stateSize)?this.cell.stateSize[t]:this.cell.stateSize,a=[n,r];if(!z(s.shape,a))throw new Xd(`State ${t} is incompatible with layer ${this.name}: expected shape=${a}, received shape=${s.shape}`);this.states_[t]=s}}this.states_=this.states_.map((e=>oa(e.clone())))}))}apply(e,t){let n=null==t?null:t.initialState,s=null==t?null:t.constants;null==t&&(t={});const r=hb(e,n,s,this.numConstants);e=r.inputs,n=r.initialState,s=r.constants;let a=[],i=[];if(null!=n){t.initialState=n,a=a.concat(n),this.stateSpec=[];for(const e of n)this.stateSpec.push(new Lm({shape:e.shape}));i=i.concat(this.stateSpec)}if(null!=s&&(t.constants=s,a=a.concat(s),this.numConstants=s.length),a[0]instanceof zm){const n=[e].concat(a),s=this.inputSpec.concat(i),r=this.inputSpec;this.inputSpec=s;const o=super.apply(n,t);return this.inputSpec=r,o}return super.apply(e,t)}call(e,t){return aa((()=>{const n=null==t?null:t.mask,s=null==t?null:t.training;let r=null==t?null:t.initialState;e=Rm(e),null==r&&(r=this.stateful?this.states_:this.getInitialState(e));const a=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;if(r.length!==a)throw new Xd(`RNN Layer has ${a} state(s) but was passed ${r.length} initial state(s).`);this.unroll&&console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");const i={training:s},o=pb(((e,t)=>{const n=this.cell.call([e].concat(t),i);return[n[0],n.slice(1)]}),e,r,this.goBackwards,n,null,this.unroll,this.returnSequences),l=o[0],u=o[1],c=o[2];this.stateful&&this.resetStates(c,s);const h=this.returnSequences?u:l;return this.returnState?[h].concat(c):h}))}getInitialState(e){return aa((()=>{let t=kl(e.shape);return t=Qo(t,[1,2]),t=Hf(t),Array.isArray(this.cell.stateSize)?this.cell.stateSize.map((e=>e>1?Jf(t,[1,e]):t)):this.cell.stateSize>1?[Jf(t,[1,this.cell.stateSize])]:[t]}))}get trainableWeights(){return this.trainable?this.cell.trainableWeights:[]}get nonTrainableWeights(){return this.trainable?this.cell.nonTrainableWeights:this.cell.weights}setFastWeightInitDuringBuild(e){super.setFastWeightInitDuringBuild(e),null!=this.cell&&this.cell.setFastWeightInitDuringBuild(e)}getConfig(){const e=super.getConfig(),t={returnSequences:this.returnSequences,returnState:this.returnState,goBackwards:this.goBackwards,stateful:this.stateful,unroll:this.unroll};null!=this.numConstants&&(t.numConstants=this.numConstants);const n=this.cell.getConfig();return this.getClassName()===db.className&&(t.cell={className:this.cell.getClassName(),config:n}),Object.assign(Object.assign(Object.assign({},n),e),t)}static fromConfig(e,t,n={}){const s=xg(t.cell,n);return new e(Object.assign(t,{cell:s}))}}db.className="RNN",ai(db);class fb extends Vm{}class mb extends fb{constructor(e){super(e),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=e.units,gf(this.units,"units"),this.activation=Fy(null==e.activation?this.DEFAULT_ACTIVATION:e.activation),this.useBias=null==e.useBias||e.useBias,this.kernelInitializer=$m(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=$m(e.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=$m(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=Py(e.kernelRegularizer),this.recurrentRegularizer=Py(e.recurrentRegularizer),this.biasRegularizer=Py(e.biasRegularizer),this.kernelConstraint=og(e.kernelConstraint),this.recurrentConstraint=og(e.recurrentConstraint),this.biasConstraint=og(e.biasConstraint),this.dropout=Bf([1,Pf([0,null==e.dropout?0:e.dropout])]),this.recurrentDropout=Bf([1,Pf([0,null==e.recurrentDropout?0:e.recurrentDropout])]),this.dropoutFunc=e.dropoutFunc,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(e){e=Am(e),this.kernel=this.addWeight("kernel",[e[e.length-1],this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(e,t){return aa((()=>{if(2!==e.length)throw new Xd(`SimpleRNNCell expects 2 input Tensors, got ${e.length}.`);let n=e[1];e=e[0];const s=null!=t.training&&t.training;let r;0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=vb({ones:()=>Il(e),rate:this.dropout,training:s,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=vb({ones:()=>Il(n),rate:this.recurrentDropout,training:s,dropoutFunc:this.dropoutFunc}));const a=this.dropoutMask,i=this.recurrentDropoutMask;r=Qf(null!=a?Xa(e,a):e,this.kernel.read()),null!=this.bias&&(r=sm(r,this.bias.read())),null!=i&&(n=Xa(n,i));let o=ja(r,Qf(n,this.recurrentKernel.read()));return null!=this.activation&&(o=this.activation.apply(o)),[o,o]}))}getConfig(){const e=super.getConfig(),t={units:this.units,activation:_y(this.activation),useBias:this.useBias,kernelInitializer:Tm(this.kernelInitializer),recurrentInitializer:Tm(this.recurrentInitializer),biasInitializer:Tm(this.biasInitializer),kernelRegularizer:zy(this.kernelRegularizer),recurrentRegularizer:zy(this.recurrentRegularizer),biasRegularizer:zy(this.biasRegularizer),activityRegularizer:zy(this.activityRegularizer),kernelConstraint:ag(this.kernelConstraint),recurrentConstraint:ag(this.recurrentConstraint),biasConstraint:ag(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout};return Object.assign(Object.assign({},e),t)}}mb.className="SimpleRNNCell",ai(mb);class gb extends db{constructor(e){e.cell=new mb(e),super(e)}call(e,t){return aa((()=>{null!=this.cell.dropoutMask&&(ia(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(ia(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const n=null==t?null:t.mask,s=null==t?null:t.training,r=null==t?null:t.initialState;return super.call(e,{mask:n,training:s,initialState:r})}))}static fromConfig(e,t){return new e(t)}}gb.className="SimpleRNN",ai(gb);class yb extends fb{constructor(e){if(super(e),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",e.resetAfter)throw new Xd("GRUCell does not support reset_after parameter set to true.");this.units=e.units,gf(this.units,"units"),this.activation=Fy(void 0===e.activation?this.DEFAULT_ACTIVATION:e.activation),this.recurrentActivation=Fy(void 0===e.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:e.recurrentActivation),this.useBias=null==e.useBias||e.useBias,this.kernelInitializer=$m(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=$m(e.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=$m(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=Py(e.kernelRegularizer),this.recurrentRegularizer=Py(e.recurrentRegularizer),this.biasRegularizer=Py(e.biasRegularizer),this.kernelConstraint=og(e.kernelConstraint),this.recurrentConstraint=og(e.recurrentConstraint),this.biasConstraint=og(e.biasConstraint),this.dropout=Bf([1,Pf([0,null==e.dropout?0:e.dropout])]),this.recurrentDropout=Bf([1,Pf([0,null==e.recurrentDropout?0:e.recurrentDropout])]),this.dropoutFunc=e.dropoutFunc,this.implementation=e.implementation,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(e){const t=(e=Am(e))[e.length-1];this.kernel=this.addWeight("kernel",[t,3*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,3*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[3*this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(e,t){return aa((()=>{if(2!==e.length)throw new Xd(`GRUCell expects 2 input Tensors (inputs, h, c), got ${e.length}.`);const n=null!=t.training&&t.training;let s=e[1];e=e[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=vb({ones:()=>Il(e),rate:this.dropout,training:n,count:3,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=vb({ones:()=>Il(s),rate:this.recurrentDropout,training:n,count:3,dropoutFunc:this.dropoutFunc}));const r=this.dropoutMask,a=this.recurrentDropoutMask;let i,o,l;0<this.dropout&&this.dropout<1&&(e=Xa(e,r[0]));let u=Qf(e,this.kernel.read());this.useBias&&(u=sm(u,this.bias.read())),0<this.recurrentDropout&&this.recurrentDropout<1&&(s=Xa(s,a[0]));const c=this.recurrentKernel.read(),[h,p]=Gl(c,[2*this.units,this.units],c.rank-1),d=Qf(s,h),[f,m,g]=Gl(u,3,u.rank-1),[y,b]=Gl(d,2,d.rank-1);i=this.recurrentActivation.apply(ja(f,y)),o=this.recurrentActivation.apply(ja(m,b));const x=Qf(Xa(o,s),p);l=this.activation.apply(ja(g,x));const w=ja(Xa(i,s),Xa(ja(1,bl(i)),l));return[w,w]}))}getConfig(){const e=super.getConfig(),t={units:this.units,activation:_y(this.activation),recurrentActivation:_y(this.recurrentActivation),useBias:this.useBias,kernelInitializer:Tm(this.kernelInitializer),recurrentInitializer:Tm(this.recurrentInitializer),biasInitializer:Tm(this.biasInitializer),kernelRegularizer:zy(this.kernelRegularizer),recurrentRegularizer:zy(this.recurrentRegularizer),biasRegularizer:zy(this.biasRegularizer),activityRegularizer:zy(this.activityRegularizer),kernelConstraint:ag(this.kernelConstraint),recurrentConstraint:ag(this.recurrentConstraint),biasConstraint:ag(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation,resetAfter:!1};return Object.assign(Object.assign({},e),t)}}yb.className="GRUCell",ai(yb);class bb extends db{constructor(e){0===e.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),e.cell=new yb(e),super(e)}call(e,t){return aa((()=>{null!=this.cell.dropoutMask&&(ia(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(ia(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const n=null==t?null:t.mask,s=null==t?null:t.training,r=null==t?null:t.initialState;return super.call(e,{mask:n,training:s,initialState:r})}))}static fromConfig(e,t){return 0===t.implmentation&&(t.implementation=1),new e(t)}}bb.className="GRU",ai(bb);class xb extends fb{constructor(e){super(e),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=e.units,gf(this.units,"units"),this.activation=Fy(void 0===e.activation?this.DEFAULT_ACTIVATION:e.activation),this.recurrentActivation=Fy(void 0===e.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:e.recurrentActivation),this.useBias=null==e.useBias||e.useBias,this.kernelInitializer=$m(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=$m(e.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=$m(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.unitForgetBias=e.unitForgetBias,this.kernelRegularizer=Py(e.kernelRegularizer),this.recurrentRegularizer=Py(e.recurrentRegularizer),this.biasRegularizer=Py(e.biasRegularizer),this.kernelConstraint=og(e.kernelConstraint),this.recurrentConstraint=og(e.recurrentConstraint),this.biasConstraint=og(e.biasConstraint),this.dropout=Bf([1,Pf([0,null==e.dropout?0:e.dropout])]),this.recurrentDropout=Bf([1,Pf([0,null==e.recurrentDropout?0:e.recurrentDropout])]),this.dropoutFunc=e.dropoutFunc,this.implementation=e.implementation,this.stateSize=[this.units,this.units],this.dropoutMask=null,this.recurrentDropoutMask=null}build(e){var t;const n=(e=Am(e))[e.length-1];let s;if(this.kernel=this.addWeight("kernel",[n,4*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,4*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){if(this.unitForgetBias){const e=this.biasInitializer,n=this.units;s=new((t=class extends lm{apply(t,s){const r=e.apply([n]),a=(new cm).apply([n]),i=e.apply([2*n]);return Yf(Yf(r,a),i)}}).className="CustomInit",t)}else s=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.units],null,s,this.biasRegularizer,!0,this.biasConstraint)}else this.bias=null;this.built=!0}call(e,t){return aa((()=>{const n=null!=t.training&&t.training;if(3!==e.length)throw new Xd(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${e.length}.`);let s=e[1];const r=e[2];e=e[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=vb({ones:()=>Il(e),rate:this.dropout,training:n,count:4,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=vb({ones:()=>Il(s),rate:this.recurrentDropout,training:n,count:4,dropoutFunc:this.dropoutFunc}));const a=this.dropoutMask,i=this.recurrentDropoutMask;let o,l,u,c;0<this.dropout&&this.dropout<1&&(e=Xa(e,a[0]));let h=Qf(e,this.kernel.read());0<this.recurrentDropout&&this.recurrentDropout<1&&(s=Xa(s,i[0])),h=ja(h,Qf(s,this.recurrentKernel.read())),this.useBias&&(h=sm(h,this.bias.read()));const[p,d,f,m]=Gl(h,4,h.rank-1);o=this.recurrentActivation.apply(p),l=this.recurrentActivation.apply(d),u=ja(Xa(l,r),Xa(o,this.activation.apply(f))),c=this.recurrentActivation.apply(m);const g=Xa(c,this.activation.apply(u));return[g,g,u]}))}getConfig(){const e=super.getConfig(),t={units:this.units,activation:_y(this.activation),recurrentActivation:_y(this.recurrentActivation),useBias:this.useBias,kernelInitializer:Tm(this.kernelInitializer),recurrentInitializer:Tm(this.recurrentInitializer),biasInitializer:Tm(this.biasInitializer),unitForgetBias:this.unitForgetBias,kernelRegularizer:zy(this.kernelRegularizer),recurrentRegularizer:zy(this.recurrentRegularizer),biasRegularizer:zy(this.biasRegularizer),activityRegularizer:zy(this.activityRegularizer),kernelConstraint:ag(this.kernelConstraint),recurrentConstraint:ag(this.recurrentConstraint),biasConstraint:ag(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation};return Object.assign(Object.assign({},e),t)}}xb.className="LSTMCell",ai(xb);class wb extends db{constructor(e){0===e.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),e.cell=new xb(e),super(e)}call(e,t){return aa((()=>{null!=this.cell.dropoutMask&&(ia(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(ia(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const n=null==t?null:t.mask,s=null==t?null:t.training,r=null==t?null:t.initialState;return super.call(e,{mask:n,training:s,initialState:r})}))}static fromConfig(e,t){return 0===t.implmentation&&(t.implementation=1),new e(t)}}wb.className="LSTM",ai(wb);class kb extends fb{constructor(e){super(e),this.cells=e.cells}get stateSize(){const e=[];for(const t of this.cells.slice().reverse())Array.isArray(t.stateSize)?e.push(...t.stateSize):e.push(t.stateSize);return e}call(e,t){return aa((()=>{let n=e.slice(1);const s=[];for(const e of this.cells.slice().reverse())Array.isArray(e.stateSize)?s.push(n.splice(0,e.stateSize.length)):s.push(n.splice(0,1));s.reverse();const r=[];let a;for(let i=0;i<this.cells.length;++i){const o=this.cells[i];n=s[i],a=0===i?[e[0]].concat(n):[a[0]].concat(n),a=o.call(a,t),r.push(a.slice(1))}n=[];for(const e of r.slice().reverse())n.push(...e);return[a[0]].concat(n)}))}build(e){let t;Em(e)&&(e=e[0]),this.cells.forEach(((n,s)=>{Df(`RNNCell_${s}`,(()=>{n.build(e),t=Array.isArray(n.stateSize)?n.stateSize[0]:n.stateSize,e=[e[0],t]}))})),this.built=!0}getConfig(){const e=super.getConfig(),t={cells:this.cells.map((e=>({className:e.getClassName(),config:e.getConfig()})))};return Object.assign(Object.assign({},e),t)}static fromConfig(e,t,n={}){const s=[];for(const e of t.cells)s.push(xg(e,n));return new e({cells:s})}get trainableWeights(){if(!this.trainable)return[];const e=[];for(const t of this.cells)e.push(...t.trainableWeights);return e}get nonTrainableWeights(){const e=[];for(const t of this.cells)e.push(...t.nonTrainableWeights);if(!this.trainable){const t=[];for(const e of this.cells)t.push(...e.trainableWeights);return t.concat(e)}return e}getWeights(){const e=[];for(const t of this.cells)e.push(...t.weights);return Om(e)}setWeights(e){const t=[];for(const n of this.cells){const s=n.weights.length,r=e.splice(s);for(let e=0;e<n.weights.length;++e)t.push([n.weights[e],r[e]])}Mm(t)}}function vb(e){const{ones:t,rate:n,training:s=!1,count:r=1,dropoutFunc:a}=e,i=()=>null!=a?a(t(),n):rm(t(),n),o=()=>am(i,t,s);return!r||r<=1?oa(o().clone()):Array(r).fill(void 0).map(o).map((e=>oa(e.clone())))}kb.className="StackedRNNCells",ai(kb);class Ib extends db{constructor(e){if(e.unroll)throw new Yd("Unrolling is not possible with convolutional RNNs.");if(Array.isArray(e.cell))throw new Yd("It is not possible at the moment to stack convolutional cells.");super(e),this.inputSpec=[new Lm({ndim:5})]}call(e,t){return aa((()=>{if(null!=this.cell.dropoutMask&&(ia(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(ia(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),t&&t.constants)throw new Xd("ConvRNN2D cell does not support constants");const n=null==t?null:t.mask,s=null==t?null:t.training,r=null==t?null:t.initialState;return super.call(e,{mask:n,training:s,initialState:r})}))}computeOutputShape(e){let t=this.computeSingleOutputShape(e);return this.returnSequences||(t=[t[0],...t.slice(2)]),this.returnState&&(t=[t,...Array(2).fill([e[0],...t.slice(-3)])]),t}getInitialState(e){return aa((()=>{const{stateSize:t}=this.cell,n=e.shape,s=this.computeSingleOutputShape(n),r=kl([s[0],...s.slice(2)]);return Array.isArray(t)?Array(t.length).fill(r):[r]}))}resetStates(e,t=!1){aa((()=>{if(!this.stateful)throw new Kd("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape,s=this.computeSingleOutputShape(n),r=[s[0],...s.slice(2)];if(null==n[0])throw new Xd("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.getStates())Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((()=>kl(r))):this.states_=[kl(r)];else if(null==e)ia(this.states_),null!=this.keptStates&&(ia(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((()=>kl(r))):this.states_[0]=kl(r);else{if(Array.isArray(e)||(e=[e]),e.length!==this.states_.length)throw new Xd(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${e.length} state value(s). Input received: ${e}`);t?this.keptStates.push(this.states_.slice()):ia(this.states_);for(let t=0;t<this.states_.length;++t){const n=e[t],s=r;if(!z(n.shape,s))throw new Xd(`State ${t} is incompatible with layer ${this.name}: expected shape=${s}, received shape=${n.shape}`);this.states_[t]=n}}this.states_=this.states_.map((e=>oa(e.clone())))}))}computeSingleOutputShape(e){const{dataFormat:t,filters:n,kernelSize:s,padding:r,strides:a,dilationRate:i}=this.cell,o="channelsFirst"===t,l=e[o?3:2],u=e[o?4:3],c=qy(l,s[0],r,a[0],i[0]),h=qy(u,s[1],r,a[1],i[1]);return[...e.slice(0,2),...o?[n,c,h]:[c,h,n]]}}Ib.className="ConvRNN2D";class Nb extends xb{constructor(e){const{filters:t,kernelSize:n,strides:s,padding:r,dataFormat:a,dilationRate:i}=e;super(Object.assign(Object.assign({},e),{units:t})),this.filters=t,gf(this.filters,"filters"),this.kernelSize=Ky(n,2,"kernelSize"),this.kernelSize.forEach((e=>gf(e,"kernelSize"))),this.strides=Ky(s||1,2,"strides"),this.strides.forEach((e=>gf(e,"strides"))),this.padding=r||"valid",Rf(this.padding),this.dataFormat=a||"channelsLast",Cf(this.dataFormat),this.dilationRate=Ky(i||1,2,"dilationRate"),this.dilationRate.forEach((e=>gf(e,"dilationRate")))}build(e){var t;e=Am(e);const n="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[n])throw new Xd(`The channel dimension of the input should be defined. Found ${e[n]}`);const s=e[n],r=this.kernelSize.concat([s,4*this.filters]);this.kernel=this.addWeight("kernel",r,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint);const a=this.kernelSize.concat([this.filters,4*this.filters]);if(this.recurrentKernel=this.addWeight("recurrent_kernel",a,null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){let e;if(this.unitForgetBias){const n=this.biasInitializer,s=this.filters;e=new((t=class extends lm{apply(e,t){return Xf([n.apply([s]),vl([s]),n.apply([2*s])])}}).className="CustomInit",t)}else e=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.filters],null,e,this.biasRegularizer,!0,this.biasConstraint)}this.built=!0}call(e,t){return aa((()=>{if(3!==e.length)throw new Xd(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${e.length}.`);const n=t.training||!1,s=e[0],r=e[1],a=e[2];0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=vb({ones:()=>Il(s),rate:this.dropout,training:n,count:4,dropoutFunc:this.dropoutFunc}));const i=this.dropoutMask,o=(e,t,n)=>t&&t[n]?Xa(t[n],e):e;let l=o(s,i,0),u=o(s,i,1),c=o(s,i,2),h=o(s,i,3);0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=vb({ones:()=>Il(r),rate:this.recurrentDropout,training:n,count:4,dropoutFunc:this.dropoutFunc}));const p=this.recurrentDropoutMask;let d=o(r,p,0),f=o(r,p,1),m=o(r,p,2),g=o(r,p,3);const[y,b,x,w]=Gl(this.kernel.read(),4,3),[k,v,I,N]=this.useBias?Gl(this.bias.read(),4):[null,null,null,null];l=this.inputConv(l,y,k,this.padding),u=this.inputConv(u,b,v,this.padding),c=this.inputConv(c,x,I,this.padding),h=this.inputConv(h,w,N,this.padding);const[S,T,$,E]=Gl(this.recurrentKernel.read(),4,3);d=this.recurrentConv(d,S),f=this.recurrentConv(f,T),m=this.recurrentConv(m,$),g=this.recurrentConv(g,E);const C=this.recurrentActivation.apply(ja(l,d)),R=this.recurrentActivation.apply(ja(u,f)),A=ja(Xa(R,a),Xa(C,this.activation.apply(ja(c,m)))),_=Xa(this.recurrentActivation.apply(ja(h,g)),this.activation.apply(A));return[_,_,A]}))}getConfig(){const e=super.getConfig(),{units:t}=e,n=function(e,t){var n={};for(var s in e)Object.prototype.hasOwnProperty.call(e,s)&&t.indexOf(s)<0&&(n[s]=e[s]);if(null!=e&&"function"==typeof Object.getOwnPropertySymbols){var r=0;for(s=Object.getOwnPropertySymbols(e);r<s.length;r++)t.indexOf(s[r])<0&&Object.prototype.propertyIsEnumerable.call(e,s[r])&&(n[s[r]]=e[s[r]])}return n}(e,["units"]),s={filters:this.filters,kernelSize:this.kernelSize,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,strides:this.strides};return Object.assign(Object.assign({},n),s)}inputConv(e,t,n,s){const r=Co(e,t,this.strides,s||"valid","channelsFirst"===this.dataFormat?"NCHW":"NHWC",this.dilationRate);return n?sm(r,n,this.dataFormat):r}recurrentConv(e,t){return Co(e,t,1,"same","channelsFirst"===this.dataFormat?"NCHW":"NHWC")}}Nb.className="ConvLSTM2DCell",ai(Nb);class Sb extends Ib{constructor(e){const t=new Nb(e);super(Object.assign(Object.assign({},e),{cell:t}))}static fromConfig(e,t){return new e(t)}}Sb.className="ConvLSTM2D",ai(Sb);class Tb extends Vm{constructor(e){super(e),this.rate=Math.max(Math.min(e.rate,1),0),this.noiseShape=e.noiseShape,this.seed=e.seed,this.supportsMasking=!0}getNoiseShape(e){if(null==this.noiseShape)return this.noiseShape;const t=e.shape,n=[];for(let e=0;e<this.noiseShape.length;++e)n.push(null==this.noiseShape[e]?t[e]:this.noiseShape[e]);return n}call(e,t){return aa((()=>{this.invokeCallHook(e,t);const n=Rm(e);if(0<this.rate&&this.rate<1){const e=null!=t.training&&t.training,s=this.getNoiseShape(n);return am((()=>rm(n,this.rate,s,this.seed)),(()=>n),e)}return e}))}getConfig(){const e={rate:this.rate,noiseShape:this.noiseShape,seed:this.seed},t=super.getConfig();return Object.assign(e,t),e}dispose(){return super.dispose()}}Tb.className="Dropout",ai(Tb);class $b extends Tb{constructor(e){super(e),this.inputSpec=[{ndim:3}]}getNoiseShape(e){const t=e.shape;return[t[0],1,t[2]]}}$b.className="SpatialDropout1D",ai($b);class Eb extends Vm{constructor(e){if(super(e),this.activation=null,this.useBias=!0,this.kernel=null,this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",null==e.batchInputShape&&null==e.inputShape&&null!=e.inputDim){let t=null;null!=e.batchSize&&(t=e.batchSize),this.batchInputShape=[t,e.inputDim]}this.units=e.units,gf(this.units,"units"),this.activation=Fy(e.activation),null!=e.useBias&&(this.useBias=e.useBias),this.kernelInitializer=$m(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.biasInitializer=$m(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelConstraint=og(e.kernelConstraint),this.biasConstraint=og(e.biasConstraint),this.kernelRegularizer=Py(e.kernelRegularizer),this.biasRegularizer=Py(e.biasRegularizer),this.activityRegularizer=Py(e.activityRegularizer),this.supportsMasking=!0,this.inputSpec=[{minNDim:2}]}build(e){const t=(e=Am(e))[e.length-1];null==this.kernel&&(this.kernel=this.addWeight("kernel",[t,this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint))),this.inputSpec=[{minNDim:2,axes:{[-1]:t}}],this.built=!0}computeOutputShape(e){const t=(e=Am(e)).slice();return t[t.length-1]=this.units,t}call(e,t){return aa((()=>{this.invokeCallHook(e,t);const n=Rm(e),s=bf(this.activation.getClassName());let r;return null!=s?r=Qf(n,this.kernel.read(),s,this.bias?this.bias.read():null):(r=Qf(n,this.kernel.read()),null!=this.bias&&(r=sm(r,this.bias.read())),null!=this.activation&&(r=this.activation.apply(r))),r}))}getConfig(){const e={units:this.units,activation:_y(this.activation),useBias:this.useBias,kernelInitializer:Tm(this.kernelInitializer),biasInitializer:Tm(this.biasInitializer),kernelRegularizer:zy(this.kernelRegularizer),biasRegularizer:zy(this.biasRegularizer),activityRegularizer:zy(this.activityRegularizer),kernelConstraint:ag(this.kernelConstraint),biasConstraint:ag(this.biasConstraint)},t=super.getConfig();return Object.assign(e,t),e}}Eb.className="Dense",ai(Eb);class Cb extends Vm{constructor(e){super(e=e||{}),this.inputSpec=[{minNDim:3}],this.dataFormat=e.dataFormat}computeOutputShape(e){e=Am(e);for(const t of e.slice(1))if(null==t)throw new Xd(`The shape of the input to "Flatten" is not fully defined (got ${e.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);return[e[0],zf(e,1)]}call(e,t){return aa((()=>{this.invokeCallHook(e,t);let n=Rm(e);if("channelsFirst"===this.dataFormat&&n.rank>1){const e=[0];for(let t=2;t<n.rank;++t)e.push(t);e.push(1),n=tu(n,e)}return function(e){if(e.rank<=1)throw new Xd(`batchFlatten requires a minimum rank of 2. Got rank: ${e.rank}.`);const t=[e.shape[0],zf(e.shape,1)];return mo(e,t)}(n)}))}getConfig(){const e={};null!=this.dataFormat&&(e.dataFormat=this.dataFormat);const t=super.getConfig();return Object.assign(e,t),e}}Cb.className="Flatten",ai(Cb);class Rb extends Vm{constructor(e){super(e),this.supportsMasking=!0,this.activation=Fy(e.activation)}call(e,t){return aa((()=>{this.invokeCallHook(e,t);const n=Rm(e);return this.activation.apply(n)}))}getConfig(){const e={activation:_y(this.activation)},t=super.getConfig();return Object.assign(e,t),e}}Rb.className="Activation",ai(Rb);class Ab extends Vm{constructor(e){super(e),this.n=e.n,this.inputSpec=[{ndim:2}]}computeOutputShape(e){return[e[0],this.n,e[1]]}call(e,t){return aa((()=>{return e=Rm(e),t=e,n=this.n,aa((()=>{if(2!==t.shape.length)throw new Xd(`repeat() expects a rank-2 tensor, but received a rank-${t.shape.length} tensor.`);return Jf(Hf(t,1),[1,n,1])}));var t,n}))}getConfig(){const e={n:this.n},t=super.getConfig();return Object.assign(e,t),e}}Ab.className="RepeatVector",ai(Ab);class _b extends Vm{constructor(e){super(e),this.targetShape=e.targetShape;for(let e=0;e<this.targetShape.length;++e)this.isUnknown(this.targetShape[e])&&(this.targetShape[e]=null)}isUnknown(e){return e<0||null==e}fixUnknownDimension(e,t){const n="Total size of new array must be unchanged.",s=t.slice();let r=1,a=null;for(let e=0;e<s.length;++e){const t=s[e];if(this.isUnknown(t)){if(null!==a)throw new Xd("Can only specifiy one unknown dimension.");a=e}else r*=t}const i=zf(e);if(null!==a){if(0===r||i%r!=0)throw new Xd(n);s[a]=i/r}else if(i!==r)throw new Xd(n);return s}computeOutputShape(e){let t=!1;for(let n=0;n<e.length;++n)if(this.isUnknown(e[n])){t=!0;break}return t?e.slice(0,1).concat(this.targetShape):e.slice(0,1).concat(this.fixUnknownDimension(e.slice(1),this.targetShape))}call(e,t){return aa((()=>{this.invokeCallHook(e,t);const n=Rm(e),s=n.shape,r=s.slice(0,1).concat(this.fixUnknownDimension(s.slice(1),this.targetShape));return mo(n,r)}))}getConfig(){const e={targetShape:this.targetShape},t=super.getConfig();return Object.assign(e,t),e}}_b.className="Reshape",ai(_b);class Db extends Vm{constructor(e){if(super(e),null==e.dims)throw new Error("Required configuration field `dims` is missing during Permute constructor call.");if(!Array.isArray(e.dims))throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${e.dims} instead.`);const t=Wf(1,e.dims.length+1);if(!z(e.dims.slice().sort(),t))throw new Error("Invalid permutation `dims`: "+JSON.stringify(e.dims)+" `dims` must contain consecutive integers starting from 1.");this.dims=e.dims,this.dimsIncludingBatch=[0].concat(this.dims),this.inputSpec=[new Lm({ndim:this.dims.length+1})]}computeOutputShape(e){const t=(e=Am(e)).slice();return this.dims.forEach(((n,s)=>{t[s+1]=e[n]})),t}call(e,t){return tu(Rm(e),this.dimsIncludingBatch)}getConfig(){const e={dims:this.dims},t=super.getConfig();return Object.assign(e,t),e}}Db.className="Permute",ai(Db);class Fb extends Vm{constructor(e){super(null==e?{}:e),this.supportsMasking=!0,this.maskValue=null!=e?null==e.maskValue?0:e.maskValue:0}computeOutputShape(e){return e}getConfig(){const e=super.getConfig(),t={maskValue:this.maskValue};return Object.assign(t,e),t}computeMask(e,t){const n=Rm(e);return Ji(xl(n,this.maskValue),-1)}call(e,t){return aa((()=>{this.invokeCallHook(e,t);const n=Rm(e),s=Ji(xl(n,this.maskValue),-1,!0);return Xa(n,Ga(s,n.dtype))}))}}Fb.className="Masking",ai(Fb);class Ob extends Vm{constructor(e){if(super(e),this.embeddings=null,this.DEFAULT_EMBEDDINGS_INITIALIZER="randomUniform",null==e.batchInputShape&&null==e.inputShape){let t=null;null!=e.batchSize&&(t=e.batchSize),null==e.inputLength?this.batchInputShape=[t,null]:this.batchInputShape=[t].concat(sf(e.inputLength))}this.inputDim=e.inputDim,gf(this.inputDim,"inputDim"),this.outputDim=e.outputDim,gf(this.outputDim,"outputDim"),this.embeddingsInitializer=$m(e.embeddingsInitializer||this.DEFAULT_EMBEDDINGS_INITIALIZER),this.embeddingsRegularizer=Py(e.embeddingsRegularizer),this.activityRegularizer=Py(e.activityRegularizer),this.embeddingsConstraint=og(e.embeddingsConstraint),this.maskZero=e.maskZero,this.supportsMasking=e.maskZero,this.inputLength=e.inputLength}build(e){this.embeddings=this.addWeight("embeddings",[this.inputDim,this.outputDim],this.dtype,this.embeddingsInitializer,this.embeddingsRegularizer,!0,this.embeddingsConstraint),this.built=!0}warnOnIncompatibleInputShape(e){}computeMask(e,t){return aa((()=>this.maskZero?(e=Rm(e),xl(e,Za(e))):null))}computeOutputShape(e){if(e=Am(e),null==this.inputLength)return[...e,this.outputDim];const t=sf(this.inputLength);if(t.length!==e.length-1)throw new Xd(`"inputLength" is ${this.inputLength}, but received input shape has shape ${e}`);{let n=0;for(let s=0;s<t.length;++s){const r=t[s],a=e[s+1];if(null!=r&&null!=a&&r!==a)throw new Xd(`"inputLength" is ${this.inputLength}, but received input shape has shape ${e}`);null==r&&(t[n]=a),n++}}return[e[0],...t,this.outputDim]}call(e,t){return aa((()=>{this.invokeCallHook(e,t);let n=Rm(e);"int32"!==n.dtype&&(n=Gf(n,"int32"));const s=em(this.embeddings.read(),mo(n,[n.size]));return mo(s,Am(this.computeOutputShape(n.shape)))}))}getConfig(){const e={inputDim:this.inputDim,outputDim:this.outputDim,embeddingsInitializer:Tm(this.embeddingsInitializer),embeddingsRegularizer:zy(this.embeddingsRegularizer),activityRegularizer:zy(this.activityRegularizer),embeddingsConstraint:ag(this.embeddingsConstraint),maskZero:this.maskZero,inputLength:this.inputLength},t=super.getConfig();return Object.assign(e,t),e}}Ob.className="Embedding",ai(Ob);class Mb extends Vm{constructor(e){super(e||{}),this.supportsMasking=!0}mergeFunction(e){throw new Yd}computeElementwiseOpOutputShape(e,t){if(null==e||null==t)return null;if(e.length<t.length)return this.computeElementwiseOpOutputShape(t,e);if(0===t.length)return e;const n=e.slice(0,e.length-t.length);for(let s=0;s<t.length;++s){const r=e[e.length-t.length+s],a=t[s];if(null==r||null==a||r<0||a<0)n.push(null);else if(1===r)n.push(a);else if(1===a)n.push(r);else{if(r!==a)throw new Xd("Operands could not be broadcast together with shapes "+JSON.stringify(e)+" "+JSON.stringify(t));n.push(r)}}return n}build(e){if(Array.isArray(e)&&!Array.isArray(e[0])&&(e=[Am(e)]),e.length<2)throw new Xd(`A merge layer should be called on an Array of at least 2 inputs. Got ${e.length} input(s).`);let t=[];for(const n of e)null!=n&&null!==n[0]&&t.push(n[0]);if(t=pf(t),t.length>1)throw new Xd(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(e)}.`);let n=null==e[0]?null:e[0].slice(1);for(let t=1;t<e.length;++t){const s=null==e[t]?null:e[t].slice(1);n=this.computeElementwiseOpOutputShape(n,s)}const s=e.map((e=>e.length));-1===e.indexOf(null)&&1===pf(s).length?this.reshapeRequired=!1:this.reshapeRequired=!0}call(e,t){return aa((()=>{if(this.reshapeRequired){const t=[],n=e.map((e=>e.rank));if(-1===n.indexOf(null)){const s=Pf(n);for(let n of e){const e=n.rank;for(let t=0;t<s-e;++t)n=Hf(n,1);t.push(n)}return this.mergeFunction(t)}{let n=!1;for(const s of e){const e=s.rank;if(null==e){const e=s.shape,r=e[0],a=e.slice(1).concat([r]);let i=mo(s,[r].concat(zf(e.slice(1))));i=tu(i,[1,0]),i=mo(i,a),t.push(i),n=!0}else if(e>1){const r=Wf(1,e).concat([0]);t.push(tu(s,r)),n=!0}else t.push(s)}let s=this.mergeFunction(t);const r=s.rank;if(n)if(null==r){const e=s.shape,t=e[e.length-1],n=[t].concat(e.slice(0,e.length-1));s=mo(tu(mo(s,[-1,t]),[1,0]),n)}else if(r>1){const e=[r-1].concat(Wf(0,r-1));s=tu(s,e)}return s}}return this.mergeFunction(e)}))}computeOutputShape(e){let t;t=null==e[0]?null:e[0].slice(1);for(let n=1;n<e.length;++n){const s=null==e[n]?null:e[n].slice(1);t=this.computeElementwiseOpOutputShape(t,s)}let n=[];for(const t of e)null!=t&&null!==t[0]&&n.push(t[0]);return n=pf(n),t=1===n.length?n.concat(t):[null].concat(t),t}computeMask(e,t){return aa((()=>{if(null==t)return null;if(!Array.isArray(t))throw new Xd("`mask` should be an Array");if(!Array.isArray(e))throw new Xd("`inputs` should be an Array");if(t.length!==e.length)throw new Xd(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${e.length} vs ${t.length})`);if(t.every((e=>null==e)))return null;let n=(t=t.map((e=>null==e?e:Vo(e,0))))[0];for(let e=1;e<t.length-1;++e)n=cl(n,t[e]);return n}))}}class Lb extends Mb{constructor(e){super(e)}mergeFunction(e){return aa((()=>{let t=e[0].clone();for(let n=1;n<e.length;++n)t=ja(t,e[n]);return t}))}}Lb.className="Add",ai(Lb);class zb extends Mb{constructor(e){super(e)}mergeFunction(e){return aa((()=>{let t=e[0].clone();for(let n=1;n<e.length;++n)t=Xa(t,e[n]);return t}))}}zb.className="Multiply",ai(zb);class Bb extends Mb{constructor(e){super(e)}mergeFunction(e){return aa((()=>{let t=e[0].clone();for(let n=1;n<e.length;++n)t=ja(t,e[n]);return Xa(1/e.length,t)}))}}Bb.className="Average",ai(Bb);class Pb extends Mb{constructor(e){super(e)}mergeFunction(e){return aa((()=>{let t=e[0];for(let n=1;n<e.length;++n)t=yi(t,e[n]);return t}))}}Pb.className="Maximum",ai(Pb);class Wb extends Mb{constructor(e){super(e)}mergeFunction(e){return aa((()=>{let t=e[0];for(let n=1;n<e.length;++n)t=gl(t,e[n]);return t}))}}Wb.className="Minimum",ai(Wb);class Vb extends Mb{constructor(e){super(e),this.DEFAULT_AXIS=-1,null==e&&(e={}),this.axis=null==e.axis?this.DEFAULT_AXIS:e.axis,this.supportsMasking=!0,this.reshapeRequired=!1}build(e){if(!Array.isArray(e)||!Array.isArray(e[0])||1===e.length)throw new Xd("A `Concatenate` layer should be called on a list of at least 2 inputs");let t=!0;for(const n of e)if(null!=n){t=!1;break}if(t)return;const n=[];for(let t=0;t<e.length;++t){const s=e[t].slice();s.splice(this.axis,1);let r=!1;for(const e of n)if(z(e,s)){r=!0;break}r||n.push(s)}if(n.length>1)throw new Xd("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: "+JSON.stringify(e))}mergeFunction(e){return aa((()=>Xf(e,this.axis)))}computeOutputShape(e){if(!Array.isArray(e)||!Array.isArray(e[0]))throw new Xd("A `Concatenate` layer should be called on a list of inputs.");const t=e,n=t[0].slice(),s=this.axis<0?n.length+this.axis:this.axis;for(const e of t.slice(1)){if(null==n[s]||null==e[s]){n[s]=null;break}n[s]+=e[s]}return n}computeMask(e,t){if(null==t)return null;if(!Array.isArray(t))throw new Xd("`mask` should be an array for Concatenate");if(!Array.isArray(e))throw new Xd("`inputs` should be an array for Concatenate");if(t.length!==e.length)throw new Xd(`Mismatch in the length of mask (${t.length}) and the legnth of inputs (${e.length})`);return aa((()=>{let n=!0;if(t.forEach((e=>{null==e||(n=!1)})),n)return null;const s=[];for(let n=0;n<e.length;++n)null==t[n]?s.push(Ga(Il(e[n]),"bool")):t[n].rank<e[n].rank?s.push(Vo(t[n],-1)):s.push(t[n]);const r=No(s,this.axis);return Yi(r,-1,!1)}))}getConfig(){const e={axis:this.axis},t=super.getConfig();return Object.assign(e,t),e}}function Ub(e,t){for(;e<0;)e+=t;return e}Vb.className="Concatenate",ai(Vb);class Gb extends Mb{constructor(e){super(e),this.axes=e.axes,this.normalize=null!=e.normalize&&e.normalize,this.supportsMasking=!0,this.reshapeRequired=!1}build(e){F(Array.isArray(e)&&2===e.length&&Array.isArray(e[0])&&Array.isArray(e[1]),(()=>"A `Dot` layer should be called on a list of exactly 2 inputs."));const t=e[0],n=e[1];if(t.length>3||n.length>3)throw new Yd("Dot layer does not support tensors of 4D or higher rank yet.");const s=this.interpretAxes(t,n);if(t[s[0]]!==n[s[1]])throw new Xd(`Dimension incompatibility: ${t[s[0]]} !== ${n[s[1]]}`)}mergeFunction(e){if(2!==e.length)throw new Xd(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${e.length} input(s).`);let t,n=e[0],s=e[1];return t=Array.isArray(this.axes)?this.axes.map(((t,n)=>Ub(t,e[n].shape.length))):[Ub(this.axes,n.shape.length),Ub(this.axes,s.shape.length)],this.normalize&&(n=wg(n,t[0]),s=wg(s,t[1])),function(e,t,n){if(e.shape.length>3||t.shape.length>3)throw new Yd("batchDot is not implemented for tensors of 4D or higher rank yet");if(F(e.shape.length>=2,(()=>`batchDot requires the rank of x to be >= 2, but got ${e.shape.length}`)),F(e.shape.length>=2,(()=>`batchDot requires the rank of y to be >= 2, but got ${t.shape.length}`)),"number"==typeof n&&(n=[n,n]),"complex64"===e.dtype||"complex64"===t.dtype)throw new Yd("batchDot is not implemented for complex64-type Tensors yet.");const s=e.shape.length,r=t.shape.length;null==n&&(n=[s-1,r-2]);const a=n;return aa((()=>{let n,i;if(s>r){n=s-r;const e=[];for(let t=0;t<n;++t)e.push(1);t=mo(t,t.shape.concat(e))}else if(r>s){n=r-s;const t=[];for(let e=0;e<n;++e)t.push(1);e=mo(e,e.shape.concat(t))}else n=0;if(2===e.shape.length&&2===t.shape.length)i=a[0]===a[1]?Qo(Xa(e,t),a[0]):Qo(Xa(tu(e,[1,0]),t),a[1]);else{const n=a[0]!==e.shape.length-1,s=a[1]===t.shape.length-1;i=hl(e,t,n,s)}if(n>0){let e;e=s>r?s+r-3:s-1;const t=[];for(let s=e;s<e+n;++s)t.push(s);i=Hl(i,t)}return 1===i.shape.length&&(i=Vo(i,1)),i}))}(n,s,t)}interpretAxes(e,t){let n;return n=Array.isArray(this.axes)?this.axes:[Ub(this.axes,e.length),Ub(this.axes,t.length)],n}computeOutputShape(e){F(Array.isArray(e)&&2===e.length&&Array.isArray(e[0])&&Array.isArray(e[1]),(()=>"A `Dot` layer should be called on a list of exactly 2 inputs."));const t=e[0].slice(),n=e[1].slice();if(t.length>3||n.length>3)throw new Yd("Dot layer does not support tensors of 4D or higher rank yet.");const s=this.interpretAxes(t,n);t.splice(s[0],1),n.splice(s[1],1),n.splice(0,1);const r=t.concat(n);return 1===r.length&&r.push(1),r}computeMask(e,t){return null}getConfig(){const e={axes:this.axes,normalize:this.normalize},t=super.getConfig();return Object.assign(e,t),e}}Gb.className="Dot",ai(Gb);class Hb extends Vm{constructor(e){super(e),this.supportsMasking=!0,this.stddev=e.stddev}computeOutputShape(e){return e}getConfig(){const e=super.getConfig(),t={stddev:this.stddev};return Object.assign(t,e),t}call(e,t){return aa((()=>{this.invokeCallHook(e,t);const n=Rm(e);return am((()=>ja(Zf(n.shape,0,this.stddev),n)),(()=>n),t.training||!1)}))}}Hb.className="GaussianNoise",ai(Hb);class jb extends Vm{constructor(e){super(e),this.supportsMasking=!0,this.rate=e.rate}computeOutputShape(e){return e}getConfig(){const e=super.getConfig(),t={rate:this.rate};return Object.assign(t,e),t}call(e,t){return aa((()=>{this.invokeCallHook(e,t);const n=Rm(e);return this.rate>0&&this.rate<1?am((()=>{const e=Math.sqrt(this.rate/(1-this.rate));return Xa(n,Zf(n.shape,1,e))}),(()=>n),t.training||!1):n}))}}jb.className="GaussianDropout",ai(jb);class Kb extends Vm{constructor(e){super(e),this.supportsMasking=!0,this.rate=e.rate,this.noiseShape=e.noiseShape}_getNoiseShape(e){return this.noiseShape||Rm(e).shape}computeOutputShape(e){return e}getConfig(){const e=super.getConfig(),t={rate:this.rate};return Object.assign(t,e),t}call(e,t){return aa((()=>{if(this.rate<1&&this.rate>0){const n=this._getNoiseShape(e);return am((()=>{const t=Rm(e),s=-1.7580993408473766;let r=qo(Rl(n),this.rate);r=Gf(r,"float32");const a=((1-this.rate)*(1+this.rate*s**2))**-.5,i=-a*s*this.rate,o=ja(Xa(t,r),Xa(ja(r,-1),s));return ja(Xa(o,a),i)}),(()=>Rm(e)),t.training||!1)}return e}))}}function qb(e,t,n,s,r,a=.001){let i;if(2===e.rank)i=xo(e,t,n,s,r,a);else if(3===e.rank)i=wo(e,t,n,s,r,a);else{if(4!==e.rank)throw new Yd(`batchNormalization is not implemented for array of rank ${e.rank} yet`);i=ko(e,t,n,s,r,a)}return i}Kb.className="AlphaDropout",ai(Kb);class Xb extends Vm{constructor(e){null==e&&(e={}),super(e),this.supportsMasking=!0,this.axis=null==e.axis?-1:e.axis,this.momentum=null==e.momentum?.99:e.momentum,this.epsilon=null==e.epsilon?.001:e.epsilon,this.center=null==e.center||e.center,this.scale=null==e.scale||e.scale,this.betaInitializer=$m(e.betaInitializer||"zeros"),this.gammaInitializer=$m(e.gammaInitializer||"ones"),this.movingMeanInitializer=$m(e.movingMeanInitializer||"zeros"),this.movingVarianceInitializer=$m(e.movingVarianceInitializer||"ones"),this.betaConstraint=og(e.betaConstraint),this.gammaConstraint=og(e.gammaConstraint),this.betaRegularizer=Py(e.betaRegularizer),this.gammaRegularizer=Py(e.gammaRegularizer)}build(e){e=Am(e);const t=this.axis>=0?this.axis:this.axis+e.length,n=e[t];if(null==n)throw new Xd(`Axis ${t} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(e)}.`);this.inputSpec=[new Lm({ndim:e.length,axes:{[t]:n}})];const s=[n];this.scale&&(this.gamma=this.addWeight("gamma",s,null,this.gammaInitializer,this.gammaRegularizer,!0,this.gammaConstraint)),this.center&&(this.beta=this.addWeight("beta",s,null,this.betaInitializer,this.betaRegularizer,!0,this.betaConstraint)),this.movingMean=this.addWeight("moving_mean",s,null,this.movingMeanInitializer,null,!1),this.movingVariance=this.addWeight("moving_variance",s,null,this.movingVarianceInitializer,null,!1),this.built=!0}call(e,t){return aa((()=>{const n=null!=t.training&&t.training,s=Rm(e),r=s.shape,a=r.length,i=Wf(0,a),o=this.axis>=0?this.axis:this.axis+a;i.splice(o,1);const l=Qd(1,a);l[o]=r[o];const u=i.slice();u.sort();const c=!z(u,Wf(0,a).slice(0,a-1));if(!n)return(()=>{if(c){const e=mo(this.movingMean.read(),l),t=mo(this.movingVariance.read(),l),n=this.center?mo(this.beta.read(),l):null,r=this.scale?mo(this.gamma.read(),l):null;return qb(s,e,t,n,r,this.epsilon)}return qb(s,this.movingMean.read(),this.movingVariance.read(),null==this.beta?null:this.beta.read(),null==this.gamma?null:this.gamma.read(),this.epsilon)})();const[h,p,d]=function(e,t,n,s,r=.001){return z(s.slice().sort(),Wf(0,e.rank-1))?function(e,t,n,s,r=.001){return aa((()=>{const a=yl(e,s),i=a.mean,o=a.variance;return[qb(e,i,o,n,t,r),i,o]}))}(e,t,n,s,r):function(e,t,n,s,r=.001){return aa((()=>{const a=yl(e,s),i=a.mean,o=a.variance,l=[];for(const t of Wf(0,e.rank))-1!==s.indexOf(t)?l.push(1):l.push(e.shape[t]);const u=mo(i,l),c=mo(o,l),h=null==t?null:mo(t,l),p=null==n?null:mo(n,l);return[qb(e,u,c,p,h,r),i,o]}))}(e,t,n,s,r)}(s,this.gamma.read(),this.beta.read(),i,this.epsilon),f=(e,t,n)=>{aa((()=>{const s=1-n,r=e.read(),a=Xa(hi(r,t),s);e.write(hi(r,a))}))};return(()=>{f(this.movingMean,p,this.momentum),f(this.movingVariance,d,this.momentum)})(),h}))}getConfig(){const e={axis:this.axis,momentum:this.momentum,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:Tm(this.betaInitializer),gammaInitializer:Tm(this.gammaInitializer),movingMeanInitializer:Tm(this.movingMeanInitializer),movingVarianceInitializer:Tm(this.movingVarianceInitializer),betaRegularizer:zy(this.betaRegularizer),gammaRegularizer:zy(this.gammaRegularizer),betaConstraint:ag(this.betaConstraint),gammaConstraint:ag(this.gammaConstraint)},t=super.getConfig();return Object.assign(e,t),e}}Xb.className="BatchNormalization",ai(Xb);class Yb extends Vm{constructor(e){if(null==e&&(e={}),super(e),this.axis=null==e.axis?-1:e.axis,"number"==typeof this.axis){if(!Number.isInteger(this.axis))throw new Error(`Expected axis to be an integer, but received ${this.axis}`)}else{if(!Array.isArray(this.axis))throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);for(const e of this.axis)if(!Number.isInteger(e))throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`)}this.epsilon=null==e.epsilon?.001:e.epsilon,this.center=null==e.center||e.center,this.scale=null==e.scale||e.scale,this.betaInitializer=$m(e.betaInitializer||"zeros"),this.gammaInitializer=$m(e.gammaInitializer||"ones"),this.betaRegularizer=Py(e.betaRegularizer),this.gammaRegularizer=Py(e.gammaRegularizer),this.supportsMasking=!0}build(e){const t=(e=Am(e)).length;"number"==typeof this.axis&&(this.axis=[this.axis]);for(let e=0;e<this.axis.length;++e)this.axis[e]<0&&(this.axis[e]+=t);for(const e of this.axis)if(e<0||e>=t)throw new Error(`Invalid axis: ${e}`);if(this.axis.length!==pf(this.axis).length)throw new Error(`Found duplicate axes in: ${this.axis}`);const n=this.axis.map((t=>e[t])),s=!0;this.scale?this.gamma=this.addWeight("gamma",n,"float32",this.gammaInitializer,this.gammaRegularizer,s):this.gamma=null,this.center?this.beta=this.addWeight("beta",n,"float32",this.betaInitializer,this.betaRegularizer,s):this.beta=null,this.built=!0}call(e,t){const n=Rm(e),s=n.shape,r=s.length;return aa((()=>{let{mean:e,variance:t}=yl(n,this.axis,!0);const a=Qd(1,r);for(const e of this.axis)a[e]=s[e];const i=e=>null!=e&&e.shape.length!==r?mo(e,a):e;let o=this.scale?i(this.gamma.read()):null,l=this.center?i(this.beta.read()):null;const u=[],c=[];for(let e=0;e<r;++e)-1!==this.axis.indexOf(e)?(u.push(s[e]),c.push(1)):(u.push(1),c.push(s[e]));return e=Uo(e,u),t=Uo(t,u),null!=o&&(o=Uo(o,c)),null!=l&&(l=Uo(l,c)),qb(n,e,t,l,o,this.epsilon)}))}getConfig(){const e={axis:this.axis,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:Tm(this.betaInitializer),gammaInitializer:Tm(this.gammaInitializer),betaRegularizer:zy(this.betaRegularizer),gammaRegularizer:zy(this.gammaRegularizer)},t=super.getConfig();return Object.assign(e,t),e}}Yb.className="LayerNormalization",ai(Yb);class Jb extends Vm{constructor(e){if(null==e&&(e={}),super(e),this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,null==e.padding)this.padding=[[1,1],[1,1]];else if("number"==typeof e.padding)this.padding=[[e.padding,e.padding],[e.padding,e.padding]];else{if(e.padding=e.padding,2!==e.padding.length)throw new Xd(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${e.padding.length} array.`);let t,n;if("number"==typeof e.padding[0])t=[e.padding[0],e.padding[0]],n=[e.padding[1],e.padding[1]];else{if(e.padding=e.padding,2!==e.padding[0].length)throw new Xd(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${e.padding[0].length} array.`);if(t=e.padding[0],2!==e.padding[1].length)throw new Xd(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${e.padding[1].length} array.`);n=e.padding[1]}this.padding=[t,n]}this.inputSpec=[new Lm({ndim:4})]}computeOutputShape(e){let t,n;return e=Am(e),"channelsFirst"===this.dataFormat?(t=null!=e[2]&&e[2]>=0?e[2]+this.padding[0][0]+this.padding[0][1]:null,n=null!=e[3]&&e[3]>=0?e[3]+this.padding[1][0]+this.padding[1][1]:null,[e[0],e[1],t,n]):(t=null!=e[1]&&e[1]>=0?e[1]+this.padding[0][0]+this.padding[0][1]:null,n=null!=e[2]&&e[2]>=0?e[2]+this.padding[1][0]+this.padding[1][1]:null,[e[0],t,n,e[3]])}call(e,t){return aa((()=>{return t=Rm(e),n=this.padding,s=this.dataFormat,aa((()=>{if(4!==t.rank)throw new Xd(`temporalPadding expects input tensor to be 4-D, but received a ${t.rank}-D tensor.`);if(null==n&&(n=[[1,1],[1,1]]),2!==n.length||2!==n[0].length||2!==n[1].length)throw new Xd("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");if(null==s&&(s="channelsLast"),"channelsLast"!==s&&"channelsFirst"!==s)throw new Xd(`Unknown data format: ${s}. Supported data formats are 'channelsLast' and 'channelsFirst.`);let e;return e="channelsFirst"===s?[[0,0],[0,0],n[0],n[1]]:[[0,0],n[0],n[1],[0,0]],Nl(t,e)}));var t,n,s}))}getConfig(){const e={padding:this.padding,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}function Zb(e,t,n,s,r,a){return aa((()=>{let i;Cf(r),Af(a),Rf(s),null==n&&(n=[1,1]),null==s&&(s="valid"),null==r&&(r="channelsLast"),null==a&&(a="max"),e=Yy(e,r);const o="same"===s?"same":"valid";return i="max"===a?pl(e,t,n,o):go(e,t,n,o),"channelsFirst"===r&&(i=tu(i,[0,3,1,2])),i}))}function Qb(e,t,n,s,r,a){return aa((()=>{let i;Cf(r),Af(a),Rf(s),null==n&&(n=[1,1,1]),null==s&&(s="valid"),null==r&&(r="channelsLast"),null==a&&(a="max"),e=Jy(e,r);const o="same"===s?"same":"valid";return i="max"===a?dl(e,t,n,o):yo(e,t,n,o),"channelsFirst"===r&&(i=tu(i,[0,4,1,2,3])),i}))}Jb.className="ZeroPadding2D",ai(Jb);class ex extends Vm{constructor(e){if(null==e.poolSize&&(e.poolSize=2),super(e),"number"==typeof e.poolSize)this.poolSize=[e.poolSize];else{if(!Array.isArray(e.poolSize)||1!==e.poolSize.length||"number"!=typeof e.poolSize[0])throw new Xd(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(e.poolSize)}`);this.poolSize=e.poolSize}if(gf(this.poolSize,"poolSize"),null==e.strides)this.strides=this.poolSize;else if("number"==typeof e.strides)this.strides=[e.strides];else{if(!Array.isArray(e.strides)||1!==e.strides.length||"number"!=typeof e.strides[0])throw new Xd(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(e.strides)}`);this.strides=e.strides}gf(this.strides,"strides"),this.padding=null==e.padding?"valid":e.padding,Rf(this.padding),this.inputSpec=[new Lm({ndim:3})]}computeOutputShape(e){const t=qy((e=Am(e))[1],this.poolSize[0],this.padding,this.strides[0]);return[e[0],t,e[2]]}call(e,t){return aa((()=>{this.invokeCallHook(e,t),e=Hf(Rm(e),2);const n=this.poolingFunction(Rm(e),[this.poolSize[0],1],[this.strides[0],1],this.padding,"channelsLast");return Hl(n,[2])}))}getConfig(){const e={poolSize:this.poolSize,padding:this.padding,strides:this.strides},t=super.getConfig();return Object.assign(e,t),e}}class tx extends ex{constructor(e){super(e)}poolingFunction(e,t,n,s,r){return Cf(r),Rf(s),Zb(e,t,n,s,r,"max")}}tx.className="MaxPooling1D",ai(tx);class nx extends ex{constructor(e){super(e)}poolingFunction(e,t,n,s,r){return Cf(r),Rf(s),Zb(e,t,n,s,r,"avg")}}nx.className="AveragePooling1D",ai(nx);class sx extends Vm{constructor(e){if(null==e.poolSize&&(e.poolSize=[2,2]),super(e),this.poolSize=Array.isArray(e.poolSize)?e.poolSize:[e.poolSize,e.poolSize],null==e.strides)this.strides=this.poolSize;else if(Array.isArray(e.strides)){if(2!==e.strides.length)throw new Xd(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${e.strides.length}.`);this.strides=e.strides}else this.strides=[e.strides,e.strides];gf(this.poolSize,"poolSize"),gf(this.strides,"strides"),this.padding=null==e.padding?"valid":e.padding,this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,Cf(this.dataFormat),Rf(this.padding),this.inputSpec=[new Lm({ndim:4})]}computeOutputShape(e){e=Am(e);let t="channelsFirst"===this.dataFormat?e[2]:e[1],n="channelsFirst"===this.dataFormat?e[3]:e[2];return t=qy(t,this.poolSize[0],this.padding,this.strides[0]),n=qy(n,this.poolSize[1],this.padding,this.strides[1]),"channelsFirst"===this.dataFormat?[e[0],e[1],t,n]:[e[0],t,n,e[3]]}call(e,t){return aa((()=>(this.invokeCallHook(e,t),this.poolingFunction(Rm(e),this.poolSize,this.strides,this.padding,this.dataFormat))))}getConfig(){const e={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}class rx extends sx{constructor(e){super(e)}poolingFunction(e,t,n,s,r){return Cf(r),Rf(s),Zb(e,t,n,s,r,"max")}}rx.className="MaxPooling2D",ai(rx);class ax extends sx{constructor(e){super(e)}poolingFunction(e,t,n,s,r){return Cf(r),Rf(s),Zb(e,t,n,s,r,"avg")}}ax.className="AveragePooling2D",ai(ax);class ix extends Vm{constructor(e){if(null==e.poolSize&&(e.poolSize=[2,2,2]),super(e),this.poolSize=Array.isArray(e.poolSize)?e.poolSize:[e.poolSize,e.poolSize,e.poolSize],null==e.strides)this.strides=this.poolSize;else if(Array.isArray(e.strides)){if(3!==e.strides.length)throw new Xd(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${e.strides.length}.`);this.strides=e.strides}else this.strides=[e.strides,e.strides,e.strides];gf(this.poolSize,"poolSize"),gf(this.strides,"strides"),this.padding=null==e.padding?"valid":e.padding,this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,Cf(this.dataFormat),Rf(this.padding),this.inputSpec=[new Lm({ndim:5})]}computeOutputShape(e){e=Am(e);let t="channelsFirst"===this.dataFormat?e[2]:e[1],n="channelsFirst"===this.dataFormat?e[3]:e[2],s="channelsFirst"===this.dataFormat?e[4]:e[3];return t=qy(t,this.poolSize[0],this.padding,this.strides[0]),n=qy(n,this.poolSize[1],this.padding,this.strides[1]),s=qy(s,this.poolSize[2],this.padding,this.strides[2]),"channelsFirst"===this.dataFormat?[e[0],e[1],t,n,s]:[e[0],t,n,s,e[4]]}call(e,t){return aa((()=>(this.invokeCallHook(e,t),this.poolingFunction(Rm(e),this.poolSize,this.strides,this.padding,this.dataFormat))))}getConfig(){const e={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}class ox extends ix{constructor(e){super(e)}poolingFunction(e,t,n,s,r){return Cf(r),Rf(s),Qb(e,t,n,s,r,"max")}}ox.className="MaxPooling3D",ai(ox);class lx extends ix{constructor(e){super(e)}poolingFunction(e,t,n,s,r){return Cf(r),Rf(s),Qb(e,t,n,s,r,"avg")}}lx.className="AveragePooling3D",ai(lx);class ux extends Vm{constructor(e){super(e),this.inputSpec=[new Lm({ndim:3})]}computeOutputShape(e){return[e[0],e[2]]}call(e,t){throw new Yd}}class cx extends ux{constructor(e){super(e||{})}call(e,t){return aa((()=>{const t=Rm(e);return fl(t,1)}))}}cx.className="GlobalAveragePooling1D",ai(cx);class hx extends ux{constructor(e){super(e||{})}call(e,t){return aa((()=>{const t=Rm(e);return Zo(t,1)}))}}hx.className="GlobalMaxPooling1D",ai(hx);class px extends Vm{constructor(e){super(e),this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,Cf(this.dataFormat),this.inputSpec=[new Lm({ndim:4})]}computeOutputShape(e){return"channelsLast"===this.dataFormat?[e[0],e[3]]:[e[0],e[1]]}call(e,t){throw new Yd}getConfig(){const e={dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}class dx extends px{call(e,t){return aa((()=>{const t=Rm(e);return"channelsLast"===this.dataFormat?fl(t,[1,2]):fl(t,[2,3])}))}}dx.className="GlobalAveragePooling2D",ai(dx);class fx extends px{call(e,t){return aa((()=>{const t=Rm(e);return"channelsLast"===this.dataFormat?Zo(t,[1,2]):Zo(t,[2,3])}))}}fx.className="GlobalMaxPooling2D",ai(fx);class mx extends Vm{constructor(e){super(e),this.layer=e.layer}build(e){this.built=!0}get trainable(){return null!=this.layer&&this.layer.trainable}set trainable(e){null!=this.layer&&(this.layer.trainable=e)}get trainableWeights(){return this.layer.trainableWeights}get nonTrainableWeights(){return this.layer.nonTrainableWeights}get updates(){return this.layer._updates}get losses(){return this.layer.losses}getWeights(){return this.layer.getWeights()}setWeights(e){this.layer.setWeights(e)}getConfig(){const e={layer:{className:this.layer.getClassName(),config:this.layer.getConfig()}},t=super.getConfig();return Object.assign(e,t),e}setFastWeightInitDuringBuild(e){super.setFastWeightInitDuringBuild(e),null!=this.layer&&this.layer.setFastWeightInitDuringBuild(e)}static fromConfig(e,t,n={}){const s=xg(t.layer,n);delete t.layer;const r={layer:s};return Object.assign(r,t),new e(r)}}class gx extends mx{constructor(e){super(e),this.supportsMasking=!0}build(e){if((e=Am(e)).length<3)throw new Xd(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(e)}`);this.inputSpec=[{shape:e}];const t=[e[0]].concat(e.slice(2));this.layer.built||(this.layer.build(t),this.layer.built=!0),super.build(e)}computeOutputShape(e){const t=[(e=Am(e))[0]].concat(e.slice(2)),n=this.layer.computeOutputShape(t),s=e[1];return[n[0],s].concat(n.slice(1))}call(e,t){return aa((()=>pb(((e,n)=>[Rm(this.layer.call(e,t)),[]]),e=Rm(e),[],!1,null,null,!1,!0)[1]))}}gx.className="TimeDistributed",ai(gx);class yx extends mx{constructor(e){super(e);const t=e.layer.getConfig(),n={};n.className=e.layer.getClassName(),n.config=t,this.forwardLayer=xg(n),t.goBackwards=!0!==t.goBackwards;const s={};var r;if(s.className=e.layer.getClassName(),s.config=t,this.backwardLayer=xg(s),this.forwardLayer.name="forward_"+this.forwardLayer.name,this.backwardLayer.name="backward_"+this.backwardLayer.name,this.mergeMode=void 0===e.mergeMode?"concat":e.mergeMode,r=this.mergeMode,ff($f,"BidirectionalMergeMode",r),e.weights)throw new Yd("weights support is not implemented for Bidirectional layer yet.");this._stateful=e.layer.stateful,this.returnSequences=e.layer.returnSequences,this.returnState=e.layer.returnState,this.supportsMasking=!0,this._trainable=!0,this.inputSpec=e.layer.inputSpec,this.numConstants=null}get trainable(){return this._trainable}set trainable(e){this._trainable=e,null!=this.forwardLayer&&(this.forwardLayer.trainable=e),null!=this.backwardLayer&&(this.backwardLayer.trainable=e)}getWeights(){return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights())}setWeights(e){const t=e.length,n=Math.floor(t/2);this.forwardLayer.setWeights(e.slice(0,n)),this.backwardLayer.setWeights(e.slice(n))}computeOutputShape(e){let t,n,s,r=this.forwardLayer.computeOutputShape(e);return Array.isArray(r)&&Array.isArray(r[0])||(r=[r]),this.returnState?(s=r.slice(1),t=r[0]):t=r[0],"concat"===this.mergeMode?(t[t.length-1]*=2,n=[t]):n=null==this.mergeMode?[t,t.slice()]:[t],this.returnState?null==this.mergeMode?n.concat(s).concat(s.slice()):[t].concat(s).concat(s.slice()):nf(n)}apply(e,t){let n=null==t?null:t.initialState,s=null==t?null:t.constants;null==t&&(t={});const r=hb(e,n,s,this.numConstants);if(e=r.inputs,n=r.initialState,s=r.constants,Array.isArray(e)&&(n=e.slice(1),e=e[0]),(null==n||0===n.length)&&null==s)return super.apply(e,t);const a=[],i=[];if(null!=n){const e=n.length;if(e%2>0)throw new Xd("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");t.initialState=n,a.push(...n);const s=n.map((e=>new Lm({shape:e.shape})));this.forwardLayer.stateSpec=s.slice(0,e/2),this.backwardLayer.stateSpec=s.slice(e/2),i.push(...s)}if(null!=s)throw new Yd("Support for constants in Bidirectional layers is not implemented yet.");const o=a[0]instanceof zm;for(const e of a)if(e instanceof zm!==o)throw new Xd("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");if(o){const n=[e].concat(a),s=this.inputSpec.concat(i),r=this.inputSpec;this.inputSpec=s;const o=super.apply(n,t);return this.inputSpec=r,o}return super.apply(e,t)}call(e,t){return aa((()=>{const n=t.initialState;let s,r,a,i;if(null==n)s=this.forwardLayer.call(e,t),r=this.backwardLayer.call(e,t);else{const a=n.slice(0,n.length/2),i=n.slice(n.length/2);s=this.forwardLayer.call(e,Object.assign(t,{initialState:a})),r=this.backwardLayer.call(e,Object.assign(t,{initialState:i}))}return this.returnState&&(Array.isArray(s)&&(a=s.slice(1).concat(r.slice(1))),s=s[0],r=r[0]),this.returnSequences&&(r=Dl(r,1)),"concat"===this.mergeMode?i=Xf([s,r]):"sum"===this.mergeMode?i=ja(s,r):"ave"===this.mergeMode?i=Xa(.5,ja(s,r)):"mul"===this.mergeMode?i=Xa(s,r):null==this.mergeMode&&(i=[s,r]),this.returnState?null==this.mergeMode?i.concat(a):[i].concat(a):i}))}resetStates(e){this.forwardLayer.resetStates(),this.backwardLayer.resetStates()}build(e){Df(this.forwardLayer.name,(()=>{this.forwardLayer.build(e)})),Df(this.backwardLayer.name,(()=>{this.backwardLayer.build(e)})),this.built=!0}computeMask(e,t){let n;if(Array.isArray(t)&&(t=t[0]),n=this.returnSequences?null==this.mergeMode?[t,t]:t:null==this.mergeMode?[null,null]:null,this.returnState){const e=this.forwardLayer.states.map((e=>null));return Array.isArray(n)?n.concat(e).concat(e):[n].concat(e).concat(e)}return n}get trainableWeights(){return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights)}get nonTrainableWeights(){return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights)}setFastWeightInitDuringBuild(e){super.setFastWeightInitDuringBuild(e),null!=this.forwardLayer&&this.forwardLayer.setFastWeightInitDuringBuild(e),null!=this.backwardLayer&&this.backwardLayer.setFastWeightInitDuringBuild(e)}getConfig(){const e={mergeMode:this.mergeMode},t=super.getConfig();return Object.assign(e,t),e}static fromConfig(e,t){const n=xg(t.layer);if(delete t.layer,null!=t.numConstants)throw new Yd("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");const s=t;return s.layer=n,new e(s)}}yx.className="Bidirectional",ai(yx);class bx extends Vm{constructor(e){super(e),this.scale=e.scale,e.offset?this.offset=e.offset:this.offset=0}getConfig(){const e={scale:this.scale,offset:this.offset},t=super.getConfig();return Object.assign(e,t),e}call(e,t){return aa((()=>("float32"!==(e=Rm(e)).dtype&&(e=Gf(e,"float32")),ja(Xa(e,this.scale),this.offset))))}}bx.className="Rescaling",ai(bx);const{resizeBilinear:xx,cropAndResize:wx}=Qu;class kx extends Vm{constructor(e){super(e),this.height=e.height,this.width=e.width}centerCrop(e,t,n,s,r,a,i,o){return aa((()=>{let l,u=!1;const c=[t/a,n/i,(s+t)/a,(r+n)/i],h=[];3===e.rank?(u=!0,l=jl([e])):l=e;for(let e=0;e<l.shape[0];e++)h.push(c);const p=ea(h,[h.length,4]),d=Al(0,h.length,1,"int32"),f=wx(l,p,d,[s,r],"nearest");return Gf(u?Rm(Jl(f)):f,o)}))}upsize(e,t,n,s){return aa((()=>Gf(xx(e,[t,n]),s)))}call(e,t){return aa((()=>{const t=Rm(e),n=t.dtype,s=t.shape,r=s[s.length-3],a=s[s.length-2];let i=0;r!==this.height&&(i=Math.floor((r-this.height)/2));let o=0;return a!==this.width&&(o=Math.floor((a-this.width)/2),0===o&&(o=1)),i>=0&&o>=0?this.centerCrop(t,i,o,this.height,this.width,r,a,n):this.upsize(e,this.height,this.width,n)}))}getConfig(){const e={height:this.height,width:this.width},t=super.getConfig();return Object.assign(e,t),e}computeOutputShape(e){const t=(e=Am(e)).length-3,n=e.length-2;return e[t]=this.height,e[n]=this.width,e}}kx.className="CenterCrop",ai(kx);class vx extends Vm{constructor(e){super(e),this.numTokens=e.numTokens,e.outputMode?this.outputMode=e.outputMode:this.outputMode="multiHot"}getConfig(){const e={numTokens:this.numTokens,outputMode:this.outputMode},t=super.getConfig();return Object.assign(e,t),e}computeOutputShape(e){return null==(e=Am(e))?[this.numTokens]:"oneHot"===this.outputMode&&1!==e[e.length-1]?(e.push(this.numTokens),e):(e[e.length-1]=this.numTokens,e)}call(e,t){return aa((()=>{let n;if("int32"!==(e=Rm(e)).dtype&&(e=Gf(e,"int32")),void 0!==t.countWeights){if("count"!==this.outputMode)throw new Xd(`countWeights is not used when outputMode !== count.\n              Received countWeights=${t.countWeights}`);n=Rm(t.countWeights)}const s=Zo(e),r=ml(e),a=Ko(this.numTokens,s).bufferSync().get(0),i=qo(r,0).bufferSync().get(0);if(!a||!i)throw new Xd(`Input values must be between 0 < values <= numTokens with numTokens=${this.numTokens}`);return function(e,t,n,s){let r=Rm(e);if("int32"!==r.dtype&&(r=Gf(r,"int32")),"int"===t)return r;const a=r.shape;if(0===r.rank&&(r=Vo(r,-1)),"oneHot"===t&&1!==r.shape[r.shape.length-1]&&(r=Vo(r,-1)),r.rank>2)throw new Xd(`When outputMode is not int, maximum output rank is 2 Received outputMode ${t} and input shape ${a} which would result in output rank ${r.rank}.`);const i=["multiHot","oneHot"].includes(t);let o;if(o=Mo(r,void 0!==s&&"count"===t?s:[],n,i),"tfIdf"!==t)return o;if(s)return Xa(o,s);throw new Xd("When outputMode is 'tfIdf', weights must be provided.")}(e,this.outputMode,this.numTokens,n)}))}}vx.className="CategoryEncoding",ai(vx);const Ix=new Set(["bilinear","nearest"]);class Nx extends Vm{constructor(e){if(super(e),this.height=e.height,this.width=e.width,e.interpolation){if(!Ix.has(e.interpolation))throw new Xd(`Invalid interpolation parameter: ${e.interpolation} is not implemented`);this.interpolation=e.interpolation}else this.interpolation="bilinear";this.cropToAspectRatio=Boolean(e.cropToAspectRatio)}computeOutputShape(e){const t=(e=Am(e))[2];return[this.height,this.width,t]}getConfig(){const e={height:this.height,width:this.width,interpolation:this.interpolation,cropToAspectRatio:this.cropToAspectRatio},t=super.getConfig();return Object.assign(e,t),e}call(e,t){return aa((()=>{const t=[this.height,this.width];if("bilinear"===this.interpolation)return Qu.resizeBilinear(e,t,!this.cropToAspectRatio);if("nearest"===this.interpolation)return Qu.resizeNearestNeighbor(e,t,!this.cropToAspectRatio);throw new Error(`Interpolation is ${this.interpolation} but only ${[...Ix]} are supported`)}))}}Nx.className="Resizing",ai(Nx);class Sx{constructor(e){this.seed=e}next(){if(void 0!==this.seed)return this.seed++}}Sx.className="RandomSeed";class Tx extends Vm{constructor(e){super(e),this.randomGenerator=new Sx(e.seed)}getConfig(){const e={seed:this.randomGenerator.seed},t=super.getConfig();return Object.assign(e,t),e}}Tx.className="BaseRandomLayer";const $x=new Set(["bilinear","nearest"]);class Ex extends Tx{constructor(e){super(e);const{factor:t,interpolation:n="bilinear"}=e;if(this.factor=t,Array.isArray(this.factor)&&2===this.factor.length)this.widthLower=this.factor[0],this.widthUpper=this.factor[1];else{if(Array.isArray(this.factor)||!(this.factor>0))throw new Xd(`Invalid factor: ${this.factor}. Must be positive number or tuple of 2 numbers`);this.widthLower=-this.factor,this.widthUpper=this.factor}if(this.widthLower<-1||this.widthUpper<-1)throw new Xd(`factor must have values larger than -1. Got: ${this.factor}`);if(this.widthUpper<this.widthLower)throw new Xd(`factor cannot have upper bound less than lower bound.\n        Got upper bound: ${this.widthUpper}.\n        Got lower bound: ${this.widthLower}\n      `);if(n){if(!$x.has(n))throw new Xd(`Invalid interpolation parameter: ${n} is not implemented`);this.interpolation=n}}getConfig(){const e={factor:this.factor,interpolation:this.interpolation},t=super.getConfig();return Object.assign(e,t),e}computeOutputShape(e){const t=(e=Am(e))[2];return[this.imgHeight,-1,t]}call(e,t){return aa((()=>{const t=Rm(e);this.imgHeight=t.shape[t.shape.length-3];const n=t.shape[t.shape.length-2];this.widthFactor=Rl([1],1+this.widthLower,1+this.widthUpper,"float32",this.randomGenerator.next());let s=this.widthFactor.dataSync()[0]*n;s=Math.round(s);const r=[this.imgHeight,s];switch(this.interpolation){case"bilinear":return Qu.resizeBilinear(e,r);case"nearest":return Qu.resizeNearestNeighbor(e,r);default:throw new Error(`Interpolation is ${this.interpolation}\n          but only ${[...$x]} are supported`)}}))}}var Cx,Rx,Ax,_x;function Dx(e,t,n=new Map,s=new Set){if(null==e)return null;if("function"==typeof Blob&&e instanceof Blob)return e.slice();if(s.has(e))throw new Error("Circular references are not supported.");if(n.has(e))return n.get(e);const r=t(e);if(r.recurse&&null!==r.value)throw new Error("A deep map function may not return both a value and recurse=true.");if(r.recurse){if(Lx(e)){const r=Array.isArray(e)?[]:{};s.add(e);for(const a in e){const i=Dx(e[a],t,n,s);r[a]=i}return s.delete(e),e.__proto__&&(r.__proto__=e.__proto__),r}throw new Error(`Can't recurse into non-iterable type: ${e}`)}return n.set(e,r.value),r.value}function Fx(e,t=Mx){return Ox(e,t)}function Ox(e,t,n=new Set){const s=e[0];if(n.has(s))throw new Error("Circular references are not supported.");const r=t(e);if(r.recurse&&null!==r.value)throw new Error("A deep zip function may not return both a value and recurse=true.");if(r.recurse){if(Lx(s)){const r=Array.isArray(s)?[]:{};n.add(s);for(const a in s){const s=Ox(e.map((e=>e[a])),t,n);r[a]=s}return n.delete(s),r}throw new Error(`Can't recurse into non-iterable type: ${s}`)}return r.value}function Mx(e){return null===e?null:Lx(e[0])?{value:null,recurse:!0}:{value:e,recurse:!1}}function Lx(e){let t=!1;if(fe().get("IS_BROWSER"))t=e instanceof TextDecoder;else{const{StringDecoder:s}=n(222);t=e instanceof s}return null!=e&&!ArrayBuffer.isView(e)&&(Array.isArray(e)||"object"==typeof e&&!(e instanceof wr)&&!(e instanceof Promise)&&!t)}function zx(e){return Dx(e,Bx)}function Bx(e){return e instanceof wr?{value:e.clone(),recurse:!1}:Lx(e)?{value:null,recurse:!0}:{value:e,recurse:!1}}Ex.className="RandomWidth",ai(Ex),fe().registerFlag("KEEP_INTERMEDIATE_TENSORS",(()=>!1),(e=>{e&&console.warn("Keep intermediate tensors is ON. This will print the values of all intermediate tensors during model inference. Not all models support this mode. For details, check e2e/benchmarks/ model_config.js. This significantly impacts performance.")})),function(e){e[e.DT_INVALID=0]="DT_INVALID",e[e.DT_FLOAT=1]="DT_FLOAT",e[e.DT_DOUBLE=2]="DT_DOUBLE",e[e.DT_INT32=3]="DT_INT32",e[e.DT_UINT8=4]="DT_UINT8",e[e.DT_INT16=5]="DT_INT16",e[e.DT_INT8=6]="DT_INT8",e[e.DT_STRING=7]="DT_STRING",e[e.DT_COMPLEX64=8]="DT_COMPLEX64",e[e.DT_INT64=9]="DT_INT64",e[e.DT_BOOL=10]="DT_BOOL",e[e.DT_QINT8=11]="DT_QINT8",e[e.DT_QUINT8=12]="DT_QUINT8",e[e.DT_QINT32=13]="DT_QINT32",e[e.DT_BFLOAT16=14]="DT_BFLOAT16",e[e.DT_QINT16=15]="DT_QINT16",e[e.DT_QUINT16=16]="DT_QUINT16",e[e.DT_UINT16=17]="DT_UINT16",e[e.DT_COMPLEX128=18]="DT_COMPLEX128",e[e.DT_HALF=19]="DT_HALF",e[e.DT_RESOURCE=20]="DT_RESOURCE",e[e.DT_VARIANT=21]="DT_VARIANT",e[e.DT_UINT32=22]="DT_UINT32",e[e.DT_UINT64=23]="DT_UINT64",e[e.DT_FLOAT_REF=101]="DT_FLOAT_REF",e[e.DT_DOUBLE_REF=102]="DT_DOUBLE_REF",e[e.DT_INT32_REF=103]="DT_INT32_REF",e[e.DT_UINT8_REF=104]="DT_UINT8_REF",e[e.DT_INT16_REF=105]="DT_INT16_REF",e[e.DT_INT8_REF=106]="DT_INT8_REF",e[e.DT_STRING_REF=107]="DT_STRING_REF",e[e.DT_COMPLEX64_REF=108]="DT_COMPLEX64_REF",e[e.DT_INT64_REF=109]="DT_INT64_REF",e[e.DT_BOOL_REF=110]="DT_BOOL_REF",e[e.DT_QINT8_REF=111]="DT_QINT8_REF",e[e.DT_QUINT8_REF=112]="DT_QUINT8_REF",e[e.DT_QINT32_REF=113]="DT_QINT32_REF",e[e.DT_BFLOAT16_REF=114]="DT_BFLOAT16_REF",e[e.DT_QINT16_REF=115]="DT_QINT16_REF",e[e.DT_QUINT16_REF=116]="DT_QUINT16_REF",e[e.DT_UINT16_REF=117]="DT_UINT16_REF",e[e.DT_COMPLEX128_REF=118]="DT_COMPLEX128_REF",e[e.DT_HALF_REF=119]="DT_HALF_REF",e[e.DT_RESOURCE_REF=120]="DT_RESOURCE_REF",e[e.DT_VARIANT_REF=121]="DT_VARIANT_REF",e[e.DT_UINT32_REF=122]="DT_UINT32_REF",e[e.DT_UINT64_REF=123]="DT_UINT64_REF"}(Cx||(Cx={})),function(e){let t;!function(e){e[e.LEGACY=0]="LEGACY",e[e.V1=1]="V1",e[e.V2=2]="V2"}(t=e.CheckpointFormatVersion||(e.CheckpointFormatVersion={}))}(Rx||(Rx={})),Error,new Set(["Switch","Merge","Enter","Exit","NextIteration","StatelessIf","StatelessWhile","if","While"]),new Set(["NonMaxSuppressionV2","NonMaxSuppressionV3","NonMaxSuppressionV5","Where"]),new Set(["HashTable","HashTableV2","LookupTableImport","LookupTableImportV2","LookupTableFind","LookupTableFindV2","LookupTableSize","LookupTableSizeV2"]);class Px{constructor(e){if(this.capacity=e,this.begin=0,this.end=0,null==e)throw new RangeError("Can't create a ring buffer of unknown capacity.");if(e<1)throw new RangeError("Can't create ring buffer of capacity < 1.");this.data=new Array(e),this.doubledCapacity=2*e}wrap(e){for(;e<0;)e+=this.doubledCapacity;return e%this.doubledCapacity}get(e){if(e<0)throw new RangeError("Can't get item at a negative index.");return this.data[e%this.capacity]}set(e,t){if(e<0)throw new RangeError("Can't set item at a negative index.");this.data[e%this.capacity]=t}length(){let e=this.end-this.begin;return e<0&&(e=this.doubledCapacity+e),e}isFull(){return this.length()===this.capacity}isEmpty(){return 0===this.length()}push(e){if(this.isFull())throw new RangeError("Ring buffer is full.");this.set(this.end,e),this.end=this.wrap(this.end+1)}pushAll(e){for(const t of e)this.push(t)}pop(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");this.end=this.wrap(this.end-1);const e=this.get(this.end);return this.set(this.end,void 0),e}unshift(e){if(this.isFull())throw new RangeError("Ring buffer is full.");this.begin=this.wrap(this.begin-1),this.set(this.begin,e)}shift(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const e=this.get(this.begin);return this.set(this.begin,void 0),this.begin=this.wrap(this.begin+1),e}shuffleExcise(e){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const t=this.wrap(this.begin+e),n=this.get(t);return this.set(t,this.pop()),n}}class Wx extends Px{constructor(){super(Wx.INITIAL_CAPACITY)}isFull(){return!1}push(e){super.isFull()&&this.expand(),super.push(e)}unshift(e){super.isFull()&&this.expand(),super.unshift(e)}expand(){const e=2*this.capacity,t=new Array(e),n=this.length();for(let e=0;e<n;e++)t[e]=this.get(this.wrap(this.begin+e));this.data=t,this.capacity=e,this.doubledCapacity=2*this.capacity,this.begin=0,this.end=n}}Wx.INITIAL_CAPACITY=32;class Vx{async toArray(){const e=[];let t=await this.next();for(;!t.done;)e.push(t.value),t=await this.next();return e}async toArrayForTest(){const e=this.prefetch(100),t=[];let n=await e.next();for(;!n.done;)t.push(n.value),n=await e.next();return t}async resolveFully(){let e=await this.next();for(;!e.done;)e=await this.next()}async resolveWhile(e){let t=await this.next(),n=e(t.value);for(;!t.done&&n;)t=await this.next(),n=e(t.value)}handleErrors(e){return new Jx(this,e)}filter(e){return new Xx(this,e)}map(e){return new Yx(this,e)}mapAsync(e){return new Zx(this,e)}serialMapAsync(e){return new Zx(this,e).serial()}flatmap(e){return new ew(this,e)}async forEachAsync(e){return this.map(e).resolveFully()}async serialForEach(e){return this.serialMapAsync(e).resolveWhile((e=>!0===e))}rowMajorBatch(e,t=!0){return new qx(this,e,t)}columnMajorBatch(e,t=!0,n=Mx){return this.rowMajorBatch(e,t).map((e=>Fx(e,n)))}concatenate(e,t){return new tw(new Ux([this,e]),t)}take(e){return e<0||null==e?this:new Kx(this,e)}skip(e){return e<0||null==e?this:new jx(this,e)}prefetch(e){return new nw(this,e)}shuffle(e,t){return new sw(this,e,t)}serial(){return new Hx(this)}}class Ux extends Vx{constructor(e){super(),this.items=e,this.trav=0}summary(){return`Array of ${this.items.length} items`}async next(){if(this.trav>=this.items.length)return{value:null,done:!0};const e=this.items[this.trav];return this.trav++,{value:zx(e),done:!1}}}class Gx extends Vx{constructor(e){super(),this.nextFn=e}summary(){return"Function call"}async next(){try{return this.nextFn()}catch(e){throw e.message=`Error thrown while iterating through a dataset: ${e.message}`,e}}}class Hx extends Vx{constructor(e){super(),this.upstream=e,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Serial`}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){return this.upstream.next()}}class jx extends Vx{constructor(e,t){super(),this.upstream=e,this.maxCount=t,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Skip`}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){for(;this.count++<this.maxCount;){const e=await this.upstream.next();if(e.done)return e;ia(e.value)}return this.upstream.next()}}class Kx extends Vx{constructor(e,t){super(),this.upstream=e,this.maxCount=t,this.count=0}summary(){return`${this.upstream.summary()} -> Take`}async next(){return this.count++>=this.maxCount?{value:null,done:!0}:this.upstream.next()}}class qx extends Vx{constructor(e,t,n=!0){super(),this.upstream=e,this.batchSize=t,this.enableSmallLastBatch=n,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> RowMajorBatch`}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){const e=[];for(;e.length<this.batchSize;){const t=await this.upstream.next();if(t.done)return this.enableSmallLastBatch&&e.length>0?{value:e,done:!1}:{value:null,done:!0};e.push(t.value)}return{value:e,done:!1}}}class Xx extends Vx{constructor(e,t){super(),this.upstream=e,this.predicate=t,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Filter`}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){for(;;){const e=await this.upstream.next();if(e.done||this.predicate(e.value))return e;ia(e.value)}}}class Yx extends Vx{constructor(e,t){super(),this.upstream=e,this.transform=t}summary(){return`${this.upstream.summary()} -> Map`}async next(){const e=await this.upstream.next();if(e.done)return{value:null,done:!0};const t=Or(e.value),n=this.transform(e.value),s=Or(n);for(const e of t)Fr(e,s)||e.dispose();return{value:n,done:!1}}}class Jx extends Vx{constructor(e,t){super(),this.upstream=e,this.handler=t,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> handleErrors`}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){for(;;)try{return await this.upstream.next()}catch(e){if(!this.handler(e))return{value:null,done:!0}}}}class Zx extends Vx{constructor(e,t){super(),this.upstream=e,this.transform=t}summary(){return`${this.upstream.summary()} -> AsyncMap`}async next(){const e=await this.upstream.next();if(e.done)return{value:null,done:!0};const t=Or(e.value),n=await this.transform(e.value),s=Or(n);for(const e of t)Fr(e,s)||e.dispose();return{value:n,done:!1}}}class Qx extends Vx{constructor(){super(),this.outputQueue=new Wx,this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}async serialNext(){for(;0===this.outputQueue.length();)if(!await this.pump())return{value:null,done:!0};return{value:this.outputQueue.shift(),done:!1}}}class ew extends Qx{constructor(e,t){super(),this.upstream=e,this.transform=t}summary(){return`${this.upstream.summary()} -> Flatmap`}async pump(){const e=await this.upstream.next();if(e.done)return!1;const t=Or(e.value),n=this.transform(e.value),s=Or(n);this.outputQueue.pushAll(n);for(const e of t)Fr(e,s)||e.dispose();return!0}}class tw extends Vx{constructor(e,t){super(),this.baseErrorHandler=t,this.lastRead=null,this.iterator=null,this.moreIterators=e}summary(){return"TODO: fill in upstream of chained summaries -> Chained"}async next(){return this.lastRead=this.readFromChain(this.lastRead),this.lastRead}async readFromChain(e){if(await e,null==this.iterator){const e=await this.moreIterators.next();if(e.done)return{value:null,done:!0};this.iterator=e.value,null!=this.baseErrorHandler&&(this.iterator=this.iterator.handleErrors(this.baseErrorHandler))}const t=await this.iterator.next();return t.done?(this.iterator=null,this.readFromChain(e)):t}}(_x=Ax||(Ax={}))[_x.FAIL=0]="FAIL",_x[_x.SHORTEST=1]="SHORTEST",_x[_x.LONGEST=2]="LONGEST";class nw extends Vx{constructor(e,t){super(),this.upstream=e,this.bufferSize=t,this.buffer=new Px(t)}summary(){return`${this.upstream.summary()} -> Prefetch`}refill(){for(;!this.buffer.isFull();){const e=this.upstream.next();this.buffer.push(e)}}next(){return this.refill(),this.buffer.shift()}}class sw extends nw{constructor(e,t,n){super(e,t),this.upstream=e,this.windowSize=t,this.upstreamExhausted=!1,this.random=Tl.alea(n||sr().toString()),this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then((()=>this.serialNext())),this.lastRead}randomInt(e){return Math.floor(this.random()*e)}chooseIndex(){return this.randomInt(this.buffer.length())}async serialNext(){for(this.upstreamExhausted||this.refill();!this.buffer.isEmpty();){const e=this.chooseIndex(),t=await this.buffer.shuffleExcise(e);if(!t.done)return this.refill(),t;this.upstreamExhausted=!0}return{value:null,done:!0}}}class rw{constructor(){this.size=null}batch(e,t=!0){const n=this;let s;return F(e>0,(()=>`batchSize needs to be positive, but it is\n      ${e}`)),s=this.size===1/0||null==this.size?this.size:t?Math.ceil(this.size/e):Math.floor(this.size/e),aw((async()=>(await n.iterator()).columnMajorBatch(e,t,iw)),s)}concatenate(e){const t=this;let n;return n=this.size===1/0||e.size===1/0?1/0:null!=this.size&&null!=e.size?this.size+e.size:null,aw((async()=>(await t.iterator()).concatenate(await e.iterator())),n)}filter(e){const t=this;let n;return n=this.size===1/0?1/0:null,aw((async()=>(await t.iterator()).filter((t=>aa((()=>e(t)))))),n)}async forEachAsync(e){return(await this.iterator()).forEachAsync(e)}map(e){const t=this;return aw((async()=>(await t.iterator()).map((t=>aa((()=>e(t)))))),this.size)}mapAsync(e){const t=this;return aw((async()=>(await t.iterator()).mapAsync(e)),this.size)}prefetch(e){if(null==e)throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");const t=this;return aw((async()=>(await t.iterator()).prefetch(e)),this.size)}repeat(e){const t=this;let n;return n=null!=this.size&&e>0?this.size*e:0===e?0:null!=this.size&&(void 0===e||e<0)?1/0:null,aw((async()=>{return n=(r=async()=>({value:await t.iterator(),done:!1}),new Gx(r)).take(e),new tw(n,s);var n,s,r}),n)}skip(e){const t=this;let n;return n=null!=this.size&&e>=0&&this.size>=e?this.size-e:null!=this.size&&(this.size<e||void 0===e||e<0)?0:null,aw((async()=>(await t.iterator()).skip(e)),n)}shuffle(e,t,n=!0){if(null==e||e<0)throw null==this.size?new RangeError("`Dataset.shuffle()` requires bufferSize to be specified."):new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);const s=this,r=Tl.alea(t||sr().toString());return aw((async()=>{let t=r.int32();return n&&(t+=r.int32()),(await s.iterator()).shuffle(e,t.toString())}),this.size)}take(e){const t=this;let n;return n=null!=this.size&&this.size>e?e:null!=this.size&&this.size<=e?this.size:null,aw((async()=>(await t.iterator()).take(e)),n)}async toArray(){if(this.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArray()}async toArrayForTest(){if(this.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArrayForTest()}}function aw(e,t=null){return new class extends rw{constructor(){super(...arguments),this.size=t}async iterator(){return e()}}}function iw(e){if(null===e)return null;return null==(t=e[0])||null===(n=t)||"object"!=typeof n&&"function"!=typeof n||Array.isArray(t)||"object"==typeof t&&t instanceof wr||ir(t)?{value:function(e){if(0===e.length)throw new Error("Can't make a batch of zero elements.");return e[0]instanceof wr?jl(e):ea(e)}(e),recurse:!1}:{value:null,recurse:!0};var t,n}function ow(e,t){Array.isArray(e)||(e=[e]),e.forEach((e=>{null!=e&&F("complex64"!==e.dtype,(()=>`${t} does not support complex64 tensors in the CPU backend.`))}))}rw.MAX_BUFFER_SIZE=1e4,Symbol("out"),Symbol("field"),Symbol("quote"),Symbol("quoteafterquote"),Symbol("quoteinquote");const lw=dh;class uw extends E{nextDataId(){return uw.nextDataId++}constructor(){super(),this.blockSize=48,this.firstUse=!0,this.data=new $(this,sa())}write(e,t,n){this.firstUse&&(this.firstUse=!1,fe().get("IS_NODE")&&Cs("\n============================\nHi, looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, visit https://github.com/tensorflow/tfjs-node for more details. \n============================"));const s={id:this.nextDataId()};return this.data.set(s,{values:e,dtype:n,refCount:1}),s}makeTensorInfo(e,t,n){let s;if("string"===t&&null!=n&&n.length>0&&Y(n[0])){const r=n.map((e=>rr(e)));s=this.write(r,e,t)}else s=this.write(n,e,t);return{dataId:s,shape:e,dtype:t}}refCount(e){return this.data.has(e)?this.data.get(e).refCount:0}incRef(e){this.data.get(e).refCount++}decRef(e){this.data.has(e)&&this.data.get(e).refCount--}move(e,t,n,s,r){this.data.set(e,{values:t,dtype:s,refCount:r})}numDataIds(){return this.data.numDataIds()}async read(e){return this.readSync(e)}readSync(e){const{dtype:t,complexTensorInfos:n}=this.data.get(e);return"complex64"===t?Ac(this.readSync(n.real.dataId),this.readSync(n.imag.dataId)):function(e,t){if(Array.isArray(e))return e;if("float32"===t)return e instanceof Float32Array?e:new Float32Array(e);if("int32"===t)return e instanceof Int32Array?e:new Int32Array(e);if("bool"===t||"string"===t)return Uint8Array.from(new Int32Array(e));throw new Error(`Unknown dtype ${t}`)}(this.data.get(e).values,t)}bufferSync(e){const t=this.readSync(e.dataId);if("string"===e.dtype)try{const n=t.map((e=>ar(e)));return Ua(e.shape,e.dtype,n)}catch(e){throw new Error("Failed to decode encoded string bytes into utf-8")}return Ua(e.shape,e.dtype,t)}makeOutput(e,t,n){return sa().makeTensorFromTensorInfo(this.makeTensorInfo(t,n,e),this)}disposeData(e,t=!1){if(this.data.has(e)){if(this.data.get(e).refCount--,!t&&this.data.get(e).refCount>0)return!1;const{complexTensorInfos:n}=this.data.get(e);null!=n&&(this.disposeData(n.real.dataId,!0),this.disposeData(n.imag.dataId,!0)),this.data.delete(e)}return!0}disposeIntermediateTensorInfo(e){this.disposeData(e.dataId)}async time(e){const t=sr();return e(),{kernelMs:sr()-t}}memory(){return{unreliable:!0,reasons:["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]}}where(e){ow([e],"where");const t=this.readSync(e.dataId);return lw(e.shape,t)}dispose(){}floatPrecision(){return 32}epsilon(){return super.epsilon()}}function cw(e){return(t,n,s)=>{const r=K(n,t.length);for(let n=0;n<t.length;++n)r[n]=e(t[n],s);return r}}function hw(e,t,n){return pw(e,cw(t),n)}function pw(e,t,n){return({inputs:s,attrs:r,backend:a})=>{const{x:i}=s;ow(i,e);const o=a,l=o.data.get(i.dataId).values;let u;if("string"===i.dtype){if(!Array.isArray(l))throw new Error("String tensor's value was not an instance of Array");u=hh(l)}else u=l;const c=n||i.dtype,h=t(u,c,r);return o.makeTensorInfo(i.shape,c,h)}}uw.nextDataId=0,la("cpu",(()=>new uw),1);const dw=hw(gt,(e=>e>=0?e:Math.exp(e)-1)),fw={kernelName:gt,backendName:"cpu",kernelFunc:dw};function mw(e){const{inputs:t,backend:n}=e,{x:s}=t;return n.incRef(s.dataId),{dataId:s.dataId,shape:s.shape,dtype:s.dtype}}const gw={kernelName:Dt,backendName:"cpu",kernelFunc:mw};function yw(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{alpha:a}=s;ow([r],"leakyRelu");const i=L(r.shape),o=n.data.get(r.dataId).values,l=j("float32",i);for(let e=0;e<o.length;e++)l[e]=o[e]<0?a*o[e]:o[e];return n.makeTensorInfo(r.shape,"float32",l)}const bw={kernelName:Bt,backendName:"cpu",kernelFunc:yw};function xw(e){return(t,n,s,r,a)=>{const i=gi(t,n),o=i.length,l=te(i),u=j(a,L(i)),c=t.length,h=n.length,p=te(t),d=te(n),f=fi(t,i),m=fi(n,i);if(f.length+m.length===0)for(let t=0;t<u.length;++t)u[t]=e(s[t%s.length],r[t%r.length]);else for(let t=0;t<u.length;++t){const n=ue(t,o,l),a=n.slice(-c);f.forEach((e=>a[e]=0));const i=le(a,c,p),g=n.slice(-h);m.forEach((e=>g[e]=0));const y=le(g,h,d);u[t]=e(s[i],r[y])}return[u,i]}}const ww=xw(((e,t)=>e<0?t*e:e));function kw(e){const{inputs:t,backend:n}=e,{x:s,alpha:r}=t;ow([s,r],"prelu");const a=n.data.get(s.dataId).values,i=n.data.get(r.dataId).values,[o,l]=ww(s.shape,r.shape,a,i,"float32");return n.makeTensorInfo(l,"float32",o)}const vw={kernelName:kn,backendName:"cpu",kernelFunc:kw},Iw=hw(Cn,(e=>Math.max(0,e))),Nw={kernelName:Cn,backendName:"cpu",kernelFunc:Iw},Sw=hw(On,(e=>Math.min(Math.max(0,e),6))),Tw={kernelName:On,backendName:"cpu",kernelFunc:Sw},$w=cw((e=>1/(1+Math.exp(-e)))),Ew=hw(qn,(e=>1/(1+Math.exp(-e)))),Cw={kernelName:qn,backendName:"cpu",kernelFunc:Ew};function Rw(e,t,n,s,r){if("linear"===n)return mw({inputs:{x:t},backend:e});if("relu"===n)return Iw({inputs:{x:t},backend:e});if("elu"===n)return dw({inputs:{x:t},backend:e});if("relu6"===n)return Sw({inputs:{x:t},backend:e});if("prelu"===n)return kw({inputs:{x:t,alpha:s},backend:e});if("leakyrelu"===n)return yw({inputs:{x:t},backend:e,attrs:{alpha:r}});if("sigmoid"===n)return Ew({inputs:{x:t},backend:e});throw new Error(`Activation ${n} has not been implemented for the CPU backend.`)}function Aw(e){const{inputs:t,backend:n}=e,{real:s,imag:r}=t,a=n.data.get(s.dataId).values,i=n.data.get(r.dataId).values,o=n.makeTensorInfo(s.shape,"complex64");return n.data.get(o.dataId).complexTensorInfos={real:n.makeTensorInfo(s.shape,"float32",a),imag:n.makeTensorInfo(r.shape,"float32",i)},o}const _w={kernelName:He,backendName:"cpu",kernelFunc:Aw};function Dw(e,t,n="float32"){if("complex64"===n)return Aw({inputs:{real:Dw(e,t,"float32"),imag:Dw(e,t,"float32")},backend:e});const s=ae(L(t),n);return e.makeTensorInfo(t,n,s)}function Fw(e){const{inputs:t,backend:n}=e,{input:s}=t,r=n.data.get(s.dataId).complexTensorInfos.real,a=n.data.get(r.dataId).values;return n.makeTensorInfo(r.shape,r.dtype,a)}const Ow={kernelName:$n,backendName:"cpu",kernelFunc:Fw};function Mw(e,t,n,s){if("int32"===s)return[t,"int32",Int32Array.from(e)];if("bool"===s){const s=nr([0],n),[r,a]=xw(((e,t)=>e!==t?1:0))(t,[],e,s,"bool");return[a,"bool",r]}throw new Error(`Error in Cast: failed to cast ${n} to ${s}`)}function Lw(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{dtype:a}=s;if("complex64"===a){if("complex64"===r.dtype)return mw({inputs:{x:r},backend:n});const e=Dw(n,r.shape,r.dtype),t=Lw({inputs:{x:r},backend:n,attrs:{dtype:"float32"}}),s=Aw({inputs:{real:t,imag:e},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),s}if("complex64"===r.dtype){const e=Fw({inputs:{input:r},backend:n}),t=Lw({inputs:{x:e},backend:n,attrs:{dtype:a}});return n.disposeIntermediateTensorInfo(e),t}if(!q(r.dtype,a)){const e=mw({inputs:{x:r},backend:n});return{dataId:e.dataId,shape:e.shape,dtype:a}}const i=n.data.get(r.dataId).values,[o,l,u]=Mw(i,r.shape,r.dtype,a);return n.makeTensorInfo(o,l,u)}const zw={kernelName:Ve,backendName:"cpu",kernelFunc:Lw};function Bw(e,t,n,s){return null==n?({inputs:n,backend:r})=>{const{a,b:i}=n,o=r;ow([a,i],e);const l=o.data.get(a.dataId).values,u=o.data.get(i.dataId).values,c="string"===a.dtype?hh(l):l,h="string"===a.dtype?hh(u):u,p=s||a.dtype,[d,f]=t(a.shape,i.shape,c,h,p);return o.makeTensorInfo(f,p,d)}:({inputs:e,backend:r})=>{const{a,b:i}=e,o=r;if("complex64"===a.dtype||"complex64"===i.dtype){const e=Lw({inputs:{x:a},backend:o,attrs:{dtype:"complex64"}}),t=o.data.get(e.dataId),s=t.complexTensorInfos.real,r=t.complexTensorInfos.imag,l=o.data.get(s.dataId).values,u=o.data.get(r.dataId).values,c=Lw({inputs:{x:i},backend:o,attrs:{dtype:"complex64"}}),h=o.data.get(c.dataId),p=h.complexTensorInfos.real,d=h.complexTensorInfos.imag,f=o.data.get(p.dataId).values,m=o.data.get(d.dataId).values,[g,y,b]=n(a.shape,i.shape,l,u,f,m),x=o.makeTensorInfo(b,"float32",g),w=o.makeTensorInfo(b,"float32",y),k=Aw({inputs:{real:x,imag:w},backend:o});return o.disposeIntermediateTensorInfo(e),o.disposeIntermediateTensorInfo(c),o.disposeIntermediateTensorInfo(x),o.disposeIntermediateTensorInfo(w),k}{const e=o.data.get(a.dataId).values,n=o.data.get(i.dataId).values,r=s||a.dtype,[l,u]=t(a.shape,i.shape,e,n,r);return o.makeTensorInfo(u,r,l)}}}function Pw(e){return(t,n,s,r,a,i)=>{const o=gi(t,n),l=L(o),u=o.length,c=te(o),h=j("float32",l),p=j("float32",l),d=fi(t,o),f=fi(n,o),m=Ac(s,r),g=Ac(a,i),y=t.length,b=te(t),x=n.length,w=te(n);if(d.length+f.length===0)for(let t=0;t<h.length;t++){const n=t%m.length,s=t%g.length,r=e(m[2*n],m[2*n+1],g[2*s],g[2*s+1]);h[t]=r.real,p[t]=r.imag}else for(let t=0;t<h.length;t++){const n=ue(t,u,c),s=n.slice(-y);d.forEach((e=>s[e]=0));const r=le(s,y,b),a=n.slice(-x);f.forEach((e=>a[e]=0));const i=le(a,x,w),o=e(m[2*r],m[2*r+1],g[2*i],g[2*i+1]);h[t]=o.real,p[t]=o.imag}return[h,p,o]}}const Ww=xw(((e,t)=>e+t)),Vw=Pw(((e,t,n,s)=>({real:e+n,imag:t+s}))),Uw=Bw(ve,Ww,Vw),Gw={kernelName:ve,backendName:"cpu",kernelFunc:Uw};function Hw(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{shape:a}=s,i=L(r.shape),o=U(a,i),l=L(o);F(i===l,(()=>`The new shape (${o}) has ${l} elements and the old shape (${r.shape}) has ${i} elements. The new shape and old shape must have the same number of elements.`)),n.incRef(r.dataId);const u=n.data.get(r.dataId);if(null!=u.complexTensorInfos){const e=u.complexTensorInfos.real,t=u.complexTensorInfos.imag;e.shape=o,t.shape=o}return{dataId:r.dataId,shape:o,dtype:r.dtype}}const jw={kernelName:Rn,backendName:"cpu",kernelFunc:Hw};function Kw(e){const{inputs:t,backend:n,attrs:s}=e,{a:r,b:a}=t,{transposeA:i,transposeB:o}=s;ow([r,a],"matMul");const l=r.shape.length,u=a.shape.length,c=i?r.shape[l-2]:r.shape[l-1],h=o?a.shape[u-1]:a.shape[u-2],p=i?r.shape[l-1]:r.shape[l-2],d=o?a.shape[u-2]:a.shape[u-1],f=r.shape.slice(0,-2),m=a.shape.slice(0,-2),g=L(f),y=L(m),b=gi(r.shape.slice(0,-2),a.shape.slice(0,-2)).concat([p,d]);F(c===h,(()=>`Error in matMul: inner shapes (${c}) and (${h}) of Tensors with shapes ${r.shape} and ${a.shape} and transposeA=${i} and transposeB=${o} must match.`));const x=o?[y,d,h]:[y,h,d],w=Hw({inputs:{x:r},backend:n,attrs:{shape:i?[g,c,p]:[g,p,c]}}),k=Hw({inputs:{x:a},backend:n,attrs:{shape:x}}),v=i?w.shape[1]:w.shape[2],I=i?w.shape[2]:w.shape[1],N=o?k.shape[1]:k.shape[2],S=Math.max(g,y),T=n.data.get(w.dataId).values,$=n.data.get(k.dataId).values,E=te(w.shape),C=te(k.shape),[R,A,_]=i?[E[0],1,E[1]]:[E[0],E[1],1],[D,O,M]=o?[1,C[1],C[0]]:[C[1],1,C[0]],z=I*N,B=Ua([S,I,N],w.dtype),P=B.values,W=n.blockSize;for(let e=0;e<S;e++){const t=e%g,n=e%y;for(let s=0;s<I;s+=W){const r=Math.min(s+W,I);for(let a=0;a<N;a+=W){const i=Math.min(a+W,N);for(let o=0;o<v;o+=W){const l=Math.min(o+W,v);for(let u=s;u<r;u++)for(let s=a;s<i;s++){let r=0;for(let e=o;e<l;e++)r+=T[t*R+u*A+e*_]*$[e*D+s*O+n*M];P[e*z+(u*N+s)]+=r}}}}}return n.disposeIntermediateTensorInfo(w),n.disposeIntermediateTensorInfo(k),n.makeTensorInfo(b,B.dtype,B.values)}const qw={kernelName:Le,backendName:"cpu",kernelFunc:Kw},Xw={kernelName:Ts,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{a:r,b:a,bias:i,preluActivationWeights:o}=t,{transposeA:l,transposeB:u,activation:c,leakyreluAlpha:h}=s;let p,d,f;const m=[];p=Kw({inputs:{a:r,b:a},attrs:{transposeA:l,transposeB:u},backend:n}),i&&(d=Uw({inputs:{a:p,b:i},backend:n}),m.push(p),p=d),c&&(f=Rw(n,p,c,o,h),m.push(p),p=f);for(const e of m)n.disposeIntermediateTensorInfo(e);return p}};function Yw(e){const t=new Float32Array(e.length);for(let n=0;n<e.length;++n)t[n]=Math.abs(e[n]);return t}const Jw={kernelName:xe,backendName:"cpu",kernelFunc:e=>{const{x:t}=e.inputs,n=e.backend;ow(t,"abs");let s=new Float32Array(L(t.shape));return s=Yw(n.data.get(t.dataId).values),n.makeOutput(s,t.shape,t.dtype)}},Zw=hw(we,(e=>Math.acos(e))),Qw={kernelName:we,backendName:"cpu",kernelFunc:Zw},ek=hw(ke,(e=>Math.acosh(e))),tk={kernelName:ke,backendName:"cpu",kernelFunc:ek},nk={kernelName:Ie,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,s=t;ow(t,"addN");const r=s.map((e=>n.data.get(e.dataId).values)),a=Ua(s[0].shape,s[0].dtype),i=a.values;for(let e=0;e<s.length;e++){const t=r[e];for(let e=0;e<i.length;e++)i[e]+=t[e]}return n.makeTensorInfo(a.shape,a.dtype,a.values)}};function sk(e,t,n,s,r){const a=t.length,i=L(t),o=te(t),l=te(r),u=j(n,L(r));for(let t=0;t<i;++t){const n=ue(t,a,o),r=new Array(n.length);for(let e=0;e<r.length;e++)r[e]=n[s[e]];u[le(r,a,l)]=e[t]}return u}function rk(e){const{inputs:t,attrs:n,backend:s}=e,{x:r}=t,{perm:a}=n;ow(r,"transpose");const i=r.shape.length,o=new Array(i);for(let e=0;e<o.length;e++)o[e]=r.shape[a[e]];const l=sk(s.data.get(r.dataId).values,r.shape,r.dtype,a,o);return{dataId:s.write(l,o,r.dtype),shape:o,dtype:r.dtype}}const ak={kernelName:xs,backendName:"cpu",kernelFunc:rk},ik={kernelName:Ne,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,keepDims:i}=s;ow(r,"all");const o=G(a,r.shape);let l=o;const u=il(l,r.shape.length);let c=r;null!=u&&(c=rk({inputs:{x:r},backend:n,attrs:{perm:u}}),l=ll(l.length,r.shape.length)),al("all",l,c.shape.length);const[h,p]=sl(c.shape,l),d=L(p),f=ae(L(h),c.dtype),m=n.data.get(c.dataId).values;for(let e=0;e<f.length;++e){const t=e*d;let n=m[t];for(let e=0;e<d;++e){const s=m[t+e];n=n&&s}f[e]=n}null!=u&&n.disposeIntermediateTensorInfo(c);const g=n.makeTensorInfo(h,c.dtype,f);if(i){const e=Hw({inputs:{x:g},backend:n,attrs:{shape:rl(h,o)}});return n.disposeIntermediateTensorInfo(g),e}return g}},ok={kernelName:Se,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,keepDims:i}=s;ow(r,"any");const o=G(a,r.shape);let l=o;const u=il(l,r.shape.length);let c=r;null!=u&&(c=rk({inputs:{x:r},backend:n,attrs:{perm:u}}),l=ll(l.length,r.shape.length)),al("any",l,c.shape.length);const[h,p]=sl(c.shape,l),d=L(p),f=ae(L(h),c.dtype),m=n.data.get(c.dataId).values;for(let e=0;e<f.length;++e){const t=e*d;let n=m[t];for(let e=0;e<d;++e){const s=m[t+e];n=n||s}f[e]=n}null!=u&&n.disposeIntermediateTensorInfo(c);const g=n.makeTensorInfo(h,c.dtype,f);if(i){const e=Hw({inputs:{x:g},backend:n,attrs:{shape:rl(h,o)}});return n.disposeIntermediateTensorInfo(g),e}return g}},lk={kernelName:Te,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a}=s;ow(r,"argMax");let i=G(a,r.shape);const o=il(i,r.shape.length);let l=r;const u=[];null!=o&&(l=rk({inputs:{x:r},backend:n,attrs:{perm:o}}),u.push(l),i=ll(i.length,l.shape.length)),i=[i[0]],al("argMax",i,l.shape.length);const[c,h]=sl(l.shape,i),p=ae(L(c),"int32"),d=L(h),f=n.data.get(l.dataId).values;for(let e=0;e<p.length;++e){const t=e*d;let n=f[t],s=0;for(let e=0;e<d;++e){const r=f[t+e];r>n&&(n=r,s=e)}p[e]=s}return u.forEach((e=>n.disposeIntermediateTensorInfo(e))),n.makeTensorInfo(c,"int32",p)}},uk={kernelName:$e,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a}=s;ow(r,"argMin");let i=G(a,r.shape);const o=il(i,r.shape.length);let l=r;const u=[];null!=o&&(l=rk({inputs:{x:r},backend:n,attrs:{perm:o}}),u.push(l),i=ll(i.length,l.shape.length)),i=[i[0]],al("argMin",i,l.shape.length);const[c,h]=sl(l.shape,i),p=ae(L(c),"int32"),d=L(h),f=n.data.get(l.dataId).values;for(let e=0;e<p.length;++e){const t=e*d;let n=f[t],s=0;for(let e=0;e<d;++e){const r=f[t+e];r<n&&(n=r,s=e)}p[e]=s}return u.forEach((e=>n.disposeIntermediateTensorInfo(e))),n.makeTensorInfo(c,"int32",p)}},ck=hw(Ee,(e=>Math.asin(e))),hk={kernelName:Ee,backendName:"cpu",kernelFunc:ck},pk=hw(Ce,(e=>Math.asinh(e))),dk={kernelName:Ce,backendName:"cpu",kernelFunc:pk},fk=hw(Re,(e=>Math.atan(e))),mk={kernelName:Re,backendName:"cpu",kernelFunc:fk},gk=xw(((e,t)=>Math.atan2(e,t))),yk=Bw(_e,gk),bk={kernelName:_e,backendName:"cpu",kernelFunc:yk},xk=hw(Ae,(e=>Math.atanh(e))),wk={kernelName:Ae,backendName:"cpu",kernelFunc:xk};function kk(e,t,n,s,r,a){const i=r.strideHeight,o=r.strideWidth,l=r.dilationHeight,u=r.dilationWidth,c=r.effectiveFilterHeight,h=r.effectiveFilterWidth,p=r.padInfo.top,d=r.padInfo.left,f="max"===a?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,m=Ua(r.outShape,n),g=m.values,y=r.outShape[1]*r.outShape[2]*r.outShape[3],b=r.outShape[2]*r.outShape[3],x=r.outShape[3];for(let t=0;t<r.batchSize;++t){const n=t*y,m=t*s[0];for(let t=0;t<r.inChannels;++t)for(let y=0;y<r.outHeight;++y){const w=y*i-p,k=Math.max(0,w),v=Math.min(r.inHeight,c+w),I=n+y*b;for(let n=0;n<r.outWidth;++n){const i=n*o-d,c=Math.max(0,i),p=Math.min(r.inWidth,h+i);let y=f,b=0,w=0;for(let n=k;n<v;n+=l){const r=m+n*s[1];for(let n=c;n<p;n+=u){const i=e[r+n*s[2]+t];"max"===a&&i>y?y=i:"avg"===a&&(b+=i,w++)}if(isNaN(y))break}g[I+n*x+t]="avg"===a?b/w:y}}}return m}function vk(e,t,n,s,r=!1,a=!1){const i=Ua(s.outShape,"int32"),o=s.strideHeight,l=s.strideWidth,u=s.dilationHeight,c=s.dilationWidth,h=s.effectiveFilterHeight,p=s.effectiveFilterWidth,d=s.padInfo.top,f=s.padInfo.left,m=Ua(t,n,e);for(let e=0;e<s.batchSize;++e)for(let t=0;t<s.inChannels;++t)for(let n=0;n<s.outHeight;++n){const g=n*o-d;let y=g;for(;y<0;)y+=u;const b=Math.min(s.inHeight,h+g);for(let o=0;o<s.outWidth;++o){const h=o*l-f;let d=h;for(;d<0;)d+=c;const x=Math.min(s.inWidth,p+h);let w=Number.NEGATIVE_INFINITY,k=-1;for(let n=y;n<b;n+=u){const i=n-g;for(let o=d;o<x;o+=c){const l=o-h,u=m.get(e,n,o,t);u>w&&(w=u,k=r?a?((e*s.inHeight+n)*s.inWidth+o)*s.inChannels+t:(n*s.inWidth+o)*s.inChannels+t:i*p+l)}}i.set(k,e,n,o,t)}}return i}function Ik(e,t,n,s,r,a){const i=r.strideDepth,o=r.strideHeight,l=r.strideWidth,u=r.dilationDepth,c=r.dilationHeight,h=r.dilationWidth,p=r.effectiveFilterDepth,d=r.effectiveFilterHeight,f=r.effectiveFilterWidth,m=r.padInfo.front,g=r.padInfo.top,y=r.padInfo.left,b="max"===a?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,x=Ua(r.outShape,n),w=x.values,k=r.outShape[1]*r.outShape[2]*r.outShape[3]*r.outShape[4],v=r.outShape[2]*r.outShape[3]*r.outShape[4],I=r.outShape[3]*r.outShape[4],N=r.outShape[4];for(let t=0;t<r.batchSize;++t){const n=t*k,x=t*s[0];for(let t=0;t<r.inChannels;++t)for(let k=0;k<r.outDepth;++k){const S=k*i-m;let T=S;for(;T<0;)T+=u;const $=Math.min(r.inDepth,p+S),E=n+k*v;for(let n=0;n<r.outHeight;++n){const i=n*o-g;let p=i;for(;p<0;)p+=c;const m=Math.min(r.inHeight,d+i),k=E+n*I;for(let n=0;n<r.outWidth;++n){const i=n*l-y;let o=i;for(;o<0;)o+=h;const d=Math.min(r.inWidth,f+i),g=k+n*N;let v=b,I=0,S=0;for(let n=T;n<$;n+=u){const r=x+n*s[1];for(let n=p;n<m;n+=c){const i=r+n*s[2];for(let n=o;n<d;n+=h){const r=e[i+n*s[3]+t];if("max"===a&&r>v?v=r:"avg"===a&&(I+=r,S++),isNaN(v))break}if(isNaN(v))break}if(isNaN(v))break}w[g+t]="avg"===a?I/Math.max(S,1):v}}}}return x}const Nk={kernelName:De,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t;ow(r,"avgPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:l}=s;F(co(i,1),(()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));const u=eo(r.shape,a,i,1,o,l);let c;if(1===u.filterWidth&&1===u.filterHeight&&z(u.inShape,u.outShape))c=mw({inputs:{x:r},backend:n});else{const e=n.data.get(r.dataId).values,t=te(r.shape),s=kk(e,r.shape,r.dtype,t,u,"avg");c=n.makeTensorInfo(u.outShape,r.dtype,s.values)}return c}},Sk={kernelName:Oe,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{filterSize:a,strides:i,pad:o,dimRoundingMode:l,dataFormat:u}=s;ow(r,"avgPool3d");const c=to(r.shape,a,i,1,o,l,u),h=Ik(n.data.get(r.dataId).values,r.shape,r.dtype,te(r.shape),c,"avg");return n.makeTensorInfo(h.shape,"float32",h.values)}},Tk={kernelName:Me,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,input:a}=t,{filterSize:i,strides:o,pad:l,dimRoundingMode:u}=s;ow([r,a],"avgPool3DGrad");const c=to(a.shape,i,o,1,l,u),h=c.strideDepth,p=c.strideHeight,d=c.strideWidth,f=c.filterDepth,m=c.filterHeight,g=c.filterWidth,y=c.dilationDepth,b=c.dilationHeight,x=c.dilationWidth,w=c.effectiveFilterDepth,k=c.effectiveFilterHeight,v=c.effectiveFilterWidth,I=w-1-c.padInfo.front,N=v-1-c.padInfo.left,S=k-1-c.padInfo.top,T=Ua(a.shape,"float32"),$=1/(f*m*g),E=n.bufferSync(r);for(let e=0;e<c.batchSize;++e)for(let t=0;t<c.inChannels;++t)for(let n=0;n<c.inDepth;++n)for(let s=0;s<c.inHeight;++s)for(let r=0;r<c.inWidth;++r){const a=n-I,i=s-S,o=r-N;let l=0;for(let n=0;n<w;n+=y){const s=(a+n)/h;if(!(s<0||s>=c.outDepth||Math.floor(s)!==s))for(let n=0;n<k;n+=b){const r=(i+n)/p;if(!(r<0||r>=c.outHeight||Math.floor(r)!==r))for(let n=0;n<v;n+=x){const a=(o+n)/d;a<0||a>=c.outWidth||Math.floor(a)!==a||(l+=E.get(e,s,r,a,t))}}}T.set(l*$,e,n,s,r,t)}return n.makeTensorInfo(T.shape,T.dtype,T.values)}},$k={kernelName:Fe,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,input:a}=t,i=a;ow([r,a],"avgPoolGrad");const{filterSize:o,strides:l,pad:u}=s,c=eo(i.shape,o,l,1,u),h=c.strideHeight,p=c.strideWidth,d=c.filterHeight,f=c.filterWidth,m=c.dilationHeight,g=c.dilationWidth,y=c.effectiveFilterHeight,b=c.effectiveFilterWidth,x=b-1-c.padInfo.left,w=y-1-c.padInfo.top,k=Ua(i.shape,"float32"),v=1/(d*f),I=n.data.get(r.dataId).values,N=Ua(r.shape,"float32",I);for(let e=0;e<c.batchSize;++e)for(let t=0;t<c.inChannels;++t)for(let n=0;n<c.inHeight;++n)for(let s=0;s<c.inWidth;++s){const r=n-w,a=s-x;let i=0;for(let n=0;n<y;n+=m){const s=(r+n)/h;if(!(s<0||s>=c.outHeight||Math.floor(s)!==s))for(let n=0;n<b;n+=g){const r=(a+n)/p;r<0||r>=c.outWidth||Math.floor(r)!==r||(i+=N.get(e,s,r,t))}}k.set(i*v,e,n,s,t)}return n.makeTensorInfo(k.shape,k.dtype,k.values)}},Ek={kernelName:Et,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,scale:a,offset:i,mean:o,variance:l}=t;F(o.shape.length===l.shape.length,(()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),F(null==i||o.shape.length===i.shape.length,(()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),F(null==a||o.shape.length===a.shape.length,(()=>"Batch normalization gradient requires mean and scale to have equal ranks.")),ow([r,o,l,a,i],"batchNorm");let{varianceEpsilon:u}=s;null==u&&(u=.001);const c=n.data.get(r.dataId).values,h=n.data.get(o.dataId).values,p=n.data.get(l.dataId).values,d=a?n.data.get(a.dataId).values:new Float32Array([1]),f=i?n.data.get(i.dataId).values:new Float32Array([0]),m=new Float32Array(c.length),g=f.length,y=d.length,b=p.length,x=h.length;let w=0,k=0,v=0,I=0;for(let e=0;e<c.length;++e)m[e]=f[w++]+(c[e]-h[k++])*d[v++]/Math.sqrt(p[I++]+u),w>=g&&(w=0),k>=x&&(k=0),v>=y&&(v=0),I>=b&&(I=0);return n.makeTensorInfo(r.shape,r.dtype,m)}};function Ck(e,t,n,s,r){const a=Hi(s,t,n),i=L(n),o=te(s);if(a){const n=ji(t,o);return"string"===r?e.slice(n,n+i):e.subarray(n,n+i)}const l=Ua(s,r,"string"===r?hh(e):e),u=Ua(n,r);for(let e=0;e<u.size;++e){const n=u.indexToLoc(e),s=n.map(((e,n)=>e+t[n]));u.set(l.get(...s),...n)}return"string"===r?ph(u.values):u.values}function Rk(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{begin:a,size:i}=s;ow(r,"slice");const[o,l]=Ki(r,a,i);Di(r,o,l);const u=Ck(n.data.get(r.dataId).values,o,l,r.shape,r.dtype);return n.makeTensorInfo(l,r.dtype,u)}const Ak={kernelName:Gn,backendName:"cpu",kernelFunc:Rk},_k={kernelName:ze,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{blockShape:a,crops:i}=s;ow([r],"batchToSpaceND");const o=a.reduce(((e,t)=>e*t)),l=fc(r.shape,a,o),u=mc(l.length,a.length),c=gc(r.shape,a,o),h=yc(i,a.length),p=bc(c,i,a.length),d=Hw({inputs:{x:r},backend:n,attrs:{shape:l}}),f=rk({inputs:{x:d},backend:n,attrs:{perm:u}}),m=Hw({inputs:{x:f},backend:n,attrs:{shape:c}}),g=Rk({inputs:{x:m},backend:n,attrs:{begin:h,size:p}});return n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),n.disposeIntermediateTensorInfo(m),g}};function Dk(e,t,n,s,r){const a=L(s),i=ae(r,n);for(let n=0;n<e.length;n++){const s=e[n];if(s<0)throw new Error("Input x must be non-negative!");s>=r||(i[s]+=a>0?t[n]:1)}return i}function Fk(e,t,n,s=!1){const r=e.shape[0],a=e.shape[1],i=Ua([r,n],t.dtype);for(let o=0;o<r;o++)for(let r=0;r<a;r++){const a=e.get(o,r);if(a<0)throw new Error("Input x must be non-negative!");a>=n||(s?i.set(1,o,a):t.size>0?i.set(i.get(o,a)+t.get(o,r),o,a):i.set(i.get(o,a)+1,o,a))}return i}const Ok={kernelName:Be,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,weights:a}=t,{size:i}=s,o=Dk(n.data.get(r.dataId).values,n.data.get(a.dataId).values,a.dtype,a.shape,i);return n.makeTensorInfo([i],a.dtype,o)}},Mk=xw(((e,t)=>e&t)),Lk={kernelName:Pe,backendName:"cpu",kernelFunc:Bw(Pe,Mk)},zk={kernelName:We,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{s0:s,s1:r}=t,a=n.data.get(s.dataId).values,i=n.data.get(r.dataId).values,o=gi(Array.from(a),Array.from(i));return n.makeTensorInfo([o.length],"int32",Int32Array.from(o))}},Bk=cw((e=>Math.ceil(e))),Pk=pw(Ue,Bk),Wk={kernelName:Ue,backendName:"cpu",kernelFunc:Pk},Vk=hw(Ge,((e,t)=>{const n=t;return e>n.clipValueMax?n.clipValueMax:e<n.clipValueMin?n.clipValueMin:e})),Uk={kernelName:Ge,backendName:"cpu",kernelFunc:Vk},Gk={kernelName:je,backendName:"cpu",kernelFunc:e=>{const{x:t}=e.inputs,n=e.backend,s=new Float32Array(L(t.shape)),r=n.data.get(t.dataId),a=r.complexTensorInfos.real,i=r.complexTensorInfos.imag,o=n.data.get(a.dataId).values,l=n.data.get(i.dataId).values;for(let e=0;e<o.length;e++){const t=o[e],n=l[e];s[e]=Math.hypot(t,n)}return n.makeOutput(s,t.shape,"float32")}};function Hk(e,t,n,s){const r=K(n,L(t));if(s&&"string"!==n){let t=0;e.forEach((e=>{const n=L(e.shape);r.set(e.vals,t),t+=n}))}else{let s=0;e.forEach((e=>{const a="string"===n?hh(e.vals):e.vals;let i=0;for(let n=0;n<e.shape[0];++n){const o=n*t[1]+s;for(let t=0;t<e.shape[1];++t)r[o+t]=a[i++]}s+=e.shape[1]}))}return r}function jk(e){const{inputs:t,backend:n}=e,{input:s}=t,r=n.data.get(s.dataId).complexTensorInfos.imag,a=n.data.get(r.dataId).values;return n.makeTensorInfo(r.shape,r.dtype,a)}const Kk={kernelName:Ot,backendName:"cpu",kernelFunc:jk};function qk(e){const{inputs:t,backend:n,attrs:s}=e,{axis:r}=s,a=G(r,t[0].shape)[0];rc(t.map((e=>e.shape)),a);let i=ac(t.map((e=>e.shape)),a);if(0===L(i))return n.makeTensorInfo(i,t[0].dtype,[]);const o=t.filter((e=>L(e.shape)>0));if(1===o.length)return mw({inputs:{x:o[0]},backend:n});if("complex64"===o[0].dtype){const e=o.map((e=>Fw({inputs:{input:e},backend:n}))),t=o.map((e=>jk({inputs:{input:e},backend:n}))),s=qk({inputs:e,backend:n,attrs:{axis:a}}),r=qk({inputs:t,backend:n,attrs:{axis:a}}),i=Aw({inputs:{real:s,imag:r},backend:n});return e.forEach((e=>n.disposeIntermediateTensorInfo(e))),t.forEach((e=>n.disposeIntermediateTensorInfo(e))),n.disposeIntermediateTensorInfo(s),n.disposeIntermediateTensorInfo(r),i}const l=o.map((e=>{const t=L(e.shape.slice(a));return Hw({inputs:{x:e},backend:n,attrs:{shape:[-1,t]}})})),u=l.map((e=>({vals:n.data.get(e.dataId).values,shape:e.shape})));i=ac(l.map((e=>e.shape)),1);const c=1===l[0].shape[0],h=Hk(u,i,t[0].dtype,c),p=ac(o.map((e=>e.shape)),a),d=n.makeTensorInfo(p,t[0].dtype,h);return l.forEach((e=>n.disposeIntermediateTensorInfo(e))),d}const Xk={kernelName:Ke,backendName:"cpu",kernelFunc:qk};function Yk(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,filter:a}=t,{strides:i,pad:o,dataFormat:l,dilations:u,dimRoundingMode:c}=s;ow([r,a],"conv2d");const h=po(l),p=no(r.shape,a.shape,i,u,o,c,!1,h),d=p.filterHeight,f=p.filterWidth,m=p.dilationHeight,g=p.dilationWidth,y=p.padInfo.left,b=p.padInfo.top,x="channelsLast"===p.dataFormat,w=new gr(p.outShape,r.dtype),k=te(r.shape),v=te(a.shape),I=k[0],N=x?k[1]:k[2],S=x?k[2]:1,T=x?1:k[1],$=w.strides[0],E=x?w.strides[1]:w.strides[2],C=x?w.strides[2]:1,R=x?1:w.strides[1],A=n.data.get(r.dataId).values,_=n.data.get(a.dataId).values,D=w.values;for(let e=0;e<p.batchSize;++e){const t=e*I,n=e*$;for(let e=0;e<p.outHeight;++e){const s=n+e*E,r=e*p.strideHeight-b;for(let e=0;e<d;++e){const n=r+e*m;if(n<0||n>=p.inHeight)continue;const a=e*v[0],i=t+n*N;for(let e=0;e<p.outWidth;++e){const t=s+e*C,n=e*p.strideWidth-y;for(let e=0;e<f;++e){const s=n+e*g;if(s<0||s>=p.inWidth)continue;const r=i+s*S;let o=a+e*v[1];for(let e=0;e<p.inChannels;++e){const n=A[r+e*T];for(let e=0;e<p.outChannels;++e)D[t+e*R]+=n*_[o+e];o+=p.outChannels}}}}}}return n.makeTensorInfo(w.shape,w.dtype,D)}const Jk={kernelName:qe,backendName:"cpu",kernelFunc:Yk},Zk={kernelName:Xe,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,dy:a}=t,{strides:i,pad:o,dataFormat:l,dimRoundingMode:u,filterShape:c}=s;ow([r,a],"conv2dBackpropFilter");const h=po(l),p=no(r.shape,c,i,1,o,u,!1,h),{strideHeight:d,strideWidth:f,filterHeight:m,filterWidth:g}=p,y="channelsLast"===p.dataFormat,b=new gr(p.filterShape,"float32"),x=p.padInfo.left,w=p.padInfo.top,k=n.data.get(r.dataId).values,v=n.data.get(a.dataId).values,I=new gr(r.shape,r.dtype,k),N=new gr(a.shape,a.dtype,v);for(let e=0;e<m;++e){const t=Math.max(0,Math.ceil((w-e)/d)),n=Math.min(p.outHeight,(p.inHeight+w-e)/d);for(let s=0;s<g;++s){const r=Math.max(0,Math.ceil((x-s)/f)),a=Math.min(p.outWidth,(p.inWidth+x-s)/f);for(let i=0;i<p.inChannels;++i)for(let o=0;o<p.outChannels;++o){let l=0;for(let u=0;u<p.batchSize;++u)for(let c=t;c<n;++c){const t=e+c*d-w;for(let e=r;e<a;++e){const n=s+e*f-x;l+=y?I.get(u,t,n,i)*N.get(u,c,e,o):I.get(u,i,t,n)*N.get(u,o,c,e)}}b.set(l,e,s,i,o)}}}return n.makeTensorInfo(b.shape,b.dtype,b.values)}},Qk={kernelName:Ye,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,filter:a}=t,{inputShape:i,strides:o,pad:l,dataFormat:u,dimRoundingMode:c}=s;ow([r,a],"conv2dBackpropInput");const h=te(a.shape),p=te(r.shape);let d=po(u);const f=no(i,a.shape,o,1,l,c,!1,d),m=new gr(f.inShape,"float32"),g=m.values,y=n.data.get(r.dataId).values,b=n.data.get(a.dataId).values,[x,w,k]=h,{batchSize:v,filterHeight:I,filterWidth:N,inChannels:S,inHeight:T,inWidth:$,outChannels:E,outHeight:C,outWidth:R,strideHeight:A,strideWidth:_}=f;d=f.dataFormat;const D=I-1-f.padInfo.top,F=N-1-f.padInfo.left,O="channelsLast"===d,M=m.strides[0],L=O?m.strides[1]:m.strides[2],z=O?m.strides[2]:1,B=O?1:m.strides[1],P=p[0],W=O?p[1]:p[2],V=O?p[2]:1,U=O?1:p[1];for(let e=0;e<v;++e)for(let t=0;t<S;++t)for(let n=0;n<T;++n){const s=n-D,r=Math.max(0,Math.ceil(s/A)),a=Math.min(C,(I+s)/A);for(let i=0;i<$;++i){const o=i-F,l=Math.max(0,Math.ceil(o/_)),u=Math.min(R,(N+o)/_);let c=0;for(let n=r;n<a;++n){const r=n*A-s;for(let s=l;s<u;++s){const a=P*e+W*n+V*s,i=x*(I-1-r)+w*(N-1-(s*_-o))+k*t;for(let e=0;e<E;++e)c+=y[a+U*e]*b[i+e]}}g[M*e+L*n+z*i+B*t]=c}}return n.makeTensorInfo(m.shape,m.dtype,m.values)}},ev={kernelName:Je,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,filter:a}=t,{strides:i,pad:o,dilations:l}=s;ow([r,a],"conv3d");const u=so(r.shape,a.shape,i,l,o),{filterDepth:c,filterHeight:h,filterWidth:p,dilationDepth:d,dilationHeight:f,dilationWidth:m,padInfo:g}=u,y=g.front,b=g.left,x=g.top,w=new gr(u.outShape,r.dtype),k=n.data.get(r.dataId).values,v=n.data.get(a.dataId).values,I=w.values,N=te(r.shape),S=te(a.shape);for(let e=0;e<u.batchSize;++e){const t=e*N[0],n=e*w.strides[0];for(let e=0;e<u.outDepth;++e){const s=n+e*w.strides[1],r=e*u.strideDepth-y;for(let e=0;e<c;++e){const n=r+e*d;if(n<0||n>=u.inDepth)continue;const a=e*S[0],i=t+n*N[1];for(let e=0;e<u.outHeight;++e){const t=s+e*w.strides[2],n=e*u.strideHeight-x;for(let e=0;e<h;++e){const s=n+e*f;if(s<0||s>=u.inHeight)continue;const r=a+e*S[1],o=i+s*N[2];for(let e=0;e<u.outWidth;++e){const n=t+e*u.outChannels,s=e*u.strideWidth-b;for(let e=0;e<p;++e){const t=s+e*m;if(t<0||t>=u.inWidth)continue;const a=r+e*S[2],i=o+t*u.inChannels;let l=a;for(let e=0;e<u.inChannels;++e){const t=k[i+e];for(let e=0;e<u.outChannels;++e)I[n+e]+=t*v[l+e];l+=u.outChannels}}}}}}}}return n.makeTensorInfo(w.shape,w.dtype,w.values)}},tv={kernelName:Ze,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,dy:a}=t,{strides:i,pad:o,filterShape:l}=s;ow([r,a],"conv3dBackpropFilterV2");const u=te(r.shape),c=te(a.shape),h=so(r.shape,l,i,1,o),p=h.strideDepth,d=h.strideHeight,f=h.strideWidth,m=h.filterDepth,g=h.filterHeight,y=h.filterWidth,b=new gr(h.filterShape,"float32"),x=b.values,[w,k,v,I]=b.strides,N=n.data.get(a.dataId).values,[S,T,$,E]=c,C=n.data.get(r.dataId).values,[R,A,_,D]=u,F=h.padInfo.front,O=h.padInfo.left,M=h.padInfo.top;for(let e=0;e<m;++e){const t=Math.max(0,Math.ceil((F-e)/p)),n=Math.min(h.outDepth,(h.inDepth+F-e)/p),s=e*w;for(let r=0;r<g;++r){const a=Math.max(0,Math.ceil((M-r)/d)),i=Math.min(h.outHeight,(h.inHeight+M-r)/d),o=r*k+s;for(let s=0;s<y;++s){const l=Math.max(0,Math.ceil((O-s)/f)),u=Math.min(h.outWidth,(h.inWidth+O-s)/f),c=s*v+o;for(let o=0;o<h.inChannels;++o){const m=o*I+c;for(let c=0;c<h.outChannels;++c){let g=0;for(let m=0;m<h.batchSize;++m){const h=m*R,y=m*S;for(let m=t;m<n;++m){const t=(e+m*p-F)*A+h,n=m*T+y;for(let e=a;e<i;++e){const a=(r+e*d-M)*_+t,i=e*$+n;for(let e=l;e<u;++e){const t=e*E+i;g+=C[(s+e*f-O)*D+a+o]*N[t+c]}}}}x[m+c]=g}}}}}return n.makeTensorInfo(b.shape,b.dtype,b.values)}},nv={kernelName:Qe,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,filter:a}=t,{pad:i,strides:o,inputShape:l}=s;ow([r],"conv3dBackpropInputV2");const u=te(r.shape),c=te(a.shape),h=so(l,a.shape,o,1,i),p=new gr(h.inShape,"float32"),d=p.values,[f,m,g,y]=p.strides,b=n.data.get(r.dataId).values,[x,w,k,v]=u,I=n.data.get(a.dataId).values,[N,S,T,$]=c,{batchSize:E,filterDepth:C,filterHeight:R,filterWidth:A,inChannels:_,inDepth:D,inHeight:F,inWidth:O,outChannels:M,outDepth:L,outHeight:z,outWidth:B,strideDepth:P,strideHeight:W,strideWidth:V}=h,U=C-1-h.padInfo.front,G=R-1-h.padInfo.top,H=A-1-h.padInfo.left;for(let e=0;e<E;++e)for(let t=0;t<_;++t)for(let n=0;n<D;++n){const s=n-U,r=Math.max(0,Math.ceil(s/P)),a=Math.min(L,(C+s)/P);for(let i=0;i<F;++i){const o=i-G,l=Math.max(0,Math.ceil(o/W)),u=Math.min(z,(R+o)/W);for(let c=0;c<O;++c){const h=c-H,p=Math.max(0,Math.ceil(h/V)),E=Math.min(B,(A+h)/V);let _=0;for(let n=r;n<a;++n){const r=n*P-s;for(let s=l;s<u;++s){const a=s*W-o;for(let i=p;i<E;++i){const o=x*e+w*n+k*s+v*i,l=N*(C-1-r)+S*(R-1-a)+T*(A-1-(i*V-h))+$*t;for(let e=0;e<M;++e)_+=b[o+e]*I[l+e]}}}d[f*e+m*n+g*i+y*c+t]=_}}}return n.makeTensorInfo(p.shape,p.dtype,p.values)}},sv=hw(et,(e=>Math.cos(e))),rv={kernelName:et,backendName:"cpu",kernelFunc:sv},av=hw(tt,(e=>Math.cosh(e))),iv={kernelName:tt,backendName:"cpu",kernelFunc:av},ov={kernelName:rt,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{image:r,boxes:a,boxInd:i}=t,{cropSize:o,method:l,extrapolationValue:u}=s,[c,h,p,d]=r.shape,f=a.shape[0],[m,g]=o,y=Ua([f,m,g,d],"float32"),b=n.data.get(a.dataId).values,x=n.data.get(i.dataId).values,w=n.data.get(r.dataId).values,k=te(r.shape),v=te(y.shape);for(let e=0;e<f;e++){const t=4*e,n=b[t],s=b[t+1],r=b[t+2],a=b[t+3],i=x[e];if(i>=c)continue;const o=m>1?(r-n)*(h-1)/(m-1):0,f=g>1?(a-s)*(p-1)/(g-1):0;for(let t=0;t<m;t++){const c=m>1?n*(h-1)+t*o:.5*(n+r)*(h-1);if(c<0||c>h-1)for(let n=0;n<g;n++)for(let s=0;s<d;s++){const r=s+n*v[2]+t*v[1]+e*v[0];y.values[r]=u}else if("bilinear"===l){const n=Math.floor(c),r=Math.ceil(c),o=c-n;for(let l=0;l<g;l++){const c=g>1?s*(p-1)+l*f:.5*(s+a)*(p-1);if(c<0||c>p-1){for(let n=0;n<d;n++){const s=n+l*v[2]+t*v[1]+e*v[0];y.values[s]=u}continue}const h=Math.floor(c),m=Math.ceil(c),b=c-h;for(let s=0;s<d;s++){let a=s+h*k[2]+n*k[1]+i*k[0];const u=w[a];a=s+m*k[2]+n*k[1]+i*k[0];const c=w[a];a=s+h*k[2]+r*k[1]+i*k[0];const p=w[a];a=s+m*k[2]+r*k[1]+i*k[0];const d=u+(c-u)*b,f=p+(w[a]-p)*b;a=s+l*v[2]+t*v[1]+e*v[0],y.values[a]=d+(f-d)*o}}}else for(let n=0;n<g;++n){const r=g>1?s*(p-1)+n*f:.5*(s+a)*(p-1);if(r<0||r>p-1){for(let s=0;s<d;s++){const r=s+n*v[2]+t*v[1]+e*v[0];y.values[r]=u}continue}const o=Math.round(r),l=Math.round(c);for(let s=0;s<d;s++){const r=s+o*k[2]+l*k[1]+i*k[0],a=s+n*v[2]+t*v[1]+e*v[0];y.values[a]=w[r]}}}}return n.makeTensorInfo(y.shape,y.dtype,y.values)}},lv={kernelName:nt,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,exclusive:i,reverse:o}=s;ow(r,"cumprod");const l=il([a],r.shape.length);let u=r;null!=l&&(u=rk({inputs:{x:r},backend:n,attrs:{perm:l}}));const c=ll(1,r.shape.length)[0];if(c!==u.shape.length-1)throw new Error(`backend.cumprod in CPU expects an inner-most axis=${u.shape.length-1} but got axis=${c}`);const h=Cr(u.dtype,"int32"),p=re(L(u.shape),h),d=n.data.get(u.dataId).values,f=u.shape[u.shape.length-1],m=o?(e,t)=>e+f-t-1:(e,t)=>e+t;for(let e=0;e<d.length;e+=f)for(let t=0;t<f;t++){const n=m(e,t);if(0===t)p[n]=i?1:d[n];else{const s=m(e,t-1);p[n]=i?d[s]*p[s]:d[n]*p[s]}}const g=n.makeTensorInfo(u.shape,h,p);if(null!=l){const e=rk({inputs:{x:g},backend:n,attrs:{perm:ol(l)}});return n.disposeIntermediateTensorInfo(g),n.disposeIntermediateTensorInfo(u),e}return g}},uv={kernelName:st,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,exclusive:i,reverse:o}=s;ow(r,"cumsum");const l=il([a],r.shape.length);let u=r;null!=l&&(u=rk({inputs:{x:r},backend:n,attrs:{perm:l}}));const c=ll(1,r.shape.length)[0];if(c!==u.shape.length-1)throw new Error(`backend.cumsum in CPU expects an inner-most axis=${u.shape.length-1} but got axis=${c}`);const h=Cr(u.dtype,"int32"),p=ae(L(u.shape),h),d=n.data.get(u.dataId).values,f=u.shape[u.shape.length-1],m=o?(e,t)=>e+f-t-1:(e,t)=>e+t;for(let e=0;e<d.length;e+=f)for(let t=0;t<f;t++){const n=m(e,t);if(0===t)p[n]=i?0:d[n];else{const s=m(e,t-1);p[n]=i?d[s]+p[s]:d[n]+p[s]}}const g=n.makeTensorInfo(u.shape,h,p);if(null!=l){const e=rk({inputs:{x:g},backend:n,attrs:{perm:ol(l)}});return n.disposeIntermediateTensorInfo(g),n.disposeIntermediateTensorInfo(u),e}return g}},cv={kernelName:at,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,weights:a}=t,{size:i,binaryOutput:o}=s;if(1===r.shape.length){const e=Dk(n.data.get(r.dataId).values,n.data.get(a.dataId).values,a.dtype,a.shape,i);return n.makeTensorInfo([i],a.dtype,e)}if(2===r.shape.length){const e=Fk(n.bufferSync(r),n.bufferSync(a),i,o);return n.makeTensorInfo(e.shape,a.dtype,e.values)}throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${r.shape.length}.`)}},hv={kernelName:it,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{blockSize:a,dataFormat:i}=s;F("NHWC"===i,(()=>`Only NHWC dataFormat supported on CPU for depthToSpace. Got ${i}`));const o=r.shape[0],l=r.shape[1],u=r.shape[2],c=r.shape[3],h=l*a,p=u*a,d=c/(a*a),f=n.data.get(r.dataId).values,m=new Float32Array(o*h*p*d);let g=0;for(let e=0;e<o;++e)for(let t=0;t<h;++t){const n=Math.floor(t/a),s=t%a;for(let t=0;t<p;++t){const r=Math.floor(t/a),i=(s*a+t%a)*d;for(let t=0;t<d;++t){const s=t+i+c*(r+u*(n+l*e));m[g++]=f[s]}}}return n.makeTensorInfo([o,h,p,d],r.dtype,m)}};function pv(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,filter:a}=t,{strides:i,pad:o,dilations:l,dimRoundingMode:u}=s;ow([r,a],"depthwiseConv2DNative");const c=te(r.shape),h=te(a.shape);let p=l;null==p&&(p=[1,1]),F(co(i,p),(()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${i} and dilations '${p}'`));const d=no(r.shape,a.shape,i,p,o,u,!0),{filterHeight:f,filterWidth:m,dilationHeight:g,dilationWidth:y,padInfo:b}=d,x=b.left,w=b.top,k=d.outChannels/d.inChannels,v=new gr(d.outShape,r.dtype),I=n.data.get(r.dataId).values,N=n.data.get(a.dataId).values,S=v.values;for(let e=0;e<d.batchSize;++e){const t=e*c[0],n=e*v.strides[0];for(let e=0;e<d.outHeight;++e){const s=n+e*v.strides[1],r=e*d.strideHeight-w;for(let e=0;e<f;++e){const n=r+e*g;if(n<0||n>=d.inHeight)continue;const a=e*h[0],i=t+n*c[1];for(let e=0;e<d.outWidth;++e){const t=s+e*v.strides[2],n=e*d.strideWidth-x;for(let e=0;e<m;++e){const s=n+e*y;if(s<0||s>=d.inWidth)continue;const r=a+e*h[1],o=i+s*d.inChannels;let l=t,u=r;for(let e=0;e<d.inChannels;++e){const t=I[o+e];for(let e=0;e<k;++e)S[l+e]+=t*N[u+e];l+=k,u+=k}}}}}}return n.makeTensorInfo(v.shape,v.dtype,v.values)}const dv={kernelName:ot,backendName:"cpu",kernelFunc:pv},fv={kernelName:lt,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,dy:a}=t,{strides:i,dilations:o,pad:l,dimRoundingMode:u,filterShape:c}=s;ow([r,a],"depthwiseConv2dNativeBackpropFilter");const h=no(r.shape,c,i,o,l,u,!0),{strideHeight:p,strideWidth:d,filterHeight:f,filterWidth:m}=h,g=new gr(h.filterShape,"float32"),y=h.padInfo.left,b=h.padInfo.top,x=h.outChannels/h.inChannels,w=n.data.get(r.dataId).values,k=new gr(r.shape,r.dtype,w),v=n.data.get(a.dataId).values,I=new gr(a.shape,a.dtype,v);for(let e=0;e<f;++e){const t=Math.max(0,Math.ceil((b-e)/p)),n=Math.min(h.outHeight,(h.inHeight+b-e)/p);for(let s=0;s<m;++s){const r=Math.max(0,Math.ceil((y-s)/d)),a=Math.min(h.outWidth,(h.inWidth+y-s)/d);for(let i=0;i<h.outChannels;++i){const o=Math.trunc(i/x),l=i%x;let u=0;for(let l=0;l<h.batchSize;++l)for(let c=t;c<n;++c){const t=e+c*p-b;for(let e=r;e<a;++e){const n=s+e*d-y;u+=k.get(l,t,n,o)*I.get(l,c,e,i)}}g.set(u,e,s,o,l)}}}return n.makeTensorInfo(g.shape,g.dtype,g.values)}},mv={kernelName:ut,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,filter:a}=t,{strides:i,dilations:o,pad:l,dimRoundingMode:u,inputShape:c}=s;ow([r,a],"depthwiseConv2DNativeBackpropInput");const h=te(r.shape),p=te(a.shape),d=no(c,a.shape,i,o,l,u,!0),f=new gr(d.inShape,"float32"),m=f.values,[g,y,b]=f.strides,x=n.data.get(r.dataId).values,[w,k,v]=h,I=n.data.get(a.dataId).values,[N,S,T]=p,{batchSize:$,filterHeight:E,filterWidth:C,inChannels:R,inHeight:A,inWidth:_,outChannels:D,outHeight:F,outWidth:O,strideHeight:M,strideWidth:L}=d,z=E-1-d.padInfo.top,B=C-1-d.padInfo.left,P=D/R;for(let e=0;e<$;++e)for(let t=0;t<R;++t)for(let n=0;n<A;++n){const s=n-z,r=Math.max(0,Math.ceil(s/M)),a=Math.min(F,(E+s)/M);for(let i=0;i<_;++i){const o=i-B,l=Math.max(0,Math.ceil(o/L)),u=Math.min(O,(C+o)/L);let c=0;for(let n=r;n<a;++n){const r=n*M-s;for(let s=l;s<u;++s){const a=w*e+k*n+v*s,i=N*(E-1-r)+S*(C-1-(s*L-o))+T*t;for(let e=0;e<P;++e)c+=x[a+(t*P+e)]*I[i+e]}}m[g*e+y*n+b*i+t]=c}}return n.makeTensorInfo(f.shape,f.dtype,f.values)}},gv={kernelName:ct,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{x:s}=t,r=L(s.shape),a=n.data.get(s.dataId).values,i=Ua([r,r],s.dtype),o=i.values;for(let e=0;e<a.length;e++)o[e*r+e]=a[e];const l=[...s.shape,...s.shape];return n.makeTensorInfo(l,i.dtype,i.values)}},yv={kernelName:ht,backendName:"cpu",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:s,filter:r}=e,{strides:a,pad:i,dilations:o}=n,l=t,u=l.data.get(s.dataId).values,c=s.shape.length,h=l.data.get(r.dataId).values,p=r.shape.length,{batchSize:d,inHeight:f,inWidth:m,inChannels:g,outHeight:y,outWidth:b,padInfo:x,strideHeight:w,strideWidth:k,filterHeight:v,filterWidth:I,dilationHeight:N,dilationWidth:S,outShape:T}=Qi(s.shape,r.shape,a,i,"NHWC",o),$=L(T),E=T.length,C=K(s.dtype,$);for(let e=0;e<d;++e)for(let t=0;t<y;++t){const n=t*w-x.top;for(let a=0;a<b;++a){const i=a*k-x.left;for(let o=0;o<g;++o){let l=Number.MIN_SAFE_INTEGER;for(let t=0;t<v;++t){const a=n+t*N;if(a>=0&&a<f)for(let n=0;n<I;++n){const d=i+n*S;if(d>=0&&d<m){const i=le([e,a,d,o],c,te(s.shape)),f=le([t,n,o],p,te(r.shape)),m=u[i]+h[f];m>l&&(l=m)}}}C[le([e,t,a,o],E,te(T))]=l}}}return{dataId:l.write(nr(C,s.dtype),T,s.dtype),shape:T,dtype:s.dtype}}},bv={kernelName:dt,backendName:"cpu",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:s,filter:r,dy:a}=e,{strides:i,pad:o,dilations:l}=n,u=t,c=se(s.shape,u.data.get(s.dataId).values),h=se(r.shape,u.data.get(r.dataId).values),{batchSize:p,inHeight:d,inWidth:f,inChannels:m,outHeight:g,outWidth:y,padInfo:b,strideHeight:x,strideWidth:w,filterHeight:k,filterWidth:v,dilationHeight:I,dilationWidth:N,outShape:S}=Qi(s.shape,r.shape,i,o,"NHWC",l);F(a.rank===S.length,(()=>`Error in ${dt}, dy must have the same rank as output ${S.length}, but got ${a.rank}`));const T=se(S,u.data.get(a.dataId).values),$=ie(r.shape,r.dtype);for(let e=0;e<p;++e)for(let t=0;t<g;++t){const n=t*x-b.top;for(let s=0;s<y;++s){const r=s*w-b.left;for(let a=0;a<m;++a){let i=Number.MIN_SAFE_INTEGER,o=0,l=0;for(let t=0;t<k;++t){const s=n+t*I;if(s>=0&&s<d)for(let n=0;n<v;++n){const u=r+n*N;if(u>=0&&u<f){const r=c[e][s][u][a]+h[t][n][a];r>i&&(i=r,o=t,l=n)}}}$[o][l][a]+=T[e][t][s][a]}}}return{dataId:u.write(nr($,s.dtype),r.shape,r.dtype),shape:r.shape,dtype:r.dtype}}},xv={kernelName:pt,backendName:"cpu",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:s,filter:r,dy:a}=e,{strides:i,pad:o,dilations:l}=n,u=t,c=se(s.shape,u.data.get(s.dataId).values),h=se(r.shape,u.data.get(r.dataId).values),{batchSize:p,inHeight:d,inWidth:f,inChannels:m,outHeight:g,outWidth:y,padInfo:b,strideHeight:x,strideWidth:w,filterHeight:k,filterWidth:v,dilationHeight:I,dilationWidth:N,outShape:S}=Qi(s.shape,r.shape,i,o,"NHWC",l);F(a.rank===S.length,(()=>`Error in ${pt}, dy must have the same rank as output ${S.length}, but got ${a.rank}`));const T=se(S,u.data.get(a.dataId).values),$=ie(s.shape,s.dtype);for(let e=0;e<p;++e)for(let t=0;t<g;++t){const n=t*x-b.top;for(let s=0;s<y;++s){const r=s*w-b.left;for(let a=0;a<m;++a){let i=Number.MIN_SAFE_INTEGER,o=n<0?0:n,l=r<0?0:r;for(let t=0;t<k;++t){const s=n+t*I;if(s>=0&&s<d)for(let n=0;n<v;++n){const u=r+n*N;if(u>=0&&u<f){const r=c[e][s][u][a]+h[t][n][a];r>i&&(i=r,o=s,l=u)}}}$[e][o][l][a]+=T[e][t][s][a]}}}return{dataId:u.write(nr($,s.dtype),s.shape,s.dtype),shape:s.shape,dtype:s.dtype}}},wv={kernelName:"Draw",backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{image:r}=t,{canvas:a,options:i}=s,{contextOptions:o,imageOptions:l}=i||{},u=(null==l?void 0:l.alpha)||1,c=(null==o?void 0:o.contextType)||"2d";if("2d"!==c)throw new Error(`Context type ${o.contextType} is not supported by the CPU backend.`);const h=a.getContext(c,(null==o?void 0:o.contextAttributes)||{});if(null==h)throw new Error(`Could not get the context with ${c} type.`);const[p,d]=r.shape.slice(0,2),f=2===r.shape.length?1:r.shape[2],m=n.data.get(r.dataId).values,g="float32"===r.dtype?255:1,y=new Uint8ClampedArray(d*p*4);for(let e=0;e<p*d;++e){const t=[0,0,0,255*u];for(let n=0;n<f;n++){const s=m[e*f+n];if("float32"===r.dtype){if(s<0||s>1)throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${s}.`)}else if("int32"===r.dtype&&(s<0||s>255))throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${s}.`);1===f?(t[0]=s*g,t[1]=s*g,t[2]=s*g):t[n]=s*g}const n=4*e;y[n+0]=Math.round(t[0]),y[n+1]=Math.round(t[1]),y[n+2]=Math.round(t[2]),y[n+3]=Math.round(t[3])}a.width=d,a.height=p;const b=new ImageData(y,d,p);return h.putImageData(b,0,0),r}},kv=xw(((e,t)=>e*t)),vv=Pw(((e,t,n,s)=>({real:e*n-t*s,imag:e*s+t*n}))),Iv=Bw(cn,kv,vv),Nv={kernelName:cn,backendName:"cpu",kernelFunc:Iv};function Sv(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,keepDims:i}=s;let o;ow(r,"sum"),o="bool"===r.dtype?Lw({inputs:{x:r},backend:n,attrs:{dtype:"int32"}}):mw({inputs:{x:r},backend:n});const l=o.shape.length,u=G(a,o.shape),c=il(u,l);let h=u,p=o;null!=c&&(p=rk({inputs:{x:o},backend:n,attrs:{perm:c}}),h=ll(h.length,l)),al("sum",h,p.shape.length);const[d,f]=sl(p.shape,h);let m=Dw(n,d,Cr(p.dtype,"int32"));const g=L(f),y=n.data.get(m.dataId).values,b=n.data.get(p.dataId).values;for(let e=0;e<y.length;++e){const t=e*g;let n=0;for(let e=0;e<g;++e)n+=b[t+e];y[e]=n}if(i){const e=m;m=Hw({inputs:{x:m},backend:n,attrs:{shape:rl(m.shape,u)}}),n.disposeIntermediateTensorInfo(e)}return n.disposeIntermediateTensorInfo(o),null!=c&&n.disposeIntermediateTensorInfo(p),m}const Tv={kernelName:Jn,backendName:"cpu",kernelFunc:Sv},$v={kernelName:mt,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{equation:r}=s,a=t,{allDims:i,summedDims:o,idDims:l}=Uc(r,a.length);Hc(i.length,l,a);const{path:u,steps:c}=jc(o,l),h=c.length;let p=null,d=i.length;const f=[];for(let e=0;e<h;++e){for(const t of c[e]){const{permutationIndices:e,expandDims:s}=Gc(d,l[t]);let r;Kc(e)?r=a[t]:(r=rk({inputs:{x:a[t]},backend:n,attrs:{perm:e}}),f.push(r));const i=r.shape.slice();for(let e=0;e<s.length;++e)i.splice(s[e],0,1);z(r.shape,i)||(r=Hw({inputs:{x:r},backend:n,attrs:{shape:i}}),f.push(r)),null===p?p=r:(p=Iv({inputs:{a:r,b:p},backend:n}),f.push(p))}e<h-1&&(u[e]>=0&&(p=Sv({inputs:{x:p},backend:n,attrs:{axis:u[e]-(i.length-d),keepDims:!1}}),f.push(p)),d--)}for(const e of f)e!==p&&n.disposeIntermediateTensorInfo(e);return p}},Ev={kernelName:yt,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{dy:s,y:r}=t;ow([s,r],"eluGrad");const a=new Float32Array(L(r.shape)),i=n.data.get(r.dataId).values,o=n.data.get(s.dataId).values;for(let e=0;e<i.length;++e){const t=i[e];a[e]=t>=0?o[e]:o[e]*(t+1)}return n.makeTensorInfo(r.shape,"float32",a)}},Cv=xw(((e,t)=>e===t?1:0)),Rv=Bw(xt,Cv,null,"bool"),Av={kernelName:xt,backendName:"cpu",kernelFunc:Rv},_v=Sc,Dv=Tc,Fv=$c,Ov=Ec,Mv=Cc,Lv=Rc,zv=hw(bt,(e=>{const t=Math.sign(e),n=Math.abs(e),s=1/(1+_v*n);return t*(1-((((Lv*s+Mv)*s+Ov)*s+Fv)*s+Dv)*s*Math.exp(-n*n))})),Bv={kernelName:bt,backendName:"cpu",kernelFunc:zv},Pv=cw((e=>Math.exp(e))),Wv=pw(wt,Pv,"float32"),Vv={kernelName:wt,backendName:"cpu",kernelFunc:Wv};function Uv(e){const{inputs:t,backend:n,attrs:s}=e,{input:r}=t,{dim:a}=s,i=r.shape.length,o=r.shape.slice();let l=a;return a<0&&(F(-(i+1)<=a,(()=>`Axis must be in the interval [${-(i+1)}, ${i}]`)),l=i+a+1),o.splice(l,0,1),Hw({inputs:{x:r},backend:n,attrs:{shape:o}})}const Gv={kernelName:kt,backendName:"cpu",kernelFunc:Uv},Hv=cw((e=>Math.expm1(e))),jv=pw(vt,Hv),Kv={kernelName:vt,backendName:"cpu",kernelFunc:jv},qv=xw(((e,t)=>e/t)),Xv=Bw(ft,qv),Yv={kernelName:ft,backendName:"cpu",kernelFunc:Xv},Jv=xw(((e,t)=>e-t)),Zv=Pw(((e,t,n,s)=>({real:e-n,imag:t-s}))),Qv=Bw(ds,Jv,Zv),eI={kernelName:ds,backendName:"cpu",kernelFunc:Qv};function tI(e,t,n){const s=e.shape,r=s[0],a=s[1],i=n.data.get(e.dataId),o=i.complexTensorInfos.real,l=i.complexTensorInfos.imag,u=[r,a],c=L(u),h=j("float32",c),p=j("float32",c);for(let e=0;e<r;e++){const s=Rk({inputs:{x:o},backend:n,attrs:{begin:[e,0],size:[1,a]}}),r=Rk({inputs:{x:l},backend:n,attrs:{begin:[e,0],size:[1,a]}}),i=Aw({inputs:{real:s,imag:r},backend:n}),{real:u,imag:c}=nI(i,t,n),d=Ac(u,c);for(let t=0;t<a;t++){const n=Oc(d,t);h[e*a+t]=n.real,p[e*a+t]=n.imag}n.disposeIntermediateTensorInfo(s),n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(i)}const d=n.makeTensorInfo(u,"float32",h),f=n.makeTensorInfo(u,"float32",p),m=Aw({inputs:{real:d,imag:f},backend:n});return n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),m}function nI(e,t,n){const s=L(e.shape),r=n.data.get(e.dataId),a=n.data.get(r.complexTensorInfos.real.dataId).values,i=n.data.get(r.complexTensorInfos.imag.dataId).values;if((o=s)&o-1){const e=function(e,t,n){const s=new Float32Array(2*t);for(let r=0;r<t;r++){let a=0,i=0;for(let s=0;s<t;s++){const o=zc(r*s,t,n),l=Oc(e,s);a+=l.real*o.real-l.imag*o.imag,i+=l.real*o.imag+l.imag*o.real}n&&(a/=t,i/=t),Mc(s,a,i,r)}return s}(Ac(a,i),s,t);return _c(e)}{const r=sI(a,i,s,t,n),o=[e.shape[0],e.shape[1]];if(t){const e=n.makeTensorInfo(o,"float32",r.real),t=n.makeTensorInfo(o,"float32",r.imag),a=n.makeTensorInfo([],"float32",tr(s,"float32")),i=mw({inputs:{x:a},backend:n}),l=Yv.kernelFunc({inputs:{a:e,b:a},backend:n}),u=Yv.kernelFunc({inputs:{a:t,b:i},backend:n}),c=n.data.get(l.dataId).values,h=n.data.get(u.dataId).values;return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(l),n.disposeIntermediateTensorInfo(u),{real:c,imag:h}}return r}var o}function sI(e,t,n,s,r){if(1===n)return{real:e,imag:t};const a=Ac(e,t),i=n/2,o=Dc(a),l=o.real,u=o.imag,c=[l.length],h=r.makeTensorInfo(c,"float32",l),p=r.makeTensorInfo(c,"float32",u),d=Aw({inputs:{real:h,imag:p},backend:r}),f=Fc(a),m=f.real,g=f.imag,y=[m.length],b=r.makeTensorInfo(y,"float32",m),x=r.makeTensorInfo(y,"float32",g),w=Aw({inputs:{real:b,imag:x},backend:r}),k=sI(l,u,i,s,r),v=k.real,I=k.imag,N=[v.length],S=r.makeTensorInfo(N,"float32",v),T=r.makeTensorInfo(N,"float32",I),$=Aw({inputs:{real:S,imag:T},backend:r}),E=sI(m,g,i,s,r),C=E.real,R=E.imag,A=[C.length],_=r.makeTensorInfo(A,"float32",C),D=r.makeTensorInfo(A,"float32",R),F=Aw({inputs:{real:_,imag:D},backend:r}),O=Lc(n,s),M=[O.real.length],L=r.makeTensorInfo(M,"float32",O.real),z=r.makeTensorInfo(M,"float32",O.imag),B=Aw({inputs:{real:L,imag:z},backend:r}),P=Iv({inputs:{a:B,b:F},backend:r}),W=Uw({inputs:{a:$,b:P},backend:r}),V=Qv({inputs:{a:$,b:P},backend:r}),U=Fw({inputs:{input:W},backend:r}),G=Fw({inputs:{input:V},backend:r}),H=jk({inputs:{input:W},backend:r}),j=jk({inputs:{input:V},backend:r}),K=qk({inputs:[U,G],backend:r,attrs:{axis:0}}),q=qk({inputs:[H,j],backend:r,attrs:{axis:0}}),X=r.data.get(K.dataId).values,Y=r.data.get(q.dataId).values;return r.disposeIntermediateTensorInfo(h),r.disposeIntermediateTensorInfo(p),r.disposeIntermediateTensorInfo(d),r.disposeIntermediateTensorInfo(b),r.disposeIntermediateTensorInfo(x),r.disposeIntermediateTensorInfo(w),r.disposeIntermediateTensorInfo(S),r.disposeIntermediateTensorInfo(T),r.disposeIntermediateTensorInfo($),r.disposeIntermediateTensorInfo(_),r.disposeIntermediateTensorInfo(D),r.disposeIntermediateTensorInfo(F),r.disposeIntermediateTensorInfo(L),r.disposeIntermediateTensorInfo(z),r.disposeIntermediateTensorInfo(B),r.disposeIntermediateTensorInfo(P),r.disposeIntermediateTensorInfo(W),r.disposeIntermediateTensorInfo(V),r.disposeIntermediateTensorInfo(U),r.disposeIntermediateTensorInfo(H),r.disposeIntermediateTensorInfo(G),r.disposeIntermediateTensorInfo(j),r.disposeIntermediateTensorInfo(K),r.disposeIntermediateTensorInfo(q),{real:X,imag:Y}}const rI={kernelName:It,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{input:s}=t,r=L(s.shape),a=s.shape[s.shape.length-1],i=Hw({inputs:{x:s},backend:n,attrs:{shape:[r/a,a]}}),o=tI(i,!1,n),l=Hw({inputs:{x:o},backend:n,attrs:{shape:s.shape}});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(o),l}};function aI(e){const{backend:t,attrs:n}=e,{shape:s,value:r,dtype:a}=n,i=a||Z(r),o=K(i,L(s));return function(e,t){e.fill(t)}(o,r),t.makeTensorInfo(s,i,o)}const iI={kernelName:Nt,backendName:"cpu",kernelFunc:aI},oI={kernelName:St,backendName:"cpu",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{image:s}=e,r=n,a=j(s.dtype,L(s.shape)),[i,o,l,u]=s.shape,c=r.data.get(s.dataId).values;for(let e=0;e<i;e++){const t=e*l*o*u;for(let e=0;e<o;e++){const n=e*(l*u);for(let e=0;e<l;e++){const s=e*u;for(let r=0;r<u;r++){const i=Math.round(l-e-1),o=t+n+s+r;let h=c[o];i>=0&&i<l&&(h=c[t+n+i*u+r]),a[o]=h}}}}return{dataId:r.write(a,s.shape,s.dtype),shape:s.shape,dtype:s.dtype}}},lI=cw((e=>Math.floor(e))),uI=pw(Tt,lI),cI={kernelName:Tt,backendName:"cpu",kernelFunc:uI},hI=xw(((e,t)=>Math.floor(e/t))),pI=Bw($t,hI,null,"int32"),dI={kernelName:$t,backendName:"cpu",kernelFunc:pI},fI={kernelName:$s,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,filter:a,bias:i,preluActivationWeights:o}=t,{strides:l,pad:u,dataFormat:c,dilations:h,dimRoundingMode:p,activation:d,leakyreluAlpha:f}=s;let m=Yk({inputs:{x:r,filter:a},backend:n,attrs:{strides:l,pad:u,dataFormat:c,dilations:h,dimRoundingMode:p}});if(i){const e=m;if("NCHW"===c&&1===i.shape.length&&1!==i.shape[0]){const e=Hw({inputs:{x:i},backend:n,attrs:{shape:[i.shape[0],1,1]}});m=Uw({inputs:{a:m,b:e},backend:n}),n.disposeIntermediateTensorInfo(e)}else m=Uw({inputs:{a:m,b:i},backend:n});n.disposeIntermediateTensorInfo(e)}if(d){const e=m;if("NCHW"===c&&"prelu"===d&&1===o.shape.length&&1!==o.shape[0]){const e=Hw({inputs:{x:o},backend:n,attrs:{shape:[o.shape[0],1,1]}});m=Rw(n,m,d,e,f),n.disposeIntermediateTensorInfo(e)}else m=Rw(n,m,d,o,f);n.disposeIntermediateTensorInfo(e)}return m}},mI={kernelName:Es,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,filter:a,bias:i,preluActivationWeights:o}=t,{strides:l,pad:u,dataFormat:c,dilations:h,dimRoundingMode:p,activation:d,leakyreluAlpha:f}=s;let m=pv({inputs:{x:r,filter:a},backend:n,attrs:{strides:l,pad:u,dataFormat:c,dilations:h,dimRoundingMode:p}});if(i){const e=m;m=Uw({inputs:{a:m,b:i},backend:n}),n.disposeIntermediateTensorInfo(e)}if(d){const e=m;m=Rw(n,m,d,o,f),n.disposeIntermediateTensorInfo(e)}return m}};function gI(e,t,n,s,r,a,i,o,l){const u=Ua([s,a],n);for(let n=0;n<s;n++){const s=[];let c=0;for(let t=0;t<r;t++){const a=e[n*r+t];c+=a*i[t],s.push(a)}if(c<0||c>=l/a)throw new Error(`Invalid indices: ${s} does not index into ${o}`);for(let e=0;e<a;e++)u.values[n*a+e]=t.get(...t.indexToLoc(c*a+e))}return u}const yI={kernelName:Rt,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{params:s,indices:r}=t,a=L(s.shape),i=r.shape,o=i[i.length-1],[l,u,c,h]=xc(s,r);if(0===u)return n.makeTensorInfo(l,s.dtype,[]);const p=gI(n.data.get(r.dataId).values,n.bufferSync(s),s.dtype,u,o,c,h,s.shape,a);return n.makeTensorInfo(l,s.dtype,p.values)}};function bI(e,t,n){const s=Ua(n,e.dtype);for(let n=0;n<s.size;++n){const r=s.indexToLoc(n).slice(),a=r[0],i=r[2],o=t.locToIndex([a,i]);r[2]=t.values[o];const l=e.locToIndex(r);0<=l&&l<e.values.length&&(s.values[n]=e.values[l])}return s}const xI={kernelName:Ct,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,indices:a}=t,{axis:i,batchDims:o}=s;ow([r,a],"gatherV2");const l=G(i,r.shape)[0],u=n.data.get(a.dataId).values,c=r.shape[l];for(let e=0;e<u.length;++e){const t=u[e];F(t<=c-1&&t>=0,(()=>`GatherV2: the index value ${t} is not in [0, ${c-1}]`))}let h=o;null==o&&(h=0);const p=L(a.shape),d=ch(r,a,l,h),f=Hw({inputs:{x:r},backend:n,attrs:{shape:[d.batchSize,d.outerSize,d.dimSize,d.sliceSize]}}),m=Hw({inputs:{x:a},backend:n,attrs:{shape:[d.batchSize,p/d.batchSize]}}),g=[d.batchSize,d.outerSize,p/d.batchSize,d.sliceSize],y=n.bufferSync(m),b=bI(n.bufferSync(f),y,g);return n.disposeIntermediateTensorInfo(f),n.disposeIntermediateTensorInfo(m),n.makeTensorInfo(d.outputShape,b.dtype,b.values)}},wI=xw(((e,t)=>e>t?1:0)),kI=Bw(At,wI,null,"bool"),vI={kernelName:At,backendName:"cpu",kernelFunc:kI},II=xw(((e,t)=>e>=t?1:0)),NI=Bw(_t,II,null,"bool"),SI={kernelName:_t,backendName:"cpu",kernelFunc:NI},TI={kernelName:Ft,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{input:s}=t,r=L(s.shape),a=s.shape[s.shape.length-1],i=Hw({inputs:{x:s},backend:n,attrs:{shape:[r/a,a]}}),o=tI(i,!0,n),l=Hw({inputs:{x:o},backend:n,attrs:{shape:s.shape}});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(o),l}},$I=hw(Mt,(e=>Number.isFinite(e)?1:0),"bool"),EI={kernelName:Mt,backendName:"cpu",kernelFunc:$I},CI=hw(Lt,(e=>Math.abs(e)===1/0?1:0),"bool"),RI={kernelName:Lt,backendName:"cpu",kernelFunc:CI},AI=hw(zt,(e=>Number.isNaN(e)?1:0),"bool"),_I={kernelName:zt,backendName:"cpu",kernelFunc:AI},DI=xw(((e,t)=>e<t?1:0)),FI=Bw(Pt,DI,null,"bool"),OI={kernelName:Pt,backendName:"cpu",kernelFunc:FI},MI=xw(((e,t)=>e<=t?1:0)),LI=Bw(Wt,MI,null,"bool"),zI={kernelName:Wt,backendName:"cpu",kernelFunc:LI};function BI(e,t,n){const s=(t-e)/(n-1),r=ae(n,"float32");r[0]=e;for(let e=1;e<r.length;e++)r[e]=r[e-1]+s;return r}const PI={kernelName:Vt,backendName:"cpu",kernelFunc:function(e){const{backend:t,attrs:n}=e,{start:s,stop:r,num:a}=n,i=BI(s,r,a);return t.makeTensorInfo([i.length],"float32",i)}},WI=cw((e=>Math.log(e))),VI=pw(Ut,WI),UI={kernelName:Ut,backendName:"cpu",kernelFunc:VI},GI=hw(Gt,(e=>Math.log1p(e))),HI={kernelName:Gt,backendName:"cpu",kernelFunc:GI},jI=xw(((e,t)=>e&&t)),KI=Bw(Ht,jI,null,"bool"),qI={kernelName:Ht,backendName:"cpu",kernelFunc:KI},XI=hw(jt,(e=>e?0:1),"bool"),YI={kernelName:jt,backendName:"cpu",kernelFunc:XI},JI=xw(((e,t)=>e||t)),ZI=Bw(Kt,JI,null,"bool"),QI={kernelName:Kt,backendName:"cpu",kernelFunc:ZI},eN={kernelName:qt,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{depthRadius:a,bias:i,alpha:o,beta:l}=s;ow(r,"LRN");const u=r.shape[3],c=u-1,h=n.data.get(r.dataId).values,p=L(r.shape),d=new Float32Array(p);function f(e){const t=e%u;let n=e-t+Math.max(0,t-a);const s=e-t+Math.min(t+a,c);let r=0;for(;n<=s;n++){const e=h[n];r+=e*e}return r}for(let e=0;e<p;e++){const t=f(e),n=h[e]*Math.pow(i+o*t,-l);d[e]=n}return n.makeTensorInfo(r.shape,r.dtype,d)}},tN={kernelName:Xt,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,y:a,dy:i}=t,{depthRadius:o,bias:l,alpha:u,beta:c}=s;ow(i,"LRNGrad");const h=L(i.shape),p=i.shape[3],d=n.data.get(i.dataId).values,f=n.data.get(r.dataId).values,m=n.data.get(a.dataId).values,g=new Float32Array(h),y=h;for(let e=0;e<y;e++){const t=e%p,n=e-t+Math.max(0,t-o),s=e-t+Math.min(p,t+o+1);let r=0;for(let e=n;e<s;e++)r+=Math.pow(f[e],2);r=u*r+l;for(let t=n;t<s;t++){let n=-2*u*c*f[t]*m[e]/r;e===t&&(n+=Math.pow(r,-c)),n*=d[e],g[t]+=n}}return n.makeTensorInfo(i.shape,r.dtype,g)}};function nN(e,t,n,s){const r=j(s,L(n));for(let n=0;n<r.length;++n){const s=n*t;let a=e[s];for(let n=0;n<t;++n){const t=e[s+n];(Number.isNaN(t)||t>a)&&(a=t)}r[n]=a}return r}function sN(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{reductionIndices:a,keepDims:i}=s,o=n;let l=r.shape;const u=l.length,c=G(a,l);let h=c;const p=il(h,u);let d=o.data.get(r.dataId).values;if(null!=p){const e=new Array(u);for(let t=0;t<e.length;t++)e[t]=l[p[t]];d=sk(d,l,r.dtype,p,e),h=ll(h.length,u),l=e}ow(r,"max"),al("max",h,u);const[f,m]=sl(l,h),g=nN(d,L(m),f,r.dtype),y=o.write(g,f,r.dtype);let b=f;return i&&(b=rl(f,c)),{dataId:y,shape:b,dtype:r.dtype}}const rN={kernelName:Yt,backendName:"cpu",kernelFunc:sN},aN=xw(((e,t)=>Math.max(e,t))),iN=Bw(Jt,aN),oN={kernelName:Jt,backendName:"cpu",kernelFunc:iN},lN={kernelName:Zt,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t;ow(r,"maxPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:l}=s;F(co(i,1),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));const u=eo(r.shape,a,i,1,o,l);let c;if(1===u.filterWidth&&1===u.filterHeight&&z(u.inShape,u.outShape))c=mw({inputs:{x:r},backend:n});else{const e=n.data.get(r.dataId).values,t=te(r.shape),s=kk(e,r.shape,r.dtype,t,u,"max");c=n.makeTensorInfo(u.outShape,r.dtype,s.values)}return c}},uN={kernelName:en,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{filterSize:a,strides:i,pad:o,dimRoundingMode:l,dataFormat:u}=s;ow(r,"maxPool3d");const c=to(r.shape,a,i,1,o,l,u),h=Ik(n.data.get(r.dataId).values,r.shape,r.dtype,te(r.shape),c,"max");return n.makeTensorInfo(h.shape,"float32",h.values)}},cN={kernelName:tn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,input:a}=t,{filterSize:i,strides:o,pad:l,dimRoundingMode:u}=s;ow([r,a],"maxPool3DGrad");const c=to(a.shape,i,o,1,l,u),h=function(e,t){const n=Ua(t.outShape,"int32"),s=t.strideDepth,r=t.strideHeight,a=t.strideWidth,i=t.dilationDepth,o=t.dilationHeight,l=t.dilationWidth,u=t.effectiveFilterDepth,c=t.effectiveFilterHeight,h=t.effectiveFilterWidth,p=t.padInfo.front,d=t.padInfo.top,f=t.padInfo.left;for(let m=0;m<t.batchSize;++m)for(let g=0;g<t.inChannels;++g)for(let y=0;y<t.outDepth;++y){const b=y*s-p;let x=b;for(;x<0;)x+=i;const w=Math.min(t.inDepth,u+b);for(let s=0;s<t.outHeight;++s){const u=s*r-d;let p=u;for(;p<0;)p+=o;const k=Math.min(t.inHeight,c+u);for(let r=0;r<t.outWidth;++r){const d=r*a-f;let v=d;for(;v<0;)v+=l;const I=Math.min(t.inWidth,h+d);let N=Number.NEGATIVE_INFINITY,S=-1;for(let t=x;t<w;t+=i){const n=t-b;for(let s=p;s<k;s+=o){const r=s-u;for(let a=v;a<I;a+=l){const i=a-d,o=e.get(m,t,s,a,g);o>=N&&(N=o,S=n*c*h+r*c+i)}}}n.set(S,m,y,s,r,g)}}}return n}(n.bufferSync(a),c),p=c.strideDepth,d=c.strideHeight,f=c.strideWidth,m=c.dilationDepth,g=c.dilationHeight,y=c.dilationWidth,b=c.effectiveFilterDepth,x=c.effectiveFilterHeight,w=c.effectiveFilterWidth,k=b-1-c.padInfo.front,v=w-1-c.padInfo.left,I=x-1-c.padInfo.top,N=Ua(a.shape,"float32"),S=n.bufferSync(r);for(let e=0;e<c.batchSize;++e)for(let t=0;t<c.inChannels;++t)for(let n=0;n<c.inDepth;++n)for(let s=0;s<c.inHeight;++s)for(let r=0;r<c.inWidth;++r){const a=n-k,i=s-I,o=r-v;let l=0;for(let n=0;n<b;n+=m){const s=(a+n)/p;if(!(s<0||s>=c.outDepth||Math.floor(s)!==s))for(let r=0;r<x;r+=g){const a=(i+r)/d;if(!(a<0||a>=c.outHeight||Math.floor(a)!==a))for(let i=0;i<w;i+=y){const u=(o+i)/f;if(u<0||u>=c.outWidth||Math.floor(u)!==u)continue;const p=b*x*w-1-h.get(e,s,a,u,t)===n*x*w+r*w+i?1:0;0!==p&&(l+=S.get(e,s,a,u,t)*p)}}}N.set(l,e,n,s,r,t)}return n.makeTensorInfo(N.shape,N.dtype,N.values)}},hN={kernelName:Qt,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,input:a,output:i}=t,o=a;ow([a,i],"maxPoolGrad");const{filterSize:l,strides:u,pad:c,dimRoundingMode:h}=s,p=eo(o.shape,l,u,1,c,h),d=n.data.get(o.dataId).values,f=Ua(p.outShape,o.dtype,vk(d,o.shape,o.dtype,p).values),m=p.strideHeight,g=p.strideWidth,y=p.dilationHeight,b=p.dilationWidth,x=p.effectiveFilterHeight,w=p.effectiveFilterWidth,k=w-1-p.padInfo.left,v=x-1-p.padInfo.top,I=Ua(o.shape,"float32"),N=n.data.get(r.dataId).values,S=Ua(r.shape,"float32",N);for(let e=0;e<p.batchSize;++e)for(let t=0;t<p.inChannels;++t)for(let n=0;n<p.inHeight;++n)for(let s=0;s<p.inWidth;++s){const r=n-v,a=s-k;let i=0;for(let n=0;n<x;n+=y){const s=(r+n)/m;if(!(s<0||s>=p.outHeight||Math.floor(s)!==s))for(let r=0;r<w;r+=b){const o=(a+r)/g;if(o<0||o>=p.outWidth||Math.floor(o)!==o)continue;const l=x*w-1-f.get(e,s,o,t)===n*w+r?1:0;0!==l&&(i+=S.get(e,s,o,t)*l)}}I.set(i,e,n,s,t)}return n.makeTensorInfo(I.shape,I.dtype,I.values)}},pN={kernelName:nn,backendName:"cpu",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{x:s}=e,{filterSize:r,strides:a,pad:i,includeBatchInIndex:o}=t,l=n;ow(s,"MaxPoolWithArgmax");const u=l.data.get(s.dataId).values,c=eo(s.shape,r,a,[1,1],i),[h,p]=function(e,t,n,s,r){const a=kk(e,0,n,te(t),r,"max"),i=vk(e,t,n,r,!0,s);return[a.values,i.values]}(u,s.shape,s.dtype,o,c),d=l.write(h,c.outShape,s.dtype),f=l.write(p,c.outShape,s.dtype);return[{dataId:d,shape:c.outShape,dtype:s.dtype},{dataId:f,shape:c.outShape,dtype:"int32"}]}},dN={kernelName:sn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,keepDims:i}=s,o=G(a,r.shape),l=L(sl(r.shape,o)[1]),u=[],c=n.makeTensorInfo([],"float32",new Float32Array([l]));u.push(c);const h=Lw({inputs:{x:r},backend:n,attrs:{dtype:"float32"}});u.push(h);const p=Xv({inputs:{a:h,b:c},backend:n});u.push(p);const d=Sv({inputs:{x:p},backend:n,attrs:{axis:a,keepDims:i}});return u.forEach((e=>n.disposeIntermediateTensorInfo(e))),d}},fN={kernelName:rn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,keepDims:i}=s;ow(r,"min");const o=G(a,r.shape);let l=o;const u=il(l,r.shape.length);let c=r;null!=u&&(c=rk({inputs:{x:r},backend:n,attrs:{perm:u}}),l=ll(l.length,r.shape.length)),al("min",l,c.shape.length);const[h,p]=sl(c.shape,l),d=L(p),f=ae(L(h),c.dtype),m=n.data.get(c.dataId).values;for(let e=0;e<f.length;++e){const t=e*d;let n=m[t];for(let e=0;e<d;++e){const s=m[t+e];(Number.isNaN(s)||s<n)&&(n=s)}f[e]=n}null!=u&&n.disposeIntermediateTensorInfo(c);const g=n.makeTensorInfo(h,c.dtype,f);if(i){const e=Hw({inputs:{x:g},backend:n,attrs:{shape:rl(h,o)}});return n.disposeIntermediateTensorInfo(g),e}return g}},mN=xw(((e,t)=>Math.min(e,t))),gN=Bw(an,mN),yN={kernelName:an,backendName:"cpu",kernelFunc:gN},bN={kernelName:on,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{paddings:a,mode:i}=s;ow(r,"mirrorPad");const o=a.map(((e,t)=>e[0]+r.shape[t]+e[1])),l=a.map((e=>e[0])),u=a.map(((e,t)=>e[0]+r.shape[t])),c="reflect"===i?0:1,h=n.data.get(r.dataId).values,p=r.shape.length,d=te(r.shape),f=L(o),m=o.length,g=te(o),y=j(r.dtype,f);for(let e=0;e<f;e++){let t=ue(e,m,g);for(let e=0;e<m;e++)t[e]<l[e]?t[e]=2*l[e]-t[e]-c:t[e]>=u[e]&&(t[e]=2*(u[e]-1)-t[e]+c);t=t.map(((e,t)=>e-l[t]));const n=le(t,p,d);y[e]=h[n]}return{dataId:n.write(y,o,r.dtype),shape:o,dtype:r.dtype}}},xN=xw(((e,t)=>{const n=e%t;return e<0&&t<0||e>=0&&t>=0?n:(n+t)%t})),wN=Bw(ln,xN),kN={kernelName:ln,backendName:"cpu",kernelFunc:wN};function vN(e){const{inputs:t,backend:n,attrs:s}=e,{logits:r}=t,{dim:a}=s,i=r.shape.length;let o=a;if(-1===o&&(o=i-1),o!==i-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${i} and dim was ${o}`);const l=G([o],r.shape),u=sN({inputs:{x:r},backend:n,attrs:{reductionIndices:l,keepDims:!1}}),c=rl(u.shape,l),h=Hw({inputs:{x:u},backend:n,attrs:{shape:c}}),p=Qv({inputs:{a:r,b:h},backend:n}),d=Wv({inputs:{x:p},backend:n}),f=Sv({inputs:{x:d},backend:n,attrs:{axis:l,keepDims:!1}}),m=Hw({inputs:{x:f},backend:n,attrs:{shape:c}}),g=Xv({inputs:{a:d,b:m},backend:n});return n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(p),n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),n.disposeIntermediateTensorInfo(m),g}const IN={kernelName:es,backendName:"cpu",kernelFunc:vN},NN={kernelName:un,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{logits:r}=t,{numSamples:a,seed:i,normalized:o}=s;ow(r,"multinomial");const l=o?r:vN({inputs:{logits:r},backend:n,attrs:{dim:-1}}),u=l.shape[0],c=l.shape[1],h=n.data.get(l.dataId).values,p=[u,a],d=ae(L(p),"int32");for(let e=0;e<u;++e){const t=e*c,n=new Float32Array(c-1);n[0]=h[t];for(let e=1;e<n.length;++e)n[e]=n[e-1]+h[t+e];const s=Tl.alea(i.toString()),r=e*a;for(let e=0;e<a;++e){const t=s();d[r+e]=n.length;for(let s=0;s<n.length;s++)if(t<n[s]){d[r+e]=s;break}}}return o||n.disposeIntermediateTensorInfo(l),n.makeTensorInfo(p,"int32",d)}};function SN(e,t,n){const s=tr(-1,n);return kv([],t,s,e,n)}const TN={kernelName:hn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{x:s}=t;ow(s,"neg");const r=n.data.get(s.dataId).values,[a,i]=SN(r,s.shape,s.dtype);return n.makeTensorInfo(i,s.dtype,a)}},$N=Eu,EN={kernelName:dn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{boxes:r,scores:a}=t,{maxOutputSize:i,iouThreshold:o,scoreThreshold:l}=s;ow(r,"NonMaxSuppression");const u=n.data.get(r.dataId).values,c=n.data.get(a.dataId).values,{selectedIndices:h}=$N(u,c,i,o,l);return n.makeTensorInfo([h.length],"int32",new Int32Array(h))}},CN=Cu,RN={kernelName:fn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{boxes:r,scores:a}=t,{maxOutputSize:i,iouThreshold:o,scoreThreshold:l,padToMaxOutputSize:u}=s;ow(r,"NonMaxSuppressionPadded");const c=n.data.get(r.dataId).values,h=n.data.get(a.dataId).values,{selectedIndices:p,validOutputs:d}=CN(c,h,i,o,l,u);return[n.makeTensorInfo([p.length],"int32",new Int32Array(p)),n.makeTensorInfo([],"int32",new Int32Array([d]))]}},AN=Ru,_N={kernelName:mn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{boxes:r,scores:a}=t,{maxOutputSize:i,iouThreshold:o,scoreThreshold:l,softNmsSigma:u}=s;ow(r,"NonMaxSuppressionWithScore");const c=n.data.get(r.dataId).values,h=n.data.get(a.dataId).values,p=i,d=o,f=l,m=u,{selectedIndices:g,selectedScores:y}=AN(c,h,p,d,f,m);return[n.makeTensorInfo([g.length],"int32",new Int32Array(g)),n.makeTensorInfo([y.length],"float32",new Float32Array(y))]}},DN=xw(((e,t)=>e!==t?1:0)),FN=Bw(pn,DN,null,"bool"),ON={kernelName:pn,backendName:"cpu",kernelFunc:FN},MN={kernelName:yn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{indices:r}=t,{dtype:a,depth:i,onValue:o,offValue:l}=s;ow(r,"oneHot");const u=L(r.shape),c=new Float32Array(u*i);c.fill(l);const h=n.data.get(r.dataId).values;for(let e=0;e<u;++e)h[e]>=0&&h[e]<i&&(c[e*i+h[e]]=o);return n.makeTensorInfo([...r.shape,i],a,c)}};function LN(e){const{inputs:t,backend:n}=e,{x:s}=t;if("string"===s.dtype)throw new Error("zerosLike is not supported for string tensors");if("complex64"===s.dtype){const e=Fw({inputs:{input:s},backend:n}),t=LN({inputs:{x:e},backend:n}),r=jk({inputs:{input:s},backend:n}),a=LN({inputs:{x:r},backend:n}),i=Aw({inputs:{real:t,imag:a},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(a),i}return aI({backend:n,attrs:{shape:s.shape,value:0,dtype:s.dtype}})}const zN={kernelName:Is,backendName:"cpu",kernelFunc:LN},BN={kernelName:gn,backendName:"cpu",kernelFunc:function e(t){const{inputs:n,backend:s}=t,{x:r}=n;if("string"===r.dtype)throw new Error("onesLike is not supported for string tensors");if("complex64"===r.dtype){const t=Fw({inputs:{input:r},backend:s}),n=e({inputs:{x:t},backend:s}),a=jk({inputs:{input:r},backend:s}),i=LN({inputs:{x:a},backend:s}),o=Aw({inputs:{real:n,imag:i},backend:s});return s.disposeIntermediateTensorInfo(t),s.disposeIntermediateTensorInfo(n),s.disposeIntermediateTensorInfo(a),s.disposeIntermediateTensorInfo(i),o}return aI({backend:s,attrs:{shape:r.shape,value:1,dtype:r.dtype}})}};function PN(e){const{inputs:t,backend:n,attrs:s}=e,{axis:r}=s;if(1===t.length)return Uv({inputs:{input:t[0]},backend:n,attrs:{dim:r}});const a=t[0].shape,i=t[0].dtype;t.forEach((e=>{O(a,e.shape,"All tensors passed to stack must have matching shapes"),F(i===e.dtype,(()=>"All tensors passed to stack must have matching dtypes"))}));const o=[],l=qk({inputs:t.map((e=>{const t=Uv({inputs:{input:e},backend:n,attrs:{dim:r}});return o.push(t),t})),backend:n,attrs:{axis:r}});return o.forEach((e=>n.disposeIntermediateTensorInfo(e))),l}const WN={kernelName:bn,backendName:"cpu",kernelFunc:PN},VN={kernelName:xn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{paddings:a,constantValue:i}=s;ow(r,"pad");const o=a.map(((e,t)=>e[0]+r.shape[t]+e[1])),l=a.map((e=>e[0])),u=n.data.get(r.dataId).values,c=L(r.shape),h=r.shape.length,p=te(r.shape),d=L(o),f=o.length,m=te(o),g=j(r.dtype,d);0!==i&&g.fill(i);for(let e=0;e<c;e++)g[le(ue(e,h,p).map(((e,t)=>e+l[t])),f,m)]=u[e];return{dataId:n.write(g,o,r.dtype),shape:o,dtype:r.dtype}}},UN=xw(((e,t)=>Math.pow(e,t))),GN=Bw(wn,UN),HN={kernelName:wn,backendName:"cpu",kernelFunc:GN};function jN(e,t,n,s){const[r,a]=sl(e,s),i=Cr(t,"int32"),o=ae(L(r),i),l=L(a);for(let e=0;e<o.length;++e){const t=e*l;let s=1;for(let e=0;e<l;++e)s*=n[t+e];o[e]=s}return{outVals:o,outShape:r,outDtype:i}}const KN={kernelName:vn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,keepDims:i}=s;ow(r,"prod");const o=r.shape.length,l=G(a,r.shape),u=il(l,o);let c=l,h=r;const p=[];null!=u&&(h=rk({inputs:{x:r},backend:n,attrs:{perm:u}}),p.push(h),c=ll(c.length,o));const d=n.data.get(h.dataId).values,{outVals:f,outShape:m,outDtype:g}=jN(h.shape,h.dtype,d,c);let y=m;return i&&(y=rl(m,l)),p.forEach((e=>n.disposeIntermediateTensorInfo(e))),n.makeTensorInfo(y,g,f)}};function qN(e,t){const n=e.slice(0,t);for(;n.length<t;)n.push(1);for(let s=t;s<e.length;s++)n[t-1]*=e[s];return n}function XN(e,t,n,s,r,a,i,o){if(0===e.length)throw new Error("paramsNestedSplits must be non empty");if(0===t[0].length)throw new Error("Split tensors must not be scalars");if(function(e,t,n){e.forEach(((e,s)=>{if(e<0||e>=n){const r=ue(s,t.length,te(t)).join(",");throw new Error(`indices[${r}] = ${e} is not in [0, ${n})`)}}))}(a,i,t[0][0]-1),0===s.length)throw new Error("params.rank must be nonzero");const l=s[0],{outSplits:u,valueSlices:c,numValues:h}=function(e,t,n,s){const r=[];let a=0;const i=t.length-1+n.length,o=new Array(i).fill(null).map((()=>[0]));!function(e,t){for(let n=0;n<e.length;++n){const s=e[n],r=n===e.length-1?t:e[n+1].length;if(0===s.length)throw new Error("Ragged splits may not be empty");if(s[0]<0)throw new Error("Ragged splits must be non-negative");if(s[s.length-1]>r)throw new Error("Ragged splits must not point past values");for(let e=1;e<s.length;++e)if(s[e-1]>s[e])throw new Error("Ragged splits must be sorted in ascending order")}}(n,s);let l=1;for(let e=0;e<t.length-1;++e){l*=t[e];const n=t[e+1];for(let t=1;t<l+1;++t)o[e].push(t*n)}for(let s=0;s<e.length;++s){let i=e[s],l=e[s]+1;for(let e=0;e<n.length;++e){const s=n[e],r=e+t.length-1;if(r>=0){const e=o[r],t=e[e.length-1]-s[i];for(let e=i;e<l;++e)o[r].push(s[e+1]+t)}i=s[i],l=s[l]}l!==i&&(r.push([i,l]),a+=l-i)}return{outSplits:o,valueSlices:r,numValues:a}}(a,i,e,l),p=function(e){const t=[];for(let n=0;n<e.length;++n){const s=K("int32",e[n].length);t.push(s),e[n].forEach(((e,t)=>s[t]=e))}return t}(u),d=function(e,t,n,s,r){const a=t.slice();a[0]=r;const i=K(n,L(a)),o=e.length;return function(e,t,n,s,r,a){const i=qN(t,2)[1],o=qN(a,2)[1];let l=0;for(const t of n)for(let n=t[0];n<t[1];++n){for(let t=0;t<s;++t)r[l*o+t]=e[n*i+t];++l}}(e,t,s,0===o?0:o/t[0],i,a),[i,a]}(n,s,r,c,h);return[p,d[0],d[1]]}const YN={kernelName:In,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{paramsNestedSplits:r,paramsDenseValues:a,indices:i}=t,{outputRaggedRank:o}=s,l=r.map((e=>n.data.get(e.dataId).values)),u=r.map((e=>e.shape)),c=n.data.get(a.dataId).values,h=n.data.get(i.dataId).values,[p,d,f]=XN(l,u,c,a.shape,a.dtype,h,i.shape),m=p.map((e=>n.makeTensorInfo([e.length],"int32",e))),g=n.makeTensorInfo(f,a.dtype,d);return m.concat([g])}},JN=2147483647;function ZN(e,t,n,s,r,a,i){if(t.length>1)throw new Error("starts must be a scalar or vector");if(r.length>1)throw new Error("limits must be a scalar or vector");if(i.length>1)throw new Error("deltas must be a scalar or vector");const o=0===t.length,l=0===r.length,u=0===i.length,c=[];o||c.push(t[0]),l||c.push(r[0]),u||c.push(i[0]);for(let e=1;e<c.length;++e)if(c[e]!==c[e-1])throw new Error("starts, limits, and deltas must have the same shape");const h=0===c.length?1:c[0],p=K("int32",h+1);p[0]=0;for(let t=0;t<h;++t){const n=o?e[0]:e[t],r=l?s[0]:s[t],i=u?a[0]:a[t];if(0===i)throw new Error("Requires delta != 0");let c;if(i>0&&r<n||i<0&&r>n)c=0;else if(c=Math.ceil(Math.abs((r-n)/i)),c>JN)throw new Error(`Requires ((limit - start) / delta) <= ${JN}`);p[t+1]=p[t]+c}const d=K(n,p[h]);let f=0;for(let t=0;t<h;++t){const n=p[t+1]-p[t];let s=o?e[0]:e[t];const r=u?a[0]:a[t];for(let e=0;e<n;++e)d[f++]=s,s+=r}return[p,d]}const QN={kernelName:Nn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{starts:s,limits:r,deltas:a}=t,i=n.data.get(s.dataId).values,o=n.data.get(r.dataId).values,l=n.data.get(a.dataId).values,[u,c]=ZN(i,s.shape,s.dtype,o,r.shape,l,a.shape);return[n.makeTensorInfo([u.length],"int32",u),n.makeTensorInfo([c.length],s.dtype,c)]}};var eS=ic;class tS{constructor(e,t,n,s,r,a,i,o,l,u){this.shape=e,this.shapeShape=t,this.values=n,this.valuesShape=s,this.valuesDType=r,this.defaultValue=a,this.defaultValueShape=i,this.rowPartitionValues=o,this.rowPartitionValuesShapes=l,this.rowPartitionTypes=lc(u),this.raggedRank=uc(this.rowPartitionTypes)}getRowPartitionTypeByDimension(e){return this.rowPartitionTypes[0]===eS.FIRST_DIM_SIZE?this.rowPartitionTypes[e+1]:this.rowPartitionTypes[e]}getRowPartitionTensor(e){return this.rowPartitionTypes[0]===eS.FIRST_DIM_SIZE?this.rowPartitionValues[e+1]:this.rowPartitionValues[e]}getMaxWidth(e){const t=this.getRowPartitionTensor(e-1);switch(this.getRowPartitionTypeByDimension(e-1)){case eS.VALUE_ROWIDS:return tS.getMaxWidthValueRowID(t);case eS.ROW_SPLITS:return tS.getMaxWidthRowSplit(t);default:throw new Error(`Cannot handle partition type ${eS[this.getRowPartitionTypeByDimension(e-1)]}`)}}static getMaxWidthRowSplit(e){const t=e.length;if(0===t||1===t)return 0;let n=0;for(let s=0;s<t-1;++s){const t=e[s+1]-e[s];t>n&&(n=t)}return n}static getMaxWidthValueRowID(e){const t=e.length;if(0===t)return 0;let n=0,s=e[0],r=0;for(let a=1;a<t;++a){const t=e[a];t!==s&&(s=t,r=Math.max(a-n,r),n=a)}return Math.max(t-n,r)}tensorShapeFromTensor(e,t,n=!0){if(0===t.length){if(-1===e[0])return[];throw new Error("The only valid scalar shape tensor is the fully unknown shape specified as -1.")}return sS(e,n)}calculateOutputSize(e){const t=this.valuesShape;cc(this.defaultValueShape,t);const n=this.tensorShapeFromTensor(this.shape,this.shapeShape),s=oc(this.raggedRank,n,t);s[0]<0&&(s[0]=e);for(let e=1;e<=this.raggedRank;++e)s[e]<0&&(s[e]=this.getMaxWidth(e));return s}calculateFirstParentOutputIndex(e,t,n){const s=Math.min(e,n),r=[];let a=0;for(let e=0;e<s;++e,a+=t)r.push(a);for(let t=s;t<e;++t)r.push(-1);return F(r.length===e,(()=>"Final length of result must be equal to firstDimension.")),r}calculateOutputIndexRowSplit(e,t,n,s){const r=e.length,a=[];for(let i=0;i<r-1;++i){const r=e[i+1]-e[i];let o=Math.min(s,r),l=t[i];-1===l&&(o=0);for(let e=0;e<o;++e)a.push(l),l+=n;for(let e=0;e<r-o;++e)a.push(-1)}if(r>0&&a.length!==e[r-1])throw new Error("Invalid row split size.");return a}calculateOutputIndexValueRowID(e,t,n,s){const r=e.length,a=[];if(0===r)return[];let i=0,o=e[0];if(o>=t.length)throw new Error(`Got currentValueRowId=${o}, which is not less than ${t.length}`);let l=t[o];a.push(l);for(let u=1;u<r;++u){const r=e[u];if(r===o)l>=0&&(++i,i<s?l+=n:l=-1);else{if(i=0,o=r,r>=t.length)throw new Error(`Got nextValueRowId=${r} which is not less than ${t.length}`);l=t[r]}a.push(l)}if(a.length!==e.length)throw new Error("Invalid row ids.");return a}calculateOutputIndex(e,t,n,s){const r=this.getRowPartitionTensor(e),a=this.getRowPartitionTypeByDimension(e);switch(a){case eS.VALUE_ROWIDS:return this.calculateOutputIndexValueRowID(r,t,n,s);case eS.ROW_SPLITS:if(r.length-1>t.length)throw new Error(`Row partition size is greater than output size: ${r.length-1} > ${t.length}`);return this.calculateOutputIndexRowSplit(r,t,n,s);default:throw new Error(`Unsupported partition type: ${eS[a]}`)}}getFirstDimensionSize(){const e=this.rowPartitionValues[0];if(0===this.rowPartitionTypes.length)throw new Error("No row_partition_types given.");const t=this.rowPartitionTypes[0];switch(t){case eS.FIRST_DIM_SIZE:return e[0];case eS.VALUE_ROWIDS:throw new Error("Cannot handle VALUE_ROWIDS in first dimension.");case eS.ROW_SPLITS:return this.rowPartitionValuesShapes[0][0]-1;default:throw new Error(`Cannot handle type ${eS[t]}`)}}compute(){if(this.rowPartitionValues[0].length<=0)throw new Error("Invalid first partition input. Tensor requires at least one element.");const e=this.getFirstDimensionSize(),t=this.calculateOutputSize(e),n=new Array(this.raggedRank+1);n[n.length-1]=1;for(let e=n.length-2;e>=0;--e)n[e]=n[e+1]*t[e+1];const s=sS(t,!1),r=K(this.valuesDType,L(s));if(n[0]*t[0]>0){let a=this.calculateFirstParentOutputIndex(e,n[0],t[0]);for(let e=1;e<=this.raggedRank;++e)a=this.calculateOutputIndex(e-1,a,n[e],t[e]);this.setOutput(this.raggedRank,a,r,s)}return[s,r]}setOutput(e,t,n,s){if(0===n.length)return;const r=this.values,a=n;let i=s.slice();i=i.slice(e+1);const o=L(i),l=t.length;let u=this.defaultValue;if(u.length!==o&&1!==u.length){const e=this.defaultValueShape;aa((()=>{const t=mo(u,e),n=vo(t,i);u=n.dataSync()}))}let c=0,h=0,p=0;for(let e=0;e<=l;++e){let s=e<l?t[e]:-1;if(s!==p){if(h<p){const e=r.subarray(c*o);nS(a.subarray(h*o),e,(p-h)*o)}if(e>=l){const e=n.length;s=Math.floor(e/o)}if(s>p)if(1===this.defaultValue.length)a.subarray(p*o,s*o).fill(this.defaultValue[0]),p=s;else for(;s>p;)nS(a.slice(p*o),u,o),++p;s<0?(c=e+1,h=p):(c=e,h=p,p=h+1)}else++p}}}function nS(e,t,n){for(let s=0;s<n;s++)e[s]=t[s]}function sS(e,t){const n=[];for(let s of e){if(s<0){if(!t)throw new Error(`Dimension ${s} must be >= 0`);if(s<-1)throw new Error(`Dimension ${s} must be >= -1`);s=-1}n.push(s)}return n}function rS(e,t,n,s,r,a,i,o,l,u){return new tS(e,t,n,s,r,a,i,o,l,u).compute()}const aS={kernelName:Sn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{shape:r,values:a,defaultValue:i,rowPartitionTensors:o}=t,{rowPartitionTypes:l}=s,u=n.data.get(r.dataId).values,c=n.data.get(a.dataId).values,h=n.data.get(i.dataId).values,p=o.map((e=>n.data.get(e.dataId).values)),d=o.map((e=>e.shape)),[f,m]=rS(u,r.shape,c,a.shape,a.dtype,h,i.shape,p,d,l);return n.makeTensorInfo(f,a.dtype,m)}};function iS(e,t,n,s){if(e===t||e<t&&n<0||t<e&&n>1)return ae(0,s);const r=ae(Math.abs(Math.ceil((t-e)/n)),s);t<e&&1===n&&(n=-1),r[0]=e;for(let e=1;e<r.length;e++)r[e]=r[e-1]+n;return r}const oS={kernelName:Tn,backendName:"cpu",kernelFunc:function(e){const{backend:t,attrs:n}=e,{start:s,stop:r,dtype:a,step:i}=n,o=iS(s,r,i,a);return t.makeTensorInfo([o.length],a,o)}},lS=hw(En,(e=>1/e)),uS={kernelName:En,backendName:"cpu",kernelFunc:lS},cS={kernelName:Dn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{images:r}=t,{alignCorners:a,halfPixelCenters:i,size:o}=s;ow(r,"resizeBilinear");const l=te(r.shape),[u,c]=o,[h,p,d,f]=r.shape,m=n.data.get(r.dataId).values,g=new Float32Array(L([h,u,c,f])),y=[a&&u>1?p-1:p,a&&c>1?d-1:d],b=[a&&u>1?u-1:u,a&&c>1?c-1:c];let x=0;const w=y[0]/b[0],k=y[1]/b[1];for(let e=0;e<h;e++)for(let t=0;t<u;t++){let n;n=i?w*(t+.5)-.5:w*t;const s=Math.max(0,Math.floor(n)),r=n-s,a=Math.min(p-1,Math.ceil(n)),o=e*l[0]+s*l[1],u=e*l[0]+a*l[1];for(let e=0;e<c;e++){let t;t=i?k*(e+.5)-.5:k*e;const n=Math.max(0,Math.floor(t)),s=t-n,a=Math.min(d-1,Math.ceil(t)),c=o+n*l[2],h=u+n*l[2],p=o+a*l[2],y=u+a*l[2];for(let e=0;e<f;e++){const t=m[c+e],n=m[h+e],a=t+(m[p+e]-t)*s,i=a+(n+(m[y+e]-n)*s-a)*r;g[x++]=i}}}return n.makeTensorInfo([h,u,c,f],"float32",g)}},hS={kernelName:Fn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{images:r,dy:a}=t,{alignCorners:i}=s;ow([a,r],"resizeBilinearGrad");const o=te(r.shape),[l,u,c,h]=r.shape,[,p,d]=a.shape,f=new Float32Array(l*u*c*h),m=[i&&p>1?u-1:u,i&&d>1?c-1:c],g=[i&&p>1?p-1:p,i&&d>1?d-1:d],y=m[0]/g[0],b=m[1]/g[1],x=n.data.get(a.dataId).values;let w=0;for(let e=0;e<l;e++){const t=e*o[0];for(let e=0;e<p;e++){const n=e*y,s=Math.floor(n),r=Math.min(Math.ceil(n),u-1),a=t+s*o[1],i=t+r*o[1],l=n-s,p=1-l;for(let e=0;e<d;e++){const t=e*b,n=Math.floor(t),s=Math.min(Math.ceil(t),c-1),r=t-n,u=1-r,d=a+n*o[2],m=a+s*o[2],g=i+n*o[2],y=i+s*o[2],k=p*u,v=p*r,I=l*u,N=l*r;for(let e=0;e<h;e++){const t=x[w++];f[d+e]+=t*k,f[m+e]+=t*v,f[g+e]+=t*I,f[y+e]+=t*N}}}}return n.makeTensorInfo([l,c,u,h],"float32",f)}},pS={kernelName:An,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{images:r}=t,{alignCorners:a,halfPixelCenters:i,size:o}=s;ow(r,"resizeNearestNeighbor");const l=te(r.shape),[u,c]=o,[h,p,d,f]=r.shape,m=n.data.get(r.dataId).values,g=new Float32Array(h*u*c*f),y=[a&&u>1?p-1:p,a&&c>1?d-1:d],b=[a&&u>1?u-1:u,a&&c>1?c-1:c],x=y[0]/b[0],w=y[1]/b[1];let k=0;for(let e=0;e<h;e++){const t=e*l[0];for(let e=0;e<u;e++){const n=i?x*(e+.5):x*e;let s=Math.min(p-1,a?Math.round(n):Math.floor(n));i&&(s=Math.max(0,s));const r=t+s*l[1];for(let e=0;e<c;e++){const t=i?w*(e+.5):w*e;let n=Math.min(d-1,a?Math.round(t):Math.floor(t));i&&(n=Math.max(0,n));const s=r+n*l[2];for(let e=0;e<f;e++){const t=m[s+e];g[k++]=t}}}}return n.makeTensorInfo([h,u,c,f],r.dtype,g)}},dS={kernelName:_n,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{images:r,dy:a}=t,{alignCorners:i}=s;ow([a,r],"resizeNearestNeighborGrad");const o=te(r.shape),l=te(a.shape),[u,c,h,p]=r.shape,[,d,f]=a.shape,m=new Float32Array(u*c*h*p),g=n.data.get(a.dataId).values,y=[i&&d>1?c-1:c,i&&f>1?h-1:h],b=[i&&d>1?d-1:d,i&&f>1?f-1:f],x=y[0]/b[0],w=y[1]/b[1],k=1/x,v=1/w,I=2*Math.ceil(k)+2,N=2*Math.ceil(v)+2;for(let e=0;e<u;e++){const t=e*o[0];for(let e=0;e<c;e++){const n=t+e*o[1],s=Math.floor(e*k),r=Math.floor(s-I/2);for(let s=0;s<h;s++){const a=n+s*o[2],u=Math.floor(s*v),y=Math.floor(u-N/2);for(let n=0;n<p;n++){let o=0;for(let a=0;a<I;a++){const u=a+r;if(u<0||u>=d)continue;const p=t+u*l[1],m=u*x;if(e===Math.min(c-1,i?Math.round(m):Math.floor(m)))for(let e=0;e<N;e++){const t=e+y;if(t<0||t>=f)continue;const r=p+t*l[2],a=t*w;s===Math.min(h-1,i?Math.round(a):Math.floor(a))&&(o+=g[r+n])}}m[a+n]=o}}}}return n.makeTensorInfo(r.shape,r.dtype,m)}},fS={kernelName:Mn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{dims:a}=s;ow(r,"reverse");const i=r.shape.length,o=G(a,r.shape);if(0===i)return mw({inputs:{x:r},backend:n});const l=new gr(r.shape,r.dtype),u=n.bufferSync(r);for(let e=0;e<l.size;e++){const t=l.indexToLoc(e),n=t.slice();o.forEach((e=>n[e]=r.shape[e]-1-n[e])),l.set(u.get(...n),...t)}return n.makeTensorInfo(l.shape,l.dtype,l.values)}},mS={kernelName:Ss,backendName:"cpu",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{image:s}=e,{radians:r,fillValue:a,center:i}=t,o=n,l=j(s.dtype,L(s.shape)),[u,c,h,p]=s.shape,[d,f]=dc(i,c,h),m=Math.sin(r),g=Math.cos(r),y=o.data.get(s.dataId).values;for(let e=0;e<u;e++){const t=e*h*c*p;for(let e=0;e<c;e++){const n=e*(h*p);for(let s=0;s<h;s++){const r=s*p;for(let i=0;i<p;i++){const o=[u,e,s,i],b=o[2],x=o[1];let w=(b-d)*g-(x-f)*m,k=(b-d)*m+(x-f)*g;w=Math.round(w+d),k=Math.round(k+f);let v=a;"number"!=typeof a&&(v=3===i?255:a[i]),w>=0&&w<h&&k>=0&&k<c&&(v=y[t+k*(h*p)+w*p+i]),l[t+n+r+i]=v}}}}return{dataId:o.write(l,s.shape,s.dtype),shape:s.shape,dtype:s.dtype}}},gS=hw(Ln,(e=>{const t=Math.floor(e);return e-t<.5?Math.floor(e):e-t>.5?Math.ceil(e):t%2==0?t:t+1})),yS={kernelName:Ln,backendName:"cpu",kernelFunc:gS},bS=cw((e=>1/Math.sqrt(e))),xS=pw(zn,bS),wS={kernelName:zn,backendName:"cpu",kernelFunc:xS};function kS(e,t,n,s,r,a,i,o,l,u){const c=[s/r,r],h=e.values,p=t.values;if(0===s)return Ua(n,t.dtype);const d=l instanceof gr?l:Ua(c,t.dtype);"string"==typeof l||"number"==typeof l?d.values.fill(l):"boolean"==typeof l&&d.values.fill(+l);for(let e=0;e<a;e++){const a=[];let l=0;for(let t=0;t<i;t++){const n=h[e*i+t];a.push(n),l+=n*o[t]}if(l<0||l>=s/r)throw new Error(`Invalid indices: ${a} does not index into ${n}`);for(let n=0;n<r;n++)u?d.values[l*r+n]+=p[e*r+n]:d.values[l*r+n]=0===t.rank?p[0]:p[e*r+n]}return d}const vS={kernelName:Bn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{indices:r,updates:a}=t,{shape:i}=s,{sliceRank:o,numUpdates:l,sliceSize:u,strides:c,outputSize:h}=vc(0,r,i),p=kS(n.bufferSync(r),n.bufferSync(a),i,h,u,l,o,c,0,!0);return n.makeTensorInfo(i,p.dtype,p.values)}};function IS(e,t){let n=0,s=e.length,r=0;for(;n<s;)r=Math.floor((n+s)/2),e[r]<t?n=r+1:s=r;return s}function NS(e,t){let n=0,s=e.length,r=0;for(;n<s;)r=Math.floor((n+s)/2),e[r]<=t?n=r+1:s=r;return s}const SS={kernelName:Wn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{sortedSequence:r,values:a}=t,{side:i}=s,o=function(e,t,n,s,r,a){const i=K("int32",n*r);for(let o=0;o<n;++o){const n=e.slice(o*s,(o+1)*s),l=o*r;for(let e=0;e<r;++e)i[l+e]="left"===a?IS(n,t[e+l]):NS(n,t[e+l])}return i}(n.data.get(r.dataId).values,n.data.get(a.dataId).values,r.shape[0],r.shape[1],a.shape[1],i);return n.makeTensorInfo(a.shape,"int32",o)}},TS={kernelName:Vn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{condition:s,t:r,e:a}=t;ow([s,r,a],"select");const i=s.shape.length,o=n.data.get(s.dataId).values,l=n.data.get(r.dataId).values,u=n.data.get(a.dataId).values,c=Cr(r.dtype,a.dtype),h=ae(L(r.shape),c);let p=0;const d=0===i||i>1||1===r.shape.length?1:L(r.shape.slice(1));for(let e=0;e<o.length;e++)for(let t=0;t<d;t++)1===o[e]?h[p++]=l[e]:h[p++]=u[e];return n.makeTensorInfo(r.shape,c,h)}},$S=Ic,ES=Nc,CS=hw(Un,(e=>e>=0?ES*e:$S*(Math.exp(e)-1))),RS={kernelName:Un,backendName:"cpu",kernelFunc:CS},AS=hw(Kn,(e=>e<0?-1:e>0?1:0)),_S={kernelName:Kn,backendName:"cpu",kernelFunc:AS},DS=hw(Hn,(e=>Math.sin(e))),FS={kernelName:Hn,backendName:"cpu",kernelFunc:DS},OS=hw(jn,(e=>Math.sinh(e))),MS={kernelName:jn,backendName:"cpu",kernelFunc:OS},LS=Math.log(1.1920928955078125e-7)+2,zS=hw(Xn,(e=>{const t=e>-LS,n=e<LS,s=Math.exp(e);let r;return r=n?s:t?e:Math.log(1+s),r})),BS={kernelName:Xn,backendName:"cpu",kernelFunc:zS},PS={kernelName:Zn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{blockShape:a,paddings:i}=s;ow([r],"spaceToBatchND");const o=L(a),l=[[0,0]];l.push(...i);for(let e=1+a.length;e<r.shape.length;++e)l.push([0,0]);const u=VN.kernelFunc({inputs:{x:r},backend:n,attrs:{paddings:l,constantValue:0}}),c=fc(u.shape,a,o,!1),h=mc(c.length,a.length,!1),p=gc(u.shape,a,o,!1),d=Hw({inputs:{x:u},backend:n,attrs:{shape:c}}),f=rk({inputs:{x:d},backend:n,attrs:{perm:h}}),m=Hw({inputs:{x:f},backend:n,attrs:{shape:p}});return n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),m}};function WS(e,t,n,s,r,a,i){const o=t[0],l=a[0],u=new Array(l),c=new Array(o),h=t[1];if(0===l){if(0!==o)throw new Error(Yc(o));return[K(n,0),[0,h],K(r,0),u,c]}let p=!0,d=0;const f=new Array(l).fill(0);for(let t=0;t<o;++t){const n=e[t*h];if(n<0)throw new Error(Jc(t,n));if(n>=l)throw new Error(Zc(t,n,l));++f[n],p=p&&n>=d,d=n}let m=!0;for(let e=0;e<l;++e){const t=0===f[e];u[e]=t,m=m&&!t,f[e]=Math.max(f[e],1),e>0&&(f[e]+=f[e-1])}if(m&&p){const t=e,n=s;for(let e=0;e<o;++e)c[e]=e;return[t,[o,h],n,u,c]}{const t=f[l-1],a=K(n,t*h),p=K(r,t),d=new Array(l).fill(0);for(let t=0;t<o;++t){const n=e[t*h],r=d[n],i=(0===n?0:f[n-1])+r;d[n]++;for(let n=0;n<h;++n)a[i*h+n]=e[t*h+n];p[i]=s[t],c[t]=i}for(let e=0;e<l;++e)if(0===d[e]){const t=0===e?0:f[e-1];a[t*h+0]=e;for(let e=1;e<h;++e)a[t*h+e]=0;p[t]=i}return[a,[t,h],p,u,c]}}const VS={kernelName:ts,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{indices:s,values:r,denseShape:a,defaultValue:i}=t;if(1!==a.shape.length)throw new Error(`Dense shape must be a vector, saw:\n        ${a.shape}`);if(2!==s.shape.length)throw new Error(`Indices must be a matrix, saw:\n        ${s.shape}`);if(1!==r.shape.length)throw new Error(`Values must be a vector, saw:\n        ${r.shape}`);if(0!==i.shape.length)throw new Error(`Default value must be a scalar, saw:\n        ${i.shape}`);const o=n.data.get(s.dataId).values,l=n.data.get(r.dataId).values,u=n.data.get(a.dataId).values,c=n.data.get(i.dataId).values[0],[h,p,d,f,m]=WS(o,s.shape,s.dtype,l,r.dtype,u,c);return[n.makeTensorInfo(p,s.dtype,h),n.makeTensorInfo([p[0]],r.dtype,d),n.makeTensorInfo([f.length],"bool",new Uint8Array(f.map((e=>Number(e))))),n.makeTensorInfo([m.length],s.dtype,new Int32Array(m))]}};function US(e,t,n,s,r){const a=L(s),i=t[0],o=r.length,l=[];let u=1,c=-1;for(let e=0;e<o;++e){const t=r[e];if(-1===t){if(-1!==c)throw new Error(Qc(c,e));c=e,l.push(1)}else{if(t<0)throw new Error(eh(e,t));u*=t,l.push(t)}}if(-1!==c){if(u<=0)throw new Error("reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero");const e=Math.trunc(a/u);if(u*e!==a)throw new Error(nh(s,l));l[c]=e}if(L(l)!==a)throw new Error(sh(s,l));const h=s.length,p=[];if(h>0){p[h-1]=1;for(let e=h-2;e>=0;--e)p[e]=p[e+1]*s[e+1]}const d=[];if(o>0){d[o-1]=1;for(let e=o-2;e>=0;--e)d[e]=d[e+1]*l[e+1]}const f=K(n,i*o);for(let t=0;t<i;++t){let n=0;for(let s=0;s<h;++s)n+=e[t*h+s]*p[s];for(let e=0;e<o;++e)f[t*o+e]=Math.trunc(n/d[e]),n%=d[e]}return[f,[i,o],l]}const GS={kernelName:ns,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{inputIndices:s,inputShape:r,newShape:a}=t;if(2!==s.shape.length)throw new Error(`Input indices should be a matrix but received shape\n        ${s.shape}`);if(1!==r.shape.length)throw new Error(`Input shape should be a vector but received shape\n        ${r.shape}`);if(1!==a.shape.length)throw new Error(`Target shape should be a vector but received shape ${a.shape}`);const i=Array.from(n.data.get(r.dataId).values),o=n.data.get(s.dataId).values,l=Array.from(n.data.get(a.dataId).values),[u,c,h]=US(o,s.shape,s.dtype,i,l);return[n.makeTensorInfo(c,s.dtype,u),n.makeTensorInfo([h.length],a.dtype,new Int32Array(h))]}};function HS(e,t,n,s,r,a=!1,i=0){const o=s.length,l=[t[0],e.length/t[0]],u=l[1],c=o>0?r[o-1]+1:0;if(c<0)throw new Error("segment ids must be >= 0");const h=t.slice();h[0]=c;const p=K(n,h.reduce(((e,t)=>e*t),1));if(0===o)return c>0&&p.fill(i),[p,h];if(c<=0)throw new Error("segment ids must be >= 0");let d=0,f=1,m=0,g=r[d];for(;;){let t=0;if(f<o){if(t=r[f],g===t){++f;continue}if(g>=t)throw new Error("segment ids are not increasing")}if(g<0||g>=c)throw new Error(ih(g,c));g>m&&p.fill(i,m*u,g*u);for(let t=d;t<f;++t){const n=s[t];if(n<0||n>=l[0])throw new Error(oh(t,s[t],l[0]));for(let t=0;t<u;t++)p[g*u+t]+=e[n*u+t]}if(a)for(let e=0;e<u;e++)p[g*u+e]/=f-d;if(d=f,++f,m=g+1,g=t,f>o)break}return m<c&&p.fill(i,m*u,c*u),[p,h]}const jS={kernelName:ss,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{data:s,indices:r,segmentIds:a}=t;if(s.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==r.shape.length)throw new Error(`Indices should be a vector but received shape\n          ${r.shape}`);if(1!==a.shape.length)throw new Error(`Segment ids should be a vector but received shape\n          ${a.shape}`);if(r.shape[0]!==a.shape[0])throw new Error("segmentIds and indices should have same size.");const i=n.data.get(s.dataId).values,o=n.data.get(r.dataId).values,l=n.data.get(a.dataId).values,[u,c]=HS(i,s.shape,s.dtype,o,l,!0);return n.makeTensorInfo(c,s.dtype,u)}},KS={kernelName:rs,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{data:s,indices:r,segmentIds:a}=t;if(s.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==r.shape.length)throw new Error(`Indices should be a vector but received shape\n         ${r.shape}`);if(1!==a.shape.length)throw new Error(`Segment ids should be a vector but received shape\n         ${a.shape}`);if(r.shape[0]!==a.shape[0])throw new Error("segmentIds and indices should have same size.");const i=n.data.get(s.dataId).values,o=n.data.get(r.dataId).values,l=n.data.get(a.dataId).values,[u,c]=HS(i,s.shape,s.dtype,o,l);return n.makeTensorInfo(c,s.dtype,u)}},qS={kernelName:as,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{sparseIndices:r,sparseValues:a,defaultValue:i}=t,{outputShape:o}=s,{sliceRank:l,numUpdates:u,sliceSize:c,strides:h,outputSize:p}=vc(0,r,o),d=!1,f=n.bufferSync(r);let m;switch(a.dtype){case"bool":m=kS(f,n.bufferSync(a),o,p,c,u,l,h,Boolean(n.data.get(i.dataId).values[0]),d);break;case"float32":case"int32":m=kS(f,n.bufferSync(a),o,p,c,u,l,h,n.data.get(i.dataId).values[0],d);break;case"string":m=kS(f,n.bufferSync(a),o,p,c,u,l,h,ar(n.data.get(i.dataId).values[0]),d);break;default:throw new Error(`Unsupported type ${a.dtype}`)}return n.makeTensorInfo(o,m.dtype,m.values)}},XS={kernelName:Qn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{numOrSizeSplits:a,axis:i}=s,o=G(i,r.shape)[0],l=Xc(r,a,o),u=new Array(r.shape.length).fill(0),c=r.shape.slice();return l.map((e=>{const t=[...c];t[o]=e;const s=Rk({inputs:{x:r},backend:n,attrs:{begin:u,size:t}});return u[o]+=e,s}))}},YS=cw((e=>Math.sqrt(e))),JS=hw(Yn,(e=>Math.sqrt(e))),ZS={kernelName:Yn,backendName:"cpu",kernelFunc:JS},QS={kernelName:os,backendName:"cpu",kernelFunc:({inputs:e,backend:t})=>{const{x:n}=e,s=t;ow(n,"square");const r=s.data.get(n.dataId).values,a=new Float32Array(r.length);for(let e=0;e<r.length;++e){const t=r[e];a[e]=t*t}return{dataId:s.write(a,n.shape,n.dtype),shape:n.shape,dtype:n.dtype}}},eT=xw(((e,t)=>{const n=e-t;return n*n})),tT=Bw(is,eT),nT={kernelName:is,backendName:"cpu",kernelFunc:tT},sT=cw(((e,t)=>{const{pattern:n,replaceGlobal:s,rewrite:r}=t;return e.replace(new RegExp(n,s?"g":""),r)})),rT={kernelName:ls,backendName:"cpu",kernelFunc:pw(ls,sT)},aT=hw(Ns,((e,t)=>{const n=t;return isNaN(e)?NaN:e>0?1:n.alpha})),iT={kernelName:Ns,backendName:"cpu",kernelFunc:aT};function oT(e,t,n,s){const r=Ua(e,t.dtype);for(let e=0;e<r.size;e++){const a=r.indexToLoc(e),i=new Array(a.length);for(let e=0;e<i.length;e++)i[e]=a[e]*n[e]+s[e];r.set(t.get(...i),...a)}return r}const lT={kernelName:us,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{begin:a,end:i,strides:o,beginMask:l,endMask:u,ellipsisMask:c,newAxisMask:h,shrinkAxisMask:p}=s;ow(r,"stridedSlice");const{finalShapeSparse:d,finalShape:f,isIdentity:m,sliceDim0:g,isSimpleSlice:y,begin:b,end:x,strides:w}=qi(r.shape,a,i,o,l,u,c,h,p);let k;if(m)k=Hw({inputs:{x:r},backend:n,attrs:{shape:f}});else if(g||y){F(r.shape.length>=1,(()=>`Input must have rank at least 1, got: ${r.shape.length}`));const e=Oi(b,x,w),t=Rk({inputs:{x:r},backend:n,attrs:{begin:b,size:e}});k=Hw({inputs:{x:t},backend:n,attrs:{shape:f}}),n.disposeIntermediateTensorInfo(t)}else{const e=oT(d,n.bufferSync(r),w,b);k=n.makeTensorInfo(f,e.dtype,e.values)}return k}};class uT{constructor(e,t,n,s,r,a){this.separator=rr(e),this.nGramWidths=t,this.leftPad=rr(n),this.rightPad=rr(s),this.padWidth=r,this.preserveShort=a}getPadWidth(e){return Math.min(this.padWidth<0?e-1:this.padWidth,e-1)}getNumNGrams(e,t){const n=this.getPadWidth(t);return Math.max(0,e+2*n-t+1)}createNGrams(e,t,n,s,r,a){for(let i=0;i<r;++i){const o=this.getPadWidth(a),l=Math.max(0,o-i),u=Math.max(0,o-(r-(i+1))),c=a-(l+u),h=t+(l>0?0:i-o);let p=0;p+=l*this.leftPad.length;for(let t=0;t<c;++t)p+=e[h+t].length;p+=u*this.rightPad.length,p+=(l+u+c-1)*this.separator.length,n[s+i]=new Uint8Array(p);const d=n[s+i];let f=0;const m=e=>e.forEach((e=>d[f++]=e));for(let e=0;e<l;++e)m(this.leftPad),m(this.separator);for(let t=0;t<c-1;++t)m(e[h+t]),m(this.separator);if(c>0){m(e[h+c-1]);for(let e=0;e<u;++e)m(this.separator),m(this.rightPad)}else{for(let e=0;e<u-1;++e)m(this.rightPad),m(this.separator);m(this.rightPad)}}}compute(e,t){const n=e.length,s=t.length;if(s>0){let e=t[0];if(0!==e)throw new Error(`First split value must be 0, got ${e}`);for(let r=1;r<s;++r){let s=t[r]>=e;if(s=s&&t[r]<=n,!s)throw new Error(`Invalid split value ${t[r]}, must be in [${e}, ${n}]`);e=t[r]}if(e!==n)throw new Error(`Last split value must be data size. Expected ${n}, got ${e}`)}const r=s-1,a=K("int32",s);if(0===n||0===s){const e=new Array(n);for(let e=0;e<=r;++e)a[e]=0;return[e,a]}a[0]=0;for(let e=1;e<=r;++e){const n=t[e]-t[e-1];let s=0;this.nGramWidths.forEach((e=>{s+=this.getNumNGrams(n,e)})),this.preserveShort&&n>0&&0===s&&(s=1),a[e]=a[e-1]+s}const i=new Array(a[r]);for(let n=0;n<r;++n){const s=t[n];let r=a[n];if(this.nGramWidths.forEach((a=>{const o=t[n+1]-t[n],l=this.getNumNGrams(o,a);this.createNGrams(e,s,i,r,l,a),r+=l})),this.preserveShort&&r===a[n]){const a=t[n+1]-t[n];if(0===a)continue;const o=a+2*this.padWidth,l=1;this.createNGrams(e,s,i,r,l,o)}}return[i,a]}}function cT(e,t,n,s,r,a,i,o){return new uT(n,s,r,a,i,o).compute(e,t)}const hT={kernelName:cs,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{separator:r,nGramWidths:a,leftPad:i,rightPad:o,padWidth:l,preserveShortSequences:u}=s,{data:c,dataSplits:h}=t,p=n.data.get(c.dataId).values,d=n.data.get(h.dataId).values,[f,m]=cT(p,d,r,a,i,o,l,u);return[n.makeTensorInfo([f.length],"string",f),n.makeTensorInfo(h.shape,"int32",m)]}};function pT(e,t,n,s){if(!e.length)return;if(0===t.length){for(let t=0;t<e.length;++t)s.push(e.subarray(t,t+1));return}if(1===t.length){const r=t[0];let a=e.indexOf(r);for(;-1!==a;){const t=e.subarray(0,a);n&&0===t.length||s.push(t),a=(e=e.subarray(a+1)).indexOf(r)}return void(n&&0===e.length||s.push(e))}let r=0;for(let a=0;a<e.length+1;a++)if(a===e.length||-1!==t.indexOf(e[a])){const t=e.subarray(r,a);n&&0===t.length||s.push(t),r=a+1}}function dT(e,t,n){const s=e.length,r=[];let a=0,i=0;const o=new Array(s);for(let l=0;l<s;++l){const s=r.length;pT(e[l],t,n,r);const u=r.length-s;o[l]=u,a+=u,i=Math.max(i,u)}const l=K("int32",2*a),u=new Array(a),c=[s,i];let h=0;for(let e=0;e<s;++e)for(let t=0;t<o[e];++t)l[2*h]=e,l[2*h+1]=t,u[h]=r[h],++h;return[l,u,c]}const fT={kernelName:hs,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{skipEmpty:r}=s,{input:a,delimiter:i}=t;if("string"!==a.dtype)throw new Error("Input must be of datatype string");if(1!==a.shape.length)throw new Error(`Input must be a vector, got shape: ${a.shape}`);if(0!==i.shape.length)throw new Error(`Delimiter must be a scalar, got shape: ${i.shape}`);const o=n.data.get(a.dataId).values,l=n.data.get(i.dataId).values[0],[u,c,h]=dT(o,l,r),p=c.length;return[n.makeTensorInfo([p,2],"int32",u),n.makeTensorInfo([p],"string",c),n.makeTensorInfo([2],"int32",new Int32Array(h))]}};function mT(e,t){const n=K("int32",e.length);for(let s=0;s<e.length;++s)n[s]=er(e[s]).modulo(t).getLowBitsUnsigned();return n}const gT={kernelName:ps,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{numBuckets:r}=s,{input:a}=t;if("string"!==a.dtype)throw new Error("Input must be of datatype string");if(r<=0)throw new Error("Number of buckets must be at least 1");const i=mT(n.data.get(a.dataId).values,r);return n.makeTensorInfo(a.shape,"int32",i)}},yT=hw(fs,(e=>Math.tan(e))),bT={kernelName:fs,backendName:"cpu",kernelFunc:yT},xT=hw(ms,(e=>Math.tanh(e))),wT={kernelName:Pn,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n}=e,{tensor:s,indices:r,updates:a}=t,{sliceRank:i,numUpdates:o,sliceSize:l,strides:u,outputSize:c}=vc(0,r,s.shape),h=n.bufferSync(r),p=n.bufferSync(a),d=n.bufferSync(s),f=kS(h,p,s.shape,c,l,o,i,u,d,!1);return n.makeTensorInfo(s.shape,f.dtype,f.values)}};function kT(e,t){const n=new Array(e.rank);for(let s=0;s<n.length;s++)n[s]=e.shape[s]*t[s];const s=Ua(n,e.dtype);for(let t=0;t<s.values.length;++t){const n=s.indexToLoc(t),r=new Array(e.rank);for(let t=0;t<r.length;t++)r[t]=n[t]%e.shape[t];const a=e.locToIndex(r);s.values[t]=e.values[a]}return s}const vT={kernelName:gs,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{reps:a}=s;ow(r,"tile");const i=kT(n.bufferSync(r),a);return n.makeTensorInfo(i.shape,i.dtype,i.values)}},IT=(e,t)=>{const n=t.value-e.value;return 0===n?e.index-t.index:n};function NT(e,t,n=0,s=e.length-1){for(;s>n;){if(s-n>600){const r=s-n+1,a=t-n+1,i=Math.log(r),o=.5*Math.exp(2*i/3),l=.5*Math.sqrt(i*o*(r-o)/r)*Math.sign(a-r/2);NT(e,t,Math.max(n,Math.floor(t-a*o/r+l)),Math.min(s,Math.floor(t+(r-a)*o/r+l)))}const r=e[t];let a=n,i=s;for(D(e,n,t),IT(e[s],r)>0&&D(e,n,s);a<i;){for(D(e,a,i),a++,i--;IT(e[a],r)<0;)a+=1;for(;IT(e[i],r)>0;)i-=1}0===IT(e[n],r)?D(e,n,i):(i+=1,D(e,i,s)),i<=t&&(n=i+1),t<=i&&(s=i-1)}}function ST(e,t,n,s,r){const a=t[t.length-1],[i,o]=[e.length/a,a],l=j(n,i*s),u=j("int32",i*s);for(let t=0;t<i;t++){const n=t*o,a=e.subarray(n,n+o);let i=new Array(a.length);a.forEach(((e,t)=>i[t]={value:e,index:t})),s<i.length&&(NT(i,s),i=i.slice(0,s)),r&&i.sort(IT);const c=t*s,h=l.subarray(c,c+s),p=u.subarray(c,c+s);for(let e=0;e<s;e++)h[e]=i[e].value,p[e]=i[e].index}const c=t.slice();return c[c.length-1]=s,[Ua(c,n,l),Ua(c,"int32",u)]}const TT={kernelName:ys,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{k:a,sorted:i}=s;ow(r,"topk");const o=n.data.get(r.dataId).values,[l,u]=ST(o,r.shape,r.dtype,a,i);return[n.makeTensorInfo(l.shape,l.dtype,l.values),n.makeTensorInfo(u.shape,u.dtype,u.values)]}},$T={kernelName:bs,backendName:"cpu",kernelFunc:function(e){const{inputs:t,attrs:n,backend:s}=e,{image:r,transforms:a}=t,{interpolation:i,fillMode:o,fillValue:l,outputShape:u}=n,[c,h,p,d]=r.shape,[f,m]=null!=u?u:[h,p],g=[c,f,m,d],y=te(r.shape),b=y[0],x=y[1],w=y[2],k=te(g),v=k[0],I=k[1],N=k[2],S=j(r.dtype,L(g));S.fill(l);const T=s.data.get(r.dataId).values,$=s.data.get(a.dataId).values;for(let e=0;e<c;++e){const t=1===a.shape[0]?$:$.subarray(8*e,8*e+8);for(let n=0;n<f;++n)for(let s=0;s<m;++s)for(let r=0;r<d;++r){let a;const u=t[6]*s+t[7]*n+1;if(0===u)continue;const c=(t[0]*s+t[1]*n+t[2])/u,d=(t[3]*s+t[4]*n+t[5])/u,f=ET(c,p,o),m=ET(d,h,o);switch(i){case"nearest":a=RT(T,h,p,b,x,w,e,m,f,r,l);break;case"bilinear":a=AT(T,h,p,b,x,w,e,m,f,r,l);break;default:throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${i}`)}S[e*v+n*I+s*N+r]=a}return s.makeTensorInfo(g,r.dtype,S)}return{dataId:s.write(S,g,r.dtype),shape:r.shape,dtype:r.dtype}}};function ET(e,t,n){switch(n){case"reflect":return function(e,t){let n=e;if(n<0)if(t<=1)n=0;else{const e=2*t;n<e&&(n=e*Math.trunc(-n/e)+n),n=n<-t?n+e:-n-1}else if(n>t-1)if(t<=1)n=0;else{const e=2*t;n-=e*Math.trunc(n/e),n>=t&&(n=e-n-1)}return A(0,n,t-1)}(e,t);case"wrap":return function(e,t){let n=e;if(n<0)if(t<=1)n=0;else{const e=t-1;n+=t*(Math.trunc(-n/e)+1)}else if(n>t-1)if(t<=1)n=0;else{const e=t-1;n-=t*Math.trunc(n/e)}return A(0,n,t-1)}(e,t);case"nearest":return function(e,t){return A(0,e,t-1)}(e,t);default:return e}}function CT(e,t,n,s,r,a,i,o,l,u,c){return 0<=o&&o<t&&0<=l&&l<n?e[i*s+o*r+l*a+u]:c}function RT(e,t,n,s,r,a,i,o,l,u,c){return CT(e,t,n,s,r,a,i,Math.round(o),Math.round(l),u,c)}function AT(e,t,n,s,r,a,i,o,l,u,c){const h=Math.floor(o),p=Math.floor(l),d=h+1,f=p+1;return(d-o)*((f-l)*CT(e,t,n,s,r,a,i,h,p,u,c)+(l-p)*CT(e,t,n,s,r,a,i,h,f,u,c))+(o-h)*((f-l)*CT(e,t,n,s,r,a,i,d,p,u,c)+(l-p)*CT(e,t,n,s,r,a,i,d,f,u,c))}function _T(e,t,n,s){const r=G(t,n)[0],a=[1,n[0],1];for(let e=0;e<r;e++)a[0]*=n[e];a[1]=n[r];for(let e=r+1;e<n.length;e++)a[2]*=n[e];const i=new Map,o=new Int32Array(n[r]),l=new gr(a,s,e),u=[],c=1===a[0]&&1===a[2];for(let t=0;t<n[r];t++){let n;if(c)n=e[t].toString();else{const e=[];for(let n=0;n<a[0];n++)for(let s=0;s<a[2];s++)e.push(l.get(n,t,s));n=e.join(",")}const s=i.get(n);if(null!=s)o[t]=s;else{const e=i.size;i.set(n,e),o[t]=e,u.push(t)}}const h=a.slice();h[1]=i.size;const p=new gr(h,s);u.forEach(((e,t)=>{for(let n=0;n<a[0];n++)for(let s=0;s<a[2];s++)p.set(l.get(n,e,s),n,t,s)}));const d=n.slice();return d[r]=h[1],{outputValues:p.values,outputShape:d,indices:o}}const DT={kernelName:ws,backendName:"cpu",kernelFunc:function(e){const{inputs:t,attrs:n,backend:s}=e,{axis:r}=n,{x:a}=t;ow(a,"unique");const i=s.data.get(a.dataId).values,{outputValues:o,outputShape:l,indices:u}=_T(i,r,a.shape,a.dtype);return[s.makeTensorInfo(l,a.dtype,o),s.makeTensorInfo([u.length],"int32",u)]}},FT={kernelName:ks,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{value:r}=t;let{axis:a}=s;a<0&&(a+=r.shape.length);const i=r.shape.length,o=r.shape[a],l=new Array(i-1);let u=0;for(let e=0;e<i;e++)e!==a&&(l[u++]=r.shape[e]);const c=new Array(i).fill(0),h=r.shape.slice();h[a]=1;const p=new Array(o);for(let e=0;e<p.length;e++){c[a]=e;const t=Rk({inputs:{x:r},backend:n,attrs:{begin:c,size:h}});p[e]=Hw({inputs:{x:t},backend:n,attrs:{shape:l}}),n.disposeIntermediateTensorInfo(t)}return p}},OT={kernelName:vs,backendName:"cpu",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,segmentIds:a}=t,{numSegments:i}=s;ow(r,"unsortedSegmentSum");const o=[],l=[],u=r.shape.length-a.shape.length;let c=a;for(let e=0;e<u;++e){const t=Uv({inputs:{input:c},backend:n,attrs:{dim:e+1}});c=t,l.push(t)}for(let e=0;e<i;++e){const t=tr(e,"int32"),s=n.makeTensorInfo([],"int32",t),a=Rv({inputs:{a:s,b:c},backend:n}),i=Lw({inputs:{x:a},backend:n,attrs:{dtype:"float32"}}),u=Iv({inputs:{a:i,b:r},backend:n}),h=Sv({inputs:{x:u},backend:n,attrs:{axis:0,keepDims:!1}});o.push(h),l.push(s),l.push(a),l.push(i),l.push(u),l.push(h)}const h=PN({inputs:o,backend:n,attrs:{axis:0}});return l.forEach((e=>n.disposeIntermediateTensorInfo(e))),h}},MT=[Xw,Jw,Qw,tk,Gw,nk,ik,ok,lk,uk,hk,dk,mk,bk,wk,Nk,Sk,Tk,$k,qw,Ek,_k,Ok,Lk,zk,zw,Wk,Uk,_w,Gk,Xk,Jk,Zk,Qk,ev,tv,nv,rv,iv,ov,lv,uv,cv,hv,dv,fv,mv,gv,yv,bv,xv,wv,$v,fw,Ev,Av,Bv,Vv,Gv,Kv,rI,iI,oI,cI,dI,fI,mI,yI,xI,vI,SI,gw,TI,Kk,EI,RI,_I,bw,OI,zI,PI,UI,HI,qI,YI,QI,eN,tN,rN,oN,lN,uN,cN,hN,pN,dN,fN,yN,bN,kN,NN,Nv,TN,EN,RN,_N,ON,MN,BN,WN,VN,HN,vw,KN,YN,QN,aS,oS,Ow,Yv,uS,Nw,Tw,jw,cS,hS,pS,dS,fS,mS,yS,wS,vS,SS,TS,RS,Cw,_S,FS,MS,Ak,IN,BS,PS,VS,GS,jS,KS,qS,XS,ZS,QS,nT,rT,iT,lT,hT,fT,gT,eI,Tv,bT,{kernelName:ms,backendName:"cpu",kernelFunc:xT},wT,vT,TT,$T,ak,DT,FT,OT,zN];for(const e of MT)Ms(e);const LT={},zT={alpha:!1,antialias:!1,premultipliedAlpha:!1,preserveDrawingBuffer:!1,depth:!1,stencil:!1,failIfMajorPerformanceCaveat:!0};function BT(e,t){if(!(e in LT)||null!=t){const n=function(e,t){if(1!==e&&2!==e)throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");const n=null==t?function(e){if(fe().getBool("IS_SAFARI")||"undefined"==typeof OffscreenCanvas||2!==e){if("undefined"!=typeof document)return document.createElement("canvas");throw new Error("Cannot create a canvas in this context")}return new OffscreenCanvas(300,150)}(e):t;return n.addEventListener("webglcontextlost",(t=>{t.preventDefault(),delete LT[e]}),!1),fe().getBool("SOFTWARE_WEBGL_ENABLED")&&(zT.failIfMajorPerformanceCaveat=!1),1===e?n.getContext("webgl",zT)||n.getContext("experimental-webgl",zT):n.getContext("webgl2",zT)}(e,t);if(null===n)return console.log("Could not get context for WebGL version",e),null;LT[e]=n}const n=LT[e];return null==n||n.isContextLost()?(delete LT[e],BT(e)):(n.disable(n.DEPTH_TEST),n.disable(n.STENCIL_TEST),n.disable(n.BLEND),n.disable(n.DITHER),n.disable(n.POLYGON_OFFSET_FILL),n.disable(n.SAMPLE_COVERAGE),n.enable(n.SCISSOR_TEST),n.enable(n.CULL_FACE),n.cullFace(n.BACK),LT[e])}var PT,WT,VT;function UT(e,t){return[t,e]}function GT(e){const t=L(e);return P(Math.ceil(t/4))}function HT(e,t){return[Math.max(1,Math.ceil(t/2)),Math.max(1,Math.ceil(e/2))]}function jT(e,t){const n=e;let s,r,a,i,o,l,u,c,h,p;return 2===fe().getNumber("WEBGL_VERSION")?(s=n.R32F,r=n.R16F,a=n.RGBA16F,i=n.RGBA32F,o=n.RED,u=4,c=1,h=n.HALF_FLOAT,p=n.FLOAT,l=n.RGBA8):(s=e.RGBA,r=e.RGBA,a=e.RGBA,i=n.RGBA,o=e.RGBA,u=4,c=4,h=null!=t?t.HALF_FLOAT_OES:null,p=e.FLOAT,l=e.RGBA),{internalFormatFloat:s,internalFormatHalfFloat:r,internalFormatPackedHalfFloat:a,internalFormatPackedFloat:i,textureFormatFloat:o,downloadTextureFormat:l,downloadUnpackNumChannels:u,defaultNumChannels:c,textureTypeHalfFloat:h,textureTypeFloat:p}}function KT(e,t){const n=t();return fe().getBool("DEBUG")&&function(e){const t=e.getError();if(t!==e.NO_ERROR)throw new Error("WebGL Error: "+function(e,t){switch(t){case e.NO_ERROR:return"NO_ERROR";case e.INVALID_ENUM:return"INVALID_ENUM";case e.INVALID_VALUE:return"INVALID_VALUE";case e.INVALID_OPERATION:return"INVALID_OPERATION";case e.INVALID_FRAMEBUFFER_OPERATION:return"INVALID_FRAMEBUFFER_OPERATION";case e.OUT_OF_MEMORY:return"OUT_OF_MEMORY";case e.CONTEXT_LOST_WEBGL:return"CONTEXT_LOST_WEBGL";default:return`Unknown error code ${t}`}}(e,t))}(e),n}function qT(e){return!!(fe().getBool("WEBGL_RENDER_FLOAT32_ENABLED")||0===e||5.96e-8<Math.abs(e)&&Math.abs(e)<65504)}function XT(e,t){return r$(e,(()=>e.getExtension(t)),'Extension "'+t+'" not supported on this browser.')}!function(e){e[e.DENSE=0]="DENSE",e[e.SHARED_BATCH=1]="SHARED_BATCH"}(PT||(PT={})),function(e){e[e.RENDER=0]="RENDER",e[e.UPLOAD=1]="UPLOAD",e[e.PIXELS=2]="PIXELS",e[e.DOWNLOAD=3]="DOWNLOAD"}(WT||(WT={})),function(e){e[e.UNPACKED_FLOAT16=0]="UNPACKED_FLOAT16",e[e.UNPACKED_FLOAT32=1]="UNPACKED_FLOAT32",e[e.PACKED_4X1_UNSIGNED_BYTE=2]="PACKED_4X1_UNSIGNED_BYTE",e[e.PACKED_2X2_FLOAT32=3]="PACKED_2X2_FLOAT32",e[e.PACKED_2X2_FLOAT16=4]="PACKED_2X2_FLOAT16"}(VT||(VT={}));const YT=/ERROR: [0-9]+:([0-9]+):/g;function JT(e,t){const n=YT.exec(t);if(null==n)return console.log(`Couldn't parse line number in error: ${t}`),void console.log(e);const s=+n[1],r=e.split("\n"),a=r.length.toString().length+2,i=r.map(((e,t)=>W((t+1).toString(),a)+e));let o=0;for(let e=0;e<i.length;e++)o=Math.max(i[e].length,o);const l=i.slice(0,s-1),u=i.slice(s-1,s),c=i.slice(s);console.log(l.join("\n")),console.log(t.split("\n")[0]),console.log(`%c ${W(u[0],o)}`,"border:1px solid red; background-color:#e3d2d2; color:#a61717"),console.log(c.join("\n"))}function ZT(e,t){if(KT(e,(()=>e.validateProgram(t))),!1===e.getProgramParameter(t,e.VALIDATE_STATUS))throw console.log(e.getProgramInfoLog(t)),new Error("Shader program validation failed.")}function QT(e,t,n,s,r,a,i){const o=e.getAttribLocation(t,n);return-1!==o&&(KT(e,(()=>e.bindBuffer(e.ARRAY_BUFFER,s))),KT(e,(()=>e.vertexAttribPointer(o,r,e.FLOAT,!1,a,i))),KT(e,(()=>e.enableVertexAttribArray(o))),!0)}function e$(e,t,n,s){KT(e,(()=>function(e,t,n){(function(e,t){const n=e.MAX_COMBINED_TEXTURE_IMAGE_UNITS-1,s=t+e.TEXTURE0;if(s<e.TEXTURE0||s>n)throw new Error(`textureUnit must be in [gl.TEXTURE0, gl.TEXTURE${n}].`)})(e,n),KT(e,(()=>e.activeTexture(e.TEXTURE0+n))),KT(e,(()=>e.bindTexture(e.TEXTURE_2D,t)))}(e,t,s))),KT(e,(()=>e.uniform1i(n,s)))}function t$(e,t,n){KT(e,(()=>e.bindFramebuffer(e.FRAMEBUFFER,n))),KT(e,(()=>e.framebufferTexture2D(e.FRAMEBUFFER,e.COLOR_ATTACHMENT0,e.TEXTURE_2D,t,0)))}function n$(e,t){KT(e,(()=>e.bindFramebuffer(e.FRAMEBUFFER,t))),KT(e,(()=>e.framebufferTexture2D(e.FRAMEBUFFER,e.COLOR_ATTACHMENT0,e.TEXTURE_2D,null,0)))}function s$(e){const t=e.checkFramebufferStatus(e.FRAMEBUFFER);if(t!==e.FRAMEBUFFER_COMPLETE)throw new Error("Error binding framebuffer: "+function(e,t){switch(t){case e.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_ATTACHMENT";case e.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";case e.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:return"FRAMEBUFFER_INCOMPLETE_DIMENSIONS";case e.FRAMEBUFFER_UNSUPPORTED:return"FRAMEBUFFER_UNSUPPORTED";default:return`unknown error ${t}`}}(e,t))}function r$(e,t,n){const s=KT(e,(()=>t()));if(null==s)throw new Error(n);return s}function a$(e,t=2){return L(e.slice(0,e.length-t))}function i$(e){if(0===e.length)throw Error("Cannot get rows and columns of an empty shape array.");return[e.length>1?e[e.length-2]:1,e[e.length-1]]}function o$(e){let t=[1,1,1];return 0===e.length||1===e.length&&1===e[0]||(t=[a$(e),...i$(e)]),t}function l$(e){return e%2==0}function u$(e,t){if(z(e=e.slice(-2),t=t.slice(-2)))return!0;if(!e.length||!t.length)return!0;if(0===e[0]||0===e[1]||0===t[0]||0===t[1])return!0;if(e.length!==t.length){const n=e[e.length-1],s=t[t.length-1];if(n===s)return!0;if(l$(n)&&l$(s)&&(1===e[0]||1===t[0]))return!0}return e[1]===t[1]&&l$(e[0])&&l$(t[0])}let c$,h$;function p$(e,t){return null!=e.getExtension(t)}function d$(e){try{if(null!=BT(e))return!0}catch(e){return console.log("Error when getting WebGL context: ",e),!1}return!1}function f$(e){const t=jT(e),n=e.createTexture();e.bindTexture(e.TEXTURE_2D,n),e.texImage2D(e.TEXTURE_2D,0,t.internalFormatFloat,1,1,0,t.textureFormatFloat,t.textureTypeFloat,null);const s=e.createFramebuffer();e.bindFramebuffer(e.FRAMEBUFFER,s),e.framebufferTexture2D(e.FRAMEBUFFER,e.COLOR_ATTACHMENT0,e.TEXTURE_2D,n,0);const r=e.checkFramebufferStatus(e.FRAMEBUFFER)===e.FRAMEBUFFER_COMPLETE;return e.bindTexture(e.TEXTURE_2D,null),e.bindFramebuffer(e.FRAMEBUFFER,null),e.deleteTexture(n),e.deleteFramebuffer(s),r}function m$(e,t){Array.isArray(e)||(e=[e]),e.forEach((e=>{null!=e&&F("complex64"!==e.dtype,(()=>`${t} does not support complex64 tensors in the WebGL backend.`))}))}const g$=fe();function y$(){let e,t,n,s,r,a,i,o,l,u;return 2===fe().getNumber("WEBGL_VERSION")?(e="#version 300 es",t="in",n="out",s="in",r="texture",a="outputColor",i="out vec4 outputColor;",o=fe().getBool("WEBGL2_ISNAN_CUSTOM")?"\n      bool isnan_custom(float val) {\n        uint floatToUint = floatBitsToUint(val);\n        return (floatToUint & 0x7fffffffu) > 0x7f800000u;\n      }\n\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan_custom(val.x),\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\n      }\n\n      #define isnan(value) isnan_custom(value)\n    ":"",l="",u="\n      #define round(value) newRound(value)\n      int newRound(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 newRound(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "):(e="",t="attribute",n="varying",s="varying",r="texture2D",a="gl_FragColor",i="",o="\n      #define isnan(value) isnan_custom(value)\n      bool isnan_custom(float val) {\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\n      }\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\n      }\n    ",l="\n      uniform float INFINITY;\n\n      bool isinf(float val) {\n        return abs(val) == INFINITY;\n      }\n      bvec4 isinf(vec4 val) {\n        return equal(abs(val), vec4(INFINITY));\n      }\n    ",u="\n      int round(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 round(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "),{version:e,attribute:t,varyingVs:n,varyingFs:s,texture2D:r,output:a,defineOutput:i,defineSpecialNaN:o,defineSpecialInf:l,defineRound:u}}function b$(e,t,n="index"){const s=te(t);return s.map(((t,r)=>`int ${e[r]} = ${n} / ${t}; ${r===s.length-1?`int ${e[r+1]} = ${n} - ${e[r]} * ${t}`:`index -= ${e[r]} * ${t}`};`)).join("")}function x$(e,t,n="index"){const s=te(t);return s.map(((t,r)=>`int ${e[r]} = ${n} / outShapeStrides[${r}]; ${r===s.length-1?`int ${e[r+1]} = ${n} - ${e[r]} * outShapeStrides[${r}]`:`index -= ${e[r]} * outShapeStrides[${r}]`};`)).join("")}function w$(e){const t=te(e).map((e=>e.toString()));return`\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * ${t[0]} + coords.y * ${t[1]} + coords.z;\n  }\n`}g$.registerFlag("HAS_WEBGL",(()=>g$.getNumber("WEBGL_VERSION")>0)),g$.registerFlag("WEBGL_VERSION",(()=>d$(2)?2:d$(1)?1:0)),g$.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS",(()=>!1)),g$.registerFlag("WEBGL_BUFFER_SUPPORTED",(()=>2===g$.get("WEBGL_VERSION"))),g$.registerFlag("WEBGL_CPU_FORWARD",(()=>!0)),g$.registerFlag("WEBGL_FORCE_F16_TEXTURES",(()=>!1)),g$.registerFlag("WEBGL_PACK",(()=>g$.getBool("HAS_WEBGL"))),g$.registerFlag("WEBGL_PACK_NORMALIZATION",(()=>g$.getBool("WEBGL_PACK"))),g$.registerFlag("WEBGL_PACK_CLIP",(()=>g$.getBool("WEBGL_PACK"))),g$.registerFlag("WEBGL_PACK_DEPTHWISECONV",(()=>g$.getBool("WEBGL_PACK"))),g$.registerFlag("WEBGL_PACK_BINARY_OPERATIONS",(()=>g$.getBool("WEBGL_PACK"))),g$.registerFlag("WEBGL_PACK_UNARY_OPERATIONS",(()=>g$.getBool("WEBGL_PACK"))),g$.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS",(()=>g$.getBool("WEBGL_PACK"))),g$.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS",(()=>g$.getBool("WEBGL_PACK"))),g$.registerFlag("WEBGL_PACK_REDUCE",(()=>g$.getBool("WEBGL_PACK"))),g$.registerFlag("WEBGL_LAZILY_UNPACK",(()=>g$.getBool("WEBGL_PACK"))),g$.registerFlag("WEBGL_CONV_IM2COL",(()=>g$.getBool("WEBGL_PACK"))),g$.registerFlag("WEBGL_PACK_CONV2DTRANSPOSE",(()=>g$.getBool("WEBGL_PACK"))),g$.registerFlag("WEBGL_MAX_TEXTURE_SIZE",(()=>function(e){if(null==c$){const t=BT(e);c$=t.getParameter(t.MAX_TEXTURE_SIZE)}return c$}(g$.getNumber("WEBGL_VERSION")))),g$.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER",(()=>function(e){if(null==h$){const t=BT(e);h$=t.getParameter(t.MAX_TEXTURE_IMAGE_UNITS)}return Math.min(16,h$)}(g$.getNumber("WEBGL_VERSION")))),g$.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION",(()=>{const e=g$.getNumber("WEBGL_VERSION");return 0===e?0:function(e){if(0===e)return 0;let t;const n=BT(e);return t=p$(n,"EXT_disjoint_timer_query_webgl2")&&2===e?2:p$(n,"EXT_disjoint_timer_query")?1:0,t}(e)})),g$.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE",(()=>g$.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0&&!Ur())),g$.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE",(()=>function(e){if(0===e)return!1;const t=BT(e);if(1===e){if(!p$(t,"OES_texture_float"))return!1}else if(!p$(t,"EXT_color_buffer_float"))return!1;return f$(t)}(g$.getNumber("WEBGL_VERSION")))),g$.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED",(()=>!g$.getBool("WEBGL_FORCE_F16_TEXTURES")&&g$.getBool("WEBGL_RENDER_FLOAT32_CAPABLE"))),g$.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED",(()=>function(e){if(0===e)return!1;const t=BT(e);if(1!==e){if(p$(t,"EXT_color_buffer_float"))return f$(t);const e="EXT_color_buffer_half_float";if(p$(t,e)){const n=t.getExtension(e);return function(e,t){const n=jT(e,t),s=e.createTexture();e.bindTexture(e.TEXTURE_2D,s),e.texImage2D(e.TEXTURE_2D,0,n.internalFormatHalfFloat,1,1,0,n.textureFormatFloat,n.textureTypeHalfFloat,null);const r=e.createFramebuffer();e.bindFramebuffer(e.FRAMEBUFFER,r),e.framebufferTexture2D(e.FRAMEBUFFER,e.COLOR_ATTACHMENT0,e.TEXTURE_2D,s,0);const a=e.checkFramebufferStatus(e.FRAMEBUFFER)===e.FRAMEBUFFER_COMPLETE;return e.bindTexture(e.TEXTURE_2D,null),e.bindFramebuffer(e.FRAMEBUFFER,null),e.deleteTexture(s),e.deleteFramebuffer(r),a}(t,n)}return!1}return!!p$(t,"OES_texture_float")&&!!p$(t,"WEBGL_color_buffer_float")&&f$(t)}(g$.getNumber("WEBGL_VERSION")))),g$.registerFlag("WEBGL_FENCE_API_ENABLED",(()=>{return 2===(e=g$.getNumber("WEBGL_VERSION"))&&null!=BT(e).fenceSync;var e})),g$.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM",(()=>g$.getBool("WEBGL_RENDER_FLOAT32_ENABLED")?4:0)),g$.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD",(()=>-1),(e=>{if("number"!=typeof e)throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be a number but got ${e}.`);if(e<0&&-1!==e)throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ${e}.`)})),g$.registerFlag("WEBGL_FLUSH_THRESHOLD",(()=>Ur()?1:-1),(e=>{if("number"!=typeof e)throw new Error(`WEBGL_FLUSH_THRESHOLD must be a number but got ${e}.`);if(e<0&&-1!==e)throw new Error(`WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got ${e}.`)})),g$.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD",(()=>128)),g$.registerFlag("WEBGL_USE_SHAPES_UNIFORMS",(()=>!1)),g$.registerFlag("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD",(()=>1e5)),g$.registerFlag("TOPK_K_CPU_HANDOFF_THRESHOLD",(()=>128)),g$.registerFlag("WEBGL_EXP_CONV",(()=>!1)),g$.registerFlag("SOFTWARE_WEBGL_ENABLED",(()=>g$.getBool("IS_TEST"))),g$.registerFlag("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE",(()=>1/0)),g$.registerFlag("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE",(()=>!1)),g$.registerFlag("WEBGL2_ISNAN_CUSTOM",(()=>!1)),g$.registerFlag("ENGINE_COMPILE_ONLY",(()=>!1));const k$="\n  const float FLOAT_MAX = 1.70141184e38;\n  const float FLOAT_MIN = 1.17549435e-38;\n\n  lowp vec4 encode_float(highp float v) {\n    if (isnan(v)) {\n      return vec4(255, 255, 255, 255);\n    }\n\n    highp float av = abs(v);\n\n    if(av < FLOAT_MIN) {\n      return vec4(0.0, 0.0, 0.0, 0.0);\n    } else if(v > FLOAT_MAX) {\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\n    } else if(v < -FLOAT_MAX) {\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\n    }\n\n    highp vec4 c = vec4(0,0,0,0);\n\n    highp float e = floor(log2(av));\n    highp float m = exp2(fract(log2(av))) - 1.0;\n\n    c[2] = floor(128.0 * m);\n    m -= c[2] / 128.0;\n    c[1] = floor(32768.0 * m);\n    m -= c[1] / 32768.0;\n    c[0] = floor(8388608.0 * m);\n\n    highp float ebias = e + 127.0;\n    c[3] = floor(ebias / 2.0);\n    ebias -= c[3] * 2.0;\n    c[2] += floor(ebias) * 128.0;\n\n    c[3] += 128.0 * step(0.0, -v);\n\n    return c / 255.0;\n  }\n",{getBroadcastDims:v$}=s;function I$(e,t,n){const s=[];if(e.forEach((e=>{const t=L(e.shapeInfo.logicalShape);if(e.shapeInfo.isUniform?s.push(`uniform float ${e.name}${t>1?`[${t}]`:""};`):(s.push(`uniform sampler2D ${e.name};`),s.push(`uniform int offset${e.name};`)),n.enableShapeUniforms){const{uniformShape:t}=D$(n.packedInputs,e.shapeInfo.logicalShape,e.shapeInfo.texShape);switch(t.length){case 1:s.push(`uniform int ${e.name}Shape;`);break;case 2:s.push(`uniform ivec2 ${e.name}Shape;`);break;case 3:s.push(`uniform ivec3 ${e.name}Shape;`);break;case 4:s.push(`uniform ivec4 ${e.name}Shape;`)}s.push(`uniform ivec2 ${e.name}TexShape;`)}})),n.enableShapeUniforms){switch(t.logicalShape.length){case 1:s.push("uniform int outShape;");break;case 2:s.push("uniform ivec2 outShape;"),s.push("uniform int outShapeStrides;");break;case 3:s.push("uniform ivec3 outShape;"),s.push("uniform ivec2 outShapeStrides;");break;case 4:s.push("uniform ivec4 outShape;"),s.push("uniform ivec3 outShapeStrides;")}s.push("uniform ivec2 outTexShape;")}n.customUniforms&&n.customUniforms.forEach((e=>{s.push(`uniform ${e.type} ${e.name}${e.arrayIndex?`[${e.arrayIndex}]`:""};`)}));const r=s.join("\n"),a=e.map((e=>function(e,t,n=!1,s){let r="";r+=n?S$(e,s):N$(e,s);const a=e.shapeInfo.logicalShape,i=t.logicalShape;return a.length<=i.length&&(r+=n?function(e,t){const n=e.name,s=n.charAt(0).toUpperCase()+n.slice(1),r="get"+s+"AtOutCoords",a=e.shapeInfo.logicalShape.length,i=t.logicalShape.length,o=v$(e.shapeInfo.logicalShape,t.logicalShape),l=_$(i),u=i-a;let c;const h=["x","y","z","w","u","v"];c=0===a?"":i<2&&o.length>=1?"coords = 0;":o.map((e=>`coords.${h[e+u]} = 0;`)).join("\n");let p="";p=i<2&&a>0?"coords":e.shapeInfo.logicalShape.map(((e,t)=>`coords.${h[t+u]}`)).join(", ");let d="return outputValue;";const f=1===L(e.shapeInfo.logicalShape),m=1===L(t.logicalShape);if(1!==a||f||m){if(f&&!m)d=1===i?"\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\n      ":"\n        return vec4(outputValue.x);\n      ";else if(o.length){const e=a-2,t=a-1;o.indexOf(e)>-1&&o.indexOf(t)>-1?d="return vec4(outputValue.x);":o.indexOf(e)>-1?d="return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);":o.indexOf(t)>-1&&(d="return vec4(outputValue.xx, outputValue.zz);")}}else d="\n      return vec4(outputValue.xy, outputValue.xy);\n    ";return`\n    vec4 ${r}() {\n      ${l} coords = getOutputCoords();\n      ${c}\n      vec4 outputValue = get${s}(${p});\n      ${d}\n    }\n  `}(e,t):function(e,t){const n=e.name,s=n.charAt(0).toUpperCase()+n.slice(1),r="get"+s+"AtOutCoords",a=t.texShape,i=e.shapeInfo.texShape,o=e.shapeInfo.logicalShape.length,l=t.logicalShape.length;if(!e.shapeInfo.isUniform&&o===l&&null==e.shapeInfo.flatOffset&&z(i,a))return`\n      float ${r}() {\n        return sampleTexture(${n}, resultUV);\n      }\n    `;const u=_$(l),c=v$(e.shapeInfo.logicalShape,t.logicalShape),h=l-o;let p;const d=["x","y","z","w","u","v"];p=0===o?"":l<2&&c.length>=1?"coords = 0;":c.map((e=>`coords.${d[e+h]} = 0;`)).join("\n");let f="";return f=l<2&&o>0?"coords":e.shapeInfo.logicalShape.map(((e,t)=>`coords.${d[t+h]}`)).join(", "),`\n    float ${r}() {\n      ${u} coords = getOutputCoords();\n      ${p}\n      return get${s}(${f});\n    }\n  `}(e,t)),r}(e,t,n.packedInputs,n.enableShapeUniforms))).join("\n"),i=t.texShape,o=y$(),l=function(e){return`\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\n      return ${e.texture2D}(textureSampler, uv).r;\n    }\n  `}(o);let u,c,h=function(e){return`${e.version}\n    precision highp float;\n    precision highp int;\n    precision highp sampler2D;\n    ${e.varyingFs} vec2 resultUV;\n    ${e.defineOutput}\n    const vec2 halfCR = vec2(0.5, 0.5);\n\n    struct ivec5\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n    };\n\n    struct ivec6\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n      int v;\n    };\n\n    uniform float NAN;\n    ${e.defineSpecialNaN}\n    ${e.defineSpecialInf}\n    ${e.defineRound}\n\n    int imod(int x, int y) {\n      return x - y * (x / y);\n    }\n\n    int idiv(int a, int b, float sign) {\n      int res = a / b;\n      int mod = imod(a, b);\n      if (sign < 0. && mod != 0) {\n        res -= 1;\n      }\n      return res;\n    }\n\n    //Based on the work of Dave Hoskins\n    //https://www.shadertoy.com/view/4djSRW\n    #define HASHSCALE1 443.8975\n    float random(float seed){\n      vec2 p = resultUV * seed;\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\n      p3 += dot(p3, p3.yzx + 19.19);\n      return fract((p3.x + p3.y) * p3.z);\n    }\n\n    ${T$}\n    ${$$}\n    ${E$}\n  `}(o);return t.isPacked?(u=function(e,t,n){switch(e.length){case 0:return"\n    int getOutputCoords() {\n      return 0;\n    }\n  ";case 1:return function(e,t,n){const s=[Math.ceil(t[0]/2),Math.ceil(t[1]/2)];return 1===s[0]?n?"\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));\n      }\n    ":`\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ${s[1]}.0);\n      }\n    `:1===s[1]?n?"\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));\n      }\n    ":`\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ${s[0]}.0);\n      }\n    `:n?"\n    int getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);\n    }\n  ":`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${s[0]}, ${s[1]}));\n      return 2 * (resTexRC.x * ${s[1]} + resTexRC.y);\n    }\n  `}(0,t,n);case 2:return function(e,t,n){const s=[Math.ceil(t[0]/2),Math.ceil(t[1]/2)];if(z(e,t))return n?"\n      ivec2 getOutputCoords() {\n        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        return 2 * ivec2(resultUV.yx * vec2(${s[0]}, ${s[1]}));\n      }\n    `;const r=Math.ceil(e[1]/2);return n?"\n    ivec2 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec2(r, c);\n    }\n  ":`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${s[0]}, ${s[1]}));\n\n      int index = resTexRC.x * ${s[1]} + resTexRC.y;\n      int r = 2 * (index / ${r});\n      int c = imod(index, ${r}) * 2;\n\n      return ivec2(r, c);\n    }\n  `}(e,t,n);case 3:return function(e,t,n){if(n)return"\n    ivec3 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec3(b, r, c);\n    }\n  ";const s=[Math.ceil(t[0]/2),Math.ceil(t[1]/2)],r=Math.ceil(e[2]/2),a=r*Math.ceil(e[1]/2);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${s[0]}, ${s[1]}));\n      int index = resTexRC.x * ${s[1]} + resTexRC.y;\n\n      int b = index / ${a};\n      index -= b * ${a};\n\n      int r = 2 * (index / ${r});\n      int c = imod(index, ${r}) * 2;\n\n      return ivec3(b, r, c);\n    }\n  `}(e,t,n);default:return function(e,t,n){if(n)return"\n    ivec4 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatchN = texelsInBatch * outShape[1];\n\n      int b2 = index / texelsInBatchN;\n      index -= b2 * texelsInBatchN;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec4(b2, b, r, c);\n    }\n  ";const s=[Math.ceil(t[0]/2),Math.ceil(t[1]/2)],r=Math.ceil(e[e.length-1]/2),a=r*Math.ceil(e[e.length-2]/2);let i=a,o="",l="b, r, c";for(let t=2;t<e.length-1;t++)i*=e[e.length-t-1],o=`\n      int b${t} = index / ${i};\n      index -= b${t} * ${i};\n    `+o,l=`b${t}, `+l;return`\n    ivec${e.length} getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${s[0]}, ${s[1]}));\n      int index = resTexRC.x * ${s[1]} + resTexRC.y;\n\n      ${o}\n\n      int b = index / ${a};\n      index -= b * ${a};\n\n      int r = 2 * (index / ${r});\n      int c = imod(index, ${r}) * 2;\n\n      return ivec${e.length}(${l});\n    }\n  `}(e,t,n)}}(t.logicalShape,i,n.enableShapeUniforms),c=function(e){return`\n    void setOutput(vec4 val) {\n      ${e.output} = val;\n    }\n  `}(o)):(u=function(e,t,n){switch(e.length){case 0:return"\n    int getOutputCoords() {\n      return 0;\n    }\n  ";case 1:return function(e,t,n){return 1===t[0]?n?"\n      int getOutputCoords() {\n        return int(resultUV.x * float(outTexShape[1]));\n      }\n    ":`\n      int getOutputCoords() {\n        return int(resultUV.x * ${t[1]}.0);\n      }\n    `:1===t[1]?n?"\n      int getOutputCoords() {\n        return int(resultUV.y * float(outTexShape[0]));\n      }\n    ":`\n      int getOutputCoords() {\n        return int(resultUV.y * ${t[0]}.0);\n      }\n    `:n?"\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      return resTexRC.x * outTexShape[1] + resTexRC.y;\n    }\n  ":`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${t[0]}, ${t[1]}));\n      return resTexRC.x * ${t[1]} + resTexRC.y;\n    }\n  `}(0,t,n);case 2:return function(e,t,n){return z(e,t)?n?"\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(${t[0]}, ${t[1]}));\n      }\n    `:1===e[1]?n?"\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${t[0]}, ${t[1]}));\n        int index = resTexRC.x * ${t[1]} + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    `:1===e[0]?n?"\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(0, index);\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${t[0]}, ${t[1]}));\n        int index = resTexRC.x * ${t[1]} + resTexRC.y;\n        return ivec2(0, index);\n      }\n    `:n?"\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      int r = index / outShape[1];\n      int c = index - r * outShape[1];\n      return ivec2(r, c);\n    }\n  ":`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n      int r = index / ${e[1]};\n      int c = index - r * ${e[1]};\n      return ivec2(r, c);\n    }\n  `}(e,t,n);case 3:return function(e,t,n){if(n)return`\n  ivec3 getOutputCoords() {\n    ivec2 resTexRC = ivec2(resultUV.yx *\n                           vec2(outTexShape[0], outTexShape[1]));\n    int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n    ${x$(["r","c","d"],e)}\n    return ivec3(r, c, d);\n  }\n`;const s=b$(["r","c","d"],e);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n      ${s}\n      return ivec3(r, c, d);\n    }\n  `}(e,t,n);case 4:return function(e,t,n){if(n)return`\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      ${x$(["r","c","d","d2"],e)}\n      return ivec4(r, c, d, d2);\n    }\n  `;const s=b$(["r","c","d","d2"],e);return`\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n      ${s}\n      return ivec4(r, c, d, d2);\n    }\n  `}(e,t,n);case 5:return function(e,t){const n=b$(["r","c","d","d2","d3"],e);return`\n    ivec5 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${t[0]},\n                             ${t[1]}));\n\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n\n      ${n}\n\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\n      return outShape;\n    }\n  `}(e,t);case 6:return function(e,t){const n=b$(["r","c","d","d2","d3","d4"],e);return`\n    ivec6 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n\n      ${n}\n\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\n      return result;\n    }\n  `}(e,t);default:throw new Error(`${e.length}-D output sampling is not yet supported`)}}(t.logicalShape,i,n.enableShapeUniforms),c=function(e){return`\n    void setOutput(float val) {\n      ${e.output} = vec4(val, 0, 0, 0);\n    }\n  `}(o)),n.packedInputs&&(h+=C$),[h,l,c,r,u,a,n.userCode].join("\n")}function N$(e,t=!1){const n=e.shapeInfo.logicalShape;switch(n.length){case 0:return function(e,t){const n=e.name,s="get"+n.charAt(0).toUpperCase()+n.slice(1);if(e.shapeInfo.isUniform)return`float ${s}() {return ${n};}`;const[r,a]=e.shapeInfo.texShape;if(1===r&&1===a)return`\n      float ${s}() {\n        return sampleTexture(${n}, halfCR);\n      }\n    `;const i=R$(n);if(t)return`\n    float ${s}() {\n      vec2 uv = uvFromFlat(${n}TexShape[0], ${n}TexShape[1], ${i});\n      return sampleTexture(${n}, uv);\n    }\n  `;const[o,l]=e.shapeInfo.texShape;return`\n    float ${s}() {\n      vec2 uv = uvFromFlat(${o}, ${l}, ${i});\n      return sampleTexture(${n}, uv);\n    }\n  `}(e,t);case 1:return function(e,t){const n=e.name,s="get"+n.charAt(0).toUpperCase()+n.slice(1);if(e.shapeInfo.isUniform)return`\n      float ${s}(int index) {\n        ${A$(e)}\n      }\n    `;const r=e.shapeInfo.texShape,a=r[0],i=r[1];if(1===i&&1===a)return`\n      float ${s}(int index) {\n        return sampleTexture(${n}, halfCR);\n      }\n    `;const o=R$(n);return 1===i?t?`\n      float ${s}(int index) {\n        vec2 uv = vec2(0.5, (float(index + ${o}) + 0.5) / float(${n}TexShape[0]));\n        return sampleTexture(${n}, uv);\n      }\n    `:`\n      float ${s}(int index) {\n        vec2 uv = vec2(0.5, (float(index + ${o}) + 0.5) / ${a}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `:1===a?t?`\n      float ${s}(int index) {\n        vec2 uv = vec2((float(index + ${o}) + 0.5) / float(${n}TexShape[1]), 0.5);\n        return sampleTexture(${n}, uv);\n      }\n    `:`\n      float ${s}(int index) {\n        vec2 uv = vec2((float(index + ${o}) + 0.5) / ${i}.0, 0.5);\n        return sampleTexture(${n}, uv);\n      }\n    `:t?`\n    float ${s}(int index) {\n      vec2 uv = uvFromFlat(${n}TexShape[0], ${n}TexShape[1], index + ${o});\n      return sampleTexture(${n}, uv);\n    }\n  `:`\n    float ${s}(int index) {\n      vec2 uv = uvFromFlat(${a}, ${i}, index + ${o});\n      return sampleTexture(${n}, uv);\n    }\n  `}(e,t);case 2:return function(e,t){const n=e.shapeInfo.logicalShape,s=e.name,r="get"+s.charAt(0).toUpperCase()+s.slice(1),a=e.shapeInfo.texShape;if(null!=a&&z(n,a)){if(t)return`\n      float ${r}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${s}TexShape[1], ${s}TexShape[0]);\n        return sampleTexture(${s}, uv);\n      }\n    `;const e=a[0];return`\n    float ${r}(int row, int col) {\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(${a[1]}.0, ${e}.0);\n      return sampleTexture(${s}, uv);\n    }\n  `}const{newShape:i,keptDims:o}=H(n),l=i;if(l.length<n.length){const n=["row","col"];return`\n      ${N$(F$(e,l),t)}\n      float ${r}(int row, int col) {\n        return ${r}(${O$(n,o)});\n      }\n    `}if(e.shapeInfo.isUniform)return`\n      float ${r}(int row, int col) {\n        int index = round(dot(vec2(row, col), vec2(${n[1]}, 1)));\n        ${A$(e)}\n      }\n    `;const u=a[0],c=a[1],h=R$(s);return 1===c?t?`\n      float ${r}(int row, int col) {\n        float index = dot(vec3(row, col, ${h}), vec3(${s}Shape[1], 1, 1));\n        vec2 uv = vec2(0.5, (index + 0.5) / float(${s}TexShape[0]));\n        return sampleTexture(${s}, uv);\n      }\n    `:`\n    float ${r}(int row, int col) {\n      float index = dot(vec3(row, col, ${h}), vec3(${n[1]}, 1, 1));\n      vec2 uv = vec2(0.5, (index + 0.5) / ${u}.0);\n      return sampleTexture(${s}, uv);\n    }\n  `:1===u?t?`\n      float ${r}(int row, int col) {\n        float index = dot(vec3(row, col, ${h}), vec3(${s}Shape[1], 1, 1));\n        vec2 uv = vec2((index + 0.5) / float(${s}TexShape[1]), 0.5);\n        return sampleTexture(${s}, uv);\n      }\n    `:`\n    float ${r}(int row, int col) {\n      float index = dot(vec3(row, col, ${h}), vec3(${n[1]}, 1, 1));\n      vec2 uv = vec2((index + 0.5) / ${c}.0, 0.5);\n      return sampleTexture(${s}, uv);\n    }\n  `:t?`\n      float ${r}(int row, int col) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ${s}Shape[1] + col + ${h};\n        vec2 uv = uvFromFlat(${s}TexShape[0], ${s}TexShape[1], index);\n        return sampleTexture(${s}, uv);\n      }\n    `:`\n  float ${r}(int row, int col) {\n    // Explicitly use integer operations as dot() only works on floats.\n    int index = row * ${n[1]} + col + ${h};\n    vec2 uv = uvFromFlat(${u}, ${c}, index);\n    return sampleTexture(${s}, uv);\n  }\n`}(e,t);case 3:return function(e,t){const n=e.shapeInfo.logicalShape,s=e.name,r="get"+s.charAt(0).toUpperCase()+s.slice(1),a=n[1]*n[2],i=n[2],{newShape:o,keptDims:l}=H(n),u=o;if(u.length<n.length){const n=["row","col","depth"];return`\n        ${N$(F$(e,u),t)}\n        float ${r}(int row, int col, int depth) {\n          return ${r}(${O$(n,l)});\n        }\n      `}if(e.shapeInfo.isUniform)return`\n      float ${r}(int row, int col, int depth) {\n        int index = round(dot(vec3(row, col, depth),\n                          vec3(${a}, ${i}, 1)));\n        ${A$(e)}\n      }\n    `;const c=e.shapeInfo.texShape,h=c[0],p=c[1],d=e.shapeInfo.flatOffset;if(p===a&&null==d)return t?`\n      float ${r}(int row, int col, int depth) {\n        int stride1 = ${s}Shape[2];\n        float texR = float(row);\n        float texC = dot(vec2(col, depth), vec2(stride1, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${s}TexShape[1], ${s}TexShape[0]);\n        return sampleTexture(${s}, uv);\n      }\n    `:`\n        float ${r}(int row, int col, int depth) {\n          float texR = float(row);\n          float texC = dot(vec2(col, depth), vec2(${i}, 1));\n          vec2 uv = (vec2(texC, texR) + halfCR) /\n                     vec2(${p}.0, ${h}.0);\n          return sampleTexture(${s}, uv);\n        }\n      `;if(p===i&&null==d)return t?`\n      float ${r}(int row, int col, int depth) {\n        float texR = dot(vec2(row, col), vec2(${s}Shape[1], 1));\n        float texC = float(depth);\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${s}TexShape[1], ${s}TexShape[0]);\n        return sampleTexture(${s}, uv);\n      }\n    `:`\n    float ${r}(int row, int col, int depth) {\n      float texR = dot(vec2(row, col), vec2(${n[1]}, 1));\n      float texC = float(depth);\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${p}.0, ${h}.0);\n      return sampleTexture(${s}, uv);\n    }\n  `;const f=R$(s);return t?`\n    float ${r}(int row, int col, int depth) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int stride0 = ${s}Shape[1] * ${s}Shape[2];\n      int stride1 = ${s}Shape[2];\n      int index = row * stride0 + col * stride1 + depth + ${f};\n      vec2 uv = uvFromFlat(${s}TexShape[0], ${s}TexShape[1], index);\n      return sampleTexture(${s}, uv);\n    }\n    `:`\n      float ${r}(int row, int col, int depth) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ${a} + col * ${i} + depth + ${f};\n        vec2 uv = uvFromFlat(${h}, ${p}, index);\n        return sampleTexture(${s}, uv);\n      }\n  `}(e,t);case 4:return function(e,t){const n=e.shapeInfo.logicalShape,s=e.name,r="get"+s.charAt(0).toUpperCase()+s.slice(1),a=n[3],i=n[2]*a,o=n[1]*i,{newShape:l,keptDims:u}=H(n);if(l.length<n.length){const n=["row","col","depth","depth2"];return`\n      ${N$(F$(e,l),t)}\n      float ${r}(int row, int col, int depth, int depth2) {\n        return ${r}(${O$(n,u)});\n      }\n    `}if(e.shapeInfo.isUniform)return`\n      float ${r}(int row, int col, int depth, int depth2) {\n        int index = round(dot(vec4(row, col, depth, depth2),\n                          vec4(${o}, ${i}, ${a}, 1)));\n        ${A$(e)}\n      }\n    `;const c=e.shapeInfo.flatOffset,h=e.shapeInfo.texShape,p=h[0],d=h[1],f=`int stride2 = ${s}Shape[3];`,m=`int stride1 = ${s}Shape[2] * stride2;`,g=`int stride0 = ${s}Shape[1] * stride1;`;if(d===o&&null==c)return t?`\n      float ${r}(int row, int col, int depth, int depth2) {\n        ${f}\n        ${m}\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(stride1, stride2, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${s}TexShape[1], ${s}TexShape[0]);\n        return sampleTexture(${s}, uv);\n      }\n    `:`\n      float ${r}(int row, int col, int depth, int depth2) {\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(${i}, ${a}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${d}.0, ${p}.0);\n        return sampleTexture(${s}, uv);\n      }\n    `;if(d===a&&null==c)return t?`\n      float ${r}(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(${s}Shape[1] * ${s}Shape[2], ${s}Shape[2], 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${s}TexShape[1], ${s}TexShape[0]);\n        return sampleTexture(${s}, uv);\n      }\n    `:`\n      float ${r}(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(${n[1]*n[2]}, ${n[2]}, 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${d}.0, ${p}.0);\n        return sampleTexture(${s}, uv);\n      }\n    `;const y=R$(s);return t?`\n    float ${r}(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      ${f}\n      ${m}\n      ${g}\n      int index = row * stride0 + col * stride1 +\n          depth * stride2 + depth2;\n      vec2 uv = uvFromFlat(${s}TexShape[0], ${s}TexShape[1], index + ${y});\n      return sampleTexture(${s}, uv);\n    }\n  `:`\n    float ${r}(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${o} + col * ${i} +\n          depth * ${a} + depth2;\n      vec2 uv = uvFromFlat(${p}, ${d}, index + ${y});\n      return sampleTexture(${s}, uv);\n    }\n  `}(e,t);case 5:return function(e){const t=e.shapeInfo.logicalShape,n=e.name,s="get"+n.charAt(0).toUpperCase()+n.slice(1),r=t[4],a=t[3]*r,i=t[2]*a,o=t[1]*i,{newShape:l,keptDims:u}=H(t);if(l.length<t.length){const t=["row","col","depth","depth2","depth3"];return`\n      ${N$(F$(e,l))}\n      float ${s}(int row, int col, int depth, int depth2, int depth3) {\n        return ${s}(${O$(t,u)});\n      }\n    `}if(e.shapeInfo.isUniform)return`\n      float ${s}(int row, int col, int depth, int depth2, int depth3) {\n        float index = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${o}, ${i}, ${a}, ${r})) +\n          depth3;\n        ${A$(e)}\n      }\n    `;const c=e.shapeInfo.flatOffset,h=e.shapeInfo.texShape,p=h[0],d=h[1];if(d===o&&null==c)return`\n      float ${s}(int row, int col, int depth, int depth2, int depth3) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n                         vec4(${i}, ${a}, ${r}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${d}.0, ${p}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;if(d===r&&null==c)return`\n      float ${s}(int row, int col, int depth, int depth2, int depth3) {\n        float texR = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${t[1]*t[2]*t[3]},\n               ${t[2]*t[3]}, ${t[3]}, 1));\n        int texC = depth3;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${d}.0, ${p}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;return`\n    float ${s}(int row, int col, int depth, int depth2, int depth3) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${o} + col * ${i} + depth * ${a} +\n          depth2 * ${r} + depth3 + ${R$(n)};\n      vec2 uv = uvFromFlat(${p}, ${d}, index);\n      return sampleTexture(${n}, uv);\n    }\n  `}(e);case 6:return function(e){const t=e.shapeInfo.logicalShape,n=e.name,s="get"+n.charAt(0).toUpperCase()+n.slice(1),{newShape:r,keptDims:a}=H(t);if(r.length<t.length){const t=["row","col","depth","depth2","depth3","depth4"];return`\n      ${N$(F$(e,r))}\n      float ${s}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        return ${s}(${O$(t,a)});\n      }\n    `}const i=t[5],o=t[4]*i,l=t[3]*o,u=t[2]*l,c=t[1]*u;if(e.shapeInfo.isUniform)return`\n      float ${s}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n        int index = round(dot(\n          vec4(row, col, depth, depth2),\n          vec4(${c}, ${u}, ${l}, ${o})) +\n          dot(\n            vec2(depth3, depth4),\n            vec2(${i}, 1)));\n        ${A$(e)}\n      }\n    `;const h=e.shapeInfo.flatOffset,p=e.shapeInfo.texShape,d=p[0],f=p[1];if(f===c&&null==h)return`\n      float ${s}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n          vec4(${u}, ${l}, ${o}, ${i})) +\n               float(depth4);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${f}.0, ${d}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;if(f===i&&null==h)return`\n      float ${s}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        float texR = dot(vec4(row, col, depth, depth2),\n          vec4(${t[1]*t[2]*t[3]*t[4]},\n               ${t[2]*t[3]*t[4]},\n               ${t[3]*t[4]},\n               ${t[4]})) + float(depth3);\n        int texC = depth4;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${f}.0, ${d}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `;return`\n    float ${s}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${c} + col * ${u} + depth * ${l} +\n          depth2 * ${o} + depth3 * ${i} + depth4 + ${R$(n)};\n      vec2 uv = uvFromFlat(${d}, ${f}, index);\n      return sampleTexture(${n}, uv);\n    }\n  `}(e);default:throw new Error(`${n.length}-D input sampling is not yet supported`)}}function S$(e,t){switch(e.shapeInfo.logicalShape.length){case 0:return function(e){const t=e.name;return`\n    vec4 ${"get"+t.charAt(0).toUpperCase()+t.slice(1)}() {\n      return ${y$().texture2D}(${t}, halfCR);\n    }\n  `}(e);case 1:return function(e,t){const n=e.name,s="get"+n.charAt(0).toUpperCase()+n.slice(1),r=e.shapeInfo.texShape,a=y$();if(t)return`\n    vec4 ${s}(int index) {\n      ivec2 packedTexShape = ivec2(ceil(float(${n}TexShape[0]) / 2.0), ceil(float(${n}TexShape[1]) / 2.0));\n      vec2 uv = packedUVfrom1D(\n        packedTexShape[0], packedTexShape[1], index);\n      return ${a.texture2D}(${n}, uv);\n    }\n  `;const i=[Math.ceil(r[0]/2),Math.ceil(r[1]/2)];return`\n    vec4 ${s}(int index) {\n      vec2 uv = packedUVfrom1D(\n        ${i[0]}, ${i[1]}, index);\n      return ${a.texture2D}(${n}, uv);\n    }\n  `}(e,t);case 2:return function(e,t){const n=e.shapeInfo.logicalShape,s=e.name,r="get"+s.charAt(0).toUpperCase()+s.slice(1),a=e.shapeInfo.texShape,i=a[0],o=a[1],l=y$();if(null!=a&&z(n,a))return t?`\n      vec4 ${r}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${s}TexShape[1], ${s}TexShape[0]);\n\n        return ${l.texture2D}(${s}, uv);\n      }\n    `:`\n      vec4 ${r}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${o}.0, ${i}.0);\n\n        return ${l.texture2D}(${s}, uv);\n      }\n    `;if(t)return`\n    vec4 ${r}(int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(${s}TexShape[0]) / 2.0), ceil(float(${s}TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(${s}Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);\n      return ${l.texture2D}(${s}, uv);\n    }\n  `;const u=[Math.ceil(a[0]/2),Math.ceil(a[1]/2)];return`\n    vec4 ${r}(int row, int col) {\n      vec2 uv = packedUVfrom2D(${Math.ceil(n[1]/2)}, ${u[0]}, ${u[1]}, row, col);\n      return ${l.texture2D}(${s}, uv);\n    }\n  `}(e,t);case 3:return function(e,t){const n=e.shapeInfo.logicalShape,s=e.name,r="get"+s.charAt(0).toUpperCase()+s.slice(1),a=e.shapeInfo.texShape,i=[Math.ceil(a[0]/2),Math.ceil(a[1]/2)];if(1===n[0]){const s=[1,2],a=["b","row","col"];return`\n        ${S$(F$(e,n.slice(1)),t)}\n        vec4 ${r}(int b, int row, int col) {\n          return ${r}(${O$(a,s)});\n        }\n      `}const o=y$();if(t)return`\n    vec4 ${r}(int b, int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(${s}TexShape[0]) / 2.0), ceil(float(${s}TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(${s}Shape[2]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(${s}Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom3D(\n        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);\n      return ${o.texture2D}(${s}, uv);\n    }\n  `;const l=i[0],u=i[1],c=Math.ceil(n[2]/2);return`\n    vec4 ${r}(int b, int row, int col) {\n      vec2 uv = packedUVfrom3D(\n        ${l}, ${u}, ${c*Math.ceil(n[1]/2)}, ${c}, b, row, col);\n      return ${o.texture2D}(${s}, uv);\n    }\n  `}(e,t);default:return function(e,t){const n=e.name,s="get"+n.charAt(0).toUpperCase()+n.slice(1),r=y$();if(t)return`\n    vec4 ${s}(int b2, int b, int row, int col) {\n      int valuesPerRow = int(ceil(float(${n}Shape[3]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(${n}Shape[2]) / 2.0));\n      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);\n      texelsInBatch *= ${n}Shape[1];\n      index = b2 * texelsInBatch + index;\n      ivec2 packedTexShape = ivec2(ceil(float(${n}TexShape[0]) / 2.0), ceil(float(${n}TexShape[1]) / 2.0));\n      int texR = index / packedTexShape[1];\n      int texC = index - texR * packedTexShape[1];\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return ${r.texture2D}(${n}, uv);\n    }\n  `;const a=e.shapeInfo.logicalShape,i=a.length,o=e.shapeInfo.texShape,l=[Math.ceil(o[0]/2),Math.ceil(o[1]/2)],u=l[0],c=l[1],h=Math.ceil(a[i-1]/2);let p=h*Math.ceil(a[i-2]/2),d="int b, int row, int col",f=`b * ${p} + (row / 2) * ${h} + (col / 2)`;for(let e=2;e<i-1;e++)d=`int b${e}, `+d,p*=a[i-e-1],f=`b${e} * ${p} + `+f;return`\n    vec4 ${s}(${d}) {\n      int index = ${f};\n      int texR = index / ${c};\n      int texC = index - texR * ${c};\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${c}, ${u});\n      return ${r.texture2D}(${n}, uv);\n    }\n  `}(e,t)}}const T$="\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\n  int texelIndex = index / 2;\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",$$="\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\n  int texNumC, int row, int col) {\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",E$="\nvec2 packedUVfrom3D(int texNumR, int texNumC,\n    int texelsInBatch, int texelsInLogicalRow, int b,\n    int row, int col) {\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",C$="\n  float getChannel(vec4 frag, vec2 innerDims) {\n    vec2 modCoord = mod(innerDims, 2.);\n    return modCoord.x == 0. ?\n      (modCoord.y == 0. ? frag.r : frag.g) :\n      (modCoord.y == 0. ? frag.b : frag.a);\n  }\n  float getChannel(vec4 frag, int dim) {\n    float modCoord = mod(float(dim), 2.);\n    return modCoord == 0. ? frag.r : frag.g;\n  }\n";function R$(e){return`offset${e}`}function A$(e){const t=e.name,n=L(e.shapeInfo.logicalShape);return n<2?`return ${t};`:`\n    for (int i = 0; i < ${n}; i++) {\n      if (i == index) {\n        return ${t}[i];\n      }\n    }\n  `}function _$(e){if(e<=1)return"int";if(2===e)return"ivec2";if(3===e)return"ivec3";if(4===e)return"ivec4";if(5===e)return"ivec5";if(6===e)return"ivec6";throw Error(`GPU for rank ${e} is not yet supported`)}function D$(e,t,n){const{newShape:s,keptDims:r}=H(t),a=t.length,i=e&&3===a&&1===t[0],o=i?t.slice(1):s,l=!e&&a>1&&!z(t,n)&&s.length<a||i;return{useSqueezeShape:l,uniformShape:l?o:t,keptDims:r}}function F$(e,t){const n=JSON.parse(JSON.stringify(e));return n.shapeInfo.logicalShape=t,n}function O$(e,t){return t.map((t=>e[t])).join(", ")}function M$(e,t,n){const s=[],r=[];let a,i,o,l=null,u=null;u=e.getUniformLocation(n,"NAN",!1),1===fe().getNumber("WEBGL_VERSION")&&(l=e.getUniformLocation(n,"INFINITY",!1));const c=!1;for(const r of t.variableNames){const a={name:r,uniform:e.getUniformLocation(n,r,c),offset:e.getUniformLocation(n,`offset${r}`,c)};t.enableShapeUniforms&&(a.shape=e.getUniformLocation(n,`${r}Shape`,c),a.texShape=e.getUniformLocation(n,`${r}TexShape`,c)),s.push(a)}if(t.enableShapeUniforms&&(a=e.getUniformLocation(n,"outShape",c),o=e.getUniformLocation(n,"outShapeStrides",c),i=e.getUniformLocation(n,"outTexShape",c)),t.customUniforms)for(const s of t.customUniforms)r.push(e.getUniformLocation(n,s.name,c));return{variablesLocations:s,customUniformLocations:r,infLoc:l,nanLoc:u,outShapeLocation:a,outShapeStridesLocation:o,outTexShapeLocation:i}}function L$(e,t){if(e.length!==t.length)throw Error(`Binary was compiled with ${e.length} inputs, but was executed with ${t.length} inputs`);e.forEach(((e,n)=>{const s=e.logicalShape,r=t[n],a=r.shape;if(!z(s,a))throw Error(`Binary was compiled with different shapes than the current args. Shapes ${s} and ${a} must match`);if(e.isUniform&&r.isUniform)return;const i=e.texShape,o=r.isUniform?null:r.texData.texShape;if(!z(i,o))throw Error(`Binary was compiled with different texture shapes than the current args. Shape ${i} and ${o} must match`)}))}function z$(e){return fe().getBool("WEBGL_USE_SHAPES_UNIFORMS")&&e<=4}class B${constructor(e){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.outPackingScheme=PT.DENSE,this.customUniforms=[{name:"texShape",type:"ivec2"}];const t=y$();this.outputShape=e,this.enableShapeUniforms=z$(this.outputShape.length),this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${this.enableShapeUniforms?x$(["r","c","d"],e):b$(["r","c","d"],e)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));\n        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getA(rc.x, rc.y, rc.z);\n        }\n\n        ${t.output} = result;\n      }\n    `}}class P${constructor(e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outPackingScheme=PT.DENSE,this.customUniforms=[{name:"texShape",type:"ivec2"}];const t=y$();this.outputShape=e,this.enableShapeUniforms=z$(this.outputShape.length),this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${this.enableShapeUniforms?x$(["r","c","d"],e):b$(["r","c","d"],e)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));\n        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\n        }\n\n        ${t.output} = result;\n      }\n    `}}class W${constructor(e){this.variableNames=["A"],this.outTexUsage=WT.DOWNLOAD;const t=y$();this.outputShape=e,this.userCode=`\n      ${k$}\n\n      void main() {\n        float x = getAAtOutCoords();\n        ${t.output} = encode_float(x);\n      }\n    `}}class V${constructor(e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!1,this.outTexUsage=WT.DOWNLOAD;const t=y$();this.outputShape=e,this.userCode=`\n      ${k$}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\n        ${t.output} = encode_float(x);\n      }\n    `}}const U$={R:0,G:1,B:2,A:3};class G${constructor(e,t=!1,n="RGBA"){this.variableNames=["A"],this.customUniforms=[{name:"texShape",type:"ivec2"}];const s=y$();this.outputShape=e,this.enableShapeUniforms=z$(this.outputShape.length);let r="result";t&&(r="floor(result * 255. + 0.5)");let a="";for(let e=0;e<n.length;e++){const t=n[e];a+=`\n          if(offset == ${e}) {\n            result = values[${U$[t]}];\n          }`}this.userCode=`\n      ${this.enableShapeUniforms?"\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;\n  }\n":w$(e)}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int flatIndex = getFlatIndex(coords);\n        float result = 0.;\n        int offset = imod(flatIndex, ${n.length});\n\n        flatIndex = idiv(flatIndex, ${n.length}, 1.);\n\n        int r = flatIndex / texShape[1];\n        if (r < texShape[0]) {\n          int c = imod(flatIndex, texShape[1]);\n          vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);\n          vec4 values = ${s.texture2D}(A, uv);\n          ${a}\n        }\n        ${s.output} = vec4(${r}, 0., 0., 0.);\n      }\n    `}}class H${constructor(e,t=!1){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.customUniforms=[{name:"texShape",type:"ivec2"}];const n=y$();this.outputShape=e,this.enableShapeUniforms=z$(this.outputShape.length);let s="",r="result";t&&(r="floor(result * 255. + 0.5)");for(let t=0;t<=1;t++)for(let r=0;r<=1;r++){const a=2*t+r;s+=`\n          localCoords = coords;\n          if(localCoords[2] + ${r} < ${this.enableShapeUniforms?"outShape[2]":`${e[2]}`}) {\n          localCoords[2] += ${r};\n          if (localCoords[1] + ${t} < ${this.enableShapeUniforms?"outShape[1]":`${e[1]}`}) {\n            localCoords[1] += ${t};\n\n            flatIndex = getFlatIndex(localCoords);\n            offset = imod(flatIndex, 4);\n\n            flatIndex = idiv(flatIndex, 4, 1.);\n\n            int r = flatIndex / texShape[1];\n            int c = imod(flatIndex, texShape[1]);\n            vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);\n            values = ${n.texture2D}(A, uv);\n\n            if (offset == 0) {\n              result[${a}] = values[0];\n            } else if (offset == 1) {\n              result[${a}] = values[1];\n            } else if (offset == 2) {\n              result[${a}] = values[2];\n            } else {\n              result[${a}] = values[3];\n            }\n          }\n        }\n        `}this.userCode=`\n        ${this.enableShapeUniforms?"\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;\n  }\n":w$(e)}\n\n        void main() {\n          ivec3 coords = getOutputCoords();\n\n          vec4 result = vec4(0.);\n          int flatIndex, r, c, offset;\n          ivec3 localCoords;\n          vec2 uv;\n          vec4 values;\n\n          ${s}\n\n          ${n.output} = ${r};\n        }\n    `}}function j$(e,t,n,s,r,a){!function(e,t){const n=fe().getNumber("WEBGL_MAX_TEXTURE_SIZE");if(e<=0||t<=0)throw new Error(`Requested texture size [${e}x${t}] is invalid.`);if(e>n||t>n)throw new Error(`Requested texture size [${e}x${t}] greater than WebGL maximum on this browser / GPU [${n}x${n}].`)}(t,n);const i=function(e){return r$(e,(()=>e.createTexture()),"Unable to create WebGLTexture.")}(e),o=e.TEXTURE_2D;return KT(e,(()=>e.bindTexture(o,i))),KT(e,(()=>e.texParameteri(o,e.TEXTURE_WRAP_S,e.CLAMP_TO_EDGE))),KT(e,(()=>e.texParameteri(o,e.TEXTURE_WRAP_T,e.CLAMP_TO_EDGE))),KT(e,(()=>e.texParameteri(o,e.TEXTURE_MIN_FILTER,e.NEAREST))),KT(e,(()=>e.texParameteri(o,e.TEXTURE_MAG_FILTER,e.NEAREST))),1===fe().getNumber("WEBGL_VERSION")?KT(e,(()=>e.texImage2D(o,0,s,t,n,0,r,a,null))):KT(e,(()=>e.texStorage2D(o,1,s,t,n))),KT(e,(()=>e.bindTexture(e.TEXTURE_2D,null))),{texture:i,texShape:[n,t]}}function K$(e){return e.internalFormatFloat}function q$(e){return e.internalFormatHalfFloat}function X$(e){return e.downloadTextureFormat}function Y$(e){return e.internalFormatPackedFloat}function J$(e){return e.internalFormatPackedHalfFloat}class Z${constructor(e){this.outputTexture=null,this.program=null,this.disposed=!1,this.itemsToPoll=[];const t=fe().getNumber("WEBGL_VERSION");if(null!=e?(this.gl=e,function(e,t){LT[e]=t}(t,e)):this.gl=BT(t),e=this.gl,2===fe().getNumber("WEBGL_VERSION")){const t=e;this.createVertexArray=()=>KT(t,(()=>t.createVertexArray())),this.bindVertexArray=e=>KT(t,(()=>t.bindVertexArray(e))),this.deleteVertexArray=e=>KT(t,(()=>t.deleteVertexArray(e))),this.getVertexArray=()=>KT(t,(()=>t.getParameter(t.VERTEX_ARRAY_BINDING)))}else if(null!=e){const t=e.getExtension("OES_vertex_array_object");if(null==t)throw new Error("All WebGL1 implementations are expected to offer OES_vertex_array_object.");this.createVertexArray=()=>KT(e,(()=>t.createVertexArrayOES())),this.bindVertexArray=n=>KT(e,(()=>t.bindVertexArrayOES(n))),this.deleteVertexArray=n=>KT(e,(()=>t.deleteVertexArrayOES(n))),this.getVertexArray=()=>KT(e,(()=>e.getParameter(t.VERTEX_ARRAY_BINDING_OES)))}let n="WEBGL_color_buffer_float";const s="EXT_color_buffer_half_float";if(this.parallelCompilationExtension=this.gl.getExtension("KHR_parallel_shader_compile"),1===fe().getNumber("WEBGL_VERSION")){const e="OES_texture_float",t="OES_texture_half_float";if(this.textureFloatExtension=XT(this.gl,e),p$(this.gl,t))this.textureHalfFloatExtension=XT(this.gl,t);else if(fe().get("WEBGL_FORCE_F16_TEXTURES"))throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");if(this.colorBufferFloatExtension=this.gl.getExtension(n),p$(this.gl,s))this.colorBufferHalfFloatExtension=XT(this.gl,s);else if(fe().get("WEBGL_FORCE_F16_TEXTURES"))throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.")}else if(n="EXT_color_buffer_float",p$(this.gl,n))this.colorBufferFloatExtension=this.gl.getExtension(n);else{if(!p$(this.gl,s))throw new Error("GL context does not support color renderable floats");this.colorBufferHalfFloatExtension=this.gl.getExtension(s)}this.vertexBuffer=function(e){return function(e,t){const n=r$(e,(()=>e.createBuffer()),"Unable to create WebGLBuffer");return KT(e,(()=>e.bindBuffer(e.ARRAY_BUFFER,n))),KT(e,(()=>e.bufferData(e.ARRAY_BUFFER,t,e.STATIC_DRAW))),n}(e,new Float32Array([-1,1,0,0,1,-1,-1,0,0,0,1,1,0,1,1,1,-1,0,1,0]))}(this.gl),this.indexBuffer=function(e){return function(e,t){const n=r$(e,(()=>e.createBuffer()),"Unable to create WebGLBuffer");return KT(e,(()=>e.bindBuffer(e.ELEMENT_ARRAY_BUFFER,n))),KT(e,(()=>e.bufferData(e.ELEMENT_ARRAY_BUFFER,t,e.STATIC_DRAW))),n}(e,new Uint16Array([0,1,2,2,1,3]))}(this.gl),this.framebuffer=function(e){return r$(e,(()=>e.createFramebuffer()),"Unable to create WebGLFramebuffer.")}(this.gl),this.textureConfig=jT(this.gl,this.textureHalfFloatExtension)}get debug(){return fe().getBool("DEBUG")}dispose(){if(this.disposed)return;null!=this.program&&console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing."),null!=this.outputTexture&&console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");const e=this.gl;KT(e,(()=>e.finish())),KT(e,(()=>e.bindFramebuffer(e.FRAMEBUFFER,null))),KT(e,(()=>e.deleteFramebuffer(this.framebuffer))),KT(e,(()=>e.bindBuffer(e.ARRAY_BUFFER,null))),KT(e,(()=>e.bindBuffer(e.ELEMENT_ARRAY_BUFFER,null))),KT(e,(()=>e.deleteBuffer(this.indexBuffer))),this.disposed=!0}createFloat32MatrixTexture(e,t){return this.throwIfDisposed(),function(e,t,n,s){const[r,a]=UT(t,n);return j$(e,r,a,K$(s),s.textureFormatFloat,e.FLOAT)}(this.gl,e,t,this.textureConfig)}createFloat16MatrixTexture(e,t){return this.throwIfDisposed(),function(e,t,n,s){const[r,a]=UT(t,n);return j$(e,r,a,q$(s),s.textureFormatFloat,s.textureTypeHalfFloat)}(this.gl,e,t,this.textureConfig)}createUnsignedBytesMatrixTexture(e,t){return this.throwIfDisposed(),function(e,t,n,s){const[r,a]=UT(t,n);return j$(e,r,a,X$(s),e.RGBA,e.UNSIGNED_BYTE)}(this.gl,e,t,this.textureConfig)}uploadPixelDataToTexture(e,t){this.throwIfDisposed(),function(e,t,n){KT(e,(()=>e.bindTexture(e.TEXTURE_2D,t))),n.data instanceof Uint8Array?2===fe().getNumber("WEBGL_VERSION")?KT(e,(()=>e.texSubImage2D(e.TEXTURE_2D,0,0,0,n.width,n.height,e.RGBA,e.UNSIGNED_BYTE,n.data))):KT(e,(()=>e.texImage2D(e.TEXTURE_2D,0,e.RGBA,n.width,n.height,0,e.RGBA,e.UNSIGNED_BYTE,n.data))):2===fe().getNumber("WEBGL_VERSION")?KT(e,(()=>e.texSubImage2D(e.TEXTURE_2D,0,0,0,e.RGBA,e.UNSIGNED_BYTE,n))):KT(e,(()=>e.texImage2D(e.TEXTURE_2D,0,e.RGBA,e.RGBA,e.UNSIGNED_BYTE,n))),KT(e,(()=>e.bindTexture(e.TEXTURE_2D,null)))}(this.gl,e,t)}uploadDenseMatrixToTexture(e,t,n,s){this.throwIfDisposed(),function(e,t,n,s,r,a){let i,o,l;KT(e,(()=>e.bindTexture(e.TEXTURE_2D,t))),r instanceof Uint8Array?(i=new Uint8Array(n*s*4),o=e.UNSIGNED_BYTE,l=e.RGBA):(i=new Float32Array(n*s*4),o=e.FLOAT,l=a.internalFormatPackedFloat),i.set(r),2===fe().getNumber("WEBGL_VERSION")?KT(e,(()=>e.texSubImage2D(e.TEXTURE_2D,0,0,0,n,s,e.RGBA,o,i))):KT(e,(()=>e.texImage2D(e.TEXTURE_2D,0,l,n,s,0,e.RGBA,o,i))),KT(e,(()=>e.bindTexture(e.TEXTURE_2D,null)))}(this.gl,e,t,n,s,this.textureConfig)}createFloat16PackedMatrixTexture(e,t){return this.throwIfDisposed(),function(e,t,n,s){const[r,a]=HT(t,n);return j$(e,r,a,J$(s),e.RGBA,s.textureTypeHalfFloat)}(this.gl,e,t,this.textureConfig)}createPackedMatrixTexture(e,t){return this.throwIfDisposed(),function(e,t,n,s){const[r,a]=HT(t,n);return j$(e,r,a,Y$(s),e.RGBA,e.FLOAT)}(this.gl,e,t,this.textureConfig)}deleteMatrixTexture(e){this.throwIfDisposed(),this.outputTexture===e&&(n$(this.gl,this.framebuffer),this.outputTexture=null),KT(this.gl,(()=>this.gl.deleteTexture(e)))}downloadByteEncodedFloatMatrixFromOutputTexture(e,t,n){return this.downloadMatrixDriver(e,(()=>function(e,t,n,s){const[r,a]=UT(t,n),i=new Uint8Array(t*n*4);return KT(e,(()=>e.readPixels(0,0,r,a,s.downloadTextureFormat,e.UNSIGNED_BYTE,i))),new Float32Array(i.buffer)}(this.gl,t,n,this.textureConfig)))}downloadPackedMatrixFromBuffer(e,t,n,s,r,a){return function(e,t,n,s,r,a,i){const o=e,l=new Float32Array(function(e,t){const[n,s]=HT(e,t);return n*s*4}(a,i));return o.bindBuffer(o.PIXEL_PACK_BUFFER,t),o.getBufferSubData(o.PIXEL_PACK_BUFFER,0,l),o.bindBuffer(o.PIXEL_PACK_BUFFER,null),l}(this.gl,e,0,0,0,r,a,this.textureConfig)}downloadFloat32MatrixFromBuffer(e,t){return function(e,t,n){const s=e,r=new Float32Array(n);return s.bindBuffer(s.PIXEL_PACK_BUFFER,t),s.getBufferSubData(s.PIXEL_PACK_BUFFER,0,r),s.bindBuffer(s.PIXEL_PACK_BUFFER,null),r}(this.gl,e,t)}createBufferFromTexture(e,t,n){this.bindTextureToFrameBuffer(e);const s=function(e,t,n){const s=e.createBuffer();KT(e,(()=>e.bindBuffer(e.PIXEL_PACK_BUFFER,s)));const r=16*t*n;return KT(e,(()=>e.bufferData(e.PIXEL_PACK_BUFFER,r,e.STREAM_READ))),KT(e,(()=>e.readPixels(0,0,n,t,e.RGBA,e.FLOAT,0))),KT(e,(()=>e.bindBuffer(e.PIXEL_PACK_BUFFER,null))),s}(this.gl,t,n,this.textureConfig);return this.unbindTextureToFrameBuffer(),s}createAndWaitForFence(){const e=this.createFence(this.gl);return this.pollFence(e)}createFence(e){let t,n;if(fe().getBool("WEBGL_FENCE_API_ENABLED")){const s=e,r=s.fenceSync(s.SYNC_GPU_COMMANDS_COMPLETE,0);e.flush(),n=()=>{const e=s.clientWaitSync(r,0,0);return e===s.ALREADY_SIGNALED||e===s.CONDITION_SATISFIED},t=r}else fe().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0?(t=this.beginQuery(),this.endQuery(),n=()=>this.isQueryAvailable(t,fe().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))):n=()=>!0;return{query:t,isFencePassed:n}}downloadMatrixFromPackedTexture(e,t,n){return this.downloadMatrixDriver(e,(()=>function(e,t,n){const s=new Float32Array(t*n*4);return KT(e,(()=>e.readPixels(0,0,n,t,e.RGBA,e.FLOAT,s))),s}(this.gl,t,n)))}createProgram(e){this.throwIfDisposed();const t=this.gl;null==this.vertexShader&&(this.vertexShader=function(e){const t=y$();return function(e,t){const n=r$(e,(()=>e.createShader(e.VERTEX_SHADER)),"Unable to create vertex WebGLShader.");if(KT(e,(()=>e.shaderSource(n,t))),KT(e,(()=>e.compileShader(n))),!1===e.getShaderParameter(n,e.COMPILE_STATUS))throw console.log(e.getShaderInfoLog(n)),new Error("Failed to compile vertex shader.");return n}(e,`${t.version}\n    precision highp float;\n    ${t.attribute} vec3 clipSpacePos;\n    ${t.attribute} vec2 uv;\n    ${t.varyingVs} vec2 resultUV;\n\n    void main() {\n      gl_Position = vec4(clipSpacePos, 1);\n      resultUV = uv;\n    }`)}(t));const n=function(e){return r$(e,(()=>e.createProgram()),"Unable to create WebGLProgram.")}(t);KT(t,(()=>t.attachShader(n,this.vertexShader))),KT(t,(()=>t.attachShader(n,e))),function(e,t){if(KT(e,(()=>e.linkProgram(t))),!fe().get("ENGINE_COMPILE_ONLY")&&!1===e.getProgramParameter(t,e.LINK_STATUS))throw console.log(e.getProgramInfoLog(t)),new Error("Failed to link vertex and fragment shaders.")}(t,n);const s=Object.assign(n,{vao:this.createVertexArray()});return this.debug&&ZT(t,s),s}buildVao(e){this.setProgram(e),this.bindVertexArray(e.vao);const t=this.gl;KT(t,(()=>t.bindBuffer(t.ELEMENT_ARRAY_BUFFER,this.indexBuffer))),function(e,t,n){KT(e,(()=>e.bindBuffer(e.ARRAY_BUFFER,n))),QT(e,t,"clipSpacePos",n,3,20,0)&&QT(e,t,"uv",n,2,20,12)}(t,e,this.vertexBuffer)}deleteProgram(e){this.throwIfDisposed(),e===this.program&&(this.program=null),null!=e&&(KT(this.gl,(()=>this.gl.deleteProgram(e))),this.deleteVertexArray(e.vao))}setProgram(e){this.throwIfDisposed(),this.program=e,null!=this.program&&this.debug&&ZT(this.gl,this.program),KT(this.gl,(()=>this.gl.useProgram(e)))}getUniformLocation(e,t,n=!0){return this.throwIfDisposed(),n?function(e,t,n){return r$(e,(()=>e.getUniformLocation(t,n)),'uniform "'+n+'" not present in program.')}(this.gl,e,t):function(e,t,n){return e.getUniformLocation(t,n)}(this.gl,e,t)}getAttributeLocation(e,t){return this.throwIfDisposed(),KT(this.gl,(()=>this.gl.getAttribLocation(e,t)))}getUniformLocationNoThrow(e,t){return this.throwIfDisposed(),this.gl.getUniformLocation(e,t)}setInputMatrixTexture(e,t,n){this.throwIfDisposed(),this.throwIfNoProgram(),e$(this.gl,e,t,n)}setOutputMatrixTexture(e,t,n){this.setOutputMatrixTextureDriver(e,n,t)}setOutputPackedMatrixTexture(e,t,n){this.throwIfDisposed();const[s,r]=HT(t,n);this.setOutputMatrixTextureDriver(e,s,r)}setOutputMatrixWriteRegion(e,t,n,s){this.setOutputMatrixWriteRegionDriver(n,e,s,t)}setOutputPackedMatrixWriteRegion(e,t,n,s){throw new Error("setOutputPackedMatrixWriteRegion not implemented.")}debugValidate(){null!=this.program&&ZT(this.gl,this.program),s$(this.gl)}executeProgram(){this.throwIfDisposed(),this.throwIfNoProgram();const e=this.gl;if(this.debug){const e=this.getVertexArray();console.assert(e===this.program.vao,"VAO changed between setProgram and executeProgram!"),this.debugValidate()}KT(e,(()=>e.drawElements(e.TRIANGLES,6,e.UNSIGNED_SHORT,0)))}blockUntilAllProgramsCompleted(){this.throwIfDisposed(),KT(this.gl,(()=>this.gl.finish()))}getQueryTimerExtension(){return null==this.disjointQueryTimerExtension&&(this.disjointQueryTimerExtension=XT(this.gl,2===fe().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")?"EXT_disjoint_timer_query_webgl2":"EXT_disjoint_timer_query")),this.disjointQueryTimerExtension}getQueryTimerExtensionWebGL2(){return this.getQueryTimerExtension()}getQueryTimerExtensionWebGL1(){return this.getQueryTimerExtension()}beginQuery(){if(2===fe().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")){const e=this.gl,t=this.getQueryTimerExtensionWebGL2(),n=e.createQuery();return e.beginQuery(t.TIME_ELAPSED_EXT,n),n}const e=this.getQueryTimerExtensionWebGL1(),t=e.createQueryEXT();return e.beginQueryEXT(e.TIME_ELAPSED_EXT,t),t}endQuery(){if(2===fe().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")){const e=this.gl,t=this.getQueryTimerExtensionWebGL2();return void e.endQuery(t.TIME_ELAPSED_EXT)}const e=this.getQueryTimerExtensionWebGL1();e.endQueryEXT(e.TIME_ELAPSED_EXT)}async waitForQueryAndGetTime(e){return await V((()=>this.disposed||this.isQueryAvailable(e,fe().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")))),this.getQueryTime(e,fe().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))}getQueryTime(e,t){if(0===t)return null;if(2===t){const t=this.gl;return t.getQueryParameter(e,t.QUERY_RESULT)/1e6}{const t=this.getQueryTimerExtensionWebGL1();return t.getQueryObjectEXT(e,t.QUERY_RESULT_EXT)/1e6}}isQueryAvailable(e,t){if(0===t)return!0;if(2===t){const t=this.gl,n=this.getQueryTimerExtensionWebGL2(),s=t.getQueryParameter(e,t.QUERY_RESULT_AVAILABLE);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(n.GPU_DISJOINT_EXT)),s&&!this.disjoint}{const t=this.getQueryTimerExtensionWebGL1(),n=t.getQueryObjectEXT(e,t.QUERY_RESULT_AVAILABLE_EXT);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(t.GPU_DISJOINT_EXT)),n&&!this.disjoint}}pollFence(e){return new Promise((t=>{this.addItemToPoll((()=>e.isFencePassed()),(()=>t()))}))}pollItems(){const e=function(e){let t=0;for(;t<e.length&&e[t]();++t);return t-1}(this.itemsToPoll.map((e=>e.isDoneFn)));for(let t=0;t<=e;++t){const{resolveFn:e}=this.itemsToPoll[t];e()}this.itemsToPoll=this.itemsToPoll.slice(e+1)}addItemToPoll(e,t){if(this.itemsToPoll.push({isDoneFn:e,resolveFn:t}),this.itemsToPoll.length>1)return;let n;"setTimeoutCustom"in fe().platform&&(n=fe().platform.setTimeoutCustom.bind(fe().platform)),V((()=>(this.pollItems(),0===this.itemsToPoll.length)),(()=>0),null,n)}bindTextureToFrameBuffer(e){this.throwIfDisposed(),t$(this.gl,e,this.framebuffer),this.debug&&s$(this.gl)}unbindTextureToFrameBuffer(){null!=this.outputTexture?(t$(this.gl,this.outputTexture,this.framebuffer),this.debug&&s$(this.gl)):n$(this.gl,this.framebuffer)}downloadMatrixDriver(e,t){this.bindTextureToFrameBuffer(e);const n=t();return this.unbindTextureToFrameBuffer(),n}setOutputMatrixTextureDriver(e,t,n){this.throwIfDisposed();const s=this.gl;t$(s,e,this.framebuffer),this.debug&&s$(s),this.outputTexture=e,KT(s,(()=>s.viewport(0,0,t,n))),KT(s,(()=>s.scissor(0,0,t,n)))}setOutputMatrixWriteRegionDriver(e,t,n,s){this.throwIfDisposed(),KT(this.gl,(()=>this.gl.scissor(e,t,n,s)))}throwIfDisposed(){if(this.disposed)throw new Error("Attempted to use disposed GPGPUContext.")}throwIfNoProgram(){if(null==this.program)throw new Error("No GPU program is currently set.")}}const{mx:Q$,XI:eE,Nk:tE,f6:nE,ct:sE,YG:rE,hH:aE,z3:iE,sG:oE,uM:lE,vS:uE,qB:cE,GG:hE,rq:pE,lg:dE,WR:fE,cu:mE,GE:gE,px:yE,jC:bE,He:xE,hE:wE,BF:kE,Dk:vE,cl:IE,_B:NE,ub:SE,_f:TE,Ku:$E,qy:EE,Zy:CE,bu:RE,zv:AE,dH:_E,HS:DE,yH:FE,l3:OE,z9:ME,x6:LE,_m:zE,eW:BE,GK:PE,SP:WE,yr:VE,dl:UE,Dw:GE,xT:HE,_X:jE,wz:KE}=r;function qE(e,t){return["x","y","z","w","u","v"].slice(0,t).map((t=>`${e}.${t}`))}function XE(e,t){return 1===t?[e]:qE(e,t)}class YE{constructor(e){if(this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.outputShape=e,this.rank=e.length,this.enableShapeUniforms=z$(this.outputShape.length),0===this.rank)this.userCode="\n        void main() {\n          setOutput(vec4(getA(), 0., 0., 0.));\n        }\n      ";else{const e=XE("rc",this.rank),t=_$(this.rank),n=this.getOutOfBoundsCondition(e),s=this.getSetup(e),r=this.getOutput(e);this.userCode=`\n        void main() {\n          ${t} rc = getOutputCoords();\n\n          if(${n}) {\n            setOutput(vec4(0));\n          } else {\n            ${s}\n\n            setOutput(vec4(${r}));\n          }\n        }\n      `}}getSourceCoordsArr(e){const t=[];for(let n=0;n<=1;n++)for(let s=0;s<=1;s++){let r=`${0===n?"r":"rp1"}, ${0===s?"c":"cp1"}`;for(let t=2;t<this.rank;t++)r=`${e[e.length-1-t]},`+r;t.push(r)}return t}getOutOfBoundsCondition(e){if(1===this.rank)return`rc > ${this.enableShapeUniforms?"outShape":this.outputShape[0]}`;let t="";for(let n=this.rank-2;n<this.rank;n++)t+=`${e[n]} >= ${this.enableShapeUniforms?`outShape[${n}]`:this.outputShape[n]}`,n<this.rank-1&&(t+="||");return t}getSetup(e){if(1===this.rank)return"";const t=e.slice(-2),n=this.enableShapeUniforms?`outShape[${this.rank} - 1]`:this.outputShape[this.rank-1],s=this.enableShapeUniforms?`outShape[${this.rank} - 2]`:this.outputShape[this.rank-2];return`\n      int r = ${t[0]};\n      int c = ${t[1]};\n      int rp1 = r + 1;\n      int cp1 = c + 1;\n\n      bool cEdge = cp1 >= ${n};\n      bool rEdge = rp1 >= ${s};\n    `}getOutput(e){const t=this.getSourceCoordsArr(e);return 1===this.rank?`getA(rc), (rc + 1 >= ${this.enableShapeUniforms?"outShape":this.outputShape[0]} ? 0. : getA(rc + 1)), 0, 0`:`getA(${t[0]}),\n            cEdge ? 0. : getA(${t[1]}),\n            rEdge ? 0. : getA(${t[2]}),\n            rEdge || cEdge ? 0. : getA(${t[3]})`}}class JE{constructor(e,t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"inputShape",type:"ivec3"}],this.outputShape=e,this.enableShapeUniforms=z$(this.outputShape.length);let n="";for(let e=0;e<4;e++){let t="thisRC = rc;";e%2==1&&(t+="thisRC.z += 1;"),e>1&&(t+="thisRC.y += 1;"),n+=`\n        ${t}\n        ${e>0?"if(thisRC.y < rows && thisRC.z < cols){":""}\n          int flatIndex = getFlatIndex(thisRC);\n\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\n\n          result[${e}] =\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\n        ${e>0?"}":""}\n      `}var s,r;this.userCode=`\n      ${s=t,r=this.enableShapeUniforms,`\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\n      ${r?function(e,t,n="index"){const s=function(e,t){const n=e.length,s=e.map((e=>`${t}[${e}]`)),r=new Array(n-1);r[n-2]=s[n-1];for(let e=n-3;e>=0;--e)r[e]=`(${r[e+1]} * ${s[e+1]})`;return r}(e.map(((e,t)=>t)),t);return s.map(((t,r)=>`int ${e[r]} = ${n} / ${s[r]}; ${r===s.length-1?`int ${e[r+1]} = ${n} - ${e[r]} * ${s[r]}`:`index -= ${e[r]} * ${s[r]}`};`)).join("")}(["r","c","d"],"inputShape"):b$(["r","c","d"],s)}\n      return ivec3(r, c, d);\n    }\n  `}\n      ${this.enableShapeUniforms?"\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;\n  }\n":w$(e)}\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0.);\n\n        ivec3 thisRC;\n        int rows = ${this.enableShapeUniforms?"outShape[1]":e[1]};\n        int cols = ${this.enableShapeUniforms?"outShape[2]":e[2]};\n\n        ${n}\n\n        setOutput(result);\n      }\n    `}}class ZE{constructor(e){this.gpgpu=e,this.numUsedTextures=0,this.numFreeTextures=0,this._numBytesAllocated=0,this._numBytesFree=0,this.freeTextures={},this.usedTextures={},this.logEnabled=!1}acquireTexture(e,t,n){const s=eC(t,n),r=tC(e,s,n);r in this.freeTextures||(this.freeTextures[r]=[]),r in this.usedTextures||(this.usedTextures[r]=[]);const a=QE(e,s,this.gpgpu.gl,this.gpgpu.textureConfig,n);if(this.freeTextures[r].length>0){this.numFreeTextures--,this.numUsedTextures++,this._numBytesFree-=a,this.log();const e=this.freeTextures[r].pop();return this.usedTextures[r].push(e),e}let i;return s===VT.PACKED_2X2_FLOAT32?i=this.gpgpu.createPackedMatrixTexture(e[0],e[1]):s===VT.PACKED_2X2_FLOAT16?i=this.gpgpu.createFloat16PackedMatrixTexture(e[0],e[1]):s===VT.UNPACKED_FLOAT32?i=this.gpgpu.createFloat32MatrixTexture(e[0],e[1]):s===VT.UNPACKED_FLOAT16?i=this.gpgpu.createFloat16MatrixTexture(e[0],e[1]):s===VT.PACKED_4X1_UNSIGNED_BYTE&&(i=this.gpgpu.createUnsignedBytesMatrixTexture(e[0],e[1])),this.usedTextures[r].push(i),this.numUsedTextures++,this._numBytesAllocated+=a,this.log(),i}releaseTexture(e,t,n,s){if(null==this.freeTextures)return;const r=eC(n,s),a=tC(t,r,s);a in this.freeTextures||(this.freeTextures[a]=[]);const i=QE(t,r,this.gpgpu.gl,this.gpgpu.textureConfig,s),o=fe().getNumber("WEBGL_DELETE_TEXTURE_THRESHOLD");-1!==o&&this._numBytesAllocated>o?(this.gpgpu.deleteMatrixTexture(e.texture),this._numBytesAllocated-=i):(this.freeTextures[a].push(e),this.numFreeTextures++,this._numBytesFree+=i),this.numUsedTextures--;const l=this.usedTextures[a],u=l&&l.indexOf(e);if(null==u||u<0)throw new Error("Cannot release a texture that was never provided by this texture manager");l[u]=l[l.length-1],l.pop(),this.log()}log(){if(!this.logEnabled)return;const e=this.numFreeTextures+this.numUsedTextures;console.log("Free/Used",`${this.numFreeTextures} / ${this.numUsedTextures}`,`(${e})`);const t=this._numBytesFree/this._numBytesAllocated;console.log(`Bytes allocated: ${this._numBytesAllocated}`),console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100*t)}%)`)}get numBytesAllocated(){return this._numBytesAllocated}get numBytesFree(){return this._numBytesFree}getNumUsedTextures(){return this.numUsedTextures}getNumFreeTextures(){return this.numFreeTextures}dispose(){if(null!=this.freeTextures){for(const e in this.freeTextures)this.freeTextures[e].forEach((e=>{this.gpgpu.deleteMatrixTexture(e.texture)}));for(const e in this.usedTextures)this.usedTextures[e].forEach((e=>{this.gpgpu.deleteMatrixTexture(e.texture)}));this.freeTextures=null,this.usedTextures=null,this.numUsedTextures=0,this.numFreeTextures=0,this._numBytesAllocated=0,this._numBytesFree=0}}}function QE(e,t,n,s,r){const a=function(e,t){switch(e){case VT.PACKED_2X2_FLOAT32:return Y$(t);case VT.PACKED_2X2_FLOAT16:return J$(t);case VT.UNPACKED_FLOAT32:return K$(t);case VT.UNPACKED_FLOAT16:return q$(t);case VT.PACKED_4X1_UNSIGNED_BYTE:return X$(t);default:throw new Error(`Unknown physical texture type ${e}`)}}(t,s);let i;if(r){const[t,n]=HT(e[0],e[1]);i=t*n}else{const[t,n]=UT(e[0],e[1]);i=t*n}const o=function(e,t){const n=e;if(t===n.R32F)return 4;if(t===n.R16F)return 2;if(t===n.RGBA32F)return 16;if(t===e.RGBA)return 16;if(t===n.RGBA16F)return 8;if(t===n.RGBA8)return 4;throw new Error(`Unknown internal format ${t}`)}(n,a);return i*o}function eC(e,t){if(e===WT.UPLOAD)return VT.PACKED_2X2_FLOAT32;if(e===WT.RENDER||null==e)return function(e){return fe().getBool("WEBGL_RENDER_FLOAT32_ENABLED")?e?VT.PACKED_2X2_FLOAT32:VT.UNPACKED_FLOAT32:e?VT.PACKED_2X2_FLOAT16:VT.UNPACKED_FLOAT16}(t);if(e===WT.DOWNLOAD||e===WT.PIXELS)return VT.PACKED_4X1_UNSIGNED_BYTE;throw new Error(`Unknown logical texture type ${e}`)}function tC(e,t,n){return`${e[0]}_${e[1]}_${t}_${n}`}class nC{constructor(e,t){this.variableNames=["A"],this.outputShape=e,this.enableShapeUniforms=z$(this.outputShape.length),this.userCode=`\n      float unaryOperation(float x) {\n        ${t}\n      }\n\n      void main() {\n        float x = getAAtOutCoords();\n        float y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}const sC="if (isnan(x)) return x;",rC="return abs(x);",aC=sC+"\n  return (x < 0.0) ? 0.0 : x;\n",iC=sC+"\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",oC="return x;";class lC{constructor(e,t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e,this.enableShapeUniforms=z$(this.outputShape.length),this.userCode=`\n      vec4 unaryOperation(vec4 x) {\n        ${t}\n      }\n\n      void main() {\n        vec4 x = getAAtOutCoords();\n        vec4 y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}class uC{constructor(e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!1,this.outputShape=e,this.enableShapeUniforms=z$(this.outputShape.length);const t=e.length,n=XE("rc",t),s=_$(t),r=function(e,t){if(1===e)return"rc";let n="";for(let s=0;s<e;s++)n+=t[s],s<e-1&&(n+=",");return n}(t,n),a=n.slice(-2),i=t<=1?"rc":`vec2(${a.join(",")})`;this.userCode=`\n      void main() {\n        ${s} rc = getOutputCoords();\n        vec4 packedInput = getA(${r});\n\n        setOutput(getChannel(packedInput, ${i}));\n      }\n    `}}const cC=dh,hC={},pC=fe().getNumber("CPU_HANDOFF_SIZE_THRESHOLD");class dC extends E{nextDataId(){return dC.nextDataId++}constructor(e){if(super(),this.pendingRead=new WeakMap,this.pendingDisposal=new WeakSet,this.dataRefCount=new WeakMap,this.numBytesInGPU=0,this.uploadWaitMs=0,this.downloadWaitMs=0,this.lastGlFlushTime=0,this.warnedAboutMemory=!1,this.pendingDeletes=0,this.disposed=!1,!fe().getBool("HAS_WEBGL"))throw new Error("WebGL is not supported on this device");let t;if(null!=e){if(e instanceof Z$)t=e;else{const n=BT(fe().getNumber("WEBGL_VERSION"),e);t=new Z$(n)}this.binaryCache={},this.gpgpuCreatedLocally=!1}else{const e=BT(fe().getNumber("WEBGL_VERSION"));t=new Z$(e),this.binaryCache=((n=fe().getNumber("WEBGL_VERSION"))in hC||(hC[n]={}),hC[n]),this.gpgpuCreatedLocally=!0}var n;this.gpgpu=t,this.canvas=this.gpgpu.gl.canvas,this.textureManager=new ZE(this.gpgpu),this.numMBBeforeWarning=null==fe().global.screen?1024:fe().global.screen.height*fe().global.screen.width*window.devicePixelRatio*600/1024/1024,this.texData=new $(this,sa())}numDataIds(){return this.texData.numDataIds()-this.pendingDeletes}writeTexture(e,t,n,s,r,a){const i=this.makeTensorInfo(t,n),o=this.texData.get(i.dataId);o.isPacked=!1,o.texture={texture:e,texShape:[s,r]},o.texShape=[s,r];const l=o$(t),u=new G$(l,!1,a),c=this.runWebGLProgram(u,[i],n,[[s,r]]);return c.shape=t,o.texture=null,this.disposeIntermediateTensorInfo(i),c.dataId}write(e,t,n){if((fe().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS")||fe().getBool("DEBUG"))&&this.checkNumericalProblems(e),"complex64"===n&&null!=e)throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");const s={id:this.nextDataId()};return this.texData.set(s,{shape:t,dtype:n,values:e,usage:WT.UPLOAD,refCount:1}),s}refCount(e){return this.texData.has(e)?this.texData.get(e).refCount:0}incRef(e){this.texData.get(e).refCount++}decRef(e){this.texData.has(e)&&this.texData.get(e).refCount--}move(e,t,n,s,r){if(fe().getBool("DEBUG")&&this.checkNumericalProblems(t),"complex64"===s)throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");this.texData.set(e,{shape:n,dtype:s,values:t,usage:WT.UPLOAD,refCount:r})}disposeIntermediateTensorInfo(e){this.disposeData(e.dataId)}readSync(e){const t=this.texData.get(e),{values:n,dtype:s,complexTensorInfos:r,slice:a,shape:i,isPacked:o}=t;if(null!=a){let t;t=o?new lC(i,oC):new nC(i,oC);const n=this.runWebGLProgram(t,[{dataId:e,shape:i,dtype:s}],s),r=this.readSync(n.dataId);return this.disposeIntermediateTensorInfo(n),r}if(null!=n)return this.convertAndCacheOnCPU(e);if("string"===s)return n;const l=null!=this.activeTimers;let u,c;return l&&(u=sr()),c="complex64"===s?Ac(this.readSync(r.real.dataId),this.readSync(r.imag.dataId)):this.getValuesFromTexture(e),l&&(this.downloadWaitMs+=sr()-u),this.convertAndCacheOnCPU(e,c)}async read(e){if(this.pendingRead.has(e)){const t=this.pendingRead.get(e);return new Promise((e=>t.push(e)))}const t=this.texData.get(e),{values:n,shape:s,slice:r,dtype:a,complexTensorInfos:i,isPacked:o}=t;if(null!=r){let t;t=o?new lC(s,oC):new nC(s,oC);const n=this.runWebGLProgram(t,[{dataId:e,shape:s,dtype:a}],a),r=this.read(n.dataId);return this.disposeIntermediateTensorInfo(n),r}if(null!=n)return this.convertAndCacheOnCPU(e);if(fe().getBool("DEBUG")&&!fe().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")&&2===fe().getNumber("WEBGL_VERSION"))throw new Error("tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.");let l,u,c=null;if("complex64"!==a&&fe().get("WEBGL_BUFFER_SUPPORTED")){l=this.decode(e);const t=this.texData.get(l.dataId);c=this.gpgpu.createBufferFromTexture(t.texture.texture,...GT(s))}if(this.pendingRead.set(e,[]),"complex64"!==a&&await this.gpgpu.createAndWaitForFence(),"complex64"===a){const e=await Promise.all([this.read(i.real.dataId),this.read(i.imag.dataId)]);u=Ac(e[0],e[1])}else if(null==c)u=this.getValuesFromTexture(e);else{const e=L(s);u=this.gpgpu.downloadFloat32MatrixFromBuffer(c,e)}if(null!=l&&this.disposeIntermediateTensorInfo(l),null!=c){const e=this.gpgpu.gl;KT(e,(()=>e.deleteBuffer(c)))}const h=this.convertAndCacheOnCPU(e,u),p=this.pendingRead.get(e);return this.pendingRead.delete(e),p.forEach((e=>e(h))),this.pendingDisposal.has(e)&&(this.pendingDisposal.delete(e),this.disposeData(e)&&sa().removeDataId(e,this),this.pendingDeletes--),h}readToGPU(e,t={}){const n=this.texData.get(e),{values:s,shape:r,slice:a,dtype:i,isPacked:o,texture:l}=n;if("complex64"===i)throw new Error("Does not support reading texture for complex64 dtype.");if(null!=a){let n;n=o?new lC(r,oC):new nC(r,oC);const s=this.runWebGLProgram(n,[{dataId:e,shape:r,dtype:i}],i),a=this.readToGPU(s,t);return this.disposeIntermediateTensorInfo(s),a}if(null==l)throw null!=s?new Error("Data is not on GPU but on CPU."):new Error("There is no data on GPU or CPU.");const u=this.decode(e,t.customTexShape),c=sa().makeTensorFromTensorInfo(u),h=this.texData.get(u.dataId);return Object.assign({tensorRef:c},h.texture)}bufferSync(e){const t=this.readSync(e.dataId);if("string"===e.dtype)try{const n=t.map((e=>ar(e)));return Ua(e.shape,e.dtype,n)}catch(e){throw new Error("Failed to decode encoded string bytes into utf-8")}return Ua(e.shape,e.dtype,t)}checkNumericalProblems(e){if(null!=e)for(let t=0;t<e.length;t++){const n=e[t];if(!qT(n)){if(fe().getBool("WEBGL_RENDER_FLOAT32_CAPABLE"))throw Error(`The value ${n} cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`);throw Error(`The value ${n} cannot be represented on this device.`)}}}getValuesFromTexture(e){const{shape:t,dtype:n,isPacked:s}=this.texData.get(e),r=L(t);if(fe().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")){const n=this.decode(e),s=this.texData.get(n.dataId),a=this.gpgpu.downloadMatrixFromPackedTexture(s.texture.texture,...GT(t)).subarray(0,r);return this.disposeIntermediateTensorInfo(n),a}const a=fe().getBool("WEBGL_PACK")&&!0===s,i=a?o$(t):t,o=a?new V$(i):new W$(i),l=this.runWebGLProgram(o,[{shape:i,dtype:n,dataId:e}],"float32"),u=this.texData.get(l.dataId),c=this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(u.texture.texture,u.texShape[0],u.texShape[1]).subarray(0,r);return this.disposeIntermediateTensorInfo(l),c}timerAvailable(){return fe().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0}time(e){const t=this.activeTimers,n=[];let s=!1;null==this.programTimersStack?(this.programTimersStack=n,s=!0):this.activeTimers.push(n),this.activeTimers=n,e();const r=or(this.activeTimers.map((e=>e.query))).filter((e=>null!=e)),a=or(this.activeTimers.map((e=>e.name))).filter((e=>null!=e));this.activeTimers=t,s&&(this.programTimersStack=null);const i={uploadWaitMs:this.uploadWaitMs,downloadWaitMs:this.downloadWaitMs,kernelMs:null,wallMs:null};return(async()=>{if(fe().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0){const e=await Promise.all(r);i.kernelMs=function(e){let t=0;for(let n=0;n<e.length;n++)t+=e[n];return t}(e),i.getExtraProfileInfo=()=>e.map(((e,t)=>({name:a[t],ms:e}))).map((e=>`${e.name}: ${e.ms}`)).join(", ")}else i.kernelMs={error:"WebGL query timers are not supported in this environment."};return this.uploadWaitMs=0,this.downloadWaitMs=0,i})()}memory(){return{unreliable:!1,numBytesInGPU:this.numBytesInGPU,numBytesInGPUAllocated:this.textureManager.numBytesAllocated,numBytesInGPUFree:this.textureManager.numBytesFree}}startTimer(){return fe().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?this.gpgpu.beginQuery():{startMs:sr(),endMs:null}}endTimer(e){return fe().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?(this.gpgpu.endQuery(),e):(e.endMs=sr(),e)}async getQueryTime(e){if(fe().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0)return this.gpgpu.waitForQueryAndGetTime(e);const t=e;return t.endMs-t.startMs}disposeData(e,t=!1){if(this.pendingDisposal.has(e))return!1;if(!this.texData.has(e))return!0;if(t?this.texData.get(e).refCount=0:this.texData.get(e).refCount--,!t&&this.texData.get(e).refCount>0)return!1;if(this.pendingRead.has(e))return this.pendingDisposal.add(e),this.pendingDeletes++,!1;this.releaseGPUData(e);const{complexTensorInfos:n}=this.texData.get(e);return null!=n&&(this.disposeData(n.real.dataId,t),this.disposeData(n.imag.dataId,t)),this.texData.delete(e),!0}releaseGPUData(e){const{texture:t,dtype:n,texShape:s,usage:r,isPacked:a,slice:i}=this.texData.get(e),o=i&&i.origDataId||e,l=this.dataRefCount.get(o);l>1?this.dataRefCount.set(o,l-1):(this.dataRefCount.delete(o),null!=t&&(this.numBytesInGPU-=this.computeBytes(s,n),this.textureManager.releaseTexture(t,s,r,a)));const u=this.texData.get(e);u.texture=null,u.texShape=null,u.isPacked=!1,u.slice=null}getTexture(e){return this.uploadToGPU(e),this.texData.get(e).texture.texture}getDataInfo(e){return this.texData.get(e)}shouldExecuteOnCPU(e,t=pC){return fe().getBool("WEBGL_CPU_FORWARD")&&e.every((e=>null==this.texData.get(e.dataId).texture&&L(e.shape)<t))}getGPGPUContext(){return this.gpgpu}where(e){Cs("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");const t=e.dataSync();return cC(e.shape,t)}packedUnaryOp(e,t,n){const s=new lC(e.shape,t),r=this.compileAndRun(s,[e],n);return sa().makeTensorFromTensorInfo(r)}abs(e){if(this.shouldExecuteOnCPU([e])&&"complex64"!==e.dtype){const t=_E(this.texData.get(e.dataId).values);return this.makeOutput(e.shape,e.dtype,t)}if(fe().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(e,rC,e.dtype);const t=new nC(e.shape,rC),n=this.compileAndRun(t,[e]);return sa().makeTensorFromTensorInfo(n)}makeTensorInfo(e,t,n){let s;if("string"===t&&null!=n&&n.length>0&&Y(n[0])){const r=n.map((e=>rr(e)));s=this.write(r,e,t)}else s=this.write(n,e,t);return this.texData.get(s).usage=null,{dataId:s,shape:e,dtype:t}}makeOutput(e,t,n){return sa().makeTensorFromTensorInfo(this.makeTensorInfo(e,t,n),this)}unpackTensor(e){const t=new uC(e.shape);return this.runWebGLProgram(t,[e],e.dtype)}packTensor(e){const t=new YE(e.shape);return this.runWebGLProgram(t,[e],e.dtype,null,!0)}packedReshape(e,t){const n=[a$(e.shape),...i$(e.shape)],s={dtype:e.dtype,shape:n,dataId:e.dataId},r=[a$(t),...i$(t)],a=new JE(r,n),i=[n],o=this.runWebGLProgram(a,[s],e.dtype,i,!0);return{dataId:o.dataId,shape:t,dtype:o.dtype}}decode(e,t){const n=this.texData.get(e),{isPacked:s,shape:r,dtype:a}=n;null!=t&&F(L(r)<=t[0]*t[1]*4,(()=>"customTexShape is too small. Row * Column * 4 should be equal or larger than the size of the tensor data."));const i=o$(r);let o;o=s?new P$(i):new B$(i);const l=[null!=t?t:GT(i)];return{dtype:a,shape:r,dataId:this.runWebGLProgram(o,[{shape:i,dtype:a,dataId:e}],a,l,!0,t).dataId}}runWebGLProgram(e,t,n,s,r=!1,a){const i=this.makeTensorInfo(e.outputShape,n),o=this.texData.get(i.dataId);if(e.packedOutput&&(o.isPacked=!0),e.outPackingScheme===PT.DENSE){const t=null!=a?a:GT(e.outputShape);o.texShape=t.map((e=>2*e))}if(null!=e.outTexUsage&&(o.usage=e.outTexUsage),0===L(i.shape))return o.values=j(i.dtype,0),i;const l=[],u=t.map((t=>{if("complex64"===t.dtype)throw new Error("GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.");let n=this.texData.get(t.dataId);if(null==n.texture){if(!e.packedInputs&&L(t.shape)<=fe().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM"))return{shape:t.shape,texData:null,isUniform:!0,uniformValues:n.values};e.packedInputs&&(n.isPacked=!0,n.shape=t.shape)}if(this.uploadToGPU(t.dataId),!!n.isPacked!=!!e.packedInputs)t=n.isPacked?this.unpackTensor(t):this.packTensor(t),l.push(t),n=this.texData.get(t.dataId);else if(n.isPacked&&!u$(n.shape,t.shape)){const e=t,s=t.shape;t.shape=n.shape,t=this.packedReshape(t,s),l.push(t),n=this.texData.get(t.dataId),e.shape=s}return{shape:t.shape,texData:n,isUniform:!1}}));this.uploadToGPU(i.dataId);const c={shape:i.shape,texData:o,isUniform:!1},h=function(e,t,n){let s="";t.concat(n).forEach((t=>{const r=null!=t.texData&&null!=t.texData.slice&&t.texData.slice.flatOffset>0;if(e.enableShapeUniforms&&!t.isUniform){const a=t.texData.texShape,{useSqueezeShape:i,uniformShape:o,keptDims:l}=D$(e.packedInputs,t.shape,a);let u="",c="",h="";if(1===o.length&&e.packedInputs){const e=[Math.ceil(a[0]/2),Math.ceil(a[1]/2)];u=`${e[0]>1}_${e[1]>1}`}else if(2!==o.length||e.packedInputs){if(o.length>2&&!e.packedInputs){const e=te(o);h=`${e[0]===a[1]}_${e[e.length-1]===a[1]}`}}else c=`${o[0]>1}_${o[1]>1}`;const p=t.shape.length,d=2===o.length&&z(t.shape,a),f=1===L(t.shape),m=fi(t.shape,n.shape),g=!e.packedInputs&&p===n.shape.length&&z(a,n.texData.texShape),y=e.packedInputs||o.length>2?"":`${a[0]>1}_${a[1]>1}`;s+=`${p}_${g}_${i?l:""}_${o.length}_${f}_${m}_${d}_${u}_${c}_${h}_${y}_${r}`}else{const e=t.isUniform?"uniform":t.texData.texShape;s+=`${t.shape}_${e}_${r}`}}));const r=e.userCode;let a=e.constructor.name;return a+="_"+s+"_"+r+`${fe().getNumber("WEBGL_VERSION")}`,a}(e,u,c),p=this.getAndSaveBinary(h,(()=>function(e,t,n,s){const r=n.map(((e,n)=>{const s={logicalShape:e.shape,texShape:e.isUniform?null:e.texData.texShape,isUniform:e.isUniform,isPacked:!e.isUniform&&e.texData.isPacked,flatOffset:null};return null!=e.texData&&null!=e.texData.slice&&e.texData.slice.flatOffset>0&&(s.flatOffset=e.texData.slice.flatOffset),{name:t.variableNames[n],shapeInfo:s}})),a=r.map((e=>e.shapeInfo)),i={logicalShape:s.shape,texShape:s.texData.texShape,isUniform:!1,isPacked:s.texData.isPacked,flatOffset:null},o=I$(r,i,t),l=function(e,t){const n=r$(e,(()=>e.createShader(e.FRAGMENT_SHADER)),"Unable to create fragment WebGLShader.");if(KT(e,(()=>e.shaderSource(n,t))),KT(e,(()=>e.compileShader(n))),fe().get("ENGINE_COMPILE_ONLY"))return n;if(!1===e.getShaderParameter(n,e.COMPILE_STATUS))throw JT(t,e.getShaderInfoLog(n)),new Error("Failed to compile fragment shader.");return n}(e.gl,o),u=e.createProgram(l);return fe().get("ENGINE_COMPILE_ONLY")?{program:t,fragmentShader:l,source:o,webGLProgram:u,inShapeInfos:a,outShapeInfo:i,variablesLocations:null,customUniformLocations:null,infLoc:null,nanLoc:null,outShapeLocation:null,outShapeStridesLocation:null,outTexShapeLocation:null}:(e.buildVao(u),Object.assign({program:t,fragmentShader:l,source:o,webGLProgram:u,inShapeInfos:a,outShapeInfo:i},M$(e,t,u)))}(this.gpgpu,e,u,c))),d=null!=this.activeTimers;let f;d&&(f=this.startTimer()),fe().get("ENGINE_COMPILE_ONLY")||function(e,t,n,s,r){t.program.enableShapeUniforms||(L$(t.inShapeInfos,n),L$([t.outShapeInfo],[s]));const a=s.texData.texture,i=s.texData.texShape;s.texData.isPacked?e.setOutputPackedMatrixTexture(a.texture,i[0],i[1]):e.setOutputMatrixTexture(a.texture,i[0],i[1]),e.setProgram(t.webGLProgram),e.bindVertexArray(t.webGLProgram.vao),1===fe().getNumber("WEBGL_VERSION")&&null!==t.infLoc&&e.gl.uniform1f(t.infLoc,1/0),null!==t.nanLoc&&e.gl.uniform1f(t.nanLoc,NaN);for(let s=0;s<n.length;++s){const r=n[s],{uniform:a,offset:i,shape:o,texShape:l}=t.variablesLocations[s];if(o){const{uniformShape:n}=D$(t.program.packedInputs,r.shape,r.texData.texShape);switch(n.length){case 1:e.gl.uniform1iv(o,new Int32Array(n));break;case 2:e.gl.uniform2iv(o,new Int32Array(n));break;case 3:e.gl.uniform3iv(o,new Int32Array(n));break;case 4:e.gl.uniform4iv(o,new Int32Array(n))}}if(l&&e.gl.uniform2i(l,r.texData.texShape[0],r.texData.texShape[1]),null!=a)if(r.isUniform)if(L(r.shape)<2)e.gl.uniform1f(a,r.uniformValues[0]);else{let t=r.uniformValues;t instanceof Float32Array||(t=new Float32Array(t)),e.gl.uniform1fv(a,t)}else null!=r.texData.slice&&null!=i&&e.gl.uniform1i(i,r.texData.slice.flatOffset),e.setInputMatrixTexture(r.texData.texture.texture,a,s)}const o=t.outShapeLocation;if(o)switch(s.shape.length){case 1:e.gl.uniform1iv(o,new Int32Array(s.shape));break;case 2:e.gl.uniform2iv(o,new Int32Array(s.shape));break;case 3:e.gl.uniform3iv(o,new Int32Array(s.shape));break;case 4:e.gl.uniform4iv(o,new Int32Array(s.shape))}if(t.outShapeStridesLocation){const n=te(s.shape);switch(s.shape.length){case 2:e.gl.uniform1iv(t.outShapeStridesLocation,new Int32Array(n));break;case 3:e.gl.uniform2iv(t.outShapeStridesLocation,new Int32Array(n));break;case 4:e.gl.uniform3iv(t.outShapeStridesLocation,new Int32Array(n))}}if(t.outTexShapeLocation&&e.gl.uniform2i(t.outTexShapeLocation,s.texData.texShape[0],s.texData.texShape[1]),t.program.customUniforms&&r)for(let n=0;n<t.program.customUniforms.length;++n){const s=t.program.customUniforms[n],a=t.customUniformLocations[n],i=r[n];if("float"===s.type)e.gl.uniform1fv(a,i);else if("vec2"===s.type)e.gl.uniform2fv(a,i);else if("vec3"===s.type)e.gl.uniform3fv(a,i);else if("vec4"===s.type)e.gl.uniform4fv(a,i);else if("int"===s.type)e.gl.uniform1iv(a,i);else if("ivec2"===s.type)e.gl.uniform2iv(a,i);else if("ivec3"===s.type)e.gl.uniform3iv(a,i);else{if("ivec4"!==s.type)throw Error(`uniform type ${s.type} is not supported yet.`);e.gl.uniform4iv(a,i)}}e.executeProgram()}(this.gpgpu,p,u,c,s),l.forEach((e=>this.disposeIntermediateTensorInfo(e))),d&&(f=this.endTimer(f),this.activeTimers.push({name:e.constructor.name,query:this.getQueryTime(f)}));const m=fe().getNumber("WEBGL_FLUSH_THRESHOLD");if(m>0){const e=sr();e-this.lastGlFlushTime>m&&(this.gpgpu.gl.flush(),this.lastGlFlushTime=e)}if(!fe().getBool("WEBGL_LAZILY_UNPACK")&&o.isPacked&&!1===r){const e=this.unpackTensor(i);return this.disposeIntermediateTensorInfo(i),e}return i}compileAndRun(e,t,n,s,r=!1){return n=n||t[0].dtype,this.runWebGLProgram(e,t,n,s,r)}getAndSaveBinary(e,t){return e in this.binaryCache||(this.binaryCache[e]=t()),this.binaryCache[e]}getTextureManager(){return this.textureManager}dispose(){this.disposed||(fe().getBool("IS_TEST")||Object.keys(this.binaryCache).forEach((e=>{this.gpgpu.deleteProgram(this.binaryCache[e].webGLProgram),delete this.binaryCache[e]})),this.textureManager.dispose(),null!=this.canvas&&"undefined"!=typeof HTMLCanvasElement&&this.canvas instanceof HTMLCanvasElement?this.canvas.remove():this.canvas=null,this.gpgpuCreatedLocally&&(this.gpgpu.program=null,this.gpgpu.dispose()),this.disposed=!0)}floatPrecision(){return null==this.floatPrecisionValue&&(this.floatPrecisionValue=aa((()=>{if(!fe().get("WEBGL_RENDER_FLOAT32_ENABLED")){const e=fe().getBool("DEBUG");fe().set("DEBUG",!1);const t=this.abs(ei(1e-8)).dataSync()[0];if(fe().set("DEBUG",e),t>0)return 32}return 16}))),this.floatPrecisionValue}epsilon(){return 32===this.floatPrecision()?1e-7:1e-4}uploadToGPU(e){const t=this.texData.get(e),{shape:n,dtype:s,values:r,texture:a,usage:i,isPacked:o}=t;if(null!=a)return;const l=null!=this.activeTimers;let u;l&&(u=sr());let c=t.texShape;if(null==c&&(c=function(e,t=!1){let n=fe().getNumber("WEBGL_MAX_TEXTURE_SIZE"),s=fe().getNumber("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE");if(s===1/0&&fe().getBool("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE")&&(s=n/2),t&&(n*=2,s*=2,1===(e=e.map(((t,n)=>n>=e.length-2?_(e[n]):e[n]))).length&&(e=[2,e[0]])),2!==e.length){const t=H(e);e=t.newShape}let r=L(e),a=null;e.length<=1&&r<=n?a=[1,r]:2===e.length&&e[0]<=n&&e[1]<=n?a=e:3===e.length&&e[0]*e[1]<=n&&e[2]<=n?a=[e[0]*e[1],e[2]]:3===e.length&&e[0]<=n&&e[1]*e[2]<=n?a=[e[0],e[1]*e[2]]:4===e.length&&e[0]*e[1]*e[2]<=n&&e[3]<=n?a=[e[0]*e[1]*e[2],e[3]]:4===e.length&&e[0]<=n&&e[1]*e[2]*e[3]<=n&&(a=[e[0],e[1]*e[2]*e[3]]);const i=null!=a&&Math.max(...a)>s&&Math.min(...a)<=(t?2:1)&&Math.min(...a)>0;if(null==a||i)if(t){const t=a$(e);let n=2,s=2;e.length&&([n,s]=i$(e)),r=t*(n/2)*(s/2),a=P(r).map((e=>2*e))}else a=P(r);return a}(n,o),t.texShape=c),null!=r){const e=o$(n);let a,i=c[1],h=c[0];const p=r instanceof Uint8Array||r instanceof Uint8ClampedArray;!o&&p||([i,h]=HT(c[0],c[1])),a=o?new H$(e,p):new G$(e,p);const d=p?[h,i]:c,f=this.makeTensorInfo(d,s),m=this.texData.get(f.dataId);m.usage=p?WT.PIXELS:WT.UPLOAD,m.texShape=d,this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(f.dataId),i,h,r);const g=[[h,i]],y=!0,b=this.runWebGLProgram(a,[f],s,g,y),x=this.texData.get(b.dataId);t.texShape=x.texShape,t.isPacked=x.isPacked,t.usage=x.usage,fe().get("ENGINE_COMPILE_ONLY")?this.disposeData(b.dataId):(t.texture=x.texture,t.values=null,this.texData.delete(b.dataId)),this.disposeIntermediateTensorInfo(f),l&&(this.uploadWaitMs+=sr()-u)}else{const e=this.acquireTexture(c,i,s,o);t.texture=e}}convertAndCacheOnCPU(e,t){const n=this.texData.get(e),{dtype:s}=n;return null!=t&&(n.values=function(e,t){if("float32"===t||"complex64"===t)return e;if("int32"===t||"bool"===t){const n="int32"===t?new Int32Array(e.length):new Uint8Array(e.length);for(let t=0;t<n.length;++t)n[t]=Math.round(e[t]);return n}throw new Error(`Unknown dtype ${t}`)}(t,s)),n.values}acquireTexture(e,t,n,s){if(this.numBytesInGPU+=this.computeBytes(e,n),!this.warnedAboutMemory&&this.numBytesInGPU>1024*this.numMBBeforeWarning*1024){const e=(this.numBytesInGPU/1024/1024).toFixed(2);this.warnedAboutMemory=!0,console.warn(`High memory usage in GPU: ${e} MB, most likely due to a memory leak`)}return this.textureManager.acquireTexture(e,t,s)}computeBytes(e,t){return e[0]*e[1]*X(t)}checkCompileCompletion(){for(const[,e]of Object.entries(this.binaryCache))this.checkCompletion_(e)}async checkCompileCompletionAsync(){const e=[];if(this.gpgpu.parallelCompilationExtension){for(const[,t]of Object.entries(this.binaryCache))e.push(this.checkCompletionAsync_(t));return Promise.all(e)}for(const[,t]of Object.entries(this.binaryCache)){const n=new Promise((e=>{try{this.checkCompletion_(t),e(!0)}catch(e){throw e}}));e.push(n)}return Promise.all(e)}async checkCompletionAsync_(e){return this.gpgpu.gl.getProgramParameter(e.webGLProgram,this.gpgpu.parallelCompilationExtension.COMPLETION_STATUS_KHR)?this.checkCompletion_(e):(await sc(),this.checkCompletionAsync_(e))}checkCompletion_(e){if(!1===this.gpgpu.gl.getProgramParameter(e.webGLProgram,this.gpgpu.gl.LINK_STATUS)){if(console.log(this.gpgpu.gl.getProgramInfoLog(e.webGLProgram)),!1===this.gpgpu.gl.getShaderParameter(e.fragmentShader,this.gpgpu.gl.COMPILE_STATUS))throw JT(e.source,this.gpgpu.gl.getShaderInfoLog(e.fragmentShader)),new Error("Failed to compile fragment shader.");throw new Error("Failed to link vertex and fragment shaders.")}return!0}getUniformLocations(){for(const e of Object.values(this.binaryCache)){this.gpgpu.buildVao(e.webGLProgram);const{variablesLocations:t,customUniformLocations:n,infLoc:s,nanLoc:r,outShapeLocation:a,outShapeStridesLocation:i,outTexShapeLocation:o}=M$(this.gpgpu,e.program,e.webGLProgram);e.variablesLocations=t,e.customUniformLocations=n,e.infLoc=s,e.nanLoc=r,e.outShapeLocation=a,e.outShapeStridesLocation=i,e.outTexShapeLocation=o}}createTensorFromGPUData(e,t,n){e.channels=e.channels||"RGBA";const{texture:s,height:r,width:a,channels:i}=e,o=sa().backend;if(!o.gpgpu.gl.isTexture(s))throw new Error("The texture is invalid. Also, please make sure the texture and the TFJS WebGL backend are using the same canvas. If you want to use your own custom canvas, you have to create and use the custom TFJS WebGL backend created from the canvas through 'new tf.MathBackendWebGL(customCanvas)'.");const l=o.writeTexture(s,t,n,r,a,i);return sa().makeTensorFromDataId(l,t,n,o)}}dC.nextDataId=0,Gr()&&la("webgl",(()=>new dC),2);const fC="\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n";class mC{constructor(e,t,n){this.variableNames=["A","B"],this.outputShape=gi(t,n),this.enableShapeUniforms=z$(this.outputShape.length),this.userCode=`\n      float binaryOperation(float a, float b) {\n        ${e}\n      }\n\n      void main() {\n        float a = getAAtOutCoords();\n        float b = getBAtOutCoords();\n        setOutput(binaryOperation(a, b));\n      }\n    `}}const gC="\n  result.r = isNaN.r ? NAN : result.r;\n  result.g = isNaN.g ? NAN : result.g;\n  result.b = isNaN.b ? NAN : result.b;\n  result.a = isNaN.a ? NAN : result.a;\n";class yC{constructor(e,t,n,s=!1){this.variableNames=["A","B"],this.supportsBroadcasting=!0,this.packedInputs=!0,this.packedOutput=!0,this.outputShape=gi(t,n);const r=this.outputShape.length;this.enableShapeUniforms=z$(r);let a="";if(s)if(0===r||1===L(this.outputShape))a="\n          result.y = 0.;\n          result.z = 0.;\n          result.w = 0.;\n        ";else if(a=`\n          ${_$(r)} coords = getOutputCoords();\n        `,1===r)this.enableShapeUniforms?a+="\n            result.y = (coords + 1) >= outShape ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          ":a+=`\n            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          `;else{const e=XE("coords",r);this.enableShapeUniforms?a+=`\n            bool nextRowOutOfBounds =\n              (${e[r-2]} + 1) >= outShape[${r} - 2];\n            bool nextColOutOfBounds =\n              (${e[r-1]} + 1) >= outShape[${r} - 1];\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          `:a+=`\n            bool nextRowOutOfBounds =\n              (${e[r-2]} + 1) >= ${this.outputShape[r-2]};\n            bool nextColOutOfBounds =\n              (${e[r-1]} + 1) >= ${this.outputShape[r-1]};\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          `}this.userCode=`\n      vec4 binaryOperation(vec4 a, vec4 b) {\n        ${e}\n      }\n\n      void main() {\n        vec4 a = getAAtOutCoords();\n        vec4 b = getBAtOutCoords();\n\n        vec4 result = binaryOperation(a, b);\n        ${a}\n\n        setOutput(result);\n      }\n    `}}function bC(e){const{inputs:t,backend:n}=e,{x:s}=t;return n.incRef(s.dataId),{dataId:s.dataId,shape:s.shape,dtype:s.dtype}}const xC={kernelName:Dt,backendName:"webgl",kernelFunc:bC};function wC(e){const{inputs:t,backend:n}=e,{real:s,imag:r}=t,a=n.makeTensorInfo(s.shape,"complex64"),i=n.texData.get(a.dataId),o=bC({inputs:{x:s},backend:n}),l=bC({inputs:{x:r},backend:n});return i.complexTensorInfos={real:o,imag:l},a}const kC={kernelName:He,backendName:"webgl",kernelFunc:wC},vC="return (a < 0.) ? b * a : a;",IC="\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n",NC={kernelName:Bt,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{alpha:a}=s,i=n.makeTensorInfo([],"float32",tr(a,"float32")),o=fe().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new yC(IC,r.shape,i.shape):new mC(vC,r.shape,i.shape),l=n.runWebGLProgram(o,[r,i],"float32");return n.disposeIntermediateTensorInfo(i),l}},SC="return (a < 0.) ? b * a : a;",TC="\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n",$C={kernelName:kn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{x:s,alpha:r}=t,a=fe().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new yC(TC,s.shape,r.shape):new mC(SC,s.shape,r.shape);return n.runWebGLProgram(a,[s,r],"float32")}},EC="if (isnan(x)) return x;";function CC({opSnippet:e,packedOpSnippet:t,cpuKernelImpl:n,dtype:s}){return({inputs:r,backend:a})=>{const{x:i}=r,o=a,l=s||i.dtype;if(o.shouldExecuteOnCPU([i])&&null!=n){const e=o.texData.get(i.dataId),t=n(e.values,l);return o.makeTensorInfo(i.shape,l,t)}let u;return u=fe().getBool("WEBGL_PACK_UNARY_OPERATIONS")&&null!=t?new lC(i.shape,t):new nC(i.shape,e),o.runWebGLProgram(u,[i],l)}}function RC({opSnippet:e,packedOpSnippet:t,checkOutOfBounds:n=!1,supportsComplex:s=!1,cpuKernelImpl:r,dtype:a}){return({inputs:i,backend:o})=>{const{a:l,b:u}=i,c=o;if(s&&"complex64"===l.dtype){const t=c.texData.get(l.dataId),n=c.texData.get(u.dataId),[s,r]=[[t.complexTensorInfos.real,n.complexTensorInfos.real],[t.complexTensorInfos.imag,n.complexTensorInfos.imag]].map((t=>{const[n,s]=t,r={dataId:n.dataId,dtype:n.dtype,shape:l.shape},a={dataId:s.dataId,dtype:s.dtype,shape:u.shape},i=new mC(e,l.shape,u.shape);return c.runWebGLProgram(i,[r,a],Cr(n.dtype,s.dtype))})),a=wC({inputs:{real:s,imag:r},backend:c});return c.disposeIntermediateTensorInfo(s),c.disposeIntermediateTensorInfo(r),a}const h=a||Cr(l.dtype,u.dtype);if(("string"===l.dtype||"string"===u.dtype||c.shouldExecuteOnCPU([l,u]))&&null!=r){const e=c.texData.get(l.dataId).values,t=c.texData.get(u.dataId).values,n="string"===l.dtype?hh(e):e,s="string"===l.dtype?hh(t):t,[a,i]=r(l.shape,u.shape,n,s,h),o=c.makeTensorInfo(i,h);return c.texData.get(o.dataId).values=a,o}let p;return p=fe().getBool("WEBGL_PACK_BINARY_OPERATIONS")&&null!=t?new yC(t,l.shape,u.shape,n):new mC(e,l.shape,u.shape),c.runWebGLProgram(p,[l,u],h)}}function AC(e,t=!1){if("linear"===e)return"return x;";if("relu"===e)return t?"\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n":aC;if("elu"===e)return t?"\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n":"return (x >= 0.0) ? x : (exp(x) - 1.0);";if("relu6"===e)return t?"\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n":iC;if("prelu"===e)return t?TC:SC;if("leakyrelu"===e)return t?IC:vC;if("sigmoid"===e)return"return 1.0 / (1.0 + exp(-1.0 * x));";throw new Error(`Activation ${e} has not been implemented for the WebGL backend.`)}class _C{constructor(e,t,n,s=!1,r=!1,a=!1,i=null,o=!1,l=!1){this.variableNames=["matrixA","matrixB"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=n,this.enableShapeUniforms=z$(this.outputShape.length);const u=s?e[1]:e[2],c=Math.ceil(u/2),h=s?"i * 2, rc.y":"rc.y, i * 2",p=r?"rc.z, i * 2":"i * 2, rc.z",d=s?["a.xxyy","a.zzww"]:["a.xxzz","a.yyww"],f=r?["b.xzxz","b.ywyw"]:["b.xyxy","b.zwzw"];let m="",g="";i&&(m=o?`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${i}\n        }`:l?`vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${i}\n        }`:`vec4 activation(vec4 x) {\n          ${i}\n        }`,g="result = activation(result);");const y=a?"result += getBiasAtOutCoords();":"";a&&this.variableNames.push("bias"),o&&this.variableNames.push("preluActivationWeights"),l&&this.variableNames.push("leakyreluAlpha");let b="rc.x",x="rc.x";e[0]<t[0]?b=`imod(rc.x, ${e[0]})`:t[0]<e[0]&&(x=`imod(rc.x, ${t[0]})`),this.userCode=`\n      ${m}\n      // Don't use uniform for sharedDimensionPacked for performance.\n      const float sharedDimension = ${c}.0;\n\n      vec4 dot2x2ARowBCol(ivec3 rc) {\n        vec4 result = vec4(0);\n        int batchA = ${b};\n        int batchB = ${x};\n        for (int i = 0; i < ${c}; i++) {\n          vec4 a = getMatrixA(batchA, ${h});\n          vec4 b = getMatrixB(batchB, ${p});\n\n          // These swizzled products need to be separately added.\n          // See: https://github.com/tensorflow/tfjs/issues/1735\n          result += (${d[0]} * ${f[0]});\n          result += (${d[1]} * ${f[1]});\n        }\n        return result;\n      }\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n        vec4 result = dot2x2ARowBCol(rc);\n\n        ${y}\n\n        ${g}\n\n        setOutput(result);\n      }\n    `}}class DC{constructor(e,t,n){this.variableNames=["AReal","AImag","BReal","BImag"],this.outputShape=gi(t,n),this.userCode=`\n      float binaryOpComplex(\n          float areal, float aimag, float breal, float bimag) {\n        ${e}\n      }\n\n      void main() {\n        float areal = getARealAtOutCoords();\n        float aimag = getAImagAtOutCoords();\n        float breal = getBRealAtOutCoords();\n        float bimag = getBImagAtOutCoords();\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\n      }\n    `}}const FC="return a * b;";function OC(e){const{inputs:t,backend:n}=e,{a:s,b:r}=t,a=Cr(s.dtype,r.dtype);if("complex64"===s.dtype){const e=n.texData.get(s.dataId),t=n.texData.get(r.dataId),a=new DC("return areal * breal - aimag * bimag;",s.shape,r.shape),i=new DC("return areal * bimag + aimag * breal;",s.shape,r.shape),o=[{dataId:e.complexTensorInfos.real.dataId,dtype:e.complexTensorInfos.real.dtype,shape:s.shape},{dataId:e.complexTensorInfos.imag.dataId,dtype:e.complexTensorInfos.imag.dtype,shape:s.shape},{dataId:t.complexTensorInfos.real.dataId,dtype:t.complexTensorInfos.real.dtype,shape:r.shape},{dataId:t.complexTensorInfos.imag.dataId,dtype:t.complexTensorInfos.imag.dtype,shape:r.shape}],l=n.runWebGLProgram(a,o,"float32"),u=n.runWebGLProgram(i,o,"float32"),c=wC({inputs:{real:l,imag:u},backend:n});return n.disposeIntermediateTensorInfo(l),n.disposeIntermediateTensorInfo(u),c}if(n.shouldExecuteOnCPU([s,r])){const e=n.texData.get(s.dataId),t=n.texData.get(r.dataId),[i,o]=kE(s.shape,r.shape,e.values,t.values,a),l=n.makeTensorInfo(o,a);return n.texData.get(l.dataId).values=i,l}let i;return i=fe().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new yC(FC,s.shape,r.shape):new mC(FC,s.shape,r.shape),n.runWebGLProgram(i,[s,r],a)}const MC={kernelName:cn,backendName:"webgl",kernelFunc:OC};function LC(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{shape:a}=s,i=n,o=L(r.shape),l=U(a,o),u=L(l);F(o===u,(()=>`The new shape (${l}) has ${u} elements and the old shape (${r.shape}) has ${o} elements. The new shape and old shape must have the same number of elements.`));const c=i.texData.get(r.dataId);return!c.isPacked||u$(r.shape,l)||null!==c.texture&&u$(c.shape,l)?(i.incRef(r.dataId),{dataId:r.dataId,shape:l,dtype:r.dtype}):function(e,t,n){const s=[a$(e.shape),...i$(e.shape)],r={dtype:e.dtype,shape:s,dataId:e.dataId},a=[a$(t),...i$(t)],i=new JE(a,s),o=[s],l=n.runWebGLProgram(i,[r],e.dtype,o,!0);return{dataId:l.dataId,shape:t,dtype:l.dtype}}(r,l,i)}const zC={kernelName:Rn,backendName:"webgl",kernelFunc:LC};class BC{constructor(e,t){this.variableNames=["x"];const{windowSize:n,batchSize:s,inSize:r,outSize:a}=e;this.outputShape=[s,a];const i=4*Math.floor(n/4),o=n%4;let l="sumValue += dot(values, ones);";if(null!=t){const e=1/t;l=`sumValue += dot(values * ${B(e)?e.toPrecision(2):e}, ones);`}let u="";r%n>0&&(u=`\n        if (inIdx < 0 || inIdx >= ${r}) {\n          return 0.0;\n        }\n      `),this.userCode=`\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${u}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${n};\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${i}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${l}\n        }\n\n        int inIdx = inOffset + ${i};\n        if (${1===o}) {\n          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);\n\n          ${l}\n        } else if (${2===o}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1), 0.0, 0.0);\n\n          ${l}\n        } else if (${3===o}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2), 0.0);\n\n          ${l}\n        }\n        setOutput(sumValue);\n      }\n    `}}class PC{constructor(e,t){this.variableNames=["x"];const{windowSize:n,batchSize:s,inSize:r,outSize:a}=e;this.outputShape=[s,a];let i="0.0",o="";"prod"===t?i="1.0":"min"===t?(i="1.0 / 1e-20",o="min"):"max"===t&&(i="-1.0 / 1e-20",o="max");let l=`${t}(${t}(${t}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"sum"===t?l="sumValue":"prod"===t?l="prodValue":"all"===t?l="allValue":"any"===t&&(l="anyValue");const u=4*Math.floor(n/4),c=n%4;let h=`\n      if (${"sum"===t}) {\n        sumValue += dot(values, ones);\n      } else if (${"prod"===t}) {\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\n        prodValue *= tmp[0] * tmp[1];\n      } else {\n        minMaxValue = ${o}(values, minMaxValue);\n        if (${"min"===t} || ${"max"===t}) {\n          minMaxValue = ${o}(values, minMaxValue);\n          bvec4 isNaN = isnan(values);\n          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {\n            minMaxValue = vec4(NAN);\n          }\n        }\n      }\n    `,p="vec4";"all"===t?(i="1.0",h="\n        bool reducedAllValue = all(values);\n        float floatedReducedAllValue = float(reducedAllValue);\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\n      ",p="bvec4"):"any"===t&&(i="0.0",h="\n        bool reducedAnyValue = any(values);\n        float floatedReducedAnyValue = float(reducedAnyValue);\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\n      ",p="bvec4");let d="";r%n>0&&(d=`\n        if (inIdx < 0 || inIdx >= ${r}) {\n          return initializationValue;\n        }\n      `),this.userCode=`\n      const float initializationValue = ${i};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${d}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${n};\n\n        vec4 minMaxValue = vec4(${i});\n        float prodValue = 1.0;\n        float sumValue = 0.0;\n        float allValue = 1.0;\n        float anyValue = 0.0;\n\n        for (int i = 0; i < ${u}; i += 4) {\n          int inIdx = inOffset + i;\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${h}\n        }\n\n        int inIdx = inOffset + ${u};\n        if (${1===c}) {\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          ${h}\n        } else if (${2===c}) {\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          ${h}\n        } else if (${3===c}) {\n          ${p} values = ${p}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          ${h}\n        }\n        setOutput(${l});\n      }\n    `}}function WC(e,t,n,s){const r=function(e){const t=[];for(;0===t.length||1!==t[t.length-1].outSize;){const n=t.length?t[t.length-1].outSize:e[1],s=pc(n);t.push({inSize:n,windowSize:s,outSize:Math.ceil(n/s)})}return t}(e.shape);let a=e;for(let i=0;i<r.length;i++){const{inSize:o,windowSize:l,outSize:u}=r[i];let c,h;c="mean"===n?0===i?new BC({windowSize:l,inSize:o,batchSize:e.shape[0],outSize:u},o):new BC({windowSize:l,inSize:o,batchSize:e.shape[0],outSize:u}):new PC({windowSize:l,inSize:o,batchSize:e.shape[0],outSize:u},n),h=a,a=s.runWebGLProgram(c,[a],t),h.dataId!==e.dataId&&s.disposeIntermediateTensorInfo(h)}return a}class VC{constructor(e,t){this.variableNames=["A"];const n=new Array(e.length);for(let s=0;s<n.length;s++)n[s]=e[t[s]];this.outputShape=n,this.rank=n.length;const s=_$(this.rank),r=function(e){const t=e.length;if(t>6)throw Error(`Transpose for rank ${t} is not yet supported`);const n=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u","resRC.v"],s=new Array(t);for(let t=0;t<e.length;t++)s[e[t]]=n[t];return s.join()}(t);this.userCode=`\n    void main() {\n      ${s} resRC = getOutputCoords();\n      setOutput(getA(${r}));\n    }\n    `}}class UC{constructor(e,t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0;const n=new Array(e.length);for(let s=0;s<n.length;s++)n[s]=e[t[s]];if(this.outputShape=n,this.rank=n.length,this.rank>6)throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`);const s=_$(this.rank),r=qE("rc",this.rank),a=new Array(this.rank);for(let e=0;e<t.length;e++)a[t[e]]=r[e];const i=`vec2(${a.slice(-2).join()})`,o=`++${r[this.rank-1]} < ${n[this.rank-1]}`,l=`getChannel(getA(${a.join()}), ${i})`;this.userCode=`\n    void main() {\n      ${s} rc = getOutputCoords();\n      vec4 result = vec4(0.);\n      result[0] = ${l};\n      if(${o}) {\n        result[1] = ${l};\n      }\n      --${r[this.rank-1]};\n      if(++${r[this.rank-2]} < ${n[this.rank-2]}) {\n        result[2] = ${l};\n        if(${o}) {\n          result[3] = ${l};\n        }\n      }\n      setOutput(result);\n    }\n    `}}function GC(e,t,n){const s=fe().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new UC(e.shape,t):new VC(e.shape,t);return n.runWebGLProgram(s,[e],e.dtype)}function HC(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,keepDims:i}=s;return function(e,t,n,s){const r=t,a=e.shape.length,i=G(r,e.shape);let o=i;const l=il(o,a),u=null!=l;let c=e;u&&(c=GC(e,l,s),o=ll(o.length,a)),al("sum",o,a);const[h,p]=sl(c.shape,o);let d=h;n&&(d=rl(h,i));const f=L(p),m=LC({inputs:{x:c},attrs:{shape:[L(e.shape)/f,f]},backend:s}),g=WC(m,Rr(e.dtype),"sum",s),y=LC({inputs:{x:g},attrs:{shape:d},backend:s});return s.disposeIntermediateTensorInfo(m),s.disposeIntermediateTensorInfo(g),u&&s.disposeIntermediateTensorInfo(c),y}(r,a,i,n)}const jC={kernelName:Jn,backendName:"webgl",kernelFunc:HC};function KC(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{perm:a}=s,i=n,o=r.shape.length,l=new Array(o);for(let e=0;e<l.length;e++)l[e]=r.shape[a[e]];let u;if(i.shouldExecuteOnCPU([r])){const e=i.texData.get(r.dataId).values,t=jE(e,r.shape,r.dtype,a,l);u=i.makeTensorInfo(l,r.dtype),i.texData.get(u.dataId).values=t}else u=GC(r,a,i);return u}const qC={kernelName:xs,backendName:"webgl",kernelFunc:KC};function XC({a:e,b:t,transposeA:n,transposeB:s,backend:r,bias:a=null,preluActivationWeights:i=null,leakyreluAlpha:o=0,activation:l=null}){const u=e.shape.length,c=t.shape.length,h=n?e.shape[u-2]:e.shape[u-1],p=s?t.shape[c-1]:t.shape[c-2],d=n?e.shape[u-1]:e.shape[u-2],f=s?t.shape[c-2]:t.shape[c-1],m=e.shape.slice(0,-2),g=t.shape.slice(0,-2),y=L(m),b=L(g),x=gi(e.shape.slice(0,-2),t.shape.slice(0,-2)).concat([d,f]);F(h===p,(()=>`Error in matMul: inner shapes (${h}) and (${p}) of Tensors with shapes ${e.shape} and ${t.shape} and transposeA=${n} and transposeB=${s} must match.`));const w=n?[y,h,d]:[y,d,h],k=s?[b,f,p]:[b,p,f],v=LC({inputs:{x:e},backend:r,attrs:{shape:w}}),I=LC({inputs:{x:t},backend:r,attrs:{shape:k}}),N=[v,I],S=Math.max(y,b),T=n?v.shape[1]:v.shape[2],$=null!=a,E=null!=i,C="leakyrelu"===l,R=null!=l?AC(l,!0):null;let A;if((1===d||1===f)&&T>1e3&&!1===($||E||C||null!=R)){let e=v,t=I;n&&(e=KC({inputs:{x:v},backend:r,attrs:{perm:[0,2,1]}}),N.push(e)),s&&(t=KC({inputs:{x:I},backend:r,attrs:{perm:[0,2,1]}}),N.push(t));const a=1===f;let i=e;1!==f&&(i=LC({inputs:{x:e},backend:r,attrs:{shape:[S,T,1]}}),N.push(i));const o=1===f?2:1;let l=t;a&&(l=LC({inputs:{x:t},backend:r,attrs:{shape:[S,1,T]}}),N.push(l));const u=OC({inputs:{a:i,b:l},backend:r});A=HC({inputs:{x:u},backend:r,attrs:{axis:o,keepDims:!0}}),N.push(u)}else{const l=Cr(e.dtype,t.dtype),u=new _C(w,k,[S,d,f],n,s,$,R,E,C),c=[v,I];if(null!=a&&c.push(a),E&&c.push(i),C){const e=r.makeTensorInfo([],"float32",tr(o,"float32"));c.push(e),N.push(e)}A=r.runWebGLProgram(u,c,l)}const _=LC({inputs:{x:A},backend:r,attrs:{shape:x}});N.push(A);for(const e of N)r.disposeIntermediateTensorInfo(e);return _}const YC={kernelName:Ts,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{a:r,b:a,bias:i,preluActivationWeights:o}=t,{transposeA:l,transposeB:u,activation:c,leakyreluAlpha:h}=s;return XC({a:r,b:a,transposeA:l,transposeB:u,backend:n,bias:i,preluActivationWeights:o,leakyreluAlpha:h,activation:c})}},JC="return abs(x);",ZC={kernelName:xe,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{x:s}=t;if(n.shouldExecuteOnCPU([s])&&"complex64"!==s.dtype){const e=n.texData.get(s.dataId),t=_E(e.values);return n.makeTensorInfo(s.shape,s.dtype,t)}let r;return r=fe().getBool("WEBGL_PACK_UNARY_OPERATIONS")?new lC(s.shape,JC):new nC(s.shape,JC),n.runWebGLProgram(r,[s],s.dtype)}},QC=CC({opSnippet:sC+"\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return acos(x);\n"}),eR={kernelName:we,backendName:"webgl",kernelFunc:QC},tR=CC({opSnippet:sC+"\n  if (x < 1.0) return NAN;\nreturn log(x + sqrt(x * x - 1.0));"}),nR={kernelName:ke,backendName:"webgl",kernelFunc:tR},sR="return a + b;",rR=RC({opSnippet:sR,packedOpSnippet:sR,supportsComplex:!0,cpuKernelImpl:Q$}),aR={kernelName:ve,backendName:"webgl",kernelFunc:rR};class iR{constructor(e,t){this.outputShape=[],this.outputShape=e,this.variableNames=t.map(((e,t)=>`T${t}`));const n=[];this.variableNames.forEach((e=>{n.push(`float v${e} = get${e}AtOutCoords();`)}));const s=this.variableNames.map((e=>`v${e}`)).join(" + ");this.userCode=`\n      void main() {\n        ${n.join("\n        ")}\n\n        float result = ${s};\n        setOutput(result);\n      }\n    `}}class oR{constructor(e,t){this.outputShape=[],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e,this.variableNames=t.map(((e,t)=>`T${t}`));const n=[];this.variableNames.forEach((e=>{n.push(`vec4 v${e} = get${e}AtOutCoords();`)}));const s=this.variableNames.map((e=>`v${e}`)).join(" + ");this.userCode=`\n      void main() {\n        ${n.join("\n        ")}\n\n        vec4 result = ${s};\n        setOutput(result);\n      }\n    `}}const lR={kernelName:Ie,backendName:"webgl",kernelFunc:function e(t){const{inputs:n,backend:s}=t,r=n;if(1===r.length)return bC({inputs:{x:r[0]},backend:s});if(r.length>fe().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")){const t=Math.floor(r.length/2),n=e({inputs:r.slice(0,t),backend:s}),a=e({inputs:r.slice(t),backend:s});return e({inputs:[n,a],backend:s})}const a=r.map((e=>e.dtype)).reduce(((e,t)=>Cr(e,t))),i=r.map((e=>e.shape)),o=fe().getBool("WEBGL_PACK")?new oR(r[0].shape,i):new iR(r[0].shape,i);return s.runWebGLProgram(o,r,a)}},uR={kernelName:Ne,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,keepDims:i}=s,o=r.shape.length,l=G(a,r.shape);let u=l;const c=il(u,o);let h=r;null!=c&&(h=KC({inputs:{x:r},backend:n,attrs:{perm:c}}),u=ll(u.length,o)),al("all",u,o);const[p,d]=sl(h.shape,u),f=LC({inputs:{x:h},backend:n,attrs:{shape:[-1,L(d)]}}),m=WC(f,f.dtype,"all",n);let g;return g=LC(i?{inputs:{x:m},backend:n,attrs:{shape:rl(p,l)}}:{inputs:{x:m},backend:n,attrs:{shape:p}}),n.disposeIntermediateTensorInfo(f),n.disposeIntermediateTensorInfo(m),null!=c&&n.disposeIntermediateTensorInfo(h),g}},cR={kernelName:Se,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,keepDims:i}=s,o=r.shape.length,l=G(a,r.shape);let u=l;const c=il(u,o);let h=r;null!=c&&(h=KC({inputs:{x:r},backend:n,attrs:{perm:c}}),u=ll(u.length,o)),al("any",u,o);const[p,d]=sl(h.shape,u),f=LC({inputs:{x:h},backend:n,attrs:{shape:[-1,L(d)]}}),m=WC(f,f.dtype,"any",n);let g;return g=LC(i?{inputs:{x:m},backend:n,attrs:{shape:rl(p,l)}}:{inputs:{x:m},backend:n,attrs:{shape:p}}),n.disposeIntermediateTensorInfo(f),n.disposeIntermediateTensorInfo(m),null!=c&&n.disposeIntermediateTensorInfo(h),g}};class hR{constructor(e,t,n){this.variableNames=["A"];const{windowSize:s,batchSize:r,outSize:a}=e;n||this.variableNames.push("bestIndicesA"),this.outputShape=[r,a];const i="max"===t?">":"<",o=n?"inOffset + i;":"round(getBestIndicesA(batch, inOffset + i));";this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${s};\n\n        int bestIndex = inOffset;\n        float bestValue = getA(batch, bestIndex);\n\n        for (int i = 0; i < ${s}; i++) {\n          int inIdx = ${o};\n          float candidate = getA(batch, inIdx);\n          if (candidate ${i} bestValue) {\n            bestValue = candidate;\n            bestIndex = inIdx;\n          }\n        }\n        setOutput(float(bestIndex));\n      }\n    `}}class pR{constructor(e,t,n,s){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,F(e.length>2,(()=>`Packed arg${n.charAt(0).toUpperCase()+n.slice(1)} supports only inputs with rank above 2.`));const r=e[e.length-1],a=Math.ceil(r/t);this.outputShape=e.slice(0,-1),a>1&&this.outputShape.push(a),s||this.variableNames.push("bestIndicesA");const i=this.outputShape,o=i.length,l=_$(o),u=XE("coords",o);let c,h;if(1===a){h=o+1;const e=_$(h);c=`\n        ${e} sourceLocR = ${e}(${u.join()}, 0);\n        ++${u[o-1]};\n        ${e} sourceLocG = ${e}(${u.join()}, 0);\n        ++${u[o-2]};\n        ${e} sourceLocA = ${e}(${u.join()}, 0);\n        --${u[o-1]};\n        ${e} sourceLocB = ${e}(${u.join()}, 0);\n        --${u[o-2]};`}else h=o,c=`\n        ${l} sourceLocR = coords;\n        ++${u[o-1]};\n        ${l} sourceLocG = coords;\n        ++${u[o-2]};\n        ${l} sourceLocA = coords;\n        --${u[o-1]};\n        ${l} sourceLocB = coords;\n        --${u[o-2]};`;const p=["x","y","z","w","u","v"].slice(0,h),d="."+p[h-1],f=p.map((e=>"int "+e)),m=XE("sourceLocR",h-1).concat("inIdx.r"),g=XE("sourceLocG",h-1).concat("inIdx.g"),y=XE("sourceLocB",h-1).concat("inIdx.b"),b=XE("sourceLocA",h-1).concat("inIdx.a"),x="max"===n?"greaterThan":"lessThan",w=s?"":`\n          inIdx = round(vec4(getBestIndicesAChannel(${m.join()}),\n                             getBestIndicesAChannel(${g.join()}),\n                             getBestIndicesAChannel(${y.join()}),\n                             getBestIndicesAChannel(${b.join()})));`,k=`vec4(\n            getAChannel(${m.join()}),\n            hasNextCol ? getAChannel(${g.join()}) : 0.,\n            hasNextRow ? getAChannel(${y.join()}) : 0.,\n            hasNextRow && hasNextCol ? getAChannel(${b.join()}) : 0.)`,v=s?"":`\n      float getBestIndicesAChannel(${f.join()}) {\n        return getChannel(getBestIndicesA(${p.join()}),\n                                          vec2(${p.slice(-2).join()}));\n      }`;this.userCode=`\n      float getAChannel(${f.join()}) {\n        return getChannel(getA(${p.join()}),\n                               vec2(${p.slice(-2).join()}));\n      }\n      ${v}\n      void main() {\n        ${l} coords = getOutputCoords();\n        bool hasNextCol = ${u[o-1]} < ${i[o-1]-1};\n        bool hasNextRow = ${u[o-2]} < ${i[o-2]-1};\n        ${c}\n        ivec4 srcIdx = ivec4(sourceLocR${d}, sourceLocG${d},\n          sourceLocB${d}, sourceLocA${d}) * ${t};\n        ivec4 inIdx = srcIdx;\n        vec4 bestIndex = vec4(inIdx);\n        vec4 bestValue = ${k};\n\n        for (int i = 0; i < ${t}; i++) {\n          inIdx = srcIdx;\n          ${w}\n          vec4 candidate = ${k};\n          bvec4 nan = isnan(candidate);\n          bvec4 replace = bvec4(\n            vec4(${x}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\n\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\n                           replace.y  ? candidate.y : bestValue.y,\n                           replace.z  ? candidate.z : bestValue.z,\n                           replace.w  ? candidate.w : bestValue.w);\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\n          srcIdx++;\n        }\n        setOutput(bestIndex);\n      }\n    `}}function dR(e,t,n,s=null){let r=t.shape[0],a=t.shape[1];null!=s&&(r=s.shape[0],a=s.shape[1]);const i=pc(a),o={windowSize:i,inSize:a,batchSize:r,outSize:Math.ceil(a/i)},l=new hR(o,n,null==s),u=[t];null!=s&&u.push(s);const c=e.runWebGLProgram(l,u,"int32");if(1===c.shape[1])return c;const h=dR(e,t,n,c);return e.disposeIntermediateTensorInfo(c),h}function fR(e,t,n,s=null){const r=null!=s?s.shape:t.shape,a=pc(r[r.length-1]),i=new pR(r,a,n,null==s),o=null==s?[t]:[t,s],l=e.runWebGLProgram(i,o,"int32");if(l.shape.length===t.shape.length){const s=fR(e,t,n,l);return e.disposeIntermediateTensorInfo(l),s}return l}function mR(e,t,n,s){const r=[n];if(al("arg"+s.charAt(0).toUpperCase()+s.slice(1),r,t.shape.length),!fe().getBool("WEBGL_PACK_REDUCE")||t.shape.length<=2){const n=[],a=e.texData.get(t.dataId);let i=t;null!==a&&a.isPacked&&(i=e.unpackTensor(t),n.push(i));const[o,l]=sl(i.shape,r),u=L(l),c=LC({inputs:{x:i},backend:e,attrs:{shape:[-1,u]}});n.push(c);const h=dR(e,c,s);n.push(h);const p=LC({inputs:{x:h},backend:e,attrs:{shape:o}});return n.forEach((t=>e.disposeIntermediateTensorInfo(t))),p}return fR(e,t,s)}const gR={kernelName:Te,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a}=s;let i=G(a,r.shape);const o=il(i,r.shape.length);let l=r;const u=[];null!=o&&(l=KC({inputs:{x:r},backend:n,attrs:{perm:o}}),u.push(l),i=ll(i.length,l.shape.length)),al("argMax",[i[0]],l.shape.length);const c=mR(n,l,i[0],"max");return u.forEach((e=>n.disposeIntermediateTensorInfo(e))),c}},yR={kernelName:$e,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a}=s;let i=G(a,r.shape);const o=il(i,r.shape.length);let l=r;const u=[];null!=o&&(l=KC({inputs:{x:r},backend:n,attrs:{perm:o}}),u.push(l),i=ll(i.length,l.shape.length)),al("argMin",[i[0]],l.shape.length);const c=mR(n,l,i[0],"min");return u.forEach((e=>n.disposeIntermediateTensorInfo(e))),c}},bR=CC({opSnippet:sC+"\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return asin(x);\n"}),xR={kernelName:Ee,backendName:"webgl",kernelFunc:bR},wR=CC({opSnippet:sC+"return log(x + sqrt(x * x + 1.0));"}),kR={kernelName:Ce,backendName:"webgl",kernelFunc:wR},vR=CC({opSnippet:sC+"\n  return atan(x);\n"}),IR={kernelName:Re,backendName:"webgl",kernelFunc:vR},NR=RC({opSnippet:fC+"\n  return atan(a, b);\n",packedOpSnippet:"\n  vec4 result = atan(a, b);\n  bvec4 isNaNA = isnan(a);\n  bvec4 isNaNB = isnan(b);\n  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);\n  "+gC+"\n  return result;\n"}),SR={kernelName:_e,backendName:"webgl",kernelFunc:NR},TR=CC({opSnippet:sC+"\n  if ((x < -1.0) || (x > 1.0)) return NAN;\nreturn (log(1.0 + x) - log(1.0 - x)) / 2.0;"}),$R={kernelName:Ae,backendName:"webgl",kernelFunc:TR};class ER{constructor(e,t,n,s=!1,r=!1){if(this.variableNames=["x"],"avg"===t&&n)throw new Error("Cannot compute positions for average pool.");const a=e.filterWidth,i=e.strideHeight,o=e.strideWidth,l=e.dilationHeight,u=e.dilationWidth,c=e.effectiveFilterHeight,h=e.effectiveFilterWidth,p=e.padInfo.top,d=e.padInfo.left;this.outputShape=e.outShape;const f="avg"===t,m=`((batch  * ${e.inHeight} + xR) * ${e.inWidth} + xC) * ${e.inChannels} + d`,g=`(xR * ${e.inWidth} + xC) * ${e.inChannels} + d`;let y="0.0";if(f||(y="-1.0 / 1e-20"),n){const t=">=";return void(this.userCode=`\n        const ivec2 strides = ivec2(${i}, ${o});\n        const ivec2 pads = ivec2(${p}, ${d});\n\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int batch = coords[0];\n          int d = coords[3];\n\n          ivec2 xRCCorner = coords.yz * strides - pads;\n          int xRCorner = xRCCorner.x;\n          int xCCorner = xRCCorner.y;\n\n          // max/min x(?, ?, d) to get y(yR, yC, d).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n          float avgValue = 0.0;\n\n          for (int wR = 0; wR < ${c};\n              wR += ${l}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${h};\n                wC += ${u}) {\n              int xC = xCCorner + wC;\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              float value = getX(batch, xR, xC, d);\n\n              // If a min / max value has already been found, use it. If not,\n              // use the current value.\n              float currMinMaxValue = mix(\n                  value, minMaxValue, minMaxValueFound);\n              if (value ${t} currMinMaxValue) {\n                minMaxValue = value;\n                minMaxValueFound = 1.0;\n                minMaxPosition = ${s?r?m:g:`wR * ${h} + wC`};\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `)}let b=`${t}(${t}(${t}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"avg"===t&&(b="avgValue / max(count, 1.0)");const x=4*Math.floor(a/4),w=a%4,k=`\n      if (${f}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec2 strides = ivec2(${i}, ${o});\n      const ivec2 pads = ivec2(${p}, ${d});\n      const float initializationValue = ${y};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xR, int xC, int d) {\n        if (xC < 0 || xC >= ${e.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xR, xC, d);\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d = coords[3];\n\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // max/min x(?, ?, d) to get y(yR, yC, d).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${y});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wR = 0; wR < ${c};\n            wR += ${l}) {\n          int xR = xRCorner + wR;\n\n          if (xR < 0 || xR >= ${e.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${x}; wC += 4) {\n            int xC = xCCorner + wC * ${u};\n\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              getValue(batch, xR, xC + 2 * ${u}, d),\n              getValue(batch, xR, xC + 3 * ${u}, d)\n            );\n\n            ${k}\n          }\n\n          int xC = xCCorner + ${x};\n          if (${1===w}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              initializationValue,\n              initializationValue,\n              initializationValue\n            );\n\n            ${k}\n          } else if (${2===w}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              initializationValue,\n              initializationValue\n            );\n\n            ${k}\n          } else if (${3===w}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              getValue(batch, xR, xC + 2 * ${u}, d),\n              initializationValue\n            );\n\n            ${k}\n          }\n        }\n        setOutput(${b});\n      }\n    `}}class CR{constructor(e,t,n,s=!1,r=!1){if(this.variableNames=["x"],"avg"===t&&n)throw new Error("Cannot compute positions for average pool.");const a=e.filterWidth,i=e.strideDepth,o=e.strideHeight,l=e.strideWidth,u=e.dilationDepth,c=e.dilationHeight,h=e.dilationWidth,p=e.effectiveFilterDepth,d=e.effectiveFilterHeight,f=e.effectiveFilterWidth,m=e.padInfo.front,g=e.padInfo.top,y=e.padInfo.left;this.outputShape=e.outShape;const b="avg"===t;let x="0.0";if(b||(x="-1.0 / 1e-20"),n){const t=">=";return void(this.userCode=`\n        const ivec3 strides =\n            ivec3(${i}, ${o}, ${l});\n        const ivec3 pads = ivec3(${m}, ${g}, ${y});\n\n        void main() {\n          ivec5 coords = getOutputCoords();\n          int batch = coords.x;\n          int ch = coords.u;\n\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n          int xDCorner = xCorner.x;\n          int xRCorner = xCorner.y;\n          int xCCorner = xCorner.z;\n\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n\n          for (int wD = 0; wD < ${p};\n              wD += ${u}) {\n            int xD = xDCorner + wD;\n\n            if (xD < 0 || xD >= ${e.inDepth}) {\n              continue;\n            }\n\n            for (int wR = 0; wR < ${d};\n                wR += ${c}) {\n              int xR = xRCorner + wR;\n\n              if (xR < 0 || xR >= ${e.inHeight}) {\n                continue;\n              }\n\n              for (int wC = 0; wC < ${f};\n                  wC += ${h}) {\n                int xC = xCCorner + wC;\n\n                if (xC < 0 || xC >= ${e.inWidth}) {\n                  continue;\n                }\n\n                float value = getX(batch, xD, xR, xC, ch);\n\n                // If a min / max value has already been found, use it. If not,\n                // use the current value.\n                float currMinMaxValue = mix(\n                    value, minMaxValue, minMaxValueFound);\n                if (value ${t} currMinMaxValue) {\n                  minMaxValue = value;\n                  minMaxValueFound = 1.0;\n                  minMaxPosition = ${s?r?`(((batch * ${e.inDepth} + xD) * ${e.inHeight} + xR) * ${e.inWidth} + xC) * ${e.inChannels} + ch`:`((xD * ${e.inHeight} + xR) * ${e.inWidth} + xC) * ${e.inChannels} + ch`:`wD * ${d} * ${f} +\n                      wR * ${f} + wC`};\n                }\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `)}let w=`${t}(${t}(${t}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"avg"===t&&(w="avgValue / max(count, 1.0)");const k=4*Math.floor(a/4),v=a%4,I=`\n      if (${b}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec3 strides =\n        ivec3(${i}, ${o}, ${l});\n      const ivec3 pads = ivec3(${m}, ${g}, ${y});\n      const float initializationValue = ${x};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\n        if (xC < 0 || xC >= ${e.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xD, xR, xC, ch);\n      }\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xDCorner = xCorner.x;\n        int xRCorner = xCorner.y;\n        int xCCorner = xCorner.z;\n\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${x});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wD = 0; wD < ${p};\n            wD += ${u}) {\n          int xD = xDCorner + wD;\n\n          if (xD < 0 || xD >= ${e.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${d};\n            wR += ${c}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${k}; wC += 4) {\n              int xC = xCCorner + wC * ${h};\n\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${h}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${h}, ch),\n                getValue(batch, xD, xR, xC + 3 * ${h}, ch)\n              );\n\n              ${I}\n            }\n\n            int xC = xCCorner + ${k};\n            if (${1===v}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                initializationValue,\n                initializationValue,\n                initializationValue\n              );\n\n              ${I}\n            } else if (${2===v}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${h}, ch),\n                initializationValue,\n                initializationValue\n              );\n\n              ${I}\n            } else if (${3===v}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${h}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${h}, ch),\n                initializationValue\n              );\n\n              ${I}\n            }\n          }\n        }\n        setOutput(${w});\n      }\n    `}}const RR={kernelName:De,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t;m$(r,"avgPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:l}=s;F(co(i,1),(()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));const u=eo(r.shape,a,i,1,o,l);if(1===u.filterWidth&&1===u.filterHeight&&z(u.inShape,u.outShape))return bC({inputs:{x:r},backend:n});const c=new ER(u,"avg",!1);return n.runWebGLProgram(c,[r],"float32")}},AR={kernelName:Oe,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{filterSize:a,strides:i,pad:o,dimRoundingMode:l,dataFormat:u}=s,c=to(r.shape,a,i,[1,1,1],o,l,u),h=new CR(c,"avg",!1);return n.runWebGLProgram(h,[r],"float32")}};class _R{constructor(e){this.variableNames=["dy"],this.outputShape=e.inShape;const t=e.filterHeight,n=e.filterWidth,s=e.strideHeight,r=e.strideWidth,a=e.dilationHeight,i=e.dilationWidth,o=e.effectiveFilterHeight,l=e.effectiveFilterWidth,u=o-1-e.padInfo.top,c=l-1-e.padInfo.left,h=1/(t*n);this.userCode=`\n      const ivec2 pads = ivec2(${u}, ${c});\n      const float avgMultiplier = float(${h});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${o};\n            wR += ${a}) {\n          float dyR = float(dyRCorner + wR) / ${s}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${l};\n            wC+= ${i}) {\n            float dyC = float(dyCCorner + wC) / ${r}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n\n            dotProd += dyValue * avgMultiplier;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class DR{constructor(e){this.variableNames=["dy"],this.outputShape=e.inShape;const t=e.filterDepth,n=e.filterHeight,s=e.filterWidth,r=e.strideDepth,a=e.strideHeight,i=e.strideWidth,o=e.dilationDepth,l=e.dilationHeight,u=e.dilationWidth,c=e.effectiveFilterDepth,h=e.effectiveFilterHeight,p=e.effectiveFilterWidth,d=c-1-e.padInfo.front,f=h-1-e.padInfo.top,m=p-1-e.padInfo.left,g=1/(t*n*s);this.userCode=`\n      const ivec3 pads = ivec3(${d}, ${f}, ${m});\n      const float avgMultiplier = float(${g});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${c};\n            wD += ${o}) {\n          float dyD = float(dyDCorner + wD) / ${r}.0;\n\n          if (dyD < 0.0 || dyD >= ${e.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${h};\n              wR += ${l}) {\n            float dyR = float(dyRCorner + wR) / ${a}.0;\n\n            if (dyR < 0.0 || dyR >= ${e.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${p};\n                wC += ${u}) {\n              float dyC = float(dyCCorner + wC) / ${i}.0;\n\n              if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n\n              dotProd += dyValue * avgMultiplier;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}const FR={kernelName:Me,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,input:a}=t,i=a,{filterSize:o,strides:l,pad:u,dimRoundingMode:c}=s,h=to(i.shape,o,l,[1,1,1],u,c),p=new DR(h);return n.runWebGLProgram(p,[r],i.dtype)}},OR={kernelName:Fe,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,input:a}=t,i=a;m$([r,a],"avgPoolGrad");const{filterSize:o,strides:l,pad:u}=s,c=eo(i.shape,o,l,1,u),h=new _R(c);return n.runWebGLProgram(h,[r],i.dtype)}},MR={kernelName:Le,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{a:r,b:a}=t,{transposeA:i,transposeB:o}=s;return XC({a:r,b:a,transposeA:i,transposeB:o,backend:n})}};class LR{constructor(e,t,n,s,r,a){this.outputShape=[],this.variableNames=["x","mean","variance"],gi(e,t),gi(e,n);let i="0.0";null!=s&&(gi(e,s),this.variableNames.push("offset"),i="getOffsetAtOutCoords()");let o="1.0";null!=r&&(gi(e,r),this.variableNames.push("scale"),o="getScaleAtOutCoords()"),this.outputShape=e,this.userCode=`\n      void main() {\n        float x = getXAtOutCoords();\n        float mean = getMeanAtOutCoords();\n        float variance = getVarianceAtOutCoords();\n        float offset = ${i};\n        float scale = ${o};\n        float inv = scale * inversesqrt(variance + float(${a}));\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\n      }\n    `}}class zR{constructor(e,t,n,s,r,a){this.packedInputs=!0,this.packedOutput=!0,this.variableNames=["x","mean","variance"],gi(e,t),gi(e,n);let i="vec4(0.0)";null!=s&&(gi(e,s),this.variableNames.push("offset"),i="getOffsetAtOutCoords()");let o="vec4(1.0)";null!=r&&(gi(e,r),this.variableNames.push("scale"),o="getScaleAtOutCoords()"),this.outputShape=e,this.userCode=`\n      void main() {\n        vec4 offset = ${i};\n        vec4 scale = ${o};\n\n        vec4 x = getXAtOutCoords();\n        vec4 mean = getMeanAtOutCoords();\n        vec4 variance = getVarianceAtOutCoords();\n\n        vec4 inv = scale * inversesqrt(variance + vec4(${a}));\n\n        setOutput((x - mean) * inv + offset);\n      }\n    `}}const BR={kernelName:Et,backendName:"webgl",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:s,mean:r,variance:a,offset:i,scale:o}=e;F(r.shape.length===a.shape.length,(()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),F(null==i||r.shape.length===i.shape.length,(()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),F(null==o||r.shape.length===o.shape.length,(()=>"Batch normalization gradient requires mean and scale to have equal ranks."));let{varianceEpsilon:l}=n;null==l&&(l=.001);const u=[s,r,a];let c=null;null!=i&&(c=i.shape,u.push(i));let h=null;null!=o&&(h=o.shape,u.push(o));const p=fe().getBool("WEBGL_PACK_NORMALIZATION")?new zR(s.shape,r.shape,a.shape,c,h,l):new LR(s.shape,r.shape,a.shape,c,h,l);return t.runWebGLProgram(p,u,u[0].dtype)}};class PR{constructor(e){this.variableNames=["source"],this.outputShape=e,this.rank=e.length;const t=_$(this.rank);this.customUniforms=[{name:"start",arrayIndex:this.rank,type:"int"}];const n=function(e){if(1===e)return"sourceLoc";if(e<=6)return WR.slice(0,e).map((e=>"sourceLoc."+e)).join(",");throw Error(`Slicing for rank ${e} is not yet supported`)}(this.rank);let s;s=`\n        ${t} sourceLoc;\n        ${t} coords = getOutputCoords();\n        ${e.map(((e,t)=>`sourceLoc.${WR[t]} = start[${t}] + coords.${WR[t]};`)).join("\n")}\n      `,this.userCode=`\n      void main() {\n        ${s}\n        setOutput(getSource(${n}));\n      }\n    `}}const WR=["x","y","z","w","u","v"];class VR{constructor(e){this.variableNames=["source"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e,this.rank=e.length,this.customUniforms=[{name:"start",arrayIndex:this.rank,type:"int"}];const t=_$(this.rank),n=XE("coords",this.rank),s=XE("sourceLoc",this.rank),r=1===this.rank?"sourceLoc":`vec2(${s.slice(-2).join()})`,a=`getChannel(getSource(${s.join()}), ${r})`,i=`\n      result.x = ${a};\n      if (++${n[this.rank-1]} < ${e[this.rank-1]}) {\n        ++${s[this.rank-1]};\n        result.y = ${a};\n        --${s[this.rank-1]};\n      }\n    `,o=1===this.rank?"":`\n      --${n[this.rank-1]};\n      if (++${n[this.rank-2]} < ${e[this.rank-2]}) {\n        ++${s[this.rank-2]};\n        result.z = ${a};\n        if (++${n[this.rank-1]} < ${e[this.rank-1]}) {\n          ++${s[this.rank-1]};\n          result.w = ${a};\n        }\n      }\n    `,l=this.rank<=4?`sourceLoc = coords +\n            ${t}(${e.map(((e,t)=>`start[${t}]`)).join()});`:e.map(((e,t)=>`${s[t]} = ${n[t]} + start[${t}];`)).join("\n");this.userCode=`\n      void main() {\n        ${t} coords = getOutputCoords();\n        ${t} sourceLoc;\n        ${l}\n        vec4 result = vec4(0.);\n        ${i}\n        ${o}\n        setOutput(result);\n      }\n    `}}function UR(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{begin:a,size:i}=s,[o,l]=Ki(r,a,i);if(Di(r,o,l),0===L(l))return n.makeTensorInfo(l,r.dtype,[]);if(n.shouldExecuteOnCPU([r])||"string"===r.dtype){const e=n.texData.get(r.dataId),t=DE(e.values,o,l,r.shape,r.dtype);return n.makeTensorInfo(l,r.dtype,t)}const{isPacked:u}=n.texData.get(r.dataId),c=Hi(r.shape,o,l);if(u||!c){const e=fe().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new VR(l):new PR(l),t=[o];return n.runWebGLProgram(e,[r],r.dtype,t)}return n.uploadToGPU(r.dataId),function(e,t,n,s){const r=s.texData.get(e.dataId),a=s.makeTensorInfo(n,e.dtype),i=s.texData.get(a.dataId);Object.assign(i,r),i.refCount=1,i.shape=n,i.dtype=e.dtype;let o=ji(t,te(e.shape));r.slice&&(o+=r.slice.flatOffset),i.slice={flatOffset:o,origDataId:r.slice&&r.slice.origDataId||e.dataId};const l=s.dataRefCount.get(i.slice.origDataId)||1;return s.dataRefCount.set(i.slice.origDataId,l+1),a}(r,o,l,n)}const GR={kernelName:Gn,backendName:"webgl",kernelFunc:UR},HR={kernelName:ze,backendName:"webgl",kernelFunc:e=>{const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{blockShape:a,crops:i}=s;F(r.shape.length<=4,(()=>"batchToSpaceND for rank > 4 with a WebGL backend not implemented yet"));const o=a.reduce(((e,t)=>e*t)),l=fc(r.shape,a,o),u=mc(l.length,a.length),c=gc(r.shape,a,o),h=yc(i,a.length),p=bc(c,i,a.length),d=[],f=LC({inputs:{x:r},backend:n,attrs:{shape:l}}),m=KC({inputs:{x:f},backend:n,attrs:{perm:u}}),g=LC({inputs:{x:m},backend:n,attrs:{shape:c}}),y=UR({inputs:{x:g},backend:n,attrs:{begin:h,size:p}});return d.push(f),d.push(m),d.push(g),d.forEach((e=>n.disposeIntermediateTensorInfo(e))),y}},jR={kernelName:Be,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,weights:a}=t,{size:i}=s,o=n.readSync(r.dataId),l=n.readSync(a.dataId),u=eE(o,l,a.dtype,a.shape,i);return n.makeTensorInfo([i],a.dtype,u)}},KR={kernelName:Pe,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{a:s,b:r}=t,a=fe().getBool("WEBGL_PACK_BINARY_OPERATIONS"),i=fe().getNumber("WEBGL_VERSION");if(n.shouldExecuteOnCPU([s,r])||1===i){const e=n.texData.get(s.dataId).values,t=n.texData.get(r.dataId).values,[a,i]=nE(s.shape,r.shape,e,t,s.dtype),o=n.makeTensorInfo(i,s.dtype);return n.texData.get(o.dataId).values=a,o}let o;return o=a?new yC("\n  int r = int(a.r) & int(b.r);\n  int g = int(a.g) & int(b.g);\n  int rb = int(a.b) & int(b.b);\n  int ra = int(a.a) & int(b.a);\n  return vec4(r, g, rb, ra);\n",s.shape,r.shape,!1):new mC("\n  return float(int(a.r) & int(b.r));\n",s.shape,r.shape),n.runWebGLProgram(o,[s,r],s.dtype)}},qR={kernelName:We,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{s0:s,s1:r}=t,a=n.readSync(s.dataId),i=n.readSync(r.dataId),o=gi(Array.from(a),Array.from(i));return n.makeTensorInfo([o.length],"int32",Int32Array.from(o))}},XR=RC({opSnippet:"return float(a != b);",cpuKernelImpl:IE,dtype:"bool"}),YR={kernelName:pn,backendName:"webgl",kernelFunc:XR};function JR(e){const{inputs:t,backend:n}=e,{input:s}=t;return bC({inputs:{x:n.texData.get(s.dataId).complexTensorInfos.real},backend:n})}const ZR={kernelName:$n,backendName:"webgl",kernelFunc:JR},QR={kernelName:Ve,backendName:"webgl",kernelFunc:function e(t){const{inputs:n,backend:s,attrs:r}=t,{x:a}=n,{dtype:i}=r;if("complex64"===i){if("complex64"===a.dtype)return bC({inputs:{x:a},backend:s});const t=kl(a.shape),n=e({inputs:{x:a},backend:s,attrs:{dtype:"float32"}}),r=wC({inputs:{real:n,imag:t},backend:s});return t.dispose(),s.disposeIntermediateTensorInfo(n),r}if("complex64"===a.dtype){const t=JR({inputs:{input:a},backend:s}),n=e({inputs:{x:t},backend:s,attrs:{dtype:i}});return s.disposeIntermediateTensorInfo(t),n}if(!q(a.dtype,i)){const e=bC({inputs:{x:a},backend:s});return{dataId:e.dataId,shape:e.shape,dtype:i}}if(s.shouldExecuteOnCPU([a])){const e=s.texData.get(a.dataId).values,[t,n,r]=sE(e,a.shape,a.dtype,i);return s.makeTensorInfo(t,n,r)}if("int32"===i)return function(e,t){const n=new nC(e.shape,"return float(int(x));"),s=t.runWebGLProgram(n,[e],"int32");return{dataId:s.dataId,shape:s.shape,dtype:s.dtype}}(a,s);if("bool"===i){const e=s.makeTensorInfo([],"bool",j("bool",1)),t=XR({inputs:{a,b:e},backend:s});return s.disposeIntermediateTensorInfo(e),t}throw new Error(`Error in Cast: failed to cast ${a.dtype} to ${i}`)}},eA="return ceil(x);",tA=CC({opSnippet:eA,packedOpSnippet:eA,cpuKernelImpl:rE}),nA={kernelName:Ue,backendName:"webgl",kernelFunc:tA};class sA{constructor(e){this.variableNames=["A"],this.customUniforms=[{name:"minVal",type:"float"},{name:"maxVal",type:"float"}],this.outputShape=e,this.userCode="\n\n      void main() {\n        float value = getAAtOutCoords();\n        if (isnan(value)) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, minVal, maxVal));\n      }\n    "}}class rA{constructor(e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"minVal",type:"float"},{name:"maxVal",type:"float"}],this.outputShape=e,this.userCode="\n      void main() {\n        vec4 value = getAAtOutCoords();\n\n        if (any(isnan(value))) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\n      }\n    "}}const aA={kernelName:Ge,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{clipValueMin:a,clipValueMax:i}=s;let o;o=fe().getBool("WEBGL_PACK_CLIP")?new rA(r.shape):new sA(r.shape);const l=[[a],[i]];return n.runWebGLProgram(o,[r],r.dtype,l)}};class iA{constructor(e){this.variableNames=["real","imag"],this.outputShape=e,this.userCode="\n      void main() {\n        float re = abs(getRealAtOutCoords());\n        float im = abs(getImagAtOutCoords());\n        float mx = max(re, im);\n\n        // sadly the length function in glsl is not underflow-safe\n        // (at least not on Intel GPUs). So the safe solution is\n        // to ensure underflow-safety in all cases.\n        setOutput(\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\n        );\n      }\n    "}}function oA(e,t){return{dataId:t.dataId,dtype:t.dtype,shape:e.shape}}const lA={kernelName:je,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{x:s}=t,r=n.texData.get(s.dataId),a=new iA(s.shape),i=[oA(s,r.complexTensorInfos.real),oA(s,r.complexTensorInfos.imag)];return n.runWebGLProgram(a,i,i[0].dtype)}};class uA{constructor(e){this.outputShape=[],this.outputShape=ac(e,1),this.variableNames=e.map(((e,t)=>`T${t}`));const t=new Array(e.length-1);t[0]=e[0][1];for(let n=1;n<t.length;n++)t[n]=t[n-1]+e[n][1];const n=[`if (yC < ${t[0]}) setOutput(getT0(yR, yC));`];for(let e=1;e<t.length;e++){const s=t[e-1];n.push(`else if (yC < ${t[e]}) setOutput(getT${e}(yR, yC-${s}));`)}const s=t.length,r=t[t.length-1];n.push(`else setOutput(getT${s}(yR, yC-${r}));`),this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int yR = coords.x;\n        int yC = coords.y;\n\n        ${n.join("\n        ")}\n      }\n    `}}class cA{constructor(e,t){this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[],this.outputShape=ac(e,t);const n=this.outputShape,s=n.length,r=_$(s),a=XE("coords",s),i=["x","y","z","w","u","v"].slice(0,s);this.variableNames=e.map(((e,t)=>`T${t}`));const o=new Array(e.length-1);o[0]=e[0][t];for(let n=1;n<o.length;n++)o[n]=o[n-1]+e[n][t];const l=i[t],u=i.slice(-2),c=i.join();let h=`if (${l} < ${o[0]}) {\n        return getChannel(\n            getT0(${c}), vec2(${u.join()}));\n        }`;for(let e=1;e<o.length;e++){const t=o[e-1];h+=`\n        if (${l} < ${o[e]}  && ${l} >= ${o[e-1]}) {\n          return getChannel(\n            getT${e}(${hA(i,l,t)}),\n            vec2(${hA(u,l,t)}));\n        }`}const p=o.length,d=o[o.length-1];h+=`\n        return getChannel(\n          getT${p}(${hA(i,l,d)}),\n          vec2(${hA(u,l,d)}));`,this.userCode=`\n      float getValue(${i.map((e=>"int "+e))}) {\n        ${h}\n      }\n\n      void main() {\n        ${r} coords = getOutputCoords();\n        vec4 result = vec4(getValue(${a}), 0., 0., 0.);\n\n        ${a[s-1]} = ${a[s-1]} + 1;\n        if (${a[s-1]} < ${n[s-1]}) {\n          result.g = getValue(${a});\n        }\n\n        ${a[s-2]} = ${a[s-2]} + 1;\n        if (${a[s-2]} < ${n[s-2]}) {\n          result.a = getValue(${a});\n        }\n\n        ${a[s-1]} = ${a[s-1]} - 1;\n        if (${a[s-2]} < ${n[s-2]} &&\n            ${a[s-1]} < ${n[s-1]}) {\n          result.b = getValue(${a});\n        }\n        setOutput(result);\n      }\n    `}}function hA(e,t,n){const s=e.indexOf(t);return e.map(((e,t)=>t===s?`${e} - ${n}`:e)).join()}function pA(e){const{inputs:t,backend:n}=e,{input:s}=t;return bC({inputs:{x:n.texData.get(s.dataId).complexTensorInfos.imag},backend:n})}const dA={kernelName:Ot,backendName:"webgl",kernelFunc:pA};function fA(e,t,n){const s=e[0].dtype;if("complex64"===s){const s=e.map((e=>JR({inputs:{input:e},backend:n}))),r=e.map((e=>pA({inputs:{input:e},backend:n}))),a=fA(s,t,n),i=fA(r,t,n),o=wC({inputs:{real:a,imag:i},backend:n});return s.forEach((e=>n.disposeIntermediateTensorInfo(e))),r.forEach((e=>n.disposeIntermediateTensorInfo(e))),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(i),o}let r=n.shouldExecuteOnCPU(e);if("string"===s&&(r=!0),r){const r=e.map((e=>{const s=L(e.shape.slice(t));return LC({inputs:{x:e},backend:n,attrs:{shape:[-1,s]}})})),a=r.map((e=>({vals:n.readSync(e.dataId),shape:e.shape}))),i=ac(r.map((e=>e.shape)),1),o=1===r[0].shape[0],l=aE(a,i,s,o),u=ac(e.map((e=>e.shape)),t),c=n.makeTensorInfo(u,s,l);return r.forEach((e=>n.disposeIntermediateTensorInfo(e))),c}const a=e.filter((e=>L(e.shape)>0)),i=fe().getBool("WEBGL_PACK_ARRAY_OPERATIONS")&&a[0].shape.length>1;if(1===a.length){const t=i?new nC(e[0].shape,oC):new lC(e[0].shape,oC);return n.runWebGLProgram(t,e,s)}const o=fe().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER");if(a.length>o){const e=[];for(let s=0;s<a.length;s+=o){const r=a.slice(s,s+o);e.push(fA(r,t,n))}const s=fA(e,t,n);for(const t of e)n.disposeIntermediateTensorInfo(t);return s}if(i){const e=new cA(a.map((e=>e.shape)),t);return n.runWebGLProgram(e,a,s)}const{tensors2D:l,outShape:u}=function(e,t,n){const s=ac(e.map((e=>e.shape)),t);return{tensors2D:e.map((e=>LC({inputs:{x:e},attrs:{shape:[-1,L(e.shape.slice(t))]},backend:n}))),outShape:s}}(a,t,n),c=new uA(l.map((e=>e.shape))),h=n.runWebGLProgram(c,l,s);l.forEach((e=>n.disposeIntermediateTensorInfo(e)));const p=LC({inputs:{x:h},attrs:{shape:u},backend:n});return n.disposeIntermediateTensorInfo(h),p}function mA(e){const{inputs:t,backend:n,attrs:s}=e,{axis:r}=s,a=G(r,t[0].shape)[0];rc(t.map((e=>e.shape)),a);const i=ac(t.map((e=>e.shape)),a);if(0===L(i))return n.makeTensorInfo(i,t[0].dtype,[]);const o=t.filter((e=>L(e.shape)>0));return 1===o.length?bC({inputs:{x:o[0]},backend:n}):fA(o,a,n)}const gA={kernelName:Ke,backendName:"webgl",kernelFunc:mA};class yA{constructor(e,t=!1,n=null,s=!1,r=!1){this.variableNames=["x","W"],this.outputShape=e.outShape;const a=e.padInfo.top,i=e.padInfo.left,o=e.strideHeight,l=e.strideWidth,u=e.dilationHeight,c=e.dilationWidth,h=e.filterHeight,p=e.filterWidth,d=4*Math.floor(e.inChannels/4),f=e.inChannels%4,m="channelsLast"===e.dataFormat,g=m?1:2,y=m?2:3,b=m?3:1;let x="",w="";n&&(x=s?`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:r?`float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ${n}\n        }`:`\n          float activation(float x) {\n            ${n}\n          }\n        `,w="result = activation(result);");const k=t?"result += getBiasAtOutCoords();":"";t&&this.variableNames.push("bias"),s&&this.variableNames.push("preluActivationWeights"),r&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n      ${x}\n\n      const ivec2 strides = ivec2(${o}, ${l});\n      const ivec2 pads = ivec2(${a}, ${i});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d2 = coords[${b}];\n\n        ivec2 xRCCorner =\n            ivec2(coords[${g}], coords[${y}]) * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${h}; wR++) {\n          int xR = xRCorner + wR * ${u};\n\n          if (xR < 0 || xR >= ${e.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${p}; wC++) {\n            int xC = xCCorner + wC * ${c};\n\n            if (xC < 0 || xC >= ${e.inWidth}) {\n              continue;\n            }\n\n            for (int d1 = 0; d1 < ${d}; d1 += 4) {\n              vec4 wValues = vec4(\n                getW(wR, wC, d1, d2),\n                getW(wR, wC, d1 + 1, d2),\n                getW(wR, wC, d1 + 2, d2),\n                getW(wR, wC, d1 + 3, d2)\n              );\n\n              if (${m}) {\n                vec4 xValues = vec4(\n                  getX(batch, xR, xC, d1),\n                  getX(batch, xR, xC, d1 + 1),\n                  getX(batch, xR, xC, d1 + 2),\n                  getX(batch, xR, xC, d1 + 3)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec4 xValues = vec4(\n                  getX(batch, d1, xR, xC),\n                  getX(batch, d1 + 1, xR, xC),\n                  getX(batch, d1 + 2, xR, xC),\n                  getX(batch, d1 + 3, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n\n            if (${1===f}) {\n\n              if (${m}) {\n                dotProd +=\n                    getX(batch, xR, xC, ${d}) *\n                    getW(wR, wC, ${d}, d2);\n              } else {\n                dotProd +=\n                    getX(batch, ${d}, xR, xC) *\n                    getW(wR, wC, ${d}, d2);\n              }\n\n            } else if (${2===f}) {\n              vec2 wValues = vec2(\n                getW(wR, wC, ${d}, d2),\n                getW(wR, wC, ${d} + 1, d2)\n              );\n\n              if (${m}) {\n                vec2 xValues = vec2(\n                  getX(batch, xR, xC, ${d}),\n                  getX(batch, xR, xC, ${d} + 1)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec2 xValues = vec2(\n                  getX(batch, ${d}, xR, xC),\n                  getX(batch, ${d} + 1, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            } else if (${3===f}) {\n              vec3 wValues = vec3(\n                getW(wR, wC, ${d}, d2),\n                getW(wR, wC, ${d} + 1, d2),\n                getW(wR, wC, ${d} + 2, d2)\n              );\n\n              if (${m}) {\n                vec3 xValues = vec3(\n                  getX(batch, xR, xC, ${d}),\n                  getX(batch, xR, xC, ${d} + 1),\n                  getX(batch, xR, xC, ${d} + 2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec3 xValues = vec3(\n                  getX(batch, ${d}, xR, xC),\n                  getX(batch, ${d} + 1, xR, xC),\n                  getX(batch, ${d} + 2, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            }\n          }\n        }\n\n        float result = dotProd;\n        ${k}\n        ${w}\n        setOutput(result);\n      }\n    `}}class bA{constructor(e){this.variableNames=["x","W"],this.outputShape=e.outShape;const t=e.padInfo.front,n=e.padInfo.top,s=e.padInfo.left,r=e.strideDepth,a=e.strideHeight,i=e.strideWidth,o=e.dilationDepth,l=e.dilationHeight,u=e.dilationWidth,c=e.filterDepth,h=e.filterHeight,p=e.filterWidth,d=4*Math.floor(e.inChannels/4),f=e.inChannels%4;this.userCode=`\n      const ivec3 strides = ivec3(${r}, ${a}, ${i});\n      const ivec3 pads = ivec3(${t}, ${n}, ${s});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d2 = coords.u;\n\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xFCorner = xFRCCorner.x;\n        int xRCorner = xFRCCorner.y;\n        int xCCorner = xFRCCorner.z;\n\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\n        // values in that axis.\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${c}; wF++) {\n          int xF = xFCorner + wF * ${o};\n\n          if (xF < 0 || xF >= ${e.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${h}; wR++) {\n            int xR = xRCorner + wR * ${l};\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${p}; wC++) {\n              int xC = xCCorner + wC * ${u};\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              for (int d1 = 0; d1 < ${d}; d1 += 4) {\n                vec4 xValues = vec4(\n                  getX(batch, xF, xR, xC, d1),\n                  getX(batch, xF, xR, xC, d1 + 1),\n                  getX(batch, xF, xR, xC, d1 + 2),\n                  getX(batch, xF, xR, xC, d1 + 3)\n                );\n                vec4 wValues = vec4(\n                  getW(wF, wR, wC, d1, d2),\n                  getW(wF, wR, wC, d1 + 1, d2),\n                  getW(wF, wR, wC, d1 + 2, d2),\n                  getW(wF, wR, wC, d1 + 3, d2)\n                );\n\n                dotProd += dot(xValues, wValues);\n              }\n\n              if (${1===f}) {\n                dotProd +=\n                  getX(batch, xF, xR, xC, ${d}) *\n                  getW(wF, wR, wC, ${d}, d2);\n              } else if (${2===f}) {\n                vec2 xValues = vec2(\n                  getX(batch, xF, xR, xC, ${d}),\n                  getX(batch, xF, xR, xC, ${d} + 1)\n                );\n                vec2 wValues = vec2(\n                  getW(wF, wR, wC, ${d}, d2),\n                  getW(wF, wR, wC, ${d} + 1, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else if (${3===f}) {\n                vec3 xValues = vec3(\n                  getX(batch, xF, xR, xC, ${d}),\n                  getX(batch, xF, xR, xC, ${d} + 1),\n                  getX(batch, xF, xR, xC, ${d} + 2)\n                );\n                vec3 wValues = vec3(\n                  getW(wF, wR, wC, ${d}, d2),\n                  getW(wF, wR, wC, ${d} + 1, d2),\n                  getW(wF, wR, wC, ${d} + 2, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class xA{constructor(e,t=!1,n=null,s=!1,r=!1){this.variableNames=["x","W"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"pads",type:"ivec2"},{name:"strides",type:"ivec2"},{name:"dilations",type:"ivec2"},{name:"inDims",type:"ivec2"}],this.outputShape=e.outShape,this.enableShapeUniforms=z$(this.outputShape.length);const a=e.padInfo.left,i=e.strideWidth,o=e.dilationWidth,l=e.filterHeight,u=e.filterWidth,c=u;let h="\n       int xR; int xC; int xCOffset;\n       vec4 wTexel; vec4 previous; vec4 final;";for(let e=0;e<u;e++)h+=`\n           vec4 xTexelC${2*e};\n           int xTexelC${2*e}Ready;\n           vec4 xTexelC${2*e+1};\n           int xTexelC${2*e+1}Ready;\n           vec4 xC${e};`;h+=`\n     for (int r = 0; r < ${l}; r++) {\n      for (int d1 = 0; d1 < ${e.inChannels}; d1 += 2) {\n       `;for(let e=0;e<u;e++)h+=`\n           xTexelC${2*e} = vec4(0.0);\n           xTexelC${2*e}Ready = 0;\n           xTexelC${2*e+1} = vec4(0.0);\n           xTexelC${2*e+1}Ready = 0;\n           xC${e} = vec4(0.0);`;h+="\n         xR = xRCorner + r * dilations[0];\n         if (xR >=0 && xR < inDims[0]) {\n       ";for(let t=0;t<(c+1)/2;t++){const n=2*t;if(h+=`\n           xC = xCCorner + ${n*o};\n           `,1===i){if(n<u&&(a%2==1?(h+=`\n                 xCOffset = xC + 1;\n                 if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${n}Ready == 0) {\n                   xTexelC${n} = getX(batch, xR, xCOffset, d1);\n\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC${n}.zw = vec2(0.0);\n                   }\n                   xTexelC${n}Ready = 1;\n                 }\n               `,h+=1===o&&n>0?`\n                 xC${n} = vec4(xTexelC${n-2}.zw, xTexelC${n}.xy);\n                 `:`\n                   xCOffset = xC + 1 - 2;\n\n                   if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                     previous = getX(batch, xR, xCOffset, d1);\n\n                     // Need to manually clear unused channels in case\n                     // we're reading from recycled texture.\n                     if (xCOffset + 1 >= inDims[1]) {\n                       previous.zw = vec2(0.0);\n                     }\n\n                     xC${n} = vec4(previous.zw, xTexelC${n}.xy);\n                   } else {\n                     xC${n} = vec4(0.0, 0.0, xTexelC${n}.xy);\n                   }\n                   `):h+=`\n                 if (xC >= 0 && xC < inDims[1] && xTexelC${n}Ready == 0) {\n                   xTexelC${n} = getX(batch, xR, xC, d1);\n                   if (xC + 1 >= inDims[1]) {\n                     xTexelC${n}.zw = vec2(0.0);\n                   }\n                   xTexelC${n}Ready = 1;\n                 }\n\n                 xC${n} = xTexelC${n};\n                 `,n+1<u)){const e=a%2==0?_(o):o;o%2==0&&a%2==1||o%2!=0&&a%2!=1?(h+=`\n                   xCOffset = xC + imod(pads[1], 2) + ${e};\n\n                   if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${n+1}Ready == 0) {\n                     xTexelC${n+1} = getX(batch, xR, xCOffset, d1);\n\n                     // Need to manually clear unused channels in case\n                     // we're reading from recycled texture.\n                     if (xCOffset + 1 >= inDims[1]) {\n                       xTexelC${n+1}.zw = vec2(0.0);\n                     }\n                     xTexelC${n+1}Ready = 1;\n                   }\n                   `,h+=o>1?`\n                     xCOffset -= 2;\n                     if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                      previous = getX(batch, xR, xCOffset, d1);\n                      xC${n+1} = vec4(previous.zw, xTexelC${n+1}.xy);\n                     } else {\n                      xC${n+1} = vec4(0.0, 0.0, xTexelC${n+1}.xy);\n                     }\n                     `:`\n                     xC${n+1} = vec4(xTexelC${n}.zw, xTexelC${n+1}.xy);\n                     `):h+=1===e?`\n                     xC${n+1} = xTexelC${n};\n                     `:`\n                     xCOffset = xC + ${e};\n\n                     if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${n+1}Ready == 0) {\n                       xTexelC${n+1} = getX(batch, xR, xCOffset, d1);\n                       if (xCOffset + 1 >= inDims[1]) {\n                         xTexelC${n+1}.zw = vec2(0.0);\n                       }\n                       xTexelC${n+1}Ready = 1;\n                     }\n\n                     xC${n+1} = xTexelC${n+1};\n                     `}}else n<u&&(a%2==1?(h+=`\n                 xCOffset = xC + 1 - strides[1];\n                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${n}Ready == 0) {\n                   xTexelC${n} = getX(batch, xR, xCOffset, d1);\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC${n}.zw = vec2(0.0);\n                   }\n                   xTexelC${n}Ready = 1;\n                 }\n\n                 if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${n+1}Ready == 0) {\n                   xTexelC${n+1} = getX(batch, xR, xC + 1, d1);\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xC + 2 >= inDims[1]) {\n                     xTexelC${n+1}.zw = vec2(0.0);\n                   }\n                   xTexelC${n+1}Ready = 1;\n                 }\n\n                 xC${n} = vec4(xTexelC${n}.zw, xTexelC${n+1}.zw);\n               `,n+1<u&&(h+=`\n                   final = vec4(0.0);\n                   xCOffset = xC + 1 + strides[1];\n                   if(xCOffset >= 0 && xCOffset < inDims[1]) {\n                     final = getX(batch, xR, xCOffset, d1);\n                   }\n                   xC${n+1} = vec4(xTexelC${n+1}.xy, final.xy);\n                 `)):(h+=`\n                 if(xC >= 0 && xC < inDims[1] && xTexelC${n}Ready == 0) {\n                   xTexelC${n} = getX(batch, xR, xC, d1);\n                   if (xC + 1 >= inDims[1]) {\n                     xTexelC${n}.zw = vec2(0.0);\n                   }\n                   xTexelC${n}Ready = 1;\n                 }\n\n                 xCOffset = xC + strides[1];\n                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${n+1}Ready == 0) {\n                   xTexelC${n+1} = getX(batch, xR, xCOffset, d1);\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC${n+1}.zw = vec2(0.);\n                   }\n                   xTexelC${n+1}Ready = 1;\n                 }\n\n                 xC${n} = vec4(\n                   xTexelC${n}.xy, xTexelC${n+1}.xy);\n               `,n+1<u&&(h+=`\n                   xC${n+1} = vec4(xTexelC${n}.zw, xTexelC${n+1}.zw);\n                 `)));n<u&&(h+=`\n             wTexel = getW(r, ${n}, d1, d2);\n             dotProd += xC${n}.xxzz * vec4(wTexel.xy, wTexel.xy);\n             if(d1 + 1 < ${e.inChannels}) {\n               dotProd += xC${n}.yyww * vec4(wTexel.zw, wTexel.zw);\n             }\n           `,n+1<u&&(h+=`\n               wTexel = getW(r, ${n+1}, d1, d2);\n               dotProd += xC${n+1}.xxzz * vec4(wTexel.xy, wTexel.xy);\n               if(d1 + 1 < ${e.inChannels}) {\n                 dotProd += xC${n+1}.yyww * vec4(wTexel.zw, wTexel.zw);\n               }\n             `))}h+="\n     }\n   ",h+="\n     }\n   ",h+="\n     }\n   ";let p="",d="";n&&(p=s?`vec4 activation(vec4 a) {\n           vec4 b = getPreluActivationWeightsAtOutCoords();\n           ${n}\n         }`:r?`vec4 activation(vec4 a) {\n           vec4 b = getLeakyreluAlphaAtOutCoords();\n           ${n}\n         }`:`vec4 activation(vec4 x) {\n           ${n}\n         }`,d="result = activation(result);");const f=t?"result += getBiasAtOutCoords();":"";t&&this.variableNames.push("bias"),s&&this.variableNames.push("preluActivationWeights"),r&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n       ${p}\n\n       void main() {\n         ivec4 coords = getOutputCoords();\n         int batch = coords.x;\n         ivec2 xRCCorner = coords.yz * strides - pads;\n         int d2 = coords.w;\n         int xRCorner = xRCCorner.x;\n         int xCCorner = xRCCorner.y;\n\n         //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n         vec4 dotProd = vec4(0.000000000000001);\n\n         ${h}\n\n         vec4 result = dotProd - vec4(0.000000000000001);\n         ${f}\n         ${d}\n         setOutput(result);\n       }\n     `}}class wA{constructor(e,t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"inputShape",type:"ivec4"},{name:"pad",type:"ivec2"},{name:"stride",type:"ivec2"},{name:"dilation",type:"ivec2"},{name:"inChannels",type:"int"},{name:"itemsPerBlockRow",type:"int"},{name:"outWidth",type:"int"}],this.outputShape=e,this.enableShapeUniforms=z$(this.outputShape.length);const{dataFormat:n}=t,s=y$(),r="channelsLast"===n,a=r?1:2,i=r?2:3,o=this.enableShapeUniforms?"if(blockIndex < outShape[2] && pos < outShape[1]) {":`if(blockIndex < ${e[2]} && pos < ${e[1]}) {`;let l="";for(let e=0;e<=1;e++)for(let t=0;t<=1;t++)l+=`\n          blockIndex = rc.z + ${t};\n          pos = rc.y + ${e};\n\n          ${o}\n            offsetY = int(blockIndex / outWidth) * stride[0] - pad[0];\n            d0 = offsetY + dilation[0] * (pos / itemsPerBlockRow);\n\n            if(d0 < inputShape[${a}] && d0 >= 0) {\n              // Use custom imod instead mod. On Intel GPU, mod may generate\n              // unexpected value.\n              // https://github.com/tensorflow/tfjs/issues/5447\n              offsetX = imod(blockIndex, outWidth) * stride[1] - pad[1];\n              d1 = offsetX + dilation[1] * (imod(pos, itemsPerBlockRow) /\n                  inChannels);\n\n              if(d1 < inputShape[${i}] && d1 >= 0) {\n\n                ch = imod(pos, inChannels);\n\n                if (${r}) {\n                  innerDims = vec2(d1, ch);\n                  result[${2*e+t}] = getChannel(\n                    getA(rc.x, d0, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                } else {\n                  innerDims = vec2(d0, d1);\n                  result[${2*e+t}] = getChannel(\n                    getA(rc.x, ch, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                }\n              }\n            }\n          }\n        `;this.userCode=`\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0);\n\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\n        vec2 innerDims;\n\n        ${l}\n\n        ${s.output} = result;\n      }\n    `}}function kA(e,t){const n=e.length;return n>=3?t?[...e.slice(0,-3),e[n-3]*e[n-2],e[n-1]]:[...e.slice(0,-3),e[n-3],e[n-2]*e[n-1]]:!t&&1===n&&e[0]>1?[e[0],1]:null}function vA({x:e,filter:t,convInfo:n,backend:s,bias:r=null,preluActivationWeights:a=null,leakyreluAlpha:i=0,activation:o=null}){const l=e.shape,u=s.texData.get(e.dataId),c=n.inChannels,h=l[0]*l[1]*l[2],p=n.outChannels,d="channelsLast"===n.dataFormat,f=!1;let m;const g=[];if(null!=a){const e=kA(a.shape,d);null!=e&&(a=LC({inputs:{x:a},backend:s,attrs:{shape:e}}),g.push(a))}if(null!=r){const e=kA(r.shape,d);null!=e&&(r=LC({inputs:{x:r},backend:s,attrs:{shape:e}}),g.push(r))}if((1!==h&&1!==p||!(c>1e3))&&u.isPacked&&d&&null!=u.texture&&l[2]%2!=0&&z(u.shape.slice(-3),l.slice(-3))){const c=l[0]*l[1]*(l[2]+1),h={dataId:e.dataId,shape:[1,c,n.inChannels],dtype:e.dtype},p=u.shape;u.shape=u.shape.slice(),u.shape[u.shape.length-2]++,F(u$(u.shape,h.shape),(()=>`packed reshape ${u.shape} to ${h.shape} isn't free`));const d=LC({inputs:{x:t},backend:s,attrs:{shape:[1,n.inChannels,n.outChannels]}});g.push(d);const y=XC({a:h,b:d,backend:s,transposeA:!1,transposeB:f,bias:r,activation:o,preluActivationWeights:a,leakyreluAlpha:i}),b=s.texData.get(y.dataId);F(b.isPacked,(()=>"batchMatMul result is expected to be packed")),u.shape=p,b.shape=n.outShape,m=bC({inputs:{x:y},backend:s}),m.shape=n.outShape,g.push(y)}else{const l=n.outHeight*n.outWidth,u=LC({inputs:{x:e},backend:s,attrs:{shape:d?[n.batchSize,l,n.inChannels]:[n.batchSize,n.inChannels,l]}}),c=LC({inputs:{x:t},backend:s,attrs:{shape:[1,n.inChannels,n.outChannels]}}),h=XC({a:d?u:c,b:d?c:u,transposeA:!d,transposeB:f,backend:s,bias:r,activation:o,preluActivationWeights:a,leakyreluAlpha:i});m=LC({inputs:{x:h},backend:s,attrs:{shape:n.outShape}}),g.push(u),g.push(c),g.push(h)}for(const e of g)s.disposeIntermediateTensorInfo(e);return m}function IA({x:e,filter:t,convInfo:n,backend:s,bias:r=null,preluActivationWeights:a=null,leakyreluAlpha:i=0,activation:o=null}){const{filterWidth:l,filterHeight:u,inChannels:c,outWidth:h,outHeight:p,dataFormat:d}=n,f="channelsLast"===d,m=l*u*c,g=p*h,y=[n.batchSize,m,g],b=[];if(null!=a){const e=kA(a.shape,f);null!=e&&(a=LC({inputs:{x:a},backend:s,attrs:{shape:e}}),b.push(a))}if(null!=r){const e=kA(r.shape,f);null!=e&&(r=LC({inputs:{x:r},backend:s,attrs:{shape:e}}),b.push(r))}const x=LC({inputs:{x:t},backend:s,attrs:{shape:[1,m,L(t.shape)/m]}});b.push(x);const w=new wA(y,n),k=[e.shape,[n.padInfo.top,n.padInfo.left],[n.strideHeight,n.strideWidth],[n.dilationHeight,n.dilationWidth],[n.inChannels],[n.filterWidth*n.inChannels],[n.outWidth]],v=s.runWebGLProgram(w,[e],"float32",k),I=LC({inputs:{x:v},backend:s,attrs:{shape:y}});b.push(v),b.push(I);const N=null!=r,S=null!=a,T="leakyrelu"===o,$=o?AC(o,!0):null,E=new _C(f?I.shape:x.shape,f?x.shape:I.shape,f?[n.batchSize,g,n.outChannels]:[n.batchSize,n.outChannels,g],!0,!1,N,$,S,T),C=f?[I,x]:[x,I];if(r&&C.push(r),S&&C.push(a),T){const e=s.makeTensorInfo([],"float32",tr(i,"float32"));C.push(e),b.push(e)}const R=s.runWebGLProgram(E,C,"float32"),A=LC({inputs:{x:R},backend:s,attrs:{shape:n.outShape}});b.push(R);for(const e of b)s.disposeIntermediateTensorInfo(e);return A}const NA={kernelName:qe,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,filter:a}=t,{strides:i,pad:o,dataFormat:l,dilations:u,dimRoundingMode:c}=s,h=po(l),p=no(r.shape,a.shape,i,u,o,c,!1,h);let d;if(1!==p.filterHeight||1!==p.filterWidth||1!==p.dilationHeight||1!==p.dilationWidth||1!==p.strideHeight||1!==p.strideWidth||"SAME"!==p.padInfo.type&&"VALID"!==p.padInfo.type)if(p.strideWidth<=2&&"channelsLast"===h&&fe().getBool("WEBGL_EXP_CONV")){const e=new xA(p),t=[[p.padInfo.top,p.padInfo.left],[p.strideHeight,p.strideWidth],[p.dilationHeight,p.dilationWidth],[p.inHeight,p.inWidth]];d=n.runWebGLProgram(e,[r,a],"float32",t)}else if(fe().getBool("WEBGL_CONV_IM2COL"))d=IA({x:r,filter:a,convInfo:p,backend:n});else{const e=new yA(p);d=n.runWebGLProgram(e,[r,a],"float32")}else d=vA({x:r,filter:a,convInfo:p,backend:n});const f=LC({inputs:{x:d},backend:n,attrs:{shape:p.outShape}});return n.disposeIntermediateTensorInfo(d),f}};class SA{constructor(e){this.variableNames=["x","dy"],this.outputShape=e.filterShape;const t=e.strideHeight,n=e.strideWidth,s=e.padInfo.top,r=e.padInfo.left,a="channelsLast"===e.dataFormat;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int d2 = coords.w;\n\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${e.batchSize}; b++) {\n          for (int yR = 0; yR < ${e.outHeight}; yR++) {\n            int xR = wR + yR * ${t} - ${s};\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${e.outWidth}; yC++) {\n              int xC = wC + yC * ${n} - ${r};\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              ${a?"float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);":"float dyValue = getDy(b, d2, yR, yC);\n              float xValue = getX(b, d1, xR, xC);\n              dotProd += (xValue * dyValue);"}\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class TA{constructor(e){this.variableNames=["dy","W"],this.outputShape=e.inShape;const t=e.filterHeight,n=e.filterWidth,s=e.strideHeight,r=e.strideWidth,a="channelsLast"===e.dataFormat,i=t-1-e.padInfo.top,o=n-1-e.padInfo.left,l=a?1:2,u=a?2:3,c=a?3:1;this.userCode=`\n      const ivec2 pads = ivec2(${i}, ${o});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[${c}];\n\n        ivec2 dyCorner = ivec2(coords[${l}], coords[${u}]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${t}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${s}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${t} - 1 - wR;\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${r}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${n} - 1 - wC;\n\n            for (int d2 = 0; d2 < ${e.outChannels}; d2++) {\n\n              if (${a}) {\n                float xValue = getDy(batch, idyR, idyC, d2);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              } else {\n                float xValue = getDy(batch, d2, idyR, idyC);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class $A{constructor(e){this.variableNames=["x","dy"],this.outputShape=e.filterShape;const t=e.strideDepth,n=e.strideHeight,s=e.strideWidth,r=e.padInfo.front,a=e.padInfo.top,i=e.padInfo.left;this.userCode=`\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int wF = coords.x;\n        int wR = coords.y;\n        int wC = coords.z;\n        int d1 = coords.w;\n        int d2 = coords.u;\n\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${e.batchSize}; b++) {\n          for (int yF = 0; yF < ${e.outDepth}; yF++) {\n            int xF = wF + yF * ${t} - ${r};\n\n            if (xF < 0 || xF >= ${e.inDepth}) {\n              continue;\n            }\n\n            for (int yR = 0; yR < ${e.outHeight}; yR++) {\n              int xR = wR + yR * ${n} - ${a};\n\n              if (xR < 0 || xR >= ${e.inHeight}) {\n                continue;\n              }\n\n              for (int yC = 0; yC < ${e.outWidth}; yC++) {\n                int xC = wC + yC * ${s} - ${i};\n\n                if (xC < 0 || xC >= ${e.inWidth}) {\n                  continue;\n                }\n\n                float dyValue = getDy(b, yF, yR, yC, d2);\n                float xValue = getX(b, xF, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class EA{constructor(e){this.variableNames=["dy","W"],this.outputShape=e.inShape;const t=e.filterDepth,n=e.filterHeight,s=e.filterWidth,r=e.strideDepth,a=e.strideHeight,i=e.strideWidth,o=t-1-e.padInfo.front,l=n-1-e.padInfo.top,u=s-1-e.padInfo.left;this.userCode=`\n      const ivec3 pads = ivec3(${o}, ${l}, ${u});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.u;\n\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyFCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${t}; wF++) {\n          float dyF = float(dyFCorner + wF) / ${r}.0;\n\n          if (dyF < 0.0 || dyF >= ${e.outDepth}.0 || fract(dyF) > 0.0) {\n            continue;\n          }\n          int idyF = int(dyF);\n\n          int wFPerm = ${t} - 1 - wF;\n\n          for (int wR = 0; wR < ${n}; wR++) {\n            float dyR = float(dyRCorner + wR) / ${a}.0;\n\n            if (dyR < 0.0 || dyR >= ${e.outHeight}.0 ||\n              fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            int wRPerm = ${n} - 1 - wR;\n\n            for (int wC = 0; wC < ${s}; wC++) {\n              float dyC = float(dyCCorner + wC) / ${i}.0;\n\n              if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              int wCPerm = ${s} - 1 - wC;\n\n              for (int d2 = 0; d2 < ${e.outChannels}; d2++) {\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}const CA={kernelName:Xe,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,dy:a}=t,{strides:i,pad:o,dataFormat:l,dimRoundingMode:u,filterShape:c}=s,h=po(l),p=no(r.shape,c,i,1,o,u,!1,h),d=new SA(p);return n.runWebGLProgram(d,[r,a],"float32")}};class RA{constructor(e){this.variableNames=["dy","W"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"strides",type:"vec2"}],this.outputShape=e.inShape,this.enableShapeUniforms=z$(this.outputShape.length);const t=e.filterHeight,n=e.filterWidth,s=t-1-e.padInfo.top,r=n-1-e.padInfo.left;this.userCode=`\n      const ivec2 pads = ivec2(${s}, ${r});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n\n        ivec2 dyCorner = ivec2(coords[1], coords[2]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        vec4 result = vec4(0.);\n        for (int wR = 0; wR < ${t}; wR++) {\n          float dyR = float(dyRCorner + wR) / strides[0];\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n          int wRPerm = ${t} - 1 - wR;\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            int wCPerm = ${n} - 1 - wC;\n\n            float dyC = float(dyCCorner + wC) / strides[1];\n            bool idyCVal = (dyC >= 0.0) && (dyC < ${e.outWidth}.0)\n              && (fract(dyC) == 0.0);\n            int idyC = int(dyC);\n\n            float dyC2 = float(dyCCorner + wC + 1) / strides[1];\n            bool idyCVal2 = (dyC2 >= 0.0) && (dyC2 < ${e.outWidth}.0)\n              && (fract(dyC2) == 0.0);\n            int idyC2 = int(dyC2);\n\n            if (idyCVal && idyCVal2) {\n              for (int d2 = 0; d2 < ${e.outChannels}; d2 += 2) {\n                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);\n                vec4 dySample = getDy(batch, idyR, idyC, d2);\n                vec4 dySample2 = (idyC / 2 == idyC2 / 2) ?\n                  dySample : getDy(batch, idyR, idyC2, d2);\n\n                vec2 dyValue = mod(float(idyC), 2.) == 0. ?\n                  dySample.xy : dySample.zw;\n                result.xy += vec2(dot(dyValue, wValue.xy),\n                  dot(dyValue, wValue.zw));\n\n                dyValue = mod(float(idyC2), 2.) == 0. ?\n                  dySample2.xy : dySample2.zw;\n                result.zw += vec2(dot(dyValue, wValue.xy),\n                  dot(dyValue, wValue.zw));\n              }\n            } else if (idyCVal) {\n              for (int d2 = 0; d2 < ${e.outChannels}; d2 += 2) {\n                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);\n                vec4 dySample = getDy(batch, idyR, idyC, d2);\n                vec2 dyValue = mod(float(idyC), 2.) == 0. ?\n                  dySample.xy : dySample.zw;\n                result.xy += vec2(dot(dyValue, wValue.xy),\n                  dot(dyValue, wValue.zw));\n              }\n            } else if (idyCVal2) {\n              for (int d2 = 0; d2 < ${e.outChannels}; d2 += 2) {\n                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);\n                vec4 dySample = getDy(batch, idyR, idyC2, d2);\n                vec2 dyValue = mod(float(idyC2), 2.) == 0. ?\n                  dySample.xy : dySample.zw;\n                result.zw += vec2(dot(dyValue, wValue.xy),\n                  dot(dyValue, wValue.zw));\n              }\n            }\n          }\n        }\n        setOutput(result);\n      }\n    `}}const AA={kernelName:Ye,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,filter:a}=t,{inputShape:i,strides:o,pad:l,dataFormat:u,dimRoundingMode:c}=s,h=po(u),p=no(i,a.shape,o,1,l,c,!1,h);if(fe().getBool("WEBGL_PACK_CONV2DTRANSPOSE")&&"channelsLast"===h){const e=[[p.strideHeight,p.strideWidth]],t=new RA(p);return n.runWebGLProgram(t,[r,a],"float32",e)}{const e=new TA(p);return n.runWebGLProgram(e,[r,a],"float32")}}},_A={kernelName:Je,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,filter:a}=t,{strides:i,pad:o,dilations:l}=s,u=so(r.shape,a.shape,i,l,o),c=new bA(u);return n.runWebGLProgram(c,[r,a],"float32")}},DA={kernelName:Ze,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,dy:a}=t,{strides:i,pad:o,filterShape:l}=s,u=so(r.shape,l,i,1,o),c=new $A(u);return n.runWebGLProgram(c,[r,a],"float32")}},FA={kernelName:Qe,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,filter:a}=t,{pad:i,strides:o,inputShape:l}=s,u=so(l,a.shape,o,1,i),c=new EA(u);return n.runWebGLProgram(c,[r,a],"float32")}},OA=CC({opSnippet:EC+"\n  return cos(x);\n",packedOpSnippet:`\n  vec4 result = cos(x);\n  bvec4 isNaN = isnan(x);\n  ${gC}\n  return result;\n`}),MA={kernelName:et,backendName:"webgl",kernelFunc:OA},LA=CC({opSnippet:"\n  float e2x = exp(-x);\n  return (e2x + 1.0 / e2x) / 2.0;\n"}),zA={kernelName:tt,backendName:"webgl",kernelFunc:LA};class BA{constructor(e,t,n,s,r){this.variableNames=["Image","Boxes","BoxInd"],this.outputShape=[];const[a,i,o,l]=e,[u]=t,[c,h]=n;this.outputShape=[u,c,h,l];const p="bilinear"===s?1:0,[d,f]=[i-1+".0",o-1+".0"],[m,g,y]=c>1?[""+(i-1)/(c-1),"(y2-y1) * height_ratio",`y1*${d} + float(y)*(height_scale)`]:["0.0","0.0",`0.5 * (y1+y2) * ${d}`],[b,x,w]=h>1?[""+(o-1)/(h-1),"(x2-x1) * width_ratio",`x1*${f} + float(x)*(width_scale)`]:["0.0","0.0",`0.5 * (x1+x2) * ${f}`];this.userCode=`\n      const float height_ratio = float(${m});\n      const float width_ratio = float(${b});\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int y = coords[1];\n        int x = coords[2];\n        int d = coords[3];\n\n        // get box vals\n        float y1 = getBoxes(b,0);\n        float x1 = getBoxes(b,1);\n        float y2 = getBoxes(b,2);\n        float x2 = getBoxes(b,3);\n\n        // get image in batch index\n        int bInd = round(getBoxInd(b));\n        if(bInd < 0 || bInd >= ${a}) {\n          return;\n        }\n\n        float height_scale = ${g};\n        float width_scale = ${x};\n\n        float in_y = ${y};\n        if( in_y < 0.0 || in_y > ${d} ) {\n          setOutput(float(${r}));\n          return;\n        }\n        float in_x = ${w};\n        if( in_x < 0.0 || in_x > ${f} ) {\n          setOutput(float(${r}));\n          return;\n        }\n\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\n        if(${p} == 1) {\n          // Compute the four integer indices.\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\n\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\n\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\n\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          float newValue = top + (bottom - top) * fracCR.y;\n          setOutput(newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          ivec2 sourceNearestCR = ivec2(floor(\n            sourceFracIndexCR + vec2(0.5,0.5)));\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutput(newValue);\n        }\n      }\n    `}}const PA={kernelName:rt,backendName:"webgl",kernelFunc:e=>{const{inputs:t,backend:n,attrs:s}=e,{image:r,boxes:a,boxInd:i}=t,{cropSize:o,method:l,extrapolationValue:u}=s,c=new BA(r.shape,a.shape,o,l,u);return n.runWebGLProgram(c,[r,a,i],"float32")}};var WA;!function(e){e.Prod="*",e.Sum="+"}(WA||(WA={}));class VA{constructor(e,t,n,s){this.op=e,this.outputShape=t,this.variableNames=["x"],this.customUniforms=[{name:"index",type:"float"}];const r=this.outputShape.length,a=this.op===WA.Prod?"1.0":"0.0",i=n?a:`getX(${UA(r,"coords",this.op)})`,o=this.outputShape[this.outputShape.length-1];let l="",u="";n?(l=s?"end != "+(o-1):"end != 0",u=s?"end + 1":"end - 1"):(l=s?`end + pow2 < ${o}`:"end >= pow2",u=s?"end + pow2":"end - pow2"),this.userCode=`\n      void main() {\n        ${_$(r)} coords = getOutputCoords();\n        int end = ${GA(r,"coords",this.op)};\n        float val = ${i};\n        int pow2 = int(pow(2.0, index));\n        if (${l}) {\n          int idx = ${u};\n          ${GA(r,"coords",this.op)} = idx;\n          val ${this.op}= getX(${UA(r,"coords",this.op)});\n        }\n        setOutput(val);\n      }\n    `}}function UA(e,t,n){if(1===e)return`${t}`;if(2===e)return`${t}.x, ${t}.y`;if(3===e)return`${t}.x, ${t}.y, ${t}.z`;if(4===e)return`${t}.x, ${t}.y, ${t}.z, ${t}.w`;throw new Error(`Cumulative ${n} for rank ${e} is not yet supported`)}function GA(e,t,n){if(1===e)return`${t}`;if(2===e)return`${t}.y`;if(3===e)return`${t}.z`;if(4===e)return`${t}.w`;throw new Error(`Cumulative ${n} for rank ${e} is not yet supported`)}function HA(e,t,n,s,r,a){const i=t.shape.length,o=il([s],i);let l=t;null!=o&&(l=KC({inputs:{x:t},backend:n,attrs:{perm:o}}));const u=ll(1,i)[0];if(u!==i-1)throw new Error(`WebGL cumprod shader expects an inner-most axis=${t.shape.length-1} but got axis=${s}`);const c=l.shape[u];let h=bC({inputs:{x:l},backend:n});for(let t=0;t<=Math.ceil(Math.log2(c))-1;t++){const s=new VA(e,l.shape,!1,a),r=[[t]],i=h;h=n.runWebGLProgram(s,[h],h.dtype,r),n.disposeIntermediateTensorInfo(i)}if(r){const t=new VA(e,l.shape,r,a),s=h;h=n.runWebGLProgram(t,[h],h.dtype),n.disposeIntermediateTensorInfo(s)}if(null!=o){const e=KC({inputs:{x:h},backend:n,attrs:{perm:ol(o)}});return n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(l),e}return h}const jA={kernelName:nt,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,exclusive:i,reverse:o}=s;return HA(WA.Prod,r,n,a,i,o)}},KA={kernelName:st,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,exclusive:i,reverse:o}=s;return HA(WA.Sum,r,n,a,i,o)}},qA={kernelName:at,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,weights:a}=t,{size:i,binaryOutput:o}=s;if(1===r.shape.length){const e=n.readSync(r.dataId),t=n.readSync(a.dataId),s=eE(e,t,a.dtype,a.shape,i);return n.makeTensorInfo([i],a.dtype,s)}if(2===r.shape.length){const e=n.bufferSync(r),t=n.bufferSync(a),s=tE(e,t,i,o);return n.makeTensorInfo(s.shape,a.dtype,s.values)}throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${r.shape.length}.`)}};class XA{constructor(e,t,n){this.variableNames=["x"],this.outputShape=[],this.outputShape=e,this.blockSize=t,this.dataFormat=n,this.userCode=`\n    void main() {\n      ivec4 coords = getOutputCoords();\n      int b = coords[0];\n      int h = ${this.getHeightCoordString()};\n      int w = ${this.getWidthCoordString()};\n      int d = ${this.getDepthCoordString()};\n\n      int in_h = h / ${t};\n      int offset_h = imod(h, ${t});\n      int in_w = w / ${t};\n      int offset_w = imod(w, ${t});\n      int offset_d = (offset_h * ${t} + offset_w) *\n        ${this.getOutputDepthSize()};\n      int in_d = d + offset_d;\n\n      float result = ${this.getInputSamplingString()};\n      setOutput(result);\n    }\n  `}getHeightCoordString(){return"NHWC"===this.dataFormat?"coords[1]":"coords[2]"}getWidthCoordString(){return"NHWC"===this.dataFormat?"coords[2]":"coords[3]"}getDepthCoordString(){return"NHWC"===this.dataFormat?"coords[3]":"coords[1]"}getOutputDepthSize(){return"NHWC"===this.dataFormat?this.outputShape[3]:this.outputShape[1]}getInputSamplingString(){return"NHWC"===this.dataFormat?"getX(b, in_h, in_w, in_d)":"getX(b, in_d, in_h, in_w)"}}const YA={kernelName:it,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{blockSize:a,dataFormat:i}=s,o=r.shape[0],l=("NHWC"===i?r.shape[1]:r.shape[2])*a,u=("NHWC"===i?r.shape[2]:r.shape[3])*a,c=("NHWC"===i?r.shape[3]:r.shape[1])/(a*a),h=new XA("NHWC"===i?[o,l,u,c]:[o,c,l,u],a,i);return n.runWebGLProgram(h,[r],r.dtype)}};class JA{constructor(e,t=!1,n=null,s=!1,r=!1){this.variableNames=["x","W"],this.customUniforms=[{name:"pads",type:"ivec2"},{name:"strides",type:"ivec2"},{name:"dilations",type:"ivec2"},{name:"inDims",type:"ivec2"}],this.outputShape=e.outShape,this.enableShapeUniforms=z$(this.outputShape.length);const a=e.filterHeight,i=e.filterWidth,o=e.outChannels/e.inChannels;let l="",u="";n&&(l=s?`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:r?`float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ${n}\n        }`:`\n          float activation(float x) {\n            ${n}\n          }\n        `,u="result = activation(result);");const c=t?"result += getBiasAtOutCoords();":"";t&&this.variableNames.push("bias"),s&&this.variableNames.push("preluActivationWeights"),r&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n      ${l}\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${o};\n        int q = d2 - d1 * ${o};\n\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\n        for (int wR = 0; wR < ${a}; wR++) {\n          int xR = xRCorner + wR * dilations[0];\n\n          if (xR < 0 || xR >= inDims[0]) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${i}; wC++) {\n            int xC = xCCorner + wC * dilations[1];\n\n            if (xC < 0 || xC >= inDims[1]) {\n              continue;\n            }\n\n            float xVal = getX(batch, xR, xC, d1);\n            float wVal = getW(wR, wC, d1, q);\n            dotProd += xVal * wVal;\n          }\n        }\n\n        float result = dotProd;\n        ${c}\n        ${u}\n        setOutput(result);\n      }\n    `}}class ZA{constructor(e,t=!1,n=null,s=!1,r=!1){this.variableNames=["x","W"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"pads",type:"ivec2"},{name:"strides",type:"ivec2"},{name:"dilations",type:"ivec2"},{name:"inDims",type:"ivec2"}],this.outputShape=e.outShape,this.enableShapeUniforms=z$(this.outputShape.length);const a=e.outChannels/e.inChannels,i=e.padInfo.left,o=e.strideWidth,l=e.dilationWidth,u=e.filterHeight,c=e.filterWidth,h=c;let p="\n      int xR; int xC; int xCOffset;\n      vec4 wTexel; vec4 previous; vec4 final;";for(let e=0;e<c;e++)p+=`\n          vec4 xTexelC${2*e};\n          int xTexelC${2*e}Ready;\n          vec4 xTexelC${2*e+1};\n          int xTexelC${2*e+1}Ready;\n          vec4 xC${e};`;p+=`\n    for (int r = 0; r < ${u}; r++) {\n      `;for(let e=0;e<c;e++)p+=`\n          xTexelC${2*e} = vec4(0.0);\n          xTexelC${2*e}Ready = 0;\n          xTexelC${2*e+1} = vec4(0.0);\n          xTexelC${2*e+1}Ready = 0;\n          xC${e} = vec4(0.0);`;p+="\n        xR = xRCorner + r * dilations[0];\n        if (xR >=0 && xR < inDims[0]) {\n      ";for(let e=0;e<(h+1)/2;e++){const t=2*e;if(p+=`\n          xC = xCCorner + ${t*l};\n          `,1===o){if(t<c&&(i%2==1?(p+=`\n                xCOffset = xC + 1;\n                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${t}Ready == 0) {\n                  xTexelC${t} = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${t}.zw = vec2(0.0);\n                  }\n                  xTexelC${t}Ready = 1;\n                }\n              `,p+=1===l&&t>0?`\n                xC${t} = vec4(xTexelC${t-2}.zw, xTexelC${t}.xy);\n                `:`\n                  xCOffset = xC + 1 - 2;\n\n                  if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                    previous = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= inDims[1]) {\n                      previous.zw = vec2(0.0);\n                    }\n\n                    xC${t} = vec4(previous.zw, xTexelC${t}.xy);\n                  } else {\n                    xC${t} = vec4(0.0, 0.0, xTexelC${t}.xy);\n                  }\n                  `):p+=`\n                if (xC >= 0 && xC < inDims[1] && xTexelC${t}Ready == 0) {\n                  xTexelC${t} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= inDims[1]) {\n                    xTexelC${t}.zw = vec2(0.0);\n                  }\n                  xTexelC${t}Ready = 1;\n                }\n\n                xC${t} = xTexelC${t};\n                `,t+1<c)){const e=i%2==0?_(l):l;l%2==0&&i%2==1||l%2!=0&&i%2!=1?(p+=`\n                  xCOffset = xC + imod(pads[1], 2) + ${e};\n\n                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${t+1}Ready == 0) {\n                    xTexelC${t+1} = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= inDims[1]) {\n                      xTexelC${t+1}.zw = vec2(0.0);\n                    }\n                    xTexelC${t+1}Ready = 1;\n                  }\n                  `,p+=l>1?`\n                    xCOffset -= 2;\n                    if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                     previous = getX(batch, xR, xCOffset, d1);\n                     xC${t+1} = vec4(previous.zw, xTexelC${t+1}.xy);\n                    } else {\n                     xC${t+1} = vec4(0.0, 0.0, xTexelC${t+1}.xy);\n                    }\n                    `:`\n                    xC${t+1} = vec4(xTexelC${t}.zw, xTexelC${t+1}.xy);\n                    `):p+=1===e?`\n                    xC${t+1} = xTexelC${t};\n                    `:`\n                    xCOffset = xC + ${e};\n\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${t+1}Ready == 0) {\n                      xTexelC${t+1} = getX(batch, xR, xCOffset, d1);\n                      if (xCOffset + 1 >= inDims[1]) {\n                        xTexelC${t+1}.zw = vec2(0.0);\n                      }\n                      xTexelC${t+1}Ready = 1;\n                    }\n\n                    xC${t+1} = xTexelC${t+1};\n                    `}}else t<c&&(i%2==1?(p+=`\n                xCOffset = xC + 1 - strides[1];\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${t}Ready == 0) {\n                  xTexelC${t} = getX(batch, xR, xCOffset, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${t}.zw = vec2(0.0);\n                  }\n                  xTexelC${t}Ready = 1;\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${t+1}Ready == 0) {\n                  xTexelC${t+1} = getX(batch, xR, xC + 1, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xC + 2 >= inDims[1]) {\n                    xTexelC${t+1}.zw = vec2(0.0);\n                  }\n                  xTexelC${t+1}Ready = 1;\n                }\n\n                xC${t} = vec4(xTexelC${t}.zw, xTexelC${t+1}.zw);\n              `,t+1<c&&(p+=`\n                  final = vec4(0.0);\n                  xCOffset = xC + 1 + strides[1];\n                  if(xCOffset >= 0 && xCOffset < inDims[1]) {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xC${t+1} = vec4(xTexelC${t+1}.xy, final.xy);\n                `)):(p+=`\n                if(xC >= 0 && xC < inDims[1] && xTexelC${t}Ready == 0) {\n                  xTexelC${t} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= inDims[1]) {\n                    xTexelC${t}.zw = vec2(0.0);\n                  }\n                  xTexelC${t}Ready = 1;\n                }\n\n                xCOffset = xC + strides[1];\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${t+1}Ready == 0) {\n                  xTexelC${t+1} = getX(batch, xR, xCOffset, d1);\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC${t+1}.zw = vec2(0.);\n                  }\n                  xTexelC${t+1}Ready = 1;\n                }\n\n                xC${t} = vec4(\n                  xTexelC${t}.xy, xTexelC${t+1}.xy);\n              `,t+1<c&&(p+=`\n                  xC${t+1} = vec4(xTexelC${t}.zw, xTexelC${t+1}.zw);\n                `)));t<c&&(p+=`\n            wTexel = getW(r, ${t}, d1, q);\n            dotProd += xC${t} * vec4(wTexel.xz, wTexel.xz);\n          `,t+1<c&&(p+=`\n              wTexel = getW(r, ${t+1}, d1, q);\n              dotProd += xC${t+1} * vec4(wTexel.xz, wTexel.xz);\n            `))}p+="\n    }\n  ",p+="\n      }\n    ";let d="",f="";n&&(d=s?`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:r?`vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${n}\n        }`:`vec4 activation(vec4 x) {\n          ${n}\n        }`,f="result = activation(result);");const m=t?"result += getBiasAtOutCoords();":"";t&&this.variableNames.push("bias"),s&&this.variableNames.push("preluActivationWeights"),r&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n      ${d}\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${a};\n        int q = d2 - d1 * ${a};\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n        vec4 dotProd = vec4(0.000000000000001);\n\n        ${p}\n\n        vec4 result = dotProd - vec4(0.000000000000001);\n        ${m}\n        ${f}\n        setOutput(result);\n      }\n    `}}const QA={kernelName:ot,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,filter:a}=t,{strides:i,pad:o,dilations:l,dimRoundingMode:u}=s;let c=l;null==c&&(c=[1,1]),F(co(i,c),(()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${i} and dilations '${c}'`));const h=no(r.shape,a.shape,i,c,o,u,!0);let p;p=fe().getBool("WEBGL_PACK_DEPTHWISECONV")&&h.strideWidth<=2&&h.outChannels/h.inChannels==1?new ZA(h):new JA(h);const d=[[h.padInfo.top,h.padInfo.left],[h.strideHeight,h.strideWidth],[h.dilationHeight,h.dilationWidth],[h.inHeight,h.inWidth]];return n.runWebGLProgram(p,[r,a],"float32",d)}};class e_{constructor(e){this.variableNames=["x","dy"],this.outputShape=e.filterShape;const t=e.strideHeight,n=e.strideWidth,s=e.padInfo.top,r=e.padInfo.left,a=e.outChannels/e.inChannels;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int dm = coords.w;\n        int d2 = d1 * ${a} + dm;\n\n        float dotProd = 0.0;\n\n        // TO DO: Vec4 over the batch size\n        for (int b = 0; b < ${e.batchSize}; b++) {\n          for (int yR = 0; yR < ${e.outHeight}; yR++) {\n            int xR = wR + yR * ${t} - ${s};\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${e.outWidth}; yC++) {\n              int xC = wC + yC * ${n} - ${r};\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class t_{constructor(e){this.variableNames=["dy","W"],this.outputShape=e.inShape;const t=e.filterHeight,n=e.filterWidth,s=e.strideHeight,r=e.strideWidth,a=t-1-e.padInfo.top,i=n-1-e.padInfo.left,o=e.outChannels/e.inChannels;this.userCode=`\n      const ivec2 pads = ivec2(${a}, ${i});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n        ivec2 dyCorner = coords.yz - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        float dotProd = 0.0;\n\n        for (int wR = 0; wR < ${t}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${s}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${t} - 1 - wR;\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${r}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${n} - 1 - wC;\n\n            // TO DO: Vec4 over the channelMul\n            for (int dm = 0; dm < ${o}; dm++) {\n              int d2 = d1 * ${o} + dm;\n              float xValue = getDy(batch, idyR, idyC, d2);\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\n              dotProd += xValue * wValue;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}const n_={kernelName:lt,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,dy:a}=t,{strides:i,dilations:o,pad:l,dimRoundingMode:u,filterShape:c}=s,h=no(r.shape,c,i,o,l,u,!0),p=new e_(h);return n.runWebGLProgram(p,[r,a],"float32")}},s_={kernelName:ut,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,filter:a}=t,{strides:i,dilations:o,pad:l,dimRoundingMode:u,inputShape:c}=s,h=no(c,a.shape,i,o,l,u,!0),p=new t_(h);return n.runWebGLProgram(p,[r,a],"float32")}};class r_{constructor(e){this.variableNames=["X"],this.outputShape=[e,e],this.userCode="\n      void main() {\n          ivec2 coords = getOutputCoords();\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\n          setOutput(val);\n      }\n    "}}const a_={kernelName:ct,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{x:s}=t,r=[...s.shape,...s.shape],a=L(s.shape),i=LC({inputs:{x:s},backend:n,attrs:{shape:[a]}}),o=new r_(a),l=n.runWebGLProgram(o,[i],i.dtype),u=LC({inputs:{x:l},backend:n,attrs:{shape:r}});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(l),u}};class i_{constructor(e){this.variableNames=["x","W"],this.outputShape=e.outShape;const{inHeight:t,inWidth:n,padInfo:s,strideHeight:r,strideWidth:a,filterHeight:i,filterWidth:o,dilationHeight:l,dilationWidth:u}=e,{top:c,left:h}=s;this.userCode=`\n      const ivec2 strides = ivec2(${r}, ${a});\n      const ivec2 pads = ivec2(${c}, ${h});\n      const float neg_infinity = -3.4e38;\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.w;\n        ivec2 outTopLeftCorner =\n            coords.yz * strides - pads;\n        int hBeg = outTopLeftCorner.x;\n        int wBeg = outTopLeftCorner.y;\n\n        float curVal = neg_infinity;\n        for (int h = 0; h < ${i}; h++) {\n          int hIn = hBeg + h * ${l};\n\n          if (hIn >= 0 && hIn < ${t}) {\n            for (int w = 0; w < ${o}; w++) {\n              int wIn = wBeg + w * ${u};\n\n              if (wIn >= 0 && wIn < ${n}) {\n                float xVal = getX(batch, hIn, wIn, d1);\n                float wVal = getW(h, w, d1);\n\n                float val = xVal + wVal;\n                if (val > curVal) {\n                  curVal = val;\n                }\n              }\n            }\n          }\n        }\n\n        float result = curVal;\n        setOutput(result);\n      }\n    `}}const o_={kernelName:ht,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,filter:a}=t,{strides:i,pad:o,dilations:l}=s,u=Qi(r.shape,a.shape,i,o,"NHWC",l);let c;const h=new i_(u);c=n.runWebGLProgram(h,[r,a],"float32");const p=LC({inputs:{x:c},backend:n,attrs:{shape:u.outShape}});return n.disposeIntermediateTensorInfo(c),p}},l_={kernelName:mt,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{equation:r}=s,a=t,{allDims:i,summedDims:o,idDims:l}=Uc(r,a.length);Hc(i.length,l,a);const{path:u,steps:c}=jc(o,l),h=c.length;let p=null,d=i.length;const f=[];for(let e=0;e<h;++e){for(const t of c[e]){const{permutationIndices:e,expandDims:s}=Gc(d,l[t]);let r;Kc(e)?r=a[t]:(r=KC({inputs:{x:a[t]},backend:n,attrs:{perm:e}}),f.push(r));const i=r.shape.slice();for(let e=0;e<s.length;++e)i.splice(s[e],0,1);z(r.shape,i)||(r=LC({inputs:{x:r},backend:n,attrs:{shape:i}}),f.push(r)),null===p?p=r:(p=OC({inputs:{a:r,b:p},backend:n}),f.push(p))}e<h-1&&(u[e]>=0&&(p=HC({inputs:{x:p},backend:n,attrs:{axis:u[e]-(i.length-d),keepDims:!1}}),f.push(p)),d--)}for(const e of f)e!==p&&n.disposeIntermediateTensorInfo(e);return p}},u_=CC({opSnippet:"return (x >= 0.0) ? x : (exp(x) - 1.0);",packedOpSnippet:"\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n"}),c_={kernelName:gt,backendName:"webgl",kernelFunc:u_},h_={kernelName:yt,backendName:"webgl",kernelFunc:e=>{const{inputs:t,backend:n}=e,{dy:s,y:r}=t,a=fe().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new yC("\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\n",s.shape,r.shape):new mC("return (b >= 0.0) ? a : a * (b + 1.0);",s.shape,r.shape);return n.runWebGLProgram(a,[s,r],s.dtype)}},p_=RC({opSnippet:"return float(a == b);",packedOpSnippet:"\n  return vec4(equal(a, b));\n",dtype:"bool",cpuKernelImpl:iE}),d_={kernelName:xt,backendName:"webgl",kernelFunc:p_},f_=CC({opSnippet:`\n  // Error function is calculated approximately with elementary function.\n  // See "Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables", Abramowitz and Stegun.\n  float p = ${Sc};\n  float a1 = ${Tc};\n  float a2 = ${$c};\n  float a3 = ${Ec};\n  float a4 = ${Cc};\n  float a5 = ${Rc};\n\n  float sign = sign(x);\n  x = abs(x);\n  float t = 1.0 / (1.0 + p * x);\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\n`}),m_={kernelName:bt,backendName:"webgl",kernelFunc:f_},g_=CC({opSnippet:EC+"\n  return exp(x);\n",packedOpSnippet:"\n  vec4 result = exp(x);\n  bvec4 isNaN = isnan(x);\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",cpuKernelImpl:oE,dtype:"float32"}),y_={kernelName:wt,backendName:"webgl",kernelFunc:g_};function b_(e){const{inputs:t,attrs:n,backend:s}=e,{dim:r}=n,{input:a}=t,i=a.shape.length,o=a.shape.slice();let l=r;return r<0&&(F(-(i+1)<=r,(()=>`Axis must be in the interval [${-(i+1)}, ${i}]`)),l=i+r+1),o.splice(l,0,1),LC({inputs:{x:a},backend:s,attrs:{shape:o}})}const x_={kernelName:kt,backendName:"webgl",kernelFunc:b_},w_="return exp(x) - 1.0;",k_=CC({opSnippet:w_,packedOpSnippet:w_,cpuKernelImpl:lE}),v_={kernelName:vt,backendName:"webgl",kernelFunc:k_};class I_{constructor(e,t,n){this.variableNames=["real","imag"];const s=t[1];this.outputShape=t;const r=n?`2.0 * ${Math.PI}`:`-2.0 * ${Math.PI}`,a=n?`${s}.0`:"1.0";let i;if("real"===e)i="return real * expR - imag * expI;";else{if("imag"!==e)throw new Error(`FFT component must be either "real" or "imag", got ${e}.`);i="return real * expI + imag * expR;"}this.userCode=`\n      const float exponentMultiplier = ${r};\n\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\n        ${i}\n      }\n\n      float mulMatDFT(int batch, int index) {\n        float indexRatio = float(index) / float(${s});\n        float exponentMultiplierTimesIndexRatio =\n            exponentMultiplier * indexRatio;\n\n        float result = 0.0;\n\n        for (int i = 0; i < ${s}; i++) {\n          // x = (-2|2 * PI / N) * index * i;\n          float x = exponentMultiplierTimesIndexRatio * float(i);\n          float expR = cos(x);\n          float expI = sin(x);\n          float real = getReal(batch, i);\n          float imag = getImag(batch, i);\n\n          result +=\n              unaryOpComplex(real, expR, imag, expI) / ${a};\n        }\n\n        return result;\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        setOutput(mulMatDFT(coords[0], coords[1]));\n      }\n    `}}function N_(e,t,n){const s=n.texData.get(e.dataId),r=L(e.shape),a=e.shape[e.shape.length-1],i=LC({inputs:{x:e},backend:n,attrs:{shape:[r/a,a]}}),o=i.shape,l=new I_("real",o,t),u=new I_("imag",o,t),c=[{dataId:s.complexTensorInfos.real.dataId,dtype:s.complexTensorInfos.real.dtype,shape:o},{dataId:s.complexTensorInfos.imag.dataId,dtype:s.complexTensorInfos.imag.dtype,shape:o}],h=n.runWebGLProgram(l,c,"float32"),p=n.runWebGLProgram(u,c,"float32"),d=wC({inputs:{real:h,imag:p},backend:n});n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(p);const f=LC({inputs:{x:d},backend:n,attrs:{shape:e.shape}});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(d),f}const S_={kernelName:It,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{input:s}=t;return N_(s,!1,n)}};class T_{constructor(e,t){this.outputShape=[],this.customUniforms=[{name:"value",type:"float"}],this.variableNames=["x"],this.outputShape=e,this.userCode="\n      void main() {\n        // Input can be obtained from uniform value.\n        setOutput(value);\n      }\n    "}}function $_(e){const{backend:t,attrs:n}=e,{shape:s,value:r}=n;let{dtype:a}=n;if(a=a||Z(r),"string"===a){const e=K(a,L(s));return e.fill(r),t.makeTensorInfo(s,a,e)}{const e=new T_(s,r),n=[[r]];return t.runWebGLProgram(e,[],a,n)}}const E_={kernelName:Nt,backendName:"webgl",kernelFunc:$_};class C_{constructor(e){this.variableNames=["Image"],this.outputShape=[];const t=e[2];this.outputShape=e,this.userCode=`\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n\n          int coordX = ${t} - x - 1;\n          float outputValue;\n          if(coordX >= 0 && coordX < ${t}) {\n            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);\n          } else {\n            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}}const R_={kernelName:St,backendName:"webgl",kernelFunc:({inputs:e,backend:t})=>{const{image:n}=e,s=t,r=new C_(n.shape);return s.runWebGLProgram(r,[n],n.dtype)}},A_="return floor(x);",__=CC({opSnippet:A_,packedOpSnippet:A_,cpuKernelImpl:uE}),D_={kernelName:Tt,backendName:"webgl",kernelFunc:__},F_=RC({opSnippet:"\n  float s = sign(a) * sign(b);\n  int ia = round(a);\n  int ib = round(b);\n  if (ib != 0) {\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n    return float(idiv(ia, ib, s));\n  } else {\n    return NAN;\n  }\n",packedOpSnippet:"\n  ivec4 ia = round(a);\n  ivec4 ib = round(b);\n  bvec4 cond = notEqual(ib, ivec4(0));\n  ivec4 result = ivec4(0);\n  vec4 s = sign(a) * sign(b);\n\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n  if (cond[0]) {\n    result[0] = idiv(ia[0], ib[0], s[0]);\n  }\n  if (cond[1]) {\n    result[1] = idiv(ia[1], ib[1], s[1]);\n  }\n  if (cond[2]) {\n    result[2] = idiv(ia[2], ib[2], s[2]);\n  }\n  if (cond[3]) {\n    result[3] = idiv(ia[3], ib[3], s[3]);\n  }\n  return vec4(result);\n",dtype:"int32"}),O_={kernelName:$t,backendName:"webgl",kernelFunc:F_};class M_{constructor(e){this.variableNames=["A"];const t=y$(),[n,s]=e;this.outputShape=e,this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${s}.0, ${n}.0);\n\n        vec4 values = ${t.texture2D}(A, uv);\n        float value;\n        if (depth == 0) {\n          value = values.r;\n        } else if (depth == 1) {\n          value = values.g;\n        } else if (depth == 2) {\n          value = values.b;\n        } else if (depth == 3) {\n          value = values.a;\n        }\n\n        setOutput(floor(value * 255.0 + 0.5));\n      }\n    `}}class L_{constructor(e){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0;const t=y$(),[n,s]=e;this.outputShape=e,this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n\n        vec4 result = vec4(0.);\n\n        for(int row=0; row<=1; row++) {\n          for(int col=0; col<=1; col++) {\n            texC = coords[1] + row;\n            depth = coords[2] + col;\n\n            vec2 uv = (vec2(texC, texR) + halfCR) /\n                       vec2(${s}.0, ${n}.0);\n            vec4 values = ${t.texture2D}(A, uv);\n            float value;\n            if (depth == 0) {\n              value = values.r;\n            } else if (depth == 1) {\n              value = values.g;\n            } else if (depth == 2) {\n              value = values.b;\n            } else if (depth == 3) {\n              value = values.a;\n            }\n\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\n          }\n        }\n\n        ${t.output} = result;\n      }\n    `}}const z_={kernelName:"FromPixels",backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e;let{pixels:r}=t;const{numChannels:a}=s,i="undefined"!=typeof HTMLVideoElement&&r instanceof HTMLVideoElement,o="undefined"!=typeof HTMLImageElement&&r instanceof HTMLImageElement,[l,u]=i?[r.videoWidth,r.videoHeight]:[r.width,r.height],c=[u,l],h=[u,l,a];if(o||i){const e=fe().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");null!=B_&&e===P_||(P_=e,B_=document.createElement("canvas").getContext("2d",{willReadFrequently:P_})),B_.canvas.width=l,B_.canvas.height=u,B_.drawImage(r,0,0,l,u),r=B_.canvas}const p=n.makeTensorInfo(c,"int32");n.texData.get(p.dataId).usage=WT.PIXELS,n.gpgpu.uploadPixelDataToTexture(n.getTexture(p.dataId),r);const d=fe().getBool("WEBGL_PACK")?new L_(h):new M_(h),f=n.runWebGLProgram(d,[p],"int32");return n.disposeData(p.dataId),f}};let B_,P_=fe().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");const W_={kernelName:$s,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,filter:a,bias:i,preluActivationWeights:o}=t,{strides:l,pad:u,dataFormat:c,dilations:h,dimRoundingMode:p,activation:d,leakyreluAlpha:f}=s,m=po(c),g=no(r.shape,a.shape,l,h,u,p,!1,m);let y;const b=[],x=null!=i,w=null!=o,k="leakyrelu"===d,v=()=>{const e=[r,a],t=(e,t)=>{if("NCHW"===t&&1===e.shape.length&&1!==e.shape[0]){const t=LC({inputs:{x:e},backend:n,attrs:{shape:[e.shape[0],1,1]}});return b.push(t),t}return e};if(x&&e.push(t(i,c)),w&&e.push(t(o,c)),k){const t=n.makeTensorInfo([],"float32",tr(f,"float32"));e.push(t),b.push(t)}return e};if(1!==g.filterHeight||1!==g.filterWidth||1!==g.dilationHeight||1!==g.dilationWidth||1!==g.strideHeight||1!==g.strideWidth||"SAME"!==g.padInfo.type&&"VALID"!==g.padInfo.type)if(g.strideWidth<=2&&"channelsLast"===m&&fe().getBool("WEBGL_EXP_CONV")){const e=d?AC(d,!0):null,t=new xA(g,x,e,w,k),s=[[g.padInfo.top,g.padInfo.left],[g.strideHeight,g.strideWidth],[g.dilationHeight,g.dilationWidth],[g.inHeight,g.inWidth]],r=v();y=n.runWebGLProgram(t,r,"float32",s)}else if(fe().getBool("WEBGL_CONV_IM2COL"))y=IA({x:r,filter:a,convInfo:g,backend:n,bias:i,activation:d,preluActivationWeights:o,leakyreluAlpha:f});else{const e=d?AC(d,!1):null,t=new yA(g,x,e,w,k),s=v();y=n.runWebGLProgram(t,s,"float32")}else y=vA({x:r,filter:a,convInfo:g,backend:n,bias:i,activation:d,preluActivationWeights:o,leakyreluAlpha:f});const I=LC({inputs:{x:y},backend:n,attrs:{shape:g.outShape}});return b.push(y),b.forEach((e=>n.disposeIntermediateTensorInfo(e))),I}},V_={kernelName:Es,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,filter:a,bias:i,preluActivationWeights:o}=t,{strides:l,pad:u,dilations:c,dimRoundingMode:h,activation:p,leakyreluAlpha:d}=s,f=[];let m=c;null==m&&(m=[1,1]),F(co(l,m),(()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${l} and dilations '${m}'`));const g=no(r.shape,a.shape,l,m,u,h,!0),y=fe().getBool("WEBGL_PACK_DEPTHWISECONV")&&g.strideWidth<=2&&g.outChannels/g.inChannels==1,b=p?AC(p,y):null,x=[r,a],w=null!=i,k=null!=o,v="leakyrelu"===p;if(w&&x.push(i),k&&x.push(o),v){const e=n.makeTensorInfo([],"float32",tr(d,"float32"));x.push(e),f.push(e)}let I;I=y?new ZA(g,w,b,k,v):new JA(g,w,b,k,v);const N=[[g.padInfo.top,g.padInfo.left],[g.strideHeight,g.strideWidth],[g.dilationHeight,g.dilationWidth],[g.inHeight,g.inWidth]],S=n.runWebGLProgram(I,x,"float32",N);return f.forEach((e=>n.disposeIntermediateTensorInfo(e))),S}};class U_{constructor(e,t,n,s){this.sliceDim=e,this.strides=t,this.paramsShape=s,this.variableNames=["x","indices"],this.outputShape=n;const r=_$(n.length);let a="\n    int index;";for(let e=0;e<this.sliceDim;e++)a+=`\n          index = round(getIndices(coords[0], ${e}));\n          out_of_bounds = out_of_bounds || index < 0;\n          out_of_bounds = out_of_bounds || index >= ${this.paramsShape[e]};\n          flattenIndex += index * ${this.strides[e]};`;this.userCode=`\n         void main() {\n          ${r} coords = getOutputCoords();\n          int flattenIndex = 0;\n          bool out_of_bounds = false;\n\n          ${a}\n\n          setOutput(out_of_bounds ? 0.0 : getX(flattenIndex, coords[1]));\n        }\n      `}}const G_={kernelName:Rt,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{params:s,indices:r}=t,a=r.shape,i=a[a.length-1],o=L(s.shape),[l,u,c,h]=xc(s,r),p=LC({inputs:{x:r},backend:n,attrs:{shape:[u,i]}}),d=LC({inputs:{x:s},backend:n,attrs:{shape:[L(s.shape)/c,c]}});if(n.shouldExecuteOnCPU([s,r])||"string"===s.dtype){const e=n.readSync(r.dataId),t=n.bufferSync(s),a=cE(e,t,s.dtype,u,i,c,h,s.shape,o);return n.makeTensorInfo(l,s.dtype,a.values)}const f=new U_(i,h,[u,c],s.shape),m=n.runWebGLProgram(f,[d,p],d.dtype),g=LC({inputs:{x:m},backend:n,attrs:{shape:l}});return n.disposeIntermediateTensorInfo(p),n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(m),g}};class H_{constructor(e,t){this.variableNames=["A","indices"],this.outputShape=t,this.rank=t.length;const n=_$(this.rank),s=function(e){const t=["resRC.x","resRC.y","resRC.z","resRC.w"],n=[];for(let s=0;s<e.length;s++)2===s?n.push("index"):n.push(`${t[s]}`);return n.join()}(e);this.userCode=`\n      void main() {\n        ${n} resRC = getOutputCoords();\n        int index = int(getIndices(resRC.x, resRC.z));\n        float inBounds = (index >= 0) && (index < ${e[2]}) ? 1.0 : 0.0;\n        setOutput(inBounds * getA(${s}));\n      }\n    `}}function j_(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,indices:a}=t,{axis:i,batchDims:o}=s,l=G(i,r.shape)[0];if(fe().get("DEBUG")){const e=n.readSync(a.dataId),t=r.shape[l];for(let n=0;n<e.length;++n){const s=e[n];F(s<=t-1&&s>=0,(()=>`GatherV2: the index value ${s} is not in [0, ${t-1}]`))}}const u=ch(r,a,l,o),c=L(a.shape),h=[],p=LC({inputs:{x:r},backend:n,attrs:{shape:[u.batchSize,u.outerSize,u.dimSize,u.sliceSize]}}),d=LC({inputs:{x:a},backend:n,attrs:{shape:[u.batchSize,c/u.batchSize]}});h.push(p),h.push(d);const f=[u.batchSize,u.outerSize,c/u.batchSize,u.sliceSize];if(n.shouldExecuteOnCPU([r,a])||"string"===r.dtype){const e=n.bufferSync(d),t=n.bufferSync(p),s=hE(t,e,f);return h.forEach((e=>n.disposeIntermediateTensorInfo(e))),n.makeTensorInfo(u.outputShape,s.dtype,s.values)}const m=new H_(p.shape,f),g=n.runWebGLProgram(m,[p,d],p.dtype);h.push(g);const y=LC({inputs:{x:g},backend:n,attrs:{shape:u.outputShape}});return h.forEach((e=>n.disposeIntermediateTensorInfo(e))),y}const K_={kernelName:Ct,backendName:"webgl",kernelFunc:j_},q_=RC({opSnippet:"return float(a > b);",packedOpSnippet:"\n  return vec4(greaterThan(a, b));\n",cpuKernelImpl:pE,dtype:"bool"}),X_={kernelName:At,backendName:"webgl",kernelFunc:q_},Y_=RC({opSnippet:"return float(a >= b);",packedOpSnippet:"\n  return vec4(greaterThanEqual(a, b));\n",dtype:"bool",cpuKernelImpl:dE}),J_={kernelName:_t,backendName:"webgl",kernelFunc:Y_},Z_={kernelName:Ft,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{input:s}=t;return N_(s,!0,n)}},Q_=CC({opSnippet:"return float(!isnan(x) && !isinf(x));",dtype:"bool"}),eD={kernelName:Mt,backendName:"webgl",kernelFunc:Q_},tD=CC({opSnippet:"return float(isinf(x));",dtype:"bool"}),nD={kernelName:Lt,backendName:"webgl",kernelFunc:tD},sD=CC({opSnippet:"return float(isnan(x));",dtype:"bool"}),rD={kernelName:zt,backendName:"webgl",kernelFunc:sD},aD=RC({opSnippet:"return float(a < b);",packedOpSnippet:"\n  return vec4(lessThan(a, b));\n",cpuKernelImpl:fE,dtype:"bool"}),iD={kernelName:Pt,backendName:"webgl",kernelFunc:aD},oD=RC({opSnippet:"return float(a <= b);",packedOpSnippet:"\n  return vec4(lessThanEqual(a, b));\n",cpuKernelImpl:mE,dtype:"bool"}),lD={kernelName:Wt,backendName:"webgl",kernelFunc:oD},uD={kernelName:Vt,backendName:"webgl",kernelFunc:function(e){const{backend:t,attrs:n}=e,{start:s,stop:r,num:a}=n,i=gE(s,r,a);return t.makeTensorInfo([i.length],"float32",i)}},cD=CC({opSnippet:EC+"\n  return x < 0.0 ? 0./0. : log(x);\n",packedOpSnippet:"\n  vec4 result = log(x);\n  bvec4 isNaN = isnan(x);\n  result.r = isNaN.r ? x.r : (x.r < 0.0 ? 0./0. : result.r);\n  result.g = isNaN.g ? x.g : (x.g < 0.0 ? 0./0. : result.g);\n  result.b = isNaN.b ? x.b : (x.b < 0.0 ? 0./0. : result.b);\n  result.a = isNaN.a ? x.a : (x.a < 0.0 ? 0./0. : result.a);\n  return result;\n",cpuKernelImpl:yE}),hD={kernelName:Ut,backendName:"webgl",kernelFunc:cD},pD=CC({opSnippet:EC+"\n  return log(1.0 + x);\n"}),dD={kernelName:Gt,backendName:"webgl",kernelFunc:pD},fD=RC({opSnippet:"return float(a >= 1.0 && b >= 1.0);",packedOpSnippet:"\n  return vec4(\n    vec4(greaterThanEqual(a, vec4(1.0))) *\n    vec4(greaterThanEqual(b, vec4(1.0))));\n",dtype:"bool"}),mD={kernelName:Ht,backendName:"webgl",kernelFunc:fD},gD=CC({opSnippet:"return float(!(x >= 1.0));"}),yD={kernelName:jt,backendName:"webgl",kernelFunc:gD},bD=RC({opSnippet:"return float(a >= 1.0 || b >= 1.0);",packedOpSnippet:"\n  return min(\n    vec4(greaterThanEqual(a, vec4(1.0))) +\n    vec4(greaterThanEqual(b, vec4(1.0))),\n    vec4(1.0));\n",dtype:"bool"}),xD={kernelName:Kt,backendName:"webgl",kernelFunc:bD};class wD{constructor(e,t,n,s,r){this.variableNames=["x"],this.outputShape=[];const a=t,i=e[3]-1;let o;this.outputShape=e;const l=`float(${n}) + float(${s}) * sum`;o=.5===r?`inversesqrt(${l})`:1===r?`1.0/(${l})`:`exp(log(${l}) * float(-${r}));`,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n        int d = coords[3];\n        float x = getX(b, r, c, d);\n        float sum = 0.0;\n        for (int j = -${a}; j <= ${a}; j++) {\n          int idx = d + j;\n          if (idx >= 0 && idx <=  ${i}) {\n            float z = getX(b, r, c, idx);\n            sum += z * z;\n          }\n        }\n        float val = x * ${o};\n        setOutput(val);\n      }\n    `}}class kD{constructor(e,t,n,s,r){this.variableNames=["x"],this.outputShape=[],this.packedInputs=!0,this.packedOutput=!0;const a=t,i=e[3]-1;let o;this.outputShape=e;const l=`float(${n}) + float(${s}) * sum`;o=.5===r?`inversesqrt(${l})`:1===r?`1.0/(${l})`:`exp(log(${l}) * float(-${r}));`,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords.x;\n        int r = coords.y;\n        int c = coords.z;\n        int d = coords.w;\n\n        bool hasNextCol = d < ${this.outputShape[3]};\n        bool hasNextRow = c < ${this.outputShape[2]};\n\n        vec4 sum = vec4(0.);\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\n\n        vec4 xAtOutputCoords = vec4(\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\n          hasNextCol ?\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\n          hasNextRow ?\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\n        );\n\n        int firstChannel = d - ${a};\n        vec2 cache = vec2(0.);\n        if(firstChannel >= 0){\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\n            if(hasNextRow){\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\n            }\n        }\n\n        ivec2 depth = ivec2(d, d + 1);\n        for (int j = - ${a}; j <= ${a}; j++) {\n          ivec2 idx = depth + j;\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${i}));\n\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\n\n          if(depthInRange || depthPlusOneInRange){\n            vec4 z = vec4(0.);\n            vec4 xFragAtCurrentDepth;\n            z.xz = cache.xy;\n            if(depthPlusOneInRange && hasNextCol){\n              xFragAtCurrentDepth = idx.y != d ?\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\n              if(hasNextRow){\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\n              }\n            }\n            cache.xy = z.yw;\n            sum += z * z;\n          }\n        }\n        vec4 result = xAtOutputCoords * ${o};\n        setOutput(result);\n      }\n    `}}const vD={kernelName:qt,backendName:"webgl",kernelFunc:e=>{const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{depthRadius:a,bias:i,alpha:o,beta:l}=s,u=fe().getBool("WEBGL_PACK_NORMALIZATION")?new kD(r.shape,a,i,o,l):new wD(r.shape,a,i,o,l);return n.runWebGLProgram(u,[r],r.dtype)}};class ID{constructor(e,t,n,s,r){this.variableNames=["inputImage","outputImage","dy"],this.outputShape=[],this.outputShape=e,this.depth=e[3],this.depthRadius=t,this.bias=n,this.alpha=s,this.beta=r,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n\n        float result = 0.0;\n        for (int d = 0; d < ${this.depth}; ++d) {\n          int depthBegin = int(max(0.0, float(d - ${t})));\n          int depthEnd = int(min(float(${this.depth}),\n              float(d + ${t} + 1)));\n\n          const int MIN_DEPTH_BEGIN = 0;\n          const int MAX_DEPTH_END = ${this.depth};\n\n          float norm = 0.0;\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd) {\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\n            }\n            else {\n              break;\n            }\n          }\n\n          norm = float(${s}) * norm + float(${n});\n\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd){\n              float dyi = -2.0 * float(${s})\n                * float(${r})\n                * getInputImage(b, r, c, k) * getOutputImage(b, r, c, d)\n                / norm;\n              if (k == d) {\n                dyi += pow(norm, -1.0 * ${r});\n              }\n              if (k == coords[3]) {\n                dyi *= getDy(b, r, c, d);\n                result += dyi;\n              }\n            }\n            else {\n              break;\n            }\n          }\n      }\n      setOutput(result);\n      }\n    `}}const ND={kernelName:Xt,backendName:"webgl",kernelFunc:e=>{const{inputs:t,backend:n,attrs:s}=e,{x:r,y:a,dy:i}=t,{depthRadius:o,bias:l,alpha:u,beta:c}=s,h=new ID(r.shape,o,l,u,c);return n.runWebGLProgram(h,[r,a,i],r.dtype)}};function SD(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{reductionIndices:a,keepDims:i}=s,o=r.shape.length,l=G(a,r.shape);let u=l;const c=il(u,o),h=null!=c,p=n.shouldExecuteOnCPU([r]);let d=r;if(h){if(p){const e=n.texData.get(d.dataId).values,t=new Array(o);for(let e=0;e<t.length;e++)t[e]=r.shape[c[e]];const s=jE(e,r.shape,r.dtype,c,t);d=n.makeTensorInfo(t,r.dtype),n.texData.get(d.dataId).values=s}else d=GC(r,c,n);u=ll(u.length,o)}al("max",u,o);const[f,m]=sl(d.shape,u);let g,y=f;if(i&&(y=rl(f,l)),p){const e=n.texData.get(d.dataId).values,t=bE(e,L(m),y,r.dtype);g=n.makeTensorInfo(y,r.dtype),n.texData.get(g.dataId).values=t}else g=function(e,t,n,s){const r=L(t),a=LC({inputs:{x:e},attrs:{shape:[L(e.shape)/r,r]},backend:s}),i=WC(a,e.dtype,"max",s),o=LC({inputs:{x:i},attrs:{shape:n},backend:s});return s.disposeIntermediateTensorInfo(a),s.disposeIntermediateTensorInfo(i),o}(d,m,y,n);return h&&n.disposeIntermediateTensorInfo(d),g}const TD={kernelName:Yt,backendName:"webgl",kernelFunc:SD},$D=RC({opSnippet:fC+"\n  return max(a, b);\n",packedOpSnippet:"\n  vec4 result = vec4(max(a, b));\n  bvec4 isNaNA = isnan(a);\n  bvec4 isNaNB = isnan(b);\n  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);\n  "+gC+"\n  return result;\n",cpuKernelImpl:xE}),ED={kernelName:Jt,backendName:"webgl",kernelFunc:$D},CD={kernelName:Zt,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t;m$(r,"maxPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:l}=s;F(co(i,1),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));const u=eo(r.shape,a,i,1,o,l);if(1===u.filterWidth&&1===u.filterHeight&&z(u.inShape,u.outShape))return bC({inputs:{x:r},backend:n});const c=new ER(u,"max",!1);return n.runWebGLProgram(c,[r],r.dtype)}},RD={kernelName:en,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{filterSize:a,strides:i,pad:o,dataFormat:l,dimRoundingMode:u}=s,c=to(r.shape,a,i,[1,1,1],o,u,l),h=new CR(c,"max",!1);return n.runWebGLProgram(h,[r],r.dtype)}};class AD{constructor(e){this.variableNames=["dy","maxPos"],this.outputShape=e.inShape;const t=e.strideHeight,n=e.strideWidth,s=e.dilationHeight,r=e.effectiveFilterHeight,a=e.effectiveFilterWidth,i=r-1-e.padInfo.top,o=a-1-e.padInfo.left,l=r*a-1;this.userCode=`\n      const ivec2 pads = ivec2(${i}, ${o});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${r};\n          wR += ${s}) {\n          float dyR = float(dyRCorner + wR) / ${t}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${a}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${n}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n            int maxPosValue = ${l} - int(getMaxPos(b, idyR, idyC, d));\n\n            // Get the current value, check it against the value from the\n            // position matrix.\n            int curPosValue = wR * ${a} + wC;\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n            dotProd += dyValue * mask;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class _D{constructor(e){this.variableNames=["dy","maxPos"],this.outputShape=e.inShape;const t=e.strideDepth,n=e.strideHeight,s=e.strideWidth,r=e.dilationDepth,a=e.dilationHeight,i=e.dilationWidth,o=e.effectiveFilterDepth,l=e.effectiveFilterHeight,u=e.effectiveFilterWidth,c=o-1-e.padInfo.front,h=l-1-e.padInfo.top,p=u-1-e.padInfo.left,d=o*l*u-1;this.userCode=`\n      const ivec3 pads = ivec3(${c}, ${h}, ${p});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${o};\n           wD += ${r}) {\n          float dyD = float(dyDCorner + wD) / ${t}.0;\n\n          if (dyD < 0.0 || dyD >= ${e.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${l};\n              wR += ${a}) {\n            float dyR = float(dyRCorner + wR) / ${n}.0;\n\n            if (dyR < 0.0 || dyR >= ${e.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${u};\n                wC += ${i}) {\n              float dyC = float(dyCCorner + wC) / ${s}.0;\n\n              if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              int maxPosValue = ${d} -\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\n\n              // Get the current value, check it against the value from the\n              // position matrix.\n              int curPosValue =\n                  wD * ${l} * ${u} +\n                  wR * ${u} + wC;\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n              dotProd += dyValue * mask;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}const DD={kernelName:tn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,input:a}=t,i=a,{filterSize:o,strides:l,pad:u,dimRoundingMode:c}=s,h=to(i.shape,o,l,[1,1,1],u,c),p=new CR(h,"max",!0),d=n.runWebGLProgram(p,[i],i.dtype),f=new _D(h),m=n.runWebGLProgram(f,[r,d],i.dtype);return n.disposeIntermediateTensorInfo(d),m}},FD={kernelName:Qt,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{dy:r,input:a,output:i}=t,o=a;m$([a,i],"maxPoolGrad");const{filterSize:l,strides:u,pad:c,dimRoundingMode:h}=s,p=eo(o.shape,l,u,1,c,h),d=new ER(p,"max",!0),f=n.runWebGLProgram(d,[o],o.dtype),m=new AD(p),g=n.runWebGLProgram(m,[r,f],o.dtype);return n.disposeIntermediateTensorInfo(f),g}},OD={kernelName:nn,backendName:"webgl",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{x:s}=e,{filterSize:r,strides:a,pad:i,includeBatchInIndex:o}=t,l=n;F(4===s.shape.length,(()=>`Error in maxPool: input must be rank 4 but got rank ${s.shape.length}.`));const u=[1,1];F(co(a,u),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${a} and dilations '${u}'`));const c=eo(s.shape,r,a,u,i),[h,p]=function(e,t,n,s){let r=new ER(n,"max",!1);const a=s.runWebGLProgram(r,[e],"float32");return r=new ER(n,"max",!0,!0,t),[a,s.runWebGLProgram(r,[e],"float32")]}(s,o,c,l);return[h,p]}},MD={kernelName:sn,backendName:"webgl",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{x:s}=e,{keepDims:r,axis:a}=t,i=n,o=s.shape.length,l=G(a,s.shape);let u=l;const c=il(u,o),h=null!=c,p=i.shouldExecuteOnCPU([s]),d=[];let f=s;if(h){if(p){const e=i.texData.get(f.dataId).values,t=new Array(o);for(let e=0;e<t.length;e++)t[e]=s.shape[c[e]];const n=jE(e,s.shape,s.dtype,c,t);f=i.makeTensorInfo(t,s.dtype),i.texData.get(f.dataId).values=n}else f=GC(s,c,i);d.push(f),u=ll(u.length,o)}al("sum",u,o);const[m,g]=sl(f.shape,u);let y=m;r&&(y=rl(m,l));const b=function(e,t,n,s){const r=L(t),a=LC({inputs:{x:e},attrs:{shape:[L(e.shape)/r,r]},backend:s}),i=WC(a,"float32","mean",s),o=LC({inputs:{x:i},attrs:{shape:n},backend:s});return s.disposeIntermediateTensorInfo(a),s.disposeIntermediateTensorInfo(i),o}(f,g,y,i);for(const e of d)i.disposeIntermediateTensorInfo(e);return b}},LD={kernelName:rn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,keepDims:i}=s,o=r.shape.length,l=G(a,r.shape);let u=l;const c=il(u,o);let h=r;null!=c&&(h=KC({inputs:{x:r},backend:n,attrs:{perm:c}}),u=ll(u.length,r.shape.length)),al("min",u,o);const[p,d]=sl(h.shape,u),f=LC({inputs:{x:h},backend:n,attrs:{shape:[-1,L(d)]}}),m=WC(f,f.dtype,"min",n);let g;return g=LC(i?{inputs:{x:m},backend:n,attrs:{shape:rl(p,l)}}:{inputs:{x:m},backend:n,attrs:{shape:p}}),n.disposeIntermediateTensorInfo(f),n.disposeIntermediateTensorInfo(m),null!=c&&n.disposeIntermediateTensorInfo(h),g}},zD=RC({opSnippet:fC+"\n  return min(a, b);\n",packedOpSnippet:"\n  vec4 result = vec4(min(a, b));\n  bvec4 isNaNA = isnan(a);\n  bvec4 isNaNB = isnan(b);\n  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);\n  "+gC+"\n  return result;\n",cpuKernelImpl:wE}),BD={kernelName:an,backendName:"webgl",kernelFunc:zD};class PD{constructor(e,t,n){this.variableNames=["x"],this.outputShape=t.map(((t,n)=>t[0]+e[n]+t[1]));const s=e.length,r=_$(s),a=t.map((e=>e[0])).join(","),i=t.map(((t,n)=>t[0]+e[n])).join(","),o=["coords[0]","coords[1]","coords[2]","coords[3]"].slice(0,s),l="reflect"===n?0:1;this.userCode=1!==s?`\n      ${r} start = ${r}(${a});\n      ${r} end = ${r}(${i});\n\n      void main() {\n        ${r} outC = getOutputCoords();\n        for (int i = 0; i < ${s}; i++) {\n          if (outC[i] < start[i]) {\n            outC[i] = start[i] * 2 - outC[i] - ${l};\n          } else if(outC[i] >= end[i]) {\n            outC[i] = (end[i] - 1) * 2 - outC[i] + ${l};\n          }\n        }\n        ${r} coords = outC - start;\n        setOutput(getX(${o}));\n      }\n    `:`\n        int start = ${a};\n        int end = ${i};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start) {\n            outC = start * 2 - outC - ${l};\n          } else if(outC >= end) {\n            outC = (end - 1) * 2 - outC + ${l};\n          }\n          setOutput(getX(outC - start));\n        }\n      `}}class WD{constructor(e,t,n){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t.map(((t,n)=>t[0]+e[n]+t[1]));const s=e.length,r=_$(s),a=t.map((e=>e[0])).join(","),i=t.map(((t,n)=>t[0]+e[n])).join(","),o=XE("rc",s),l=XE("source",s),u=`${o[s-1]} < ${this.outputShape[s-1]}`,c=1===s?"source":`vec2(${l.slice(-2).join()})`,h="reflect"===n?0:1;let p="";if(1===s){const e=`\n        ${r} source = rc;\n        if (source < start) {\n          source = start * 2 - source - ${h};\n        } else if (source >= end) {\n          source = (end - 1) * 2 - source + ${h};\n        }\n        source -= start;\n      `;p=`\n        ${r} rc = outputLoc;\n        ${e}\n        result[0] = getChannel(getX(${l.join()}), ${c});\n        ${o[s-1]} += 1;\n        if(${u}) {\n          ${e}\n          result[1] = getChannel(getX(${l.join()}), ${c});\n        }\n      `}else{const e=`\n        ${r} source = rc;\n        ${r} lt = ${r}(lessThan(source, start));\n        ${r} gte = ${r}(greaterThanEqual(source, end));\n        ${r} orig = 1 - (lt + gte);\n        source = orig * source +\n                lt * (start * 2 - source - ${h}) +\n                gte * ((end - 1) * 2 - source + ${h});\n        source -= start;\n      `;p=`\n        ${r} rc = outputLoc;\n        ${e}\n        result[0] = getChannel(getX(${l.join()}), ${c});\n        ${o[s-1]} += 1;\n        if(${u}) {\n          ${e}\n          result[1] = getChannel(getX(${l.join()}), ${c});\n        }\n        rc = outputLoc;\n        ${o[s-2]} += 1;\n        if(${o[s-2]} < ${this.outputShape[s-2]}) {\n          ${e}\n          result[2] = getChannel(getX(${l.join()}), ${c});\n          ${o[s-1]} += 1;\n          if(${u}) {\n            ${e}\n            result[3] = getChannel(getX(${l.join()}), ${c});\n          }\n        }\n      `}this.userCode=`\n      const ${r} start = ${r}(${a});\n      const ${r} end = ${r}(${i});\n\n      void main() {\n        ${r} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${p}\n        setOutput(result);\n      }\n    `}}const VD={kernelName:on,backendName:"webgl",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:s}=e,{paddings:r,mode:a}=n,i=fe().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new WD(s.shape,r,a):new PD(s.shape,r,a);return t.runWebGLProgram(i,[s],s.dtype)}},UD=RC({opSnippet:"if (b == 0.0) return NAN;\n  return mod(a, b);",packedOpSnippet:"\n  vec4 result = mod(a, b);\n  bvec4 isNaN = equal(b, vec4(0.0));\n  "+gC+"\n  return result;\n"}),GD={kernelName:ln,backendName:"webgl",kernelFunc:UD};class HD{constructor(e,t,n){this.variableNames=["probs"],this.customUniforms=[{name:"seed",type:"float"}],this.outputShape=[e,n],this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n\n        float r = random(seed);\n        float cdf = 0.0;\n\n        for (int i = 0; i < ${t-1}; i++) {\n          cdf += getProbs(batch, i);\n\n          if (r < cdf) {\n            setOutput(float(i));\n            return;\n          }\n        }\n\n        // If no other event happened, last event happened.\n        setOutput(float(${t-1}));\n      }\n    `}}const jD=RC({opSnippet:"\nif (a == b) {\n  return 1.0;\n};\nreturn a / b;",packedOpSnippet:"\n  // vec4 one = vec4(equal(a, b));\n  // return one + (vec4(1.0) - one) * a / b;\n  vec4 result = a / b;\n  if(a.x == b.x) {\n    result.x = 1.;\n  }\n  if(a.y == b.y) {\n    result.y = 1.;\n  }\n  if(a.z == b.z) {\n    result.z = 1.;\n  }\n  if(a.w == b.w) {\n    result.w = 1.;\n  }\n\n  return result;\n",checkOutOfBounds:!0}),KD={kernelName:ft,backendName:"webgl",kernelFunc:jD},qD="return a - b;",XD=RC({opSnippet:qD,packedOpSnippet:qD,supportsComplex:!0,cpuKernelImpl:UE}),YD={kernelName:ds,backendName:"webgl",kernelFunc:XD};function JD(e){const{inputs:t,backend:n,attrs:s}=e,{logits:r}=t,{dim:a}=s,i=G([a],r.shape),o=SD({inputs:{x:r},backend:n,attrs:{reductionIndices:i,keepDims:!1}}),l=rl(o.shape,i),u=LC({inputs:{x:o},backend:n,attrs:{shape:l}}),c=XD({inputs:{a:r,b:u},backend:n}),h=g_({inputs:{x:c},backend:n}),p=HC({inputs:{x:h},backend:n,attrs:{axis:i,keepDims:!1}}),d=LC({inputs:{x:p},backend:n,attrs:{shape:l}}),f=jD({inputs:{a:h,b:d},backend:n});return n.disposeIntermediateTensorInfo(o),n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(c),n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(p),n.disposeIntermediateTensorInfo(d),f}const ZD={kernelName:es,backendName:"webgl",kernelFunc:JD},QD={kernelName:un,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{logits:r}=t,{numSamples:a,seed:i,normalized:o}=s,l=o?r:JD({inputs:{logits:r},backend:n,attrs:{dim:r.shape.length-1}}),u=l.shape[0],c=l.shape[1],h=new HD(u,c,a),p=[[i]],d=n.runWebGLProgram(h,[l],"int32",p);return o||n.disposeIntermediateTensorInfo(l),d}},eF=sC+"\n  return -x;\n",tF={kernelName:hn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{x:s}=t;if(n.shouldExecuteOnCPU([s])){const e=n.texData.get(s.dataId),[t,r]=vE(e.values,s.shape,s.dtype);return n.makeTensorInfo(r,s.dtype,t)}let r;return r=fe().getBool("WEBGL_PACK_UNARY_OPERATIONS")?new lC(s.shape,"\n  vec4 result = -x;\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n"):new nC(s.shape,eF),n.runWebGLProgram(r,[s],s.dtype)}},nF=Eu,sF={kernelName:dn,backendName:"webgl",kernelFunc:function(e){Cs("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{inputs:t,backend:n,attrs:s}=e,{boxes:r,scores:a}=t,{maxOutputSize:i,iouThreshold:o,scoreThreshold:l}=s,u=n.readSync(r.dataId),c=n.readSync(a.dataId),{selectedIndices:h}=nF(u,c,i,o,l);return n.makeTensorInfo([h.length],"int32",new Int32Array(h))}},rF=Cu,aF={kernelName:fn,backendName:"webgl",kernelFunc:function(e){Cs("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{inputs:t,backend:n,attrs:s}=e,{boxes:r,scores:a}=t,{maxOutputSize:i,iouThreshold:o,scoreThreshold:l,padToMaxOutputSize:u}=s,c=n.readSync(r.dataId),h=n.readSync(a.dataId),{selectedIndices:p,validOutputs:d}=rF(c,h,i,o,l,u);return[n.makeTensorInfo([p.length],"int32",new Int32Array(p)),n.makeTensorInfo([],"int32",new Int32Array([d]))]}},iF=Ru,oF={kernelName:mn,backendName:"webgl",kernelFunc:function(e){Cs("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{inputs:t,backend:n,attrs:s}=e,{boxes:r,scores:a}=t,{maxOutputSize:i,iouThreshold:o,scoreThreshold:l,softNmsSigma:u}=s,c=n.readSync(r.dataId),h=n.readSync(a.dataId),p=i,d=o,f=l,m=u,{selectedIndices:g,selectedScores:y}=iF(c,h,p,d,f,m);return[n.makeTensorInfo([g.length],"int32",new Int32Array(g)),n.makeTensorInfo([y.length],"float32",new Float32Array(y))]}};class lF{constructor(e,t,n,s){this.variableNames=["indices"],this.outputShape=[e,t],this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int index = round(getIndices(coords.x));\n        setOutput(mix(float(${s}), float(${n}),\n                      float(index == coords.y)));\n      }\n    `}}const uF={kernelName:yn,backendName:"webgl",kernelFunc:e=>{const{inputs:t,backend:n,attrs:s}=e,{indices:r}=t,{dtype:a,depth:i,onValue:o,offValue:l}=s,u=L(r.shape),c=new lF(u,i,o,l),h=LC({inputs:{x:r},backend:n,attrs:{shape:[u]}}),p=n.runWebGLProgram(c,[h],a);n.disposeIntermediateTensorInfo(h);const d=LC({inputs:{x:p},backend:n,attrs:{shape:[...r.shape,i]}});return n.disposeIntermediateTensorInfo(p),d}};function cF(e){const{inputs:t,backend:n}=e,{x:s}=t;if("complex64"===s.dtype){const e=JR({inputs:{input:s},backend:n}),t=cF({inputs:{x:e},backend:n}),r=pA({inputs:{input:s},backend:n}),a=cF({inputs:{x:r},backend:n}),i=wC({inputs:{real:t,imag:a},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(a),i}return $_({attrs:{shape:s.shape,dtype:s.dtype,value:"string"===s.dtype?"":0},backend:n})}const hF={kernelName:Is,backendName:"webgl",kernelFunc:cF},pF={kernelName:gn,backendName:"webgl",kernelFunc:function e(t){const{inputs:n,backend:s}=t,{x:r}=n;if("string"===r.dtype)throw new Error("onesLike is not supported under string dtype");if("complex64"===r.dtype){const t=JR({inputs:{input:r},backend:s}),n=e({inputs:{x:t},backend:s}),a=pA({inputs:{input:r},backend:s}),i=cF({inputs:{x:a},backend:s}),o=wC({inputs:{real:n,imag:i},backend:s});return s.disposeIntermediateTensorInfo(t),s.disposeIntermediateTensorInfo(n),s.disposeIntermediateTensorInfo(a),s.disposeIntermediateTensorInfo(i),o}return $_({attrs:{shape:r.shape,dtype:r.dtype,value:1},backend:s})}},dF={kernelName:bn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{axis:r}=s;if(1===t.length)return b_({inputs:{input:t[0]},backend:n,attrs:{dim:r}});const a=t[0].shape,i=t[0].dtype;t.forEach((e=>{O(a,e.shape,"All tensors passed to stack must have matching shapes"),F(i===e.dtype,(()=>"All tensors passed to stack must have matching dtypes"))}));const o=[],l=mA({inputs:t.map((e=>{const t=b_({inputs:{input:e},backend:n,attrs:{dim:r}});return o.push(t),t})),backend:n,attrs:{axis:r}});return o.forEach((e=>n.disposeIntermediateTensorInfo(e))),l}};class fF{constructor(e,t,n){this.variableNames=["x"],this.customUniforms=[{name:"value",type:"float"}],this.outputShape=t.map(((t,n)=>t[0]+e[n]+t[1]));const s=e.length,r=_$(s),a=t.map((e=>e[0])).join(","),i=t.map(((t,n)=>t[0]+e[n])).join(","),o=["coords[0]","coords[1]","coords[2]","coords[3]"].slice(0,s);this.userCode=1!==s?`\n      ${r} start = ${r}(${a});\n      ${r} end = ${r}(${i});\n\n      void main() {\n        ${r} outC = getOutputCoords();\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\n          setOutput(value);\n        } else {\n          ${r} coords = outC - start;\n          setOutput(getX(${o}));\n        }\n      }\n    `:`\n        int start = ${a};\n        int end = ${i};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start || outC >= end) {\n            setOutput(value);\n          } else {\n            setOutput(getX(outC - start));\n          }\n        }\n      `}}class mF{constructor(e,t,n){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"value",type:"float"}],this.outputShape=t.map(((t,n)=>t[0]+e[n]+t[1]));const s=e.length,r=_$(s),a=t.map((e=>e[0])).join(","),i=t.map(((t,n)=>t[0]+e[n])).join(","),o=XE("rc",s),l=XE("source",s),u=`${o[s-1]} < ${this.outputShape[s-1]}`,c=1===s?"source":`vec2(${l.slice(-2).join()})`,h=[`${r} rc = outputLoc;`,`${o[s-1]} += 1;\n       if(${u}) {\n      `,1===s?"":`}\n       rc = outputLoc;\n       ${o[s-2]} += 1;\n       if(${o[s-2]} < ${this.outputShape[s-2]}) {`,1===s?"":`  ${o[s-1]} += 1;\n         if(${u}) {`],p=1===s?"rc < start || rc >= end":"any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";let d="";for(let e=0,t=1===s?2:4;e<t;e++)d+=`\n        ${h[e]}\n        if (${p}) {\n          result[${e}] = float(value);\n        } else {\n          ${r} source = rc - start;\n          result[${e}] = getChannel(getX(${l.join()}), ${c});\n        }\n      `;d+=1===s?"} ":"}}",this.userCode=`\n      const ${r} start = ${r}(${a});\n      const ${r} end = ${r}(${i});\n\n      void main() {\n        ${r} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${d}\n        setOutput(result);\n      }\n    `}}const gF=e=>{const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{paddings:a,constantValue:i}=s;if(0===L(r.shape)){const e=a.map(((e,t)=>e[0]+r.shape[t]+e[1]));return $_({backend:n,attrs:{shape:e,value:i,dtype:r.dtype}})}const o=fe().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new mF(r.shape,a,i):new fF(r.shape,a,i),l=[[i]];return n.runWebGLProgram(o,[r],r.dtype,l)},yF={kernelName:xn,backendName:"webgl",kernelFunc:gF},bF=RC({opSnippet:"\n  if(a < 0.0 && floor(b) < b){\n    return NAN;\n  }\n  if (b == 0.0) {\n    return 1.0;\n  }\n  return (round(mod(b, 2.0)) != 1) ?\n      pow(abs(a), b) : sign(a) * pow(abs(a), b);\n",packedOpSnippet:"\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\n  vec4 result = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  bvec4 isExpZero = equal(b, vec4(0.0));\n  result.r = isExpZero.r ? 1.0 : result.r;\n  result.g = isExpZero.g ? 1.0 : result.g;\n  result.b = isExpZero.b ? 1.0 : result.b;\n  result.a = isExpZero.a ? 1.0 : result.a;\n\n  bvec4 isNaN1 = lessThan(a, vec4(0.0));\n  bvec4 isNaN2 = lessThan(floor(b), b);\n  bvec4 isNaN = bvec4(isNaN1.x && isNaN2.x, isNaN1.y && isNaN2.y, isNaN1.z && isNaN2.z, isNaN1.w && isNaN2.w);\n  "+gC+"\n  return result;\n"}),xF={kernelName:wn,backendName:"webgl",kernelFunc:bF},wF={kernelName:vn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{axis:a,keepDims:i}=s,o=r.shape.length,l=[],u=G(a,r.shape);let c=u;const h=il(c,o);let p,d=r;if(null!=h&&(d=KC({inputs:{x:r},backend:n,attrs:{perm:h}}),c=ll(c.length,o),l.push(d)),al("prod",c,o),n.shouldExecuteOnCPU([d])){const e=n.texData.get(d.dataId).values,{outVals:t,outShape:s,outDtype:r}=NE(d.shape,d.dtype,e,c);p=n.makeTensorInfo(s,r,t)}else{const[e,t]=sl(d.shape,c),s=L(t),a=LC({inputs:{x:d},backend:n,attrs:{shape:[-1,s]}}),i=WC(a,Rr(r.dtype),"prod",n);p=LC({inputs:{x:i},backend:n,attrs:{shape:e}}),l.push(a),l.push(i)}if(i){l.push(p);const e=rl(p.shape,u);p=LC({inputs:{x:p},backend:n,attrs:{shape:e}})}return l.forEach((e=>n.disposeIntermediateTensorInfo(e))),p}},kF={kernelName:In,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{paramsNestedSplits:r,paramsDenseValues:a,indices:i}=t,{outputRaggedRank:o}=s,l=r.map((e=>n.readSync(e.dataId))),u=r.map((e=>e.shape)),c=n.readSync(a.dataId),h=n.readSync(i.dataId),[p,d,f]=SE(l,u,c,a.shape,a.dtype,h,i.shape,o),m=p.map((e=>n.makeTensorInfo([e.length],"int32",e))),g=n.makeTensorInfo(f,a.dtype,d);return m.concat([g])}},vF={kernelName:Nn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{starts:s,limits:r,deltas:a}=t,i=n.readSync(s.dataId),o=n.readSync(r.dataId),l=n.readSync(a.dataId),[u,c]=TE(i,s.shape,s.dtype,o,r.shape,l,a.shape);return[n.makeTensorInfo([u.length],"int32",u),n.makeTensorInfo([c.length],s.dtype,c)]}},IF={kernelName:Sn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{shape:r,values:a,defaultValue:i,rowPartitionTensors:o}=t,{rowPartitionTypes:l}=s,u=n.readSync(r.dataId),c=n.readSync(a.dataId),h=n.readSync(i.dataId),p=o.map((e=>n.readSync(e.dataId))),d=o.map((e=>e.shape)),[f,m]=$E(u,r.shape,c,a.shape,a.dtype,h,i.shape,p,d,l);return n.makeTensorInfo(f,a.dtype,m)}},NF=e=>{const{backend:t,attrs:n}=e,{start:s,stop:r,step:a,dtype:i}=n,o=EE(s,r,a,i);return t.makeTensorInfo([o.length],i,o)},SF={kernelName:Tn,backendName:"webgl",kernelFunc:NF},TF=CC({opSnippet:"return 1.0 / x;"}),$F={kernelName:En,backendName:"webgl",kernelFunc:TF},EF=CC({opSnippet:sC+"\n  return (x < 0.0) ? 0.0 : x;\n",packedOpSnippet:"\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n"}),CF={kernelName:Cn,backendName:"webgl",kernelFunc:EF},RF=CC({opSnippet:sC+"\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",packedOpSnippet:"\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n"}),AF={kernelName:On,backendName:"webgl",kernelFunc:RF};class _F{constructor(e,t,n,s,r){this.variableNames=["A"],this.outputShape=[];const[a,i,o,l]=e;this.outputShape=[a,t,n,l];const u=[s&&t>1?i-1:i,s&&n>1?o-1:o],c=[s&&t>1?t-1:t,s&&n>1?n-1:n];let h;h=r?"(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)":"vec2(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${u[0]/c[0]},\n          ${u[1]/c[1]});\n      const vec2 inputShapeRC = vec2(${i}.0, ${o}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ${h};\n\n        // Compute the four integer indices.\n        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));\n        ivec2 sourceCeilRC = ivec2(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\n\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n        float newValue = top + (bottom - top) * fracRC.x;\n\n        setOutput(newValue);\n      }\n    `}}class DF{constructor(e,t,n,s,r){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[];const[a,i,o,l]=e;this.outputShape=[a,t,n,l];const u=[s&&t>1?i-1:i,s&&n>1?o-1:o],c=[s&&t>1?t-1:t,s&&n>1?n-1:n];let h;h=r?"(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)":"vec3(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${u[0]/c[0]},\n          ${u[1]/c[1]},\n          ${u[1]/c[1]});\n      const vec3 inputShapeRC = vec3(${i}.0, ${o}.0,\n                                     ${o}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ${h};\n\n        // Compute the four integer indices.\n        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));\n        ivec3 sourceCeilRC = ivec3(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${l-1};\n        bool hasNextRow = coords.z < ${n-1};\n\n        // In parallel, construct four corners for all four components in\n        // packed 2x2 cell.\n        vec4 topLeft = vec4(\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 bottomLeft = vec4(\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 topRight = vec4(\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec4 bottomRight = vec4(\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\n\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\n        vec4 newValue = mix(top, bottom, fracRC.x);\n\n        setOutput(newValue);\n      }\n    `}}const FF={kernelName:Dn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{images:r}=t,{alignCorners:a,halfPixelCenters:i,size:o}=s,[l,u]=o,c=fe().getBool("WEBGL_PACK_IMAGE_OPERATIONS")?new DF(r.shape,l,u,a,i):new _F(r.shape,l,u,a,i);return n.runWebGLProgram(c,[r],"float32")}};class OF{constructor(e,t,n){this.variableNames=["dy"],this.outputShape=[],this.outputShape=t;const[,s,r]=t,[,a,i]=e,o=[n&&a>1?s-1:s,n&&i>1?r-1:r],l=[n&&a>1?a-1:a,n&&i>1?i-1:i],u=o[0]/l[0],c=o[1]/l[1],h=1/u,p=1/c,d=2*Math.ceil(h)+2,f=2*Math.ceil(p)+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${u});\n        const float widthScale = float(${c});\n\n        const float invHeightScale = float(${h});\n        const float invWidthScale = float(${p});\n\n        const int winHeight = int(${d});\n        const int winWidth = int(${f});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(startRLerp - float(winHeight / 2));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(startCLerp - float(winWidth / 2));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${a}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${i}) {\n              continue;\n            }\n\n            float dxR = float(dyR) * heightScale;\n            int topDxRIndex = int(floor(dxR));\n            int bottomDxRIndex = int(min(ceil(dxR), ${s-1}.0));\n            float dxRLerp = dxR - float(topDxRIndex);\n            float inverseDxRLerp = 1.0 - dxRLerp;\n\n            float dxC = float(dyC) * widthScale;\n            int leftDxCIndex = int(floor(dxC));\n            int rightDxCIndex = int(min(ceil(dxC), ${r-1}.0));\n            float dxCLerp = dxC - float(leftDxCIndex);\n            float inverseDxCLerp = 1.0 - dxCLerp;\n\n            if (r == topDxRIndex && c == leftDxCIndex) {\n              // topLeft\n              accumulator +=\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\n            }\n\n            if (r == topDxRIndex && c == rightDxCIndex) {\n              // topRight\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\n              // bottomLeft\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\n              // bottomRight\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}const MF={kernelName:Fn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{images:r,dy:a}=t,{alignCorners:i}=s,o=new OF(a.shape,r.shape,i);return n.runWebGLProgram(o,[a],a.dtype)}};class LF{constructor(e,t,n,s,r){this.variableNames=["A"],this.outputShape=[];const[a,i,o,l]=e;this.outputShape=[a,t,n,l];const u=[s&&t>1?i-1:i,s&&n>1?o-1:o],c=[s&&t>1?t-1:t,s&&n>1?n-1:n],h=s?"0.5":"0.0";let p;p=r?"max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))":"vec2(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${u[0]/c[0]},\n          ${u[1]/c[1]});\n      const vec2 inputShapeRC = vec2(${i}.0, ${o}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ${p};\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec2 sourceNearestRC = ivec2(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${h})));\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n        setOutput(newValue);\n      }\n    `}}class zF{constructor(e,t,n,s,r){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[];const[a,i,o,l]=e;this.outputShape=[a,t,n,l];const u=[s&&t>1?i-1:i,s&&n>1?o-1:o],c=[s&&t>1?t-1:t,s&&n>1?n-1:n],h=s?"0.5":"0.0";let p;p=r?"max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))":"vec3(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${u[0]/c[0]},\n          ${u[1]/c[1]},\n          ${u[1]/c[1]});\n      const vec3 inputShapeRC = vec3(${i}.0, ${o}.0,\n                                     ${o}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ${p};\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec3 sourceNearestRC = ivec3(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${h})));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${l-1};\n        bool hasNextRow = coords.z < ${n-1};\n\n        vec4 newValue = vec4(\n          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),\n          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);\n\n        setOutput(newValue);\n      }\n    `}}const BF={kernelName:An,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{images:r}=t,{alignCorners:a,halfPixelCenters:i,size:o}=s,[l,u]=o,c=fe().getBool("WEBGL_PACK_IMAGE_OPERATIONS")?new zF(r.shape,l,u,a,i):new LF(r.shape,l,u,a,i);return n.runWebGLProgram(c,[r],r.dtype)}};class PF{constructor(e,t,n){this.variableNames=["dy"],this.outputShape=[],this.outputShape=t;const[,s,r]=t,[,a,i]=e,o=[n&&a>1?s-1:s,n&&i>1?r-1:r],l=[n&&a>1?a-1:a,n&&i>1?i-1:i],u=o[0]/l[0],c=o[1]/l[1],h=1/u,p=1/c,d=2*Math.ceil(h)+2,f=2*Math.ceil(p)+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${u});\n        const float widthScale = float(${c});\n\n        const float invHeightScale = float(${h});\n        const float invWidthScale = float(${p});\n\n        const int winHeight = int(${d});\n        const int winWidth = int(${f});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${a}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${i}) {\n              continue;\n            }\n\n            float sourceFracRow =\n              float(${o[0]}) *\n                (float(dyR) / float(${l[0]}));\n\n            float sourceFracCol =\n                float(${o[1]}) *\n                  (float(dyC) / float(${l[1]}));\n\n            int sourceNearestRow = int(min(\n                float(int(${s}) - 1),\n                ${n} ? float(round(sourceFracRow)) :\n                                  float(floor(sourceFracRow))));\n\n            int sourceNearestCol = int(min(\n                float(int(${r}) - 1),\n                ${n} ? float(round(sourceFracCol)) :\n                                  float(floor(sourceFracCol))));\n\n            if (r == sourceNearestRow && c == sourceNearestCol) {\n              accumulator += getDy(b, dyR, dyC, d);\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}const WF={kernelName:_n,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{images:r,dy:a}=t,{alignCorners:i}=s,o=new PF(a.shape,r.shape,i);return n.runWebGLProgram(o,[a],a.dtype)}};class VF{constructor(e,t){this.variableNames=["x"];const n=e.length;if(n>4)throw new Error(`WebGL backend: Reverse of rank-${n} tensor is not yet supported`);if(this.outputShape=e,1===n)return void(this.userCode=`\n        void main() {\n          int coord = getOutputCoords();\n          setOutput(getX(${e[0]} - coord - 1));\n        }\n      `);const s=e.map(((n,s)=>(n=>-1!==t.indexOf(n)&&1!==e[n]?`${e[n]} - coords[${n}] - 1`:`coords[${n}]`)(s))).join(","),r=_$(n);this.userCode=`\n      void main() {\n        ${r} coords = getOutputCoords();\n        setOutput(getX(${s}));\n      }\n    `}}class UF{constructor(e,t){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0;const n=e.length;if(n>4)throw new Error(`WebGL backend: Reverse of rank-${n} tensor is not yet supported`);this.outputShape=e;const s=XE("rc",n),r=`${s[n-1]} + 1 < ${this.outputShape[n-1]}`,a=`${s[n-2]} + 1 < ${this.outputShape[n-2]}`,i=_$(n);function o(n){const s=e.map(((s,r)=>function(n,s){return-1!==t.indexOf(n)&&1!==e[n]?`${e[n]} - ${s[n]} - 1`:`${s[n]}`}(r,n)));return`getChannel(getX(${s.join(",")}), vec2(${s.slice(-2).join(",")}))`}this.userCode=1===n?`\n        void main(){\n          int rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = getChannel(getX(${e[0]} - rc - 1),\n            ${e[0]} - rc - 1);\n          if(${r}){\n              result.g = getChannel(getX(${e[0]} - (rc  + 1) - 1),\n                ${e[0]} - (rc  + 1) - 1);\n          }\n          setOutput(result);\n        }\n      `:`\n        void main() {\n          ${i} rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = ${function(e){return o(e)}(s.slice())};\n          if(${r}){\n            result.g = ${function(e){return e[n-1]="("+e[n-1]+" + 1)",o(e)}(s.slice())};\n          }\n          if(${a}) {\n            result.b = ${function(e){return e[n-2]="("+e[n-2]+" + 1)",o(e)}(s.slice())};\n            if(${r}) {\n              result.a = ${function(e){return e[n-1]="("+e[n-1]+" + 1)",e[n-2]="("+e[n-2]+" + 1)",o(e)}(s.slice())};\n            }\n          }\n          setOutput(result);\n        }\n    `}}const GF={kernelName:Mn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{dims:a}=s,i=r.shape.length,o=G(a,r.shape);if(0===i)return bC({inputs:{x:r},backend:n});const l=fe().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new UF(r.shape,o):new VF(r.shape,o);return n.runWebGLProgram(l,[r],r.dtype)}};class HF{constructor(e,t){this.variableNames=["Image"],this.outputShape=[],this.customUniforms=[{name:"params",type:"vec4"}];const n=e[1],s=e[2];this.outputShape=e;let r="";r="number"==typeof t?`float outputValue = ${t.toFixed(2)};`:`\n        vec3 fill = vec3(${t.join(",")});\n        float outputValue = fill[coords[3]];`,this.userCode=`\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n          int y = coords[1];\n          float coordXFloat = (float(x) - params[0]) * params[3] -\n            (float(y) - params[1]) * params[2];\n          float coordYFloat = (float(x) - params[0]) * params[2] +\n            (float(y) - params[1]) * params[3];\n          int coordX = int(round(coordXFloat + params[0]));\n          int coordY = int(round(coordYFloat + params[1]));\n          ${r}\n          if(coordX >= 0 && coordX < ${s} && coordY >= 0 && coordY < ${n}) {\n            outputValue = getImage(coords[0], coordY, coordX, coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}}const jF={kernelName:Ss,backendName:"webgl",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{image:s}=e,{radians:r,fillValue:a,center:i}=t,o=n,l=new HF(s.shape,a),[u,c]=dc(i,s.shape[1],s.shape[2]),h=[[u,c,Math.sin(r),Math.cos(r)]];return o.runWebGLProgram(l,[s],s.dtype,h)}},KF=CC({opSnippet:"\n  // OpenGL ES does not support round function.\n  // The algorithm is based on banker's rounding.\n  float base = floor(x);\n  if ((x - base) < 0.5) {\n    return floor(x);\n  } else if ((x - base) > 0.5) {\n    return ceil(x);\n  } else {\n    if (mod(base, 2.0) == 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n"}),qF={kernelName:Ln,backendName:"webgl",kernelFunc:KF},XF=CC({opSnippet:"return inversesqrt(x);",cpuKernelImpl:CE}),YF={kernelName:zn,backendName:"webgl",kernelFunc:XF};class JF{constructor(e,t,n,s,r,a,i=!0,o=!1){this.variableNames=["updates","indices","defaultValue"],this.outputShape=a;const l=_$(r.length),u=_$(a.length);let c="";1===n?c="i":2===n&&(c="i, j");const h=`getIndices(${c})`;let p="";1===s?p="i":2===s&&(p="i, coords[1]");const d=`getUpdates(${p})`;let f="";o&&(f="coords[0], coords[1]");const m=`getDefaultValue(${f})`,g=t>1?"strides[j]":"strides";this.userCode=`\n        ${l} strides = ${l}(${r});\n\n        void main() {\n          ${u} coords = getOutputCoords();\n          float sum = 0.0;\n          bool found = false;\n          for (int i = 0; i < ${e}; i++) {\n            int flattenedIndex = 0;\n            for (int j = 0; j < ${t}; j++) {\n              int index = round(${h});\n              flattenedIndex += index * ${g};\n            }\n            if (flattenedIndex == coords[0]) {\n              sum += ${d};\n              found = true;\n            }\n          }\n          setOutput(mix(${m}, sum, float(found)));\n        }\n      `}}class ZF{constructor(e,t,n,s,r,a,i=!0,o=!1){this.variableNames=["updates","indices","defaultValue"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=a;const l=_$(r.length),u=_$(a.length);let c="";1===n?c="i":2===n&&(c="i, j");const h=`getIndices(${c})`;let p="";1===s?p="i":2===s&&(p="i, coords[1]");const d=`getUpdates(${p})`;let f="";o&&(f="coords[0], coords[1]");const m=`getDefaultValue(${f})`,g=t>1?"strides[j]":"strides",y=t>1?"strides[j + 1]":"strides";this.userCode=`\n        ${l} strides = ${l}(${r});\n\n        void main() {\n          ${u} coords = getOutputCoords();\n          vec4 sum = vec4(0.);\n          vec4 found = vec4(0.);\n          for (int i = 0; i < ${e}; i+=2) {\n            ivec2 flattenedIndex = ivec2(0);\n            for (int j = 0; j < ${t}; j+=2) {\n              ivec4 index = round(${h});\n              flattenedIndex += index.xz * ${g};\n              if (j + 1 < ${t}) {\n                flattenedIndex += index.yw * ${y};\n              }\n            }\n            if (flattenedIndex[0] == coords[0] || flattenedIndex[1] == coords[0] ||\n                flattenedIndex[0] == coords[0] + 1 || flattenedIndex[1] == coords[0] + 1) {\n              vec4 updVals = ${d};\n              if (flattenedIndex[0] == coords[0]) {\n                sum.xy += updVals.xy;\n                found.xy = vec2(1.);\n              } else if (flattenedIndex[0] == coords[0] + 1) {\n                sum.zw += updVals.xy;\n                found.zw = vec2(1.);\n              }\n              if (flattenedIndex[1] == coords[0]) {\n                sum.xy += updVals.zw;\n                found.xy = vec2(1.);\n              } else if (flattenedIndex[1] == coords[0] + 1) {\n                sum.zw += updVals.zw;\n                found.zw = vec2(1.);\n              }\n            }\n          }\n          setOutput(mix(${m}, sum, found));\n        }\n      `}}const QF={kernelName:Bn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{indices:r,updates:a}=t,{shape:i}=s,{sliceRank:o,numUpdates:l,sliceSize:u,strides:c,outputSize:h}=vc(0,r,i),p=[h/u,u];if(0===h)return n.makeTensorInfo(i,r.dtype);const d=LC({inputs:{x:r},backend:n,attrs:{shape:[l,o]}}),f=LC({inputs:{x:a},backend:n,attrs:{shape:[l,u]}}),m=n.makeTensorInfo([],"float32",new Float32Array([0]));let g;g=fe().getBool("WEBGL_PACK")?new ZF(l,o,d.shape.length,f.shape.length,c,p):new JF(l,o,d.shape.length,f.shape.length,c,p);const y=n.runWebGLProgram(g,[f,d,m],f.dtype),b=LC({inputs:{x:y},backend:n,attrs:{shape:i}});return n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),n.disposeIntermediateTensorInfo(y),n.disposeIntermediateTensorInfo(m),b}};class eO{constructor(e,t,n,s){this.variableNames=["sortedSequence","values"],this.customUniforms=[{name:"numInputs",type:"int"}],this.outputShape=[e,n];const r=`for (int i = 0; i < ${Math.ceil(Math.log2(t+1))}; ++i) { if (left >= right) break;`,a=2===fe().getNumber("WEBGL_VERSION")?"while (left < right) {":r,i="left"===s?"<":"<=";this.userCode=`\n       int findBound(int batch, float value) {\n         int left = 0;\n         int right = numInputs;\n         int mid;\n         ${a}\n           mid = (left + right) / 2;\n           if (getSortedSequence(batch, mid) ${i} value) {\n             left = mid + 1;\n           } else {\n             right = mid;\n           }\n         }\n         return right;\n       }\n\n       void main() {\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int valueIndex = coords[1];\n\n         float value = getValues(batch, valueIndex);\n\n         setOutput(float(findBound(batch, value)));\n       }\n     `}}const tO={kernelName:Wn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{sortedSequence:r,values:a}=t,{side:i}=s,o=new eO(r.shape[0],r.shape[1],a.shape[1],i),l=[[r.shape[1]]];return n.runWebGLProgram(o,[r,a],"int32",l)}};class nO{constructor(e,t,n){let s,r;if(this.variableNames=["c","a","b"],this.outputShape=t,n>4)throw Error(`Where for rank ${n} is not yet supported`);if(1===n)r="resRC",s="resRC";else{const n=["resRC.x","resRC.y","resRC.z","resRC.w"],a=[],i=[];for(let s=0;s<t.length;s++)i.push(`${n[s]}`),s<e&&a.push(`${n[s]}`);s=a.join(),r=i.join()}const a=_$(n);this.userCode=`\n      void main() {\n        ${a} resRC = getOutputCoords();\n        float cVal = getC(${s});\n        if (cVal >= 1.0) {\n          setOutput(getA(${r}));\n        } else {\n          setOutput(getB(${r}));\n        }\n      }\n    `}}const sO={kernelName:Vn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{condition:s,t:r,e:a}=t,i=new nO(s.shape.length,r.shape,r.shape.length);return n.runWebGLProgram(i,[s,r,a],Cr(r.dtype,a.dtype))}},rO=CC({opSnippet:`\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n  // see: https://arxiv.org/abs/1706.02515\n  float scaleAlpha = ${Ic};\n  float scale = ${Nc};\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\n`}),aO={kernelName:Un,backendName:"webgl",kernelFunc:rO},iO=CC({opSnippet:EC+"\n  return 1.0 / (1.0 + exp(-1.0 * x));\n",packedOpSnippet:"\n  vec4 result = 1.0 / (1.0 + exp(-1.0 * x));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",cpuKernelImpl:AE}),oO={kernelName:qn,backendName:"webgl",kernelFunc:iO},lO=CC({opSnippet:"\n  if (isnan(x)) { return 0.0; }\n  return sign(x);\n"}),uO={kernelName:Kn,backendName:"webgl",kernelFunc:lO},cO=CC({opSnippet:EC+"\n  return sin(x);\n",packedOpSnippet:`\n  vec4 result = sin(x);\n  bvec4 isNaN = isnan(x);\n  ${gC}\n  return result;\n`}),hO={kernelName:Hn,backendName:"webgl",kernelFunc:cO},pO=CC({opSnippet:"\n  float e2x = exp(x);\n  return (e2x - 1.0 / e2x) / 2.0;\n"}),dO={kernelName:jn,backendName:"webgl",kernelFunc:pO},fO=CC({opSnippet:"\n  float epsilon = 1.1920928955078125e-7;\n  float threshold = log(epsilon) + 2.0;\n\n  bool too_large = x > -threshold;\n  bool too_small = x < threshold;\n\n  float result;\n  float exp_x = exp(x);\n\n  if (too_large){\n    result = x;\n  }\n  else if (too_small){\n    result = exp_x;\n  }\n  else{\n    result = log(exp_x + 1.0);\n  }\n  return result;\n"}),mO={kernelName:Xn,backendName:"webgl",kernelFunc:fO},gO={kernelName:Zn,backendName:"webgl",kernelFunc:e=>{const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{blockShape:a,paddings:i}=s;F(r.shape.length<=4,(()=>"spaceToBatchND for rank > 4 with a WebGL backend not implemented yet"));const o=a.reduce(((e,t)=>e*t)),l=[[0,0]];l.push(...i);for(let e=1+a.length;e<r.shape.length;++e)l.push([0,0]);const u=[],c=gF({inputs:{x:r},backend:n,attrs:{paddings:l,constantValue:0}}),h=fc(c.shape,a,o,!1),p=mc(h.length,a.length,!1),d=gc(c.shape,a,o,!1),f=LC({inputs:{x:c},backend:n,attrs:{shape:h}}),m=KC({inputs:{x:f},backend:n,attrs:{perm:p}}),g=LC({inputs:{x:m},backend:n,attrs:{shape:d}});return u.push(c),u.push(f),u.push(m),u.forEach((e=>n.disposeIntermediateTensorInfo(e))),g}},yO={kernelName:ts,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{indices:s,values:r,denseShape:a,defaultValue:i}=t;if(1!==a.shape.length)throw new Error(`Dense shape must be a vector, saw:\n         ${a.shape}`);if(2!==s.shape.length)throw new Error(`Indices must be a matrix, saw:\n         ${s.shape}`);if(1!==r.shape.length)throw new Error(`Values must be a vector, saw:\n         ${r.shape}`);if(0!==i.shape.length)throw new Error(`Default value must be a scalar, saw:\n        ${i.shape}`);const o=n.readSync(s.dataId),l=n.readSync(r.dataId),u=n.readSync(a.dataId),c=n.readSync(i.dataId)[0],[h,p,d,f,m]=FE(o,s.shape,s.dtype,l,r.dtype,u,c);return[n.makeTensorInfo(p,s.dtype,h),n.makeTensorInfo([p[0]],r.dtype,d),n.makeTensorInfo([f.length],"bool",new Uint8Array(f.map((e=>Number(e))))),n.makeTensorInfo([m.length],s.dtype,new Int32Array(m))]}},bO={kernelName:ns,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{inputIndices:s,inputShape:r,newShape:a}=t;if(2!==s.shape.length)throw new Error(`Input indices should be a matrix but received shape ${s.shape}`);if(1!==r.shape.length)throw new Error(`Input shape should be a vector but received shape ${r.shape}`);if(1!==a.shape.length)throw new Error(`Target shape should be a vector but received shape ${a.shape}`);const i=Array.from(n.readSync(r.dataId)),o=n.readSync(s.dataId),l=Array.from(n.readSync(a.dataId)),[u,c,h]=OE(o,s.shape,s.dtype,i,l);return[n.makeTensorInfo(c,s.dtype,u),n.makeTensorInfo([h.length],a.dtype,new Int32Array(h))]}},xO={kernelName:ss,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{data:s,indices:r,segmentIds:a}=t;if(s.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==r.shape.length)throw new Error(`Indices should be a vector but received shape\n              ${r.shape}`);if(1!==a.shape.length)throw new Error(`Segment ids should be a vector but received shape\n              ${a.shape}`);const i=n.readSync(s.dataId),o=n.readSync(r.dataId),l=n.readSync(a.dataId),[u,c]=ME(i,s.shape,s.dtype,o,l,!0);return n.makeTensorInfo(c,s.dtype,u)}},wO={kernelName:rs,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n}=e,{data:s,indices:r,segmentIds:a}=t;if(s.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==r.shape.length)throw new Error(`Indices should be a vector but received shape\n             ${r.shape}`);if(1!==a.shape.length)throw new Error(`Segment ids should be a vector but received shape\n             ${a.shape}`);const i=n.readSync(s.dataId),o=n.readSync(r.dataId),l=n.readSync(a.dataId),[u,c]=ME(i,s.shape,s.dtype,o,l);return n.makeTensorInfo(c,s.dtype,u)}},kO={kernelName:as,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{sparseIndices:r,sparseValues:a,defaultValue:i}=t,{outputShape:o}=s,{sliceRank:l,numUpdates:u,sliceSize:c,strides:h,outputSize:p}=vc(0,r,o),d=!1;if("string"===a.dtype){const e=n.bufferSync(r),t=n.bufferSync(a),s=ar(n.readSync(i.dataId)[0]),f=RE(e,t,o,p,c,u,l,h,s,d);return n.makeTensorInfo(o,f.dtype,f.values)}const f=new JF(u,l,r.shape.length,a.shape.length,h,[p,1],d),m=n.runWebGLProgram(f,[a,r,i],a.dtype),g=LC({inputs:{x:m},backend:n,attrs:{shape:o}});return n.disposeIntermediateTensorInfo(m),g}},vO={kernelName:Qn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{numOrSizeSplits:a,axis:i}=s,o=G(i,r.shape)[0],l=Xc(r,a,o),u=r.shape.length,c=new Array(u).fill(0),h=r.shape.slice();return l.map((e=>{const t=[...h];t[o]=e;const s=UR({inputs:{x:r},backend:n,attrs:{begin:c,size:t}});return c[o]+=e,s}))}},IO="return sqrt(x);",NO=CC({opSnippet:IO,packedOpSnippet:IO,cpuKernelImpl:LE}),SO={kernelName:Yn,backendName:"webgl",kernelFunc:NO},TO={kernelName:os,backendName:"webgl",kernelFunc:CC({opSnippet:"return x * x;"})},$O="return (a - b) * (a - b);",EO=RC({opSnippet:$O,packedOpSnippet:$O}),CO={kernelName:is,backendName:"webgl",kernelFunc:EO},RO={kernelName:ls,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t;if("string"!==r.dtype)throw new Error("Input must be of datatype string");const a=hh(n.readSync(r.dataId)),i=zE(a,"string",s);return n.makeTensorInfo(r.shape,"string",i)}},AO={kernelName:Ns,backendName:"webgl",kernelFunc:function({inputs:e,attrs:t,backend:n}){const{x:s}=e,r=sC+`\n    return x > 0.0 ? 1.0 : float(${t.alpha});\n  `,a=new nC(s.shape,r);return n.runWebGLProgram(a,[s],s.dtype)}};class _O{constructor(e,t,n){this.variableNames=["x"],this.outputShape=n;const s=n.length,r=_$(n.length),a=_$(n.length);let i="";if(1===s)i="coords * strides + begin";else{let e=0;i=n.map(((t,s)=>(e++,1===n.length?`coords * strides[${s}] + begin[${s}]`:`coords[${e-1}] * strides[${s}] + begin[${s}]`))).join(",")}this.userCode=`\n      ${r} begin = ${r}(${e});\n      ${r} strides = ${r}(${t});\n\n      void main() {\n        ${a} coords = getOutputCoords();\n        setOutput(getX(${i}));\n      }\n    `}}const DO={kernelName:us,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{begin:a,end:i,strides:o,beginMask:l,endMask:u,ellipsisMask:c,newAxisMask:h,shrinkAxisMask:p}=s,{finalShapeSparse:d,finalShape:f,isIdentity:m,sliceDim0:g,isSimpleSlice:y,begin:b,end:x,strides:w}=qi(r.shape,a,i,o,l,u,c,h,p);let k;if(m)k=LC({inputs:{x:r},backend:n,attrs:{shape:f}});else if(g||y){F(r.shape.length>=1,(()=>`Input must have rank at least 1, got: ${r.shape.length}`));const e=Oi(b,x,w),t=UR({inputs:{x:r},backend:n,attrs:{begin:b,size:e}});k=LC({inputs:{x:t},backend:n,attrs:{shape:f}}),n.disposeIntermediateTensorInfo(t)}else if(n.shouldExecuteOnCPU([r])){const e=n.readSync(r.dataId),t=Ua(r.shape,r.dtype,e),s=BE(d,t,w,b);k=n.makeTensorInfo(f,r.dtype,s.values)}else{const e=new _O(b,w,d);k=n.runWebGLProgram(e,[r],r.dtype)}const v=LC({inputs:{x:k},backend:n,attrs:{shape:f}});return n.disposeIntermediateTensorInfo(k),v}},FO={kernelName:cs,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{separator:r,nGramWidths:a,leftPad:i,rightPad:o,padWidth:l,preserveShortSequences:u}=s,{data:c,dataSplits:h}=t,p=n.readSync(c.dataId),d=n.readSync(h.dataId),[f,m]=PE(p,d,r,a,i,o,l,u);return[n.makeTensorInfo([f.length],"string",f),n.makeTensorInfo(h.shape,"int32",m)]}},OO={kernelName:hs,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{skipEmpty:r}=s,{input:a,delimiter:i}=t;if("string"!==a.dtype)throw new Error("Input must be of datatype string");if(1!==a.shape.length)throw new Error(`Input must be a vector, got shape: ${a.shape}`);if(0!==i.shape.length)throw new Error(`Delimiter must be a scalar, got shape: ${i.shape}`);const o=n.readSync(a.dataId),l=n.readSync(i.dataId)[0],[u,c,h]=WE(o,l,r),p=c.length;return[n.makeTensorInfo([p,2],"int32",u),n.makeTensorInfo([p],"string",c),n.makeTensorInfo([2],"int32",new Int32Array(h))]}},MO={kernelName:ps,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{numBuckets:r}=s,{input:a}=t;if("string"!==a.dtype)throw new Error("Input must be of datatype string");if(r<=0)throw new Error("Number of buckets must be at least 1");const i=n.readSync(a.dataId),o=VE(i,r);return n.makeTensorInfo(a.shape,"int32",o)}},LO=CC({opSnippet:"return tan(x);"}),zO={kernelName:fs,backendName:"webgl",kernelFunc:LO},BO=CC({opSnippet:"\n  float e2x = exp(-2.0 * abs(x));\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\n"}),PO={kernelName:ms,backendName:"webgl",kernelFunc:BO},WO={kernelName:Pn,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{tensor:r,indices:a,updates:i}=t,{}=s,{sliceRank:o,numUpdates:l,sliceSize:u,strides:c,outputSize:h}=vc(0,a,r.shape),p=[h/u,u];if(0===h)return n.makeTensorInfo(r.shape,a.dtype);const d=LC({inputs:{x:a},backend:n,attrs:{shape:[l,o]}}),f=LC({inputs:{x:i},backend:n,attrs:{shape:[l,u]}}),m=LC({inputs:{x:r},backend:n,attrs:{shape:p}}),g=new JF(l,o,d.shape.length,f.shape.length,c,p,!1,!0),y=n.runWebGLProgram(g,[f,d,m],m.dtype),b=LC({inputs:{x:y},backend:n,attrs:{shape:r.shape}});return n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(y),b}};class VO{constructor(e,t){this.variableNames=["A"];const n=new Array(e.length);for(let s=0;s<n.length;s++)n[s]=e[s]*t[s];this.outputShape=n,this.rank=n.length;const s=_$(this.rank),r=function(e){const t=e.length;if(t>5)throw Error(`Tile for rank ${t} is not yet supported`);if(1===t)return`imod(resRC, ${e[0]})`;const n=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u"],s=[];for(let t=0;t<e.length;t++)s.push(`imod(${n[t]}, ${e[t]})`);return s.join()}(e);this.userCode=`\n      void main() {\n        ${s} resRC = getOutputCoords();\n        setOutput(getA(${r}));\n      }\n    `}}function UO(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{reps:a}=s;if("string"===r.dtype||r.shape.length>5){const e=n.readSync(r.dataId),t="string"===r.dtype?e.map((e=>ar(e))):e,s=Ua(r.shape,r.dtype,t),i=GE(s,a);return n.makeTensorInfo(i.shape,i.dtype,i.values)}const i=new VO(r.shape,a);return n.runWebGLProgram(i,[r],r.dtype)}const GO={kernelName:gs,backendName:"webgl",kernelFunc:UO};class HO{constructor(e){this.variableNames=["x","indices"],this.customUniforms=[{name:"n",type:"int"},{name:"firstPass",type:"int"},{name:"negativeInf",type:"float"},{name:"dir",type:"int"},{name:"inc",type:"int"}],this.outputShape=e,this.userCode="\n       void main() {\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // We compare elements pair-wise within a group of size 2 * inc.\n         // The comparing rule for each group alternates between ascending\n         // and descending. Within each group, we compare each pair at\n         // positions i and i+inc. To decide whether an element at position i\n         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than\n         // inc, it is in the first half of the group, we denote it as x0,\n         // otherwise we denote it as x1.\n         // For example, as shown in the Bitonic top K paper referenced above,\n         // Figure5(a) shows that element[1] is in the\n         // second half of the group when group size is 2, but it is in the\n         // first half of the group when group size is 4.\n\n         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;\n         int i = isFirstInPair ? elemIdx : elemIdx - inc;\n\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));\n         float x0 = i0 < n ? getX(batch, i0) : negativeInf;\n         float x1 = i1 < n ? getX(batch, i1) : negativeInf;\n\n         // Denotes which direction indices are in (ascending or descending).\n         bool reverse = imod(elemIdx, 2 * dir) >= dir;\n         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);\n         if (reverse == isGreater) { // Elements in opposite order of direction\n           int iTemp = i0;\n           i0 = i1;\n           i1 = iTemp;\n         }\n         if (isFirstInPair) {\n            setOutput(float(i0));\n         } else {\n            setOutput(float(i1));\n         }\n       }\n     "}}class jO{constructor(e){this.variableNames=["x","indices"],this.customUniforms=[{name:"n",type:"int"},{name:"firstPass",type:"int"},{name:"k",type:"int"}],this.outputShape=e,this.userCode="\n    void main() {\n         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // The output size is half of the previous size.\n         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),\n         // we only need to output the indices at positions |, the indices at\n         // positions _ can be thrown away, see Figure5(b) After Phase 2\n         // (Merge phase) in the Bitonic Top K paper referenced above.\n         // For example, the paper shows we only need to output the orange bars.\n         // The output sequence should look like this | | | | | | | |.\n         // Because the sequence is halved, to map the output index back\n         // to the previous sequence to find the corresponding value,\n         // we need to double the index. When we double the index,\n         // we basically interpolate a position, so 2i looks like\n         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position\n         // of each 2k positions by - elemIdx % k. E.g. for output at\n         // index 4,5,6,7, we want to get the corresponding element at\n         // original index 8,9,10,11, for output at index 8,9,10,11,\n         // we want to get the corresponding element at original index\n         // 16,17,18,19, so on and so forth.\n\n         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));\n\n         float x0 = getX(batch, i0);\n         float x1 = i1 < n ? getX(batch, i1) : x0;\n\n         setOutput(x0 >= x1 ? float(i0) : float(i1));\n       }\n     "}}function KO(e,t){null!==t&&e.disposeIntermediateTensorInfo(t)}function qO(e){let t=1;for(;t<e;)t*=2;return t}const XO={kernelName:ys,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r}=t,{k:a,sorted:i}=s,o=fe().getNumber("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD"),l=fe().getNumber("TOPK_K_CPU_HANDOFF_THRESHOLD"),u=r.shape,c=u[u.length-1];if(n.shouldExecuteOnCPU([r])||c<o||a>l){const e=n.readSync(r.dataId),[t,s]=HE(e,u,r.dtype,a,i);return[n.makeTensorInfo(t.shape,t.dtype,t.values),n.makeTensorInfo(s.shape,s.dtype,s.values)]}if(0===a)return u[u.length-1]=0,[n.makeTensorInfo(u,r.dtype,[]),n.makeTensorInfo(u,"int32",[])];if(1===c)return[r,$_({attrs:{shape:u,dtype:"int32",value:0},backend:n})];const h=n.texData.get(r.dataId),p=null!==h&&h.isPacked,d=p?n.unpackTensor(r):r,f=L(u)/c,m=LC({inputs:{x:d},attrs:{shape:[f,c]},backend:n});p&&KO(n,d);const g=qO(a),y=qO(c);let b=null;const x=()=>null===b?[m,m]:[m,b],w=(e,t,s)=>{const r=x(),a=new HO(s),i=[[c],[null===b?1:0],[Number.NEGATIVE_INFINITY],[e],[t]],o=b;b=n.runWebGLProgram(a,r,"int32",i),KO(n,o)};for(let e=1;e<g;e*=2){const t=2*e;for(let n=e;n>=1;n/=2)w(t,n,[f,y])}for(let e=y;e>g;e/=2){const t=x(),s=new jO([f,e/2]),r=[[c],[null===b?1:0],[g]],a=b;b=n.runWebGLProgram(s,t,"int32",r),KO(n,a);const i=g/2,o=2*i;for(let e=i;e>=1;e/=2)w(o,e,b.shape)}let k=b;b=UR({inputs:{x:b},backend:n,attrs:{begin:0,size:[f,a]}}),KO(n,k);let v=j_({inputs:{x:m,indices:b},backend:n,attrs:{axis:1,batchDims:1}});KO(n,m);const I=u.slice(0,-1);I.push(a),k=b,b=LC({inputs:{x:b},attrs:{shape:I},backend:n}),KO(n,k);const N=v;return v=LC({inputs:{x:v},attrs:{shape:I},backend:n}),KO(n,N),[v,b]}};class YO{constructor(e,t,n,s,r,a){this.variableNames=["Image","Transforms"],this.outputShape=a;const i="nearest"===n?1:2;let o;switch(s){case"constant":default:o=1;break;case"reflect":o=2;break;case"wrap":o=3;break;case"nearest":o=4}this.userCode=`\n            float mapCoord(float outCoord, float len) {\n              float inCoord = outCoord;\n              if(${o} == 2) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    if (inCoord < sz2) {\n                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +\n                      inCoord;\n                    }\n                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    inCoord -= sz2 * float(int(float(inCoord / sz2)));\n                    if (inCoord >= len) {\n                      inCoord = sz2 - inCoord - 1.0;\n                    }\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (${o} == 3) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord -= len * float(int(float(inCoord / sz)));\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (${o} == 4) {\n                return clamp(outCoord, 0.0, len - 1.0);\n              } else {\n                return outCoord;\n              }\n            }\n\n            float readWithFillValue(int batch, int coordY, int coordX,\n              int channel) {\n              float outputValue;\n              if (0 <= coordY && coordY < ${e} && 0 <= coordX && coordX < ${t}) {\n                  outputValue = getImage(batch, coordY, coordX, channel);\n              } else {\n                outputValue = float(${r});\n              }\n              return outputValue;\n            }\n\n            void main() {\n              ivec4 coords = getOutputCoords();\n              float outputValue;\n              int batch = coords[0];\n              int x = coords[2];\n              int y = coords[1];\n              int channel = coords[3];\n              float xf = float(x);\n              float yf = float(y);\n              float a1 = getTransforms(batch, 0);\n              float a2 = getTransforms(batch, 1);\n              float a3 = getTransforms(batch, 2);\n              float b1 = getTransforms(batch, 3);\n              float b2 = getTransforms(batch, 4);\n              float b3 = getTransforms(batch, 5);\n              float c1 = getTransforms(batch, 6);\n              float c2 = getTransforms(batch, 7);\n              float projection = c1 * xf + c2 * yf + 1.0;\n              if (projection == 0.0) {\n                outputValue = float(${r});\n              } else {\n                float inX = (a1 * xf + a2 * yf + a3) / projection;\n                float inY = (b1 * xf + b2 * yf + b3) / projection;\n                float mapX = mapCoord(inX, float(${t}));\n                float mapY = mapCoord(inY, float(${e}));\n\n                if (${i} == 1) {\n                  int coordY = int(round(mapY));\n                  int coordX = int(round(mapX));\n                  outputValue = readWithFillValue(batch, coordY, coordX,\n                    channel);\n                } else {\n                  float yFloor = floor(mapY);\n                  float xFloor = floor(mapX);\n                  float yCeil = yFloor + 1.0;\n                  float xCeil = xFloor + 1.0;\n                  float valueYFloor = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);\n                  float valueYCeil = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);\n                  outputValue = (yCeil - mapY) * valueYFloor +\n                  (mapY - yFloor) * valueYCeil;\n                }\n              }\n              setOutput(outputValue);\n            }\n        `}}const JO={kernelName:bs,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{image:r,transforms:a}=t,{interpolation:i,fillMode:o,fillValue:l,outputShape:u}=s,[c,h,p,d]=r.shape,[f,m]=null!=u?u:[h,p],g=new YO(h,p,i,o,l,[c,f,m,d]);return n.runWebGLProgram(g,[r,a],"float32")}},ZO={kernelName:ws,backendName:"webgl",kernelFunc:function(e){const{inputs:t,attrs:n,backend:s}=e,{axis:r}=n,{x:a}=t;m$(a,"unique"),console.warn("WARNING: ","UI might be locked temporarily as data is being downloaded");const i=s.readSync(a.dataId),{outputValues:o,outputShape:l,indices:u}=KE(i,r,a.shape,a.dtype);return[s.makeTensorInfo(l,a.dtype,o),s.makeTensorInfo([u.length],"int32",u)]}},QO={kernelName:ks,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{value:r}=t;let{axis:a}=s;a<0&&(a+=r.shape.length);const i=r,o=i.shape.length,l=r.shape[a],u=new Array(o-1);let c=0;for(let e=0;e<o;e++)e!==a&&(u[c++]=i.shape[e]);const h=[],p=new Array(o).fill(0),d=i.shape.slice();d[a]=1;const f=new Array(l);for(let e=0;e<f.length;e++){p[a]=e;const t=UR({inputs:{x:i},backend:n,attrs:{begin:p,size:d}}),s=LC({inputs:{x:t},backend:n,attrs:{shape:u}});f[e]=s,h.push(t)}return h.forEach((e=>n.disposeIntermediateTensorInfo(e))),f}};class eM{constructor(e,t){this.variableNames=["x","segmentIds"];const n=e.windowSize,s=e.batchSize,r=e.inSize,a=e.numSegments,i=a*Math.ceil(r/n);this.outputShape=[s,i];const o=4*Math.floor(n/4),l=n%4,u="\n        sumValue += dot(values, segFilter);\n    ";let c="";r%n>0&&(c=`\n        if (inIdx < 0 || inIdx >= ${r}) {\n          return initializationValue;\n        }\n      `);let h="";r%n>0&&(h=`\n        if (inIdx < 0 || inIdx >= ${r}) {\n          return -1.0;\n        }\n      `),this.userCode=`\n      const float initializationValue = 0.0;\n\n      float getValue(int batch, int inIdx) {\n        ${c}\n        return getX(batch, inIdx);\n      }\n\n      float getSegmentIdAtIndex(int inIdx) {\n        ${h}\n        return getSegmentIds(inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = int(floor(float(outIdx) / float(\n          ${a})) * float(${n}));\n        int currentSeg = int(mod(float(outIdx), float(${a})));\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${o}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\n          );\n\n          ${u}\n        }\n\n        int inIdx = inOffset + ${o};\n        if (${1===l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            0,\n            0,\n            0\n          );\n\n          ${u}\n        } else if (${2===l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n              0,\n              0\n          );\n\n          ${u}\n        } else if (${3===l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            0\n          );\n\n          ${u}\n        }\n        setOutput(sumValue);\n      }\n    `}}const tM={kernelName:vs,backendName:"webgl",kernelFunc:function(e){const{inputs:t,backend:n,attrs:s}=e,{x:r,segmentIds:a}=t,{numSegments:i}=s,o=r.shape.length,l=[];let u=0;const c=il([u],o);let h=r;null!=c&&(h=KC({inputs:{x:r},backend:n,attrs:{perm:c}}),l.push(h),u=ll(1,o)[0]);const p=uh(h.shape,u,i),d=L([h.shape[u]]),f=LC({inputs:{x:h},backend:n,attrs:{shape:[-1,d]}});l.push(f);const m=Rr(r.dtype),g=(e,t,s,r,a)=>{const i=e.shape[0],o=e.shape[1],u=lh(o,a),c=new eM({windowSize:u,inSize:o,batchSize:i,numSegments:a},t),h=n.compileAndRun(c,[e,s],r);if(l.push(h),h.shape[1]===a)return h;const p=NF({backend:n,attrs:{start:0,stop:a,step:1,dtype:"float32"}}),d=UO({inputs:{x:p},backend:n,attrs:{reps:[o/u]}});return l.push(p),l.push(d),g(h,t,d,r,a)},y=LC({inputs:{x:g(f,"unsortedSegmentSum",a,m,i)},backend:n,attrs:{shape:p}});let b=y;if(null!=c){l.push(y);const e=ol(c);b=KC({inputs:{x:b},backend:n,attrs:{perm:e}})}return l.forEach((e=>n.disposeIntermediateTensorInfo(e))),b}},nM=[YC,ZC,eR,nR,aR,lR,uR,cR,gR,yR,xR,kR,IR,SR,$R,RR,AR,FR,OR,MR,BR,HR,jR,KR,qR,QR,nA,aA,kC,lA,gA,NA,CA,AA,_A,DA,FA,MA,zA,PA,jA,KA,qA,YA,QA,n_,s_,a_,o_,l_,c_,h_,d_,m_,y_,x_,v_,S_,E_,R_,D_,O_,z_,W_,V_,G_,K_,X_,J_,xC,Z_,dA,eD,nD,rD,NC,iD,lD,uD,hD,dD,mD,yD,xD,vD,ND,TD,ED,CD,RD,DD,FD,OD,MD,LD,BD,VD,GD,QD,MC,tF,sF,aF,oF,YR,uF,pF,dF,yF,xF,$C,wF,kF,vF,IF,SF,ZR,KD,$F,CF,AF,zC,FF,MF,BF,WF,GF,jF,qF,YF,QF,tO,sO,aO,oO,uO,hO,dO,GR,ZD,mO,gO,yO,bO,xO,wO,kO,vO,SO,TO,CO,RO,AO,DO,FO,OO,MO,YD,jC,zO,PO,WO,GO,XO,JO,qC,ZO,QO,tM,hF];for(const e of nM)Ms(e);class sM{refCount(e){return rM("refCount")}incRef(e){return rM("incRef")}timerAvailable(){return!0}time(e){return rM("time")}read(e){return rM("read")}readSync(e){return rM("readSync")}readToGPU(e,t){return rM("readToGPU")}numDataIds(){return rM("numDataIds")}disposeData(e,t){return rM("disposeData")}write(e,t,n){return rM("write")}move(e,t,n,s,r){return rM("move")}memory(){return rM("memory")}floatPrecision(){return rM("floatPrecision")}epsilon(){return 32===this.floatPrecision()?1e-7:1e-4}dispose(){return rM("dispose")}}function rM(e){throw new Error(`'${e}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`)}function aM(e,t){if(!e)throw new Error("string"==typeof t?t:t())}function iM(e,t,n=""){aM(cM(e,t),(()=>n+` Shapes ${e} and ${t} must match`))}function oM(e){aM(null!=e,(()=>"The input to the tensor constructor must be a non-null value."))}function lM(e,t=[],n=!1){if(null==t&&(t=[]),Array.isArray(e)||fM(e)&&!n)for(let s=0;s<e.length;++s)lM(e[s],t,n);else t.push(e);return t}function uM(e){if(0===e.length)return 1;let t=e[0];for(let n=1;n<e.length;n++)t*=e[n];return t}function cM(e,t){if(e===t)return!0;if(null==e||null==t)return!1;if(e.length!==t.length)return!1;for(let n=0;n<e.length;n++)if(e[n]!==t[n])return!1;return!0}function hM(e){return e%1==0}function pM(e,t){return t<=e.length?e:e+" ".repeat(t-e.length)}function dM(e,t){const n=t.length;return aM((e=null==e?t.map(((e,t)=>t)):[].concat(e)).every((e=>e>=-n&&e<n)),(()=>`All values in axis param must be in range [-${n}, ${n}) but got axis ${e}`)),aM(e.every((e=>hM(e))),(()=>`All values in axis param must be integers but got axis ${e}`)),e.map((e=>e<0?n+e:e))}function fM(e){return e instanceof Float32Array||e instanceof Int32Array||e instanceof Uint8Array||e instanceof Uint8ClampedArray}function mM(e){if("float32"===e||"int32"===e)return 4;if("complex64"===e)return 8;if("bool"===e)return 1;throw new Error(`Unknown dtype ${e}`)}function gM(e){return"string"==typeof e||e instanceof String}function yM(e){return Array.isArray(e)?yM(e[0]):e instanceof Float32Array?"float32":e instanceof Int32Array||e instanceof Uint8Array||e instanceof Uint8ClampedArray?"int32":"number"==typeof e?"float32":gM(e)?"string":"boolean"==typeof e?"bool":"float32"}function bM(e){return!!(e&&e.constructor&&e.call&&e.apply)}function xM(e){const t=e.length;if(t<2)return[];const n=new Array(t-1);n[t-2]=e[t-1];for(let s=t-3;s>=0;--s)n[s]=n[s+1]*e[s+1];return n}function wM(e,t,n,s=!1){const r=new Array;if(1===t.length){const a=t[0]*(s?2:1);for(let t=0;t<a;t++)r[t]=n[e+t]}else{const a=t[0],i=t.slice(1),o=i.reduce(((e,t)=>e*t))*(s?2:1);for(let t=0;t<a;t++)r[t]=wM(e+t*o,i,n,s)}return r}function kM(e,t,n=!1){if(0===e.length)return t[0];const s=e.reduce(((e,t)=>e*t))*(n?2:1);if(0===s)return[];if(s!==t.length)throw new Error(`[${e}] does not match the input size ${t.length}${n?" for a complex tensor":""}.`);return wM(0,e,t,n)}function vM(e,t){const n=IM(e,t);for(let e=0;e<n.length;e++)n[e]=1;return n}function IM(e,t){if(null==t||"float32"===t||"complex64"===t)return new Float32Array(e);if("int32"===t)return new Int32Array(e);if("bool"===t)return new Uint8Array(e);throw new Error(`Unknown data type ${t}`)}function NM(e){e.forEach((t=>{aM(Number.isInteger(t)&&t>=0,(()=>`Tensor must have a shape comprised of positive integers but got shape [${e}].`))}))}function SM(e){return e&&e.then&&"function"==typeof e.then}const TM="tfjsflags";class $M{constructor(e){this.global=e,this.flags={},this.flagRegistry={},this.urlFlags={},this.getQueryParams=EM,this.populateURLFlags()}setPlatform(e,t){null!=this.platform&&(CM().getBool("IS_TEST")||CM().getBool("PROD")||console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${e}.`)),this.platformName=e,this.platform=t}registerFlag(e,t,n){if(this.flagRegistry[e]={evaluationFn:t,setHook:n},null!=this.urlFlags[e]){const t=this.urlFlags[e];CM().getBool("IS_TEST")||CM().getBool("PROD")||console.warn(`Setting feature override from URL ${e}: ${t}.`),this.set(e,t)}}async getAsync(e){return e in this.flags||(this.flags[e]=await this.evaluateFlag(e)),this.flags[e]}get(e){if(e in this.flags)return this.flags[e];const t=this.evaluateFlag(e);if(SM(t))throw new Error(`Flag ${e} cannot be synchronously evaluated. Please use getAsync() instead.`);return this.flags[e]=t,this.flags[e]}getNumber(e){return this.get(e)}getBool(e){return this.get(e)}getFlags(){return this.flags}get features(){return this.flags}set(e,t){if(null==this.flagRegistry[e])throw new Error(`Cannot set flag ${e} as it has not been registered.`);this.flags[e]=t,null!=this.flagRegistry[e].setHook&&this.flagRegistry[e].setHook(t)}evaluateFlag(e){if(null==this.flagRegistry[e])throw new Error(`Cannot evaluate flag '${e}': no evaluation function found.`);return this.flagRegistry[e].evaluationFn()}setFlags(e){this.flags=Object.assign({},e)}reset(){this.flags={},this.urlFlags={},this.populateURLFlags()}populateURLFlags(){if(void 0===this.global||void 0===this.global.location||void 0===this.global.location.search)return;const e=this.getQueryParams(this.global.location.search);TM in e&&e[TM].split(",").forEach((e=>{const[t,n]=e.split(":");this.urlFlags[t]=function(e,t){if("true"===(t=t.toLowerCase())||"false"===t)return"true"===t;if(""+ +t===t)return+t;throw new Error(`Could not parse value flag value ${t} for flag ${e}.`)}(t,n)}))}}function EM(e){const t={};return e.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g,((e,...n)=>(function(e,t,n){e[decodeURIComponent(t)]=decodeURIComponent(n||"")}(t,n[0],n[1]),n.join("=")))),t}function CM(){return AM}let RM,AM=null;function _M(){if(null==RM){let e;if("undefined"!=typeof window)e=window;else if(void 0!==n.g)e=n.g;else if("undefined"!=typeof process)e=process;else{if("undefined"==typeof self)throw new Error("Could not find a global object");e=self}RM=e}return RM}function DM(e,t){const n=function(){const e=_M();return null==e._tfGlobals&&(e._tfGlobals=new Map),e._tfGlobals}();if(n.has(e))return n.get(e);{const s=t();return n.set(e,s),n.get(e)}}const FM="Cast",OM="Fill",MM="Identity",LM="LinSpace",zM="Range",BM="Tile",PM="Transpose",WM="_FusedMatMul",VM="FusedConv2D",UM="FusedDepthwiseConv2D",GM=DM("kernelRegistry",(()=>new Map)),HM=DM("gradRegistry",(()=>new Map));function jM(e,t){const n=function(e,t){return`${t}_${e}`}(e,t);return GM.get(n)}function KM(e){return HM.get(e)}function qM(e){const t=GM.entries(),n=[];for(;;){const{done:s,value:r}=t.next();if(s)break;const[a,i]=r,[o]=a.split("_");o===e&&n.push(i)}return n}function XM(...e){CM().getBool("IS_TEST")||CM().getBool("PROD")||console.warn(...e)}const YM=Ws()||Ps;function JM(e){return YM.fromString(e,!0,16)}function ZM(e,t){if("string"===t)throw new Error("Cannot convert a string[] to a TypedArray");if(Array.isArray(e)&&(e=lM(e)),CM().getBool("DEBUG")&&function(e,t){for(let n=0;n<e.length;n++){const s=e[n];if(isNaN(s)||!isFinite(s))throw Error(`A tensor of type ${t} being uploaded contains ${s}.`)}}(e,t),function(e,t){return e instanceof Float32Array&&"float32"===t||e instanceof Int32Array&&"int32"===t||e instanceof Uint8Array&&"bool"===t}(e,t))return e;if(null==t||"float32"===t||"complex64"===t)return new Float32Array(e);if("int32"===t)return new Int32Array(e);if("bool"===t){const t=new Uint8Array(e.length);for(let n=0;n<t.length;++n)0!==Math.round(e[n])&&(t[n]=1);return t}throw new Error(`Unknown data type ${t}`)}function QM(){return CM().platform.now()}function eL(e,t="utf-8"){return t=t||"utf-8",CM().platform.decode(e,t)}JM("c3a5c85c97cb3127"),JM("b492b66fbe98f273"),JM("9ae16a3b2f90404f");class tL{constructor(e,t){this.backendTimer=e,this.logger=t,null==t&&(this.logger=new sL)}profileKernel(e,t,n){let s;const r=()=>{s=n()};let a;const i=QM();if(this.backendTimer.timerAvailable())a=this.backendTimer.time(r);else{r();for(const e of s)e.dataSync();a=Promise.resolve({kernelMs:QM()-i})}if(CM().getBool("CHECK_COMPUTATION_FOR_ERRORS"))for(let t=0;t<s.length;t++){const n=s[t];n.data().then((t=>{nL(t,n.dtype,e)}))}return{kernelName:e,outputs:s,inputs:t,timeMs:a.then((e=>e.kernelMs)),extraInfo:a.then((e=>null!=e.getExtraProfileInfo?e.getExtraProfileInfo():""))}}logKernelProfile(e){const{kernelName:t,outputs:n,timeMs:s,inputs:r,extraInfo:a}=e;n.forEach((e=>{Promise.all([e.data(),s,a]).then((n=>{this.logger.logKernelProfile(t,e,n[0],n[1],r,n[2])}))}))}}function nL(e,t,n){if("float32"!==t)return!1;for(let t=0;t<e.length;t++){const s=e[t];if(isNaN(s)||!isFinite(s))return console.warn(`Found ${s} in the result of '${n}'`),!0}return!1}class sL{logKernelProfile(e,t,n,s,r,a){const i="number"==typeof s?pM(`${s}ms`,9):s.error,o=pM(e,25),l=t.rank,u=t.size,c=pM(t.shape.toString(),14);let h="";for(const e in r){const n=r[e];if(null!=n){const s=n.shape||t.shape,r=s.length;h+=`${e}: ${r}D ${r>0?s:""} `}}console.log(`%c${o}\t%c${i}\t%c${l}D ${c}\t%c${u}\t%c${h}\t%c${a}`,"font-weight:bold","color:red","color:blue","color: orange","color: green","color: steelblue")}}function rL(e,t,n,s){const r=xM(t),a=function(e,t,n,s){const r=uM(t),a=s[s.length-1],i=new Array(a).fill(0),o=t.length,l="complex64"===n?lL(e):e;if(o>1)for(let e=0;e<r/a;e++){const t=e*a;for(let e=0;e<a;e++)i[e]=Math.max(i[e],aL(l[t+e],0,n).length)}return i}(e,t,n,r),i=t.length,o=oL(e,t,n,r,a),l=["Tensor"];return s&&(l.push(`  dtype: ${n}`),l.push(`  rank: ${i}`),l.push(`  shape: [${t}]`),l.push("  values:")),l.push(o.map((e=>"    "+e)).join("\n")),l.join("\n")}function aL(e,t,n){let s;return s=Array.isArray(e)?`${parseFloat(e[0].toFixed(7))} + ${parseFloat(e[1].toFixed(7))}j`:gM(e)?`'${e}'`:"bool"===n?iL(e):parseFloat(e.toFixed(7)).toString(),pM(s,t)}function iL(e){return 0===e?"false":"true"}function oL(e,t,n,s,r,a=!0){const i="complex64"===n?2:1,o=t[0],l=t.length;if(0===l)return"complex64"===n?[aL(lL(e)[0],0,n)]:"bool"===n?[iL(e[0])]:[e[0].toString()];if(1===l){if(o>20){const t=3*i;let s=Array.from(e.slice(0,t)),a=Array.from(e.slice((o-3)*i,o*i));return"complex64"===n&&(s=lL(s),a=lL(a)),["["+s.map(((e,t)=>aL(e,r[t],n))).join(", ")+", ..., "+a.map(((e,t)=>aL(e,r[o-3+t],n))).join(", ")+"]"]}return["["+("complex64"===n?lL(e):Array.from(e)).map(((e,t)=>aL(e,r[t],n))).join(", ")+"]"]}const u=t.slice(1),c=s.slice(1),h=s[0]*i,p=[];if(o>20){for(let t=0;t<3;t++){const s=t*h,a=s+h;p.push(...oL(e.slice(s,a),u,n,c,r,!1))}p.push("...");for(let t=o-3;t<o;t++){const s=t*h,a=s+h;p.push(...oL(e.slice(s,a),u,n,c,r,t===o-1))}}else for(let t=0;t<o;t++){const s=t*h,a=s+h;p.push(...oL(e.slice(s,a),u,n,c,r,t===o-1))}const d=2===l?",":"";p[0]="["+p[0]+d;for(let e=1;e<p.length-1;e++)p[e]=" "+p[e]+d;let f=",\n";for(let e=2;e<l;e++)f+="\n";return p[p.length-1]=" "+p[p.length-1]+"]"+(a?"":f),p}function lL(e){const t=[];for(let n=0;n<e.length;n+=2)t.push([e[n],e[n+1]]);return t}class uL{constructor(e,t,n){if(this.dtype=t,this.shape=e.slice(),this.size=uM(e),null!=n){const e=n.length;aM(e===this.size,(()=>`Length of values '${e}' does not match the size inferred by the shape '${this.size}'.`))}if("complex64"===t)throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");this.values=n||function(e,t){let n=null;if(null==e||"float32"===e)n=new Float32Array(t);else if("int32"===e)n=new Int32Array(t);else if("bool"===e)n=new Uint8Array(t);else{if("string"!==e)throw new Error(`Unknown data type ${e}`);n=new Array(t)}return n}(t,this.size),this.strides=xM(e)}set(e,...t){0===t.length&&(t=[0]),aM(t.length===this.rank,(()=>`The number of provided coordinates (${t.length}) must match the rank (${this.rank})`));const n=this.locToIndex(t);this.values[n]=e}get(...e){0===e.length&&(e=[0]);let t=0;for(const n of e){if(n<0||n>=this.shape[t]){const t=`Requested out of range element at ${e}.   Buffer shape=${this.shape}`;throw new Error(t)}t++}let n=e[e.length-1];for(let t=0;t<e.length-1;++t)n+=this.strides[t]*e[t];return this.values[n]}locToIndex(e){if(0===this.rank)return 0;if(1===this.rank)return e[0];let t=e[e.length-1];for(let n=0;n<e.length-1;++n)t+=this.strides[n]*e[n];return t}indexToLoc(e){if(0===this.rank)return[];if(1===this.rank)return[e];const t=new Array(this.shape.length);for(let n=0;n<t.length-1;++n)t[n]=Math.floor(e/this.strides[n]),e-=t[n]*this.strides[n];return t[t.length-1]=e,t}get rank(){return this.shape.length}toTensor(){return cL().makeTensor(this.values,this.shape,this.dtype)}}let cL=null,hL=null,pL=null;class dL{constructor(e,t,n,s){this.kept=!1,this.isDisposedInternal=!1,this.shape=e.slice(),this.dtype=t||"float32",this.size=uM(e),this.strides=xM(e),this.dataId=n,this.id=s,this.rankType=this.rank<5?this.rank.toString():"higher"}get rank(){return this.shape.length}async buffer(){const e=await this.data();return hL.buffer(this.shape,this.dtype,e)}bufferSync(){return hL.buffer(this.shape,this.dtype,this.dataSync())}async array(){const e=await this.data();return kM(this.shape,e,"complex64"===this.dtype)}arraySync(){return kM(this.shape,this.dataSync(),"complex64"===this.dtype)}async data(){this.throwIfDisposed();const e=cL().read(this.dataId);if("string"===this.dtype){const t=await e;try{return t.map((e=>eL(e)))}catch(e){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}}return e}dataToGPU(e){return this.throwIfDisposed(),cL().readToGPU(this.dataId,e)}dataSync(){this.throwIfDisposed();const e=cL().readSync(this.dataId);if("string"===this.dtype)try{return e.map((e=>eL(e)))}catch(e){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}return e}async bytes(){this.throwIfDisposed();const e=await cL().read(this.dataId);return"string"===this.dtype?e:new Uint8Array(e.buffer)}dispose(){this.isDisposed||(cL().disposeTensor(this),this.isDisposedInternal=!0)}get isDisposed(){return this.isDisposedInternal}throwIfDisposed(){if(this.isDisposed)throw new Error("Tensor is disposed.")}print(e=!1){return hL.print(this,e)}clone(){return this.throwIfDisposed(),hL.clone(this)}toString(e=!1){return rL(this.dataSync(),this.shape,this.dtype,e)}cast(e){return this.throwIfDisposed(),hL.cast(this,e)}variable(e=!0,t,n){return this.throwIfDisposed(),cL().makeVariable(this,e,t,n)}}Object.defineProperty(dL,Symbol.hasInstance,{value:e=>!!e&&null!=e.data&&null!=e.dataSync&&null!=e.throwIfDisposed}),DM("Tensor",(()=>dL));class fL extends dL{constructor(e,t,n,s){super(e.shape,e.dtype,e.dataId,s),this.trainable=t,this.name=n}assign(e){if(e.dtype!==this.dtype)throw new Error(`dtype of the new value (${e.dtype}) and previous value (${this.dtype}) must match`);if(!cM(e.shape,this.shape))throw new Error(`shape of the new value (${e.shape}) and previous value (${this.shape}) must match`);cL().disposeTensor(this),this.dataId=e.dataId,cL().incRef(this,null)}dispose(){cL().disposeVariable(this),this.isDisposedInternal=!0}}var mL,gL,yL,bL,xL;Object.defineProperty(fL,Symbol.hasInstance,{value:e=>e instanceof dL&&null!=e.assign&&e.assign instanceof Function}),function(e){e.R0="R0",e.R1="R1",e.R2="R2",e.R3="R3",e.R4="R4",e.R5="R5",e.R6="R6"}(mL||(mL={})),function(e){e.float32="float32",e.int32="int32",e.bool="int32",e.complex64="complex64"}(gL||(gL={})),function(e){e.float32="float32",e.int32="int32",e.bool="bool",e.complex64="complex64"}(yL||(yL={})),function(e){e.float32="float32",e.int32="float32",e.bool="float32",e.complex64="complex64"}(bL||(bL={})),function(e){e.float32="complex64",e.int32="complex64",e.bool="complex64",e.complex64="complex64"}(xL||(xL={}));const wL={float32:bL,int32:gL,bool:yL,complex64:xL};function kL(e,t){if(e.dtype===t.dtype)return[e,t];const n=function(e,t){if("string"===e||"string"===t){if("string"===e&&"string"===t)return"string";throw new Error(`Can not upcast ${e} with ${t}`)}return wL[e][t]}(e.dtype,t.dtype);return[e.cast(n),t.cast(n)]}function vL(e){const t=[];return IL(e,t,new Set),t}function IL(e,t,n){if(null==e)return;if(e instanceof dL)return void t.push(e);if(s=e,!Array.isArray(s)&&"object"!=typeof s)return;var s;const r=e;for(const e in r){const s=r[e];n.has(s)||(n.add(s),IL(s,t,n))}}function NL(e){return null!=e.kernelName}class SL{constructor(){this.registeredVariables={},this.nextTapeNodeId=0,this.numBytes=0,this.numTensors=0,this.numStringTensors=0,this.numDataBuffers=0,this.gradientDepth=0,this.kernelDepth=0,this.scopeStack=[],this.numDataMovesStack=[],this.nextScopeId=0,this.tensorInfo=new WeakMap,this.profiling=!1,this.activeProfile={newBytes:0,newTensors:0,peakBytes:0,kernels:[],result:null,get kernelNames(){return Array.from(new Set(this.kernels.map((e=>e.name))))}}}dispose(){for(const e in this.registeredVariables)this.registeredVariables[e].dispose()}}class TL{constructor(e){this.ENV=e,this.registry={},this.registryFactory={},this.pendingBackendInitId=0,this.state=new SL}async ready(){if(null!=this.pendingBackendInit)return this.pendingBackendInit.then((()=>{}));if(null!=this.backendInstance)return;const e=this.getSortedBackends();for(let t=0;t<e.length;t++){const n=e[t];if(await this.initializeBackend(n).success)return void await this.setBackend(n)}throw new Error("Could not initialize any backends, all backend initializations failed.")}get backend(){if(null!=this.pendingBackendInit)throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);if(null==this.backendInstance){const{name:e,asyncInit:t}=this.initializeBackendsAndReturnBest();if(t)throw new Error(`The highest priority backend '${e}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);this.setBackend(e)}return this.backendInstance}backendNames(){return Object.keys(this.registryFactory)}findBackend(e){if(!(e in this.registry)){if(!(e in this.registryFactory))return null;{const{asyncInit:t}=this.initializeBackend(e);if(t)return null}}return this.registry[e]}findBackendFactory(e){return e in this.registryFactory?this.registryFactory[e].factory:null}registerBackend(e,t,n=1){return e in this.registryFactory?(XM(`${e} backend was already registered. Reusing existing backend factory.`),!1):(this.registryFactory[e]={factory:t,priority:n},!0)}async setBackend(e){if(null==this.registryFactory[e])throw new Error(`Backend name '${e}' not found in registry`);if(this.backendName=e,null==this.registry[e]){this.backendInstance=null;const{success:t,asyncInit:n}=this.initializeBackend(e);if(!(n?await t:t))return!1}return this.backendInstance=this.registry[e],this.setupRegisteredKernels(),this.profiler=new tL(this.backendInstance),!0}setupRegisteredKernels(){qM(this.backendName).forEach((e=>{null!=e.setupFunc&&e.setupFunc(this.backendInstance)}))}disposeRegisteredKernels(e){qM(e).forEach((t=>{null!=t.disposeFunc&&t.disposeFunc(this.registry[e])}))}initializeBackend(e){const t=this.registryFactory[e];if(null==t)throw new Error(`Cannot initialize backend ${e}, no registration found.`);try{const n=t.factory();if(!n||n instanceof sM||"function"!=typeof n.then)return this.registry[e]=n,{success:!0,asyncInit:!1};{const t=++this.pendingBackendInitId,s=n.then((n=>!(t<this.pendingBackendInitId||(this.registry[e]=n,this.pendingBackendInit=null,0)))).catch((n=>(t<this.pendingBackendInitId||(this.pendingBackendInit=null,XM(`Initialization of backend ${e} failed`),XM(n.stack||n.message)),!1)));return this.pendingBackendInit=s,{success:s,asyncInit:!0}}}catch(t){return XM(`Initialization of backend ${e} failed`),XM(t.stack||t.message),{success:!1,asyncInit:!1}}}removeBackend(e){if(!(e in this.registryFactory))throw new Error(`${e} backend not found in registry`);this.backendName===e&&null!=this.pendingBackendInit&&this.pendingBackendInitId++,e in this.registry&&(this.disposeRegisteredKernels(e),this.registry[e].dispose(),delete this.registry[e]),delete this.registryFactory[e],this.backendName===e&&(this.pendingBackendInit=null,this.backendName=null,this.backendInstance=null)}getSortedBackends(){if(0===Object.keys(this.registryFactory).length)throw new Error("No backend found in registry.");return Object.keys(this.registryFactory).sort(((e,t)=>this.registryFactory[t].priority-this.registryFactory[e].priority))}initializeBackendsAndReturnBest(){const e=this.getSortedBackends();for(let t=0;t<e.length;t++){const n=e[t],{success:s,asyncInit:r}=this.initializeBackend(n);if(r||s)return{name:n,asyncInit:r}}throw new Error("Could not initialize any backends, all backend initializations failed.")}moveData(e,t){const n=this.state.tensorInfo.get(t),s=n.backend,r=this.readSync(t),a=s.refCount(t);s.disposeData(t,!0),n.backend=e,e.move(t,r,n.shape,n.dtype,a),this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack[this.state.numDataMovesStack.length-1]++}tidy(e,t){let n,s=null;if(null==t){if("function"!=typeof e)throw new Error("Please provide a function to tidy()");t=e}else{if("string"!=typeof e&&!(e instanceof String))throw new Error("When calling with two arguments, the first argument to tidy() must be a string");if("function"!=typeof t)throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");s=e}return this.scopedRun((()=>this.startScope(s)),(()=>this.endScope(n)),(()=>(n=t(),n instanceof Promise&&console.error("Cannot return a Promise inside of tidy."),n)))}scopedRun(e,t,n){e();try{const e=n();return t(),e}catch(e){throw t(),e}}nextTensorId(){return TL.nextTensorId++}nextVariableId(){return TL.nextVariableId++}clone(e){const t=EL.runKernel(MM,{x:e}),n={x:e};return this.addTapeNode(this.state.activeScope.name,n,[t],(e=>({x:()=>{const t={x:e};return EL.runKernel(FM,t,{dtype:"float32"})}})),[],{}),t}runKernel(e,t,n){if(null==this.backendName&&this.backend,null==jM(e,this.backendName))throw new Error(`Kernel '${e}' not registered for backend '${this.backendName}'`);return this.runKernelFunc({kernelName:e,inputs:t,attrs:n})}shouldCheckForMemLeaks(){return this.ENV.getBool("IS_TEST")}checkKernelForMemLeak(e,t,n){const s=this.backend.numDataIds();let r=0;n.forEach((e=>{r+="complex64"===e.dtype?3:1}));const a=this.state.numDataMovesStack[this.state.numDataMovesStack.length-1],i=s-t-r-a;if(i>0)throw new Error(`Backend '${this.backendName}' has an internal memory leak (${i} data ids) after running '${e}'`)}runKernelFunc(e){let t,n=[];const s=this.isTapeOn(),r=this.state.numBytes,a=this.state.numTensors;let i,o;this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack.push(0),null==this.backendName&&this.backend;const l=NL(e)?e.kernelName:null!=this.state.activeScope?this.state.activeScope.name:"";if(NL(e)){const{kernelName:t,inputs:r,attrs:a}=e;null==this.backendName&&this.backend;const l=jM(t,this.backendName);aM(null!=l,(()=>`Cannot find registered kernel '${t}' for backend '${this.backendName}'`)),i=()=>{const e=this.backend.numDataIds();o=l.kernelFunc({inputs:r,attrs:a,backend:this.backend});const i=Array.isArray(o)?o:[o];this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(t,e,i);const u=i.map((e=>null!=e.rank?e:this.makeTensorFromTensorInfo(e)));if(s){const e=this.getTensorsForGradient(t,r,u);n=this.saveTensorsForBackwardMode(e)}return u}}else{const{forwardFunc:t}=e,r=e=>{s&&(n=e.map((e=>this.keep(this.clone(e)))))};i=()=>{const e=this.backend.numDataIds();o=this.tidy((()=>t(this.backend,r)));const n=Array.isArray(o)?o:[o];return this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(l,e,n),n}}const{inputs:u,attrs:c}=e,h=NL(e)?null:e.backwardsFunc;let p;return this.scopedRun((()=>this.state.kernelDepth++),(()=>this.state.kernelDepth--),(()=>{this.ENV.getBool("DEBUG")||this.state.profiling?(p=this.profiler.profileKernel(l,u,(()=>i())),this.ENV.getBool("DEBUG")&&this.profiler.logKernelProfile(p),t=p.outputs):t=i()})),s&&this.addTapeNode(l,u,t,h,n,c),this.state.profiling&&this.state.activeProfile.kernels.push({name:l,bytesAdded:this.state.numBytes-r,totalBytesSnapshot:this.state.numBytes,tensorsAdded:this.state.numTensors-a,totalTensorsSnapshot:this.state.numTensors,inputShapes:Object.keys(u).map((e=>null!=u[e]?u[e].shape:null)),outputShapes:t.map((e=>e.shape)),kernelTimeMs:p.timeMs,extraInfo:p.extraInfo}),Array.isArray(o)?t:t[0]}saveTensorsForBackwardMode(e){return e.map((e=>this.keep(this.clone(e))))}getTensorsForGradient(e,t,n){const s=KM(e);if(null!=s){const e=s.inputsToSave||[],r=s.outputsToSave||[];let a;s.saveAllInputs?(aM(Array.isArray(t),(()=>"saveAllInputs is true, expected inputs to be an array.")),a=Object.keys(t).map((e=>t[e]))):a=e.map((e=>t[e]));const i=n.filter(((e,t)=>r[t]));return a.concat(i)}return[]}makeTensor(e,t,n,s){if(null==e)throw new Error("Values passed to engine.makeTensor() are null");n=n||"float32",s=s||this.backend;let r=e;"string"===n&&gM(e[0])&&(r=e.map((e=>function(e,t="utf-8"){return t=t||"utf-8",CM().platform.encode(e,t)}(e))));const a=s.write(r,t,n),i=new dL(t,n,a,this.nextTensorId());if(this.trackTensor(i,s),"string"===n){const e=this.state.tensorInfo.get(a),t=function(e){if(null==e)return 0;let t=0;return e.forEach((e=>t+=e.length)),t}(r);this.state.numBytes+=t-e.bytes,e.bytes=t}return i}makeTensorFromDataId(e,t,n,s){const r={dataId:e,shape:t,dtype:n=n||"float32"};return this.makeTensorFromTensorInfo(r,s)}makeTensorFromTensorInfo(e,t){const{dataId:n,shape:s,dtype:r}=e,a=new dL(s,r,n,this.nextTensorId());return this.trackTensor(a,t),a}makeVariable(e,t=!0,n,s){n=n||this.nextVariableId().toString(),null!=s&&s!==e.dtype&&(e=e.cast(s));const r=new fL(e,t,n,this.nextTensorId());if(null!=this.state.registeredVariables[r.name])throw new Error(`Variable with name ${r.name} was already registered`);return this.state.registeredVariables[r.name]=r,this.incRef(r,this.backend),r}trackTensor(e,t){this.state.numTensors++,"string"===e.dtype&&this.state.numStringTensors++;let n=0;"complex64"!==e.dtype&&"string"!==e.dtype&&(n=e.size*mM(e.dtype)),this.state.numBytes+=n,this.state.tensorInfo.has(e.dataId)||(this.state.numDataBuffers++,this.state.tensorInfo.set(e.dataId,{backend:t||this.backend,dtype:e.dtype,shape:e.shape,bytes:n})),e instanceof fL||this.track(e)}incRef(e,t){this.trackTensor(e,t),this.backend.incRef(e.dataId)}removeDataId(e,t){this.state.tensorInfo.has(e)&&this.state.tensorInfo.get(e).backend===t&&(this.state.tensorInfo.delete(e),this.state.numDataBuffers--)}disposeTensor(e){if(!this.state.tensorInfo.has(e.dataId))return;const t=this.state.tensorInfo.get(e.dataId);if(this.state.numTensors--,"string"===e.dtype&&(this.state.numStringTensors--,this.state.numBytes-=t.bytes),"complex64"!==e.dtype&&"string"!==e.dtype){const t=e.size*mM(e.dtype);this.state.numBytes-=t}t.backend.disposeData(e.dataId)&&this.removeDataId(e.dataId,t.backend)}disposeVariables(){for(const e in this.state.registeredVariables){const t=this.state.registeredVariables[e];this.disposeVariable(t)}}disposeVariable(e){this.disposeTensor(e),null!=this.state.registeredVariables[e.name]&&delete this.state.registeredVariables[e.name]}memory(){const e=this.backend.memory();return e.numTensors=this.state.numTensors,e.numDataBuffers=this.state.numDataBuffers,e.numBytes=this.state.numBytes,this.state.numStringTensors>0&&(e.unreliable=!0,null==e.reasons&&(e.reasons=[]),e.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")),e}async profile(e){this.state.profiling=!0;const t=this.state.numBytes,n=this.state.numTensors;this.state.activeProfile.kernels=[],this.state.activeProfile.result=await e(),this.state.profiling=!1,this.state.activeProfile.peakBytes=Math.max(...this.state.activeProfile.kernels.map((e=>e.totalBytesSnapshot))),this.state.activeProfile.newBytes=this.state.numBytes-t,this.state.activeProfile.newTensors=this.state.numTensors-n;for(const e of this.state.activeProfile.kernels)e.kernelTimeMs=await e.kernelTimeMs,e.extraInfo=await e.extraInfo;return this.state.activeProfile}isTapeOn(){return this.state.gradientDepth>0&&0===this.state.kernelDepth}addTapeNode(e,t,n,s,r,a){const i={id:this.state.nextTapeNodeId++,kernelName:e,inputs:t,outputs:n,saved:r},o=KM(e);null!=o&&(s=o.gradFunc),null!=s&&(i.gradient=e=>(e=e.map(((e,t)=>{if(null==e){const e=n[t],s=IM(e.size,e.dtype);return this.makeTensor(s,e.shape,e.dtype)}return e})),s(e.length>1?e:e[0],r,a))),this.state.activeTape.push(i)}keep(e){return e.kept=!0,e}startTape(){0===this.state.gradientDepth&&(this.state.activeTape=[]),this.state.gradientDepth++}endTape(){this.state.gradientDepth--}startScope(e){const t={track:[],name:"unnamed scope",id:this.state.nextScopeId++};e&&(t.name=e),this.state.scopeStack.push(t),this.state.activeScope=t}endScope(e){const t=vL(e),n=new Set(t.map((e=>e.id)));for(let e=0;e<this.state.activeScope.track.length;e++){const t=this.state.activeScope.track[e];t.kept||n.has(t.id)||t.dispose()}const s=this.state.scopeStack.pop();this.state.activeScope=0===this.state.scopeStack.length?null:this.state.scopeStack[this.state.scopeStack.length-1],t.forEach((e=>{e.kept||e.scopeId!==s.id||this.track(e)}))}gradients(e,t,n,s=!1){if(aM(t.length>0,(()=>"gradients() received an empty list of xs.")),null!=n&&"float32"!==n.dtype)throw new Error(`dy must have 'float32' dtype, but has '${n.dtype}'`);const r=this.scopedRun((()=>this.startTape()),(()=>this.endTape()),(()=>this.tidy("forward",e)));aM(r instanceof dL,(()=>"The result y returned by f() must be a tensor."));const a=function(e,t,n){const s={},r={};for(let e=0;e<t.length;e++)s[t[e].id]=!0;for(let n=0;n<e.length;n++){const a=e[n],i=a.inputs;for(const e in i){const n=i[e];let o=!1;for(let e=0;e<t.length;e++)if(s[n.id]){a.outputs.forEach((e=>s[e.id]=!0)),o=!0,r[a.id]=!0;break}if(o)break}}const a={};a[n.id]=!0;const i={};for(let t=e.length-1;t>=0;t--){const n=e[t],s=n.inputs;for(let e=0;e<n.outputs.length;e++)if(a[n.outputs[e].id]){for(const e in s)a[s[e].id]=!0,i[n.id]=!0;break}}const o=[];for(let t=0;t<e.length;t++){const n=e[t];if(r[n.id]&&i[n.id]){const e={};for(const t in n.inputs){const r=n.inputs[t];s[r.id]&&(e[t]=r)}const t=Object.assign({},n);t.inputs=e,t.outputs=n.outputs,o.push(t)}}return o}(this.state.activeTape,t,r);if(!s&&0===a.length&&t.length>0)throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");return this.tidy("backward",(()=>{const e={};e[r.id]=null==n?function(e){const t=vM(uM(e),"float32");return EL.makeTensor(t,e,"float32")}(r.shape):n,function(e,t,n,s){for(let r=t.length-1;r>=0;r--){const a=t[r],i=[];if(a.outputs.forEach((t=>{const n=e[t.id];null!=n?i.push(n):i.push(null)})),null==a.gradient)throw new Error(`Cannot compute gradient: gradient function not found for ${a.kernelName}.`);const o=a.gradient(i);for(const t in a.inputs){if(!(t in o))throw new Error(`Cannot backprop through input ${t}. Available gradients found: ${Object.keys(o)}.`);const r=n((()=>o[t]()));if("float32"!==r.dtype)throw new Error(`Error in gradient for op ${a.kernelName}. The gradient of input ${t} must have 'float32' dtype, but has '${r.dtype}'`);const i=a.inputs[t];if(!cM(r.shape,i.shape))throw new Error(`Error in gradient for op ${a.kernelName}. The gradient of input '${t}' has shape '${r.shape}', which does not match the shape of the input '${i.shape}'`);if(null==e[i.id])e[i.id]=r;else{const t=e[i.id];e[i.id]=s(t,r),t.dispose()}}}}(e,a,(e=>this.tidy(e)),CL);const s=t.map((t=>e[t.id]));return 0===this.state.gradientDepth&&(this.state.activeTape.forEach((e=>{for(const t of e.saved)t.dispose()})),this.state.activeTape=null),{value:r,grads:s}}))}customGrad(e){return aM(bM(e),(()=>"The f passed in customGrad(f) must be a function.")),(...t)=>{let n;aM(t.every((e=>e instanceof dL)),(()=>"The args passed in customGrad(f)(x1, x2,...) must all be tensors"));const s={};return t.forEach(((e,t)=>{s[t]=e})),this.runKernelFunc({forwardFunc:(s,r)=>(n=e(...t,r),aM(n.value instanceof dL,(()=>"The function f passed in customGrad(f) must return an object where `obj.value` is a tensor")),aM(bM(n.gradFunc),(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.")),n.value),backwardsFunc:(e,s)=>{const r=n.gradFunc(e,s),a=Array.isArray(r)?r:[r];aM(a.length===t.length,(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).")),aM(a.every((e=>e instanceof dL)),(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors."));const i={};return a.forEach(((e,t)=>{i[t]=()=>e})),i},inputs:s})}}readSync(e){return this.state.tensorInfo.get(e).backend.readSync(e)}read(e){return this.state.tensorInfo.get(e).backend.read(e)}readToGPU(e,t){return this.state.tensorInfo.get(e).backend.readToGPU(e,t)}async time(e){const t=QM(),n=await this.backend.time(e);return n.wallMs=QM()-t,n}track(e){return null!=this.state.activeScope&&(e.scopeId=this.state.activeScope.id,this.state.activeScope.track.push(e)),e}get registeredVariables(){return this.state.registeredVariables}reset(){this.pendingBackendInitId++,this.state.dispose(),this.ENV.reset(),this.state=new SL;for(const e in this.registry)this.disposeRegisteredKernels(e),this.registry[e].dispose(),delete this.registry[e];this.backendName=null,this.backendInstance=null,this.pendingBackendInit=null}}function $L(){const e=_M();if(null==e._tfengine){const t=new $M(e);e._tfengine=new TL(t)}var t;return t=e._tfengine.ENV,AM=t,cL=()=>e._tfengine,e._tfengine}TL.nextTensorId=0,TL.nextVariableId=0;const EL=$L();function CL(e,t){const n={a:e,b:t};return EL.runKernel("Add",n)}const RL=CM();function AL(e,t){let n=e;if(fM(e))return"string"===t?[]:[e.length];if(!Array.isArray(e))return[];const s=[];for(;Array.isArray(n)||fM(n)&&"string"!==t;)s.push(n.length),n=n[0];return Array.isArray(e)&&CM().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")&&_L(e,s,[]),s}function _L(e,t,n){if(n=n||[],!Array.isArray(e)&&!fM(e))return void aM(0===t.length,(()=>`Element arr[${n.join("][")}] is a primitive, but should be an array/TypedArray of ${t[0]} elements`));aM(t.length>0,(()=>`Element arr[${n.join("][")}] should be a primitive, but is an array of ${e.length} elements`)),aM(e.length===t[0],(()=>`Element arr[${n.join("][")}] should have ${t[0]} elements, but has ${e.length} elements`));const s=t.slice(1);for(let t=0;t<e.length;++t)_L(e[t],s,n.concat(t))}function DL(e,t,n,s){if("string_or_numeric"!==e){if(null==e)throw new Error("Expected dtype cannot be null.");if("numeric"!==e&&e!==t||"numeric"===e&&"string"===t)throw new Error(`Argument '${n}' passed to '${s}' must be ${e} tensor, but got ${t} tensor`)}}function FL(e,t,n,s="numeric"){if(e instanceof dL)return DL(s,e.dtype,t,n),e;let r=yM(e);if("string"!==r&&["bool","int32","float32"].indexOf(s)>=0&&(r=s),DL(s,r,t,n),null==e||!fM(e)&&!Array.isArray(e)&&"number"!=typeof e&&"boolean"!=typeof e&&"string"!=typeof e){const s=null==e?"null":e.constructor.name;throw new Error(`Argument '${t}' passed to '${n}' must be a Tensor or TensorLike, but got '${s}'`)}const a=AL(e,r);fM(e)||Array.isArray(e)||(e=[e]);const i="string"!==r?ZM(e,r):lM(e,[],!0);return EL.makeTensor(i,a,r)}function OL(e,t,n,s="numeric"){if(!Array.isArray(e))throw new Error(`Argument ${t} passed to ${n} must be a \`Tensor[]\` or \`TensorLike[]\``);return e.map(((e,r)=>FL(e,`${t}[${r}]`,n,s)))}RL.registerFlag("DEBUG",(()=>!1),(e=>{e&&console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.")})),RL.registerFlag("IS_BROWSER",(()=>"undefined"!=typeof window&&null!=window.document||"undefined"!=typeof WorkerGlobalScope)),RL.registerFlag("IS_NODE",(()=>"undefined"!=typeof process&&void 0!==process.versions&&void 0!==process.versions.node)),RL.registerFlag("IS_CHROME",(()=>"undefined"!=typeof navigator&&null!=navigator&&null!=navigator.userAgent&&/Chrome/.test(navigator.userAgent)&&/Google Inc/.test(navigator.vendor))),RL.registerFlag("PROD",(()=>!1)),RL.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY",(()=>RL.getBool("DEBUG"))),RL.registerFlag("DEPRECATION_WARNINGS_ENABLED",(()=>!0)),RL.registerFlag("IS_TEST",(()=>!1)),RL.registerFlag("CHECK_COMPUTATION_FOR_ERRORS",(()=>!0)),RL.registerFlag("WRAP_TO_IMAGEBITMAP",(()=>!1)),RL.registerFlag("ENGINE_COMPILE_ONLY",(()=>!1)),RL.registerFlag("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU",(()=>!1)),RL.registerFlag("USE_SETTIMEOUTCUSTOM",(()=>!1));const ML="__op";function LL(e){const t=Object.keys(e);if(1!==t.length)throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${t.length} keys.`);let n=t[0];const s=e[n];n.endsWith("_")&&(n=n.substring(0,n.length-1)),n+=ML;const r=(...e)=>{EL.startScope(n);try{const t=s(...e);return SM(t)&&console.error("Cannot return a Promise inside of tidy."),EL.endScope(t),t}catch(e){throw EL.endScope(null),e}};return Object.defineProperty(r,"name",{value:n,configurable:!0}),r}const zL=LL({complex_:function(e,t){const n=FL(e,"real","complex"),s=FL(t,"imag","complex");iM(n.shape,s.shape,`real and imag shapes, ${n.shape} and ${s.shape}, must match in call to tf.complex().`);const r={real:n,imag:s};return EL.runKernel("Complex",r)}});function BL(e,t,n,s){if(null==s&&(s=yM(e)),"complex64"===s)throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");if(!fM(e)&&!Array.isArray(e)&&"number"!=typeof e&&"boolean"!=typeof e&&"string"!=typeof e)throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");if(null!=t){NM(t);const e=uM(t),s=uM(n);aM(e===s,(()=>`Based on the provided shape, [${t}], the tensor should have ${e} values but has ${s}`));for(let e=0;e<n.length;++e){const s=n[e],r=e!==n.length-1||s!==uM(t.slice(e));aM(n[e]===t[e]||!r,(()=>`Error creating a new Tensor. Inferred shape (${n}) does not match the provided shape (${t}). `))}}return fM(e)||Array.isArray(e)||(e=[e]),t=t||n,e="string"!==s?ZM(e,s):lM(e,[],!0),EL.makeTensor(e,t,s)}function PL(e,t,n){return BL(e,t,AL(e,n),n)}const WL={float32:4,float16:2,int32:4,uint16:2,uint8:1,bool:1,complex64:8},VL=4;async function UL(e,t){const n=[],s=[],r=Array.isArray(e)?e.map((e=>e.name)):Object.keys(e);for(let a=0;a<r.length;++a){const i=r[a],o=Array.isArray(e)?e[a].tensor:e[i];if("float32"!==o.dtype&&"int32"!==o.dtype&&"bool"!==o.dtype&&"string"!==o.dtype&&"complex64"!==o.dtype)throw new Error(`Unsupported dtype in weight '${i}': ${o.dtype}`);const l={name:i,shape:o.shape,dtype:o.dtype};if("string"===o.dtype){const e=new Promise((async e=>{const t=await o.bytes(),n=t.reduce(((e,t)=>e+t.length),0)+VL*t.length,s=new Uint8Array(n);let r=0;for(let e=0;e<t.length;e++){const n=t[e],a=new Uint8Array(new Uint32Array([n.length]).buffer);s.set(a,r),r+=VL,s.set(n,r),r+=n.length}e(s)}));s.push(e)}else s.push(o.data());null!=t&&(l.group=t),n.push(l)}return{data:HL(await Promise.all(s)),specs:n}}function GL(e,t){const n={};let s,r=0;for(const a of t){const t=a.name,i=a.dtype,o=a.shape,l=uM(o);let u;if("quantization"in a){const n=a.quantization;if("uint8"===n.dtype||"uint16"===n.dtype){if(!("min"in n)||!("scale"in n))throw new Error(`Weight ${a.name} with quantization ${n.dtype} doesn't have corresponding metadata min and scale.`)}else{if("float16"!==n.dtype)throw new Error(`Weight ${a.name} has unknown quantization dtype ${n.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);if("float32"!==i)throw new Error(`Weight ${a.name} is quantized with ${n.dtype} which only supports weights of type float32 not ${i}.`)}const o=WL[n.dtype],c=e.slice(r,r+l*o),h="uint8"===n.dtype?new Uint8Array(c):new Uint16Array(c);if("float32"===i)if("uint8"===n.dtype||"uint16"===n.dtype){u=new Float32Array(h.length);for(let e=0;e<h.length;e++){const t=h[e];u[e]=t*n.scale+n.min}}else{if("float16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type float32.`);void 0===s&&(s=tz()),u=s(h)}else{if("int32"!==i)throw new Error(`Unsupported dtype in weight '${t}': ${i}`);if("uint8"!==n.dtype&&"uint16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type int32.`);u=new Int32Array(h.length);for(let e=0;e<h.length;e++){const t=h[e];u[e]=Math.round(t*n.scale+n.min)}}r+=l*o}else if("string"===i){const t=uM(a.shape);u=[];for(let n=0;n<t;n++){const t=new Uint32Array(e.slice(r,r+VL))[0];r+=VL;const n=new Uint8Array(e.slice(r,r+t));u.push(n),r+=t}}else{const s=WL[i],a=e.slice(r,r+l*s);if("float32"===i)u=new Float32Array(a);else if("int32"===i)u=new Int32Array(a);else if("bool"===i)u=new Uint8Array(a);else{if("complex64"!==i)throw new Error(`Unsupported dtype in weight '${t}': ${i}`);{u=new Float32Array(a);const e=new Float32Array(u.length/2),s=new Float32Array(u.length/2);for(let t=0;t<e.length;t++)e[t]=u[2*t],s[t]=u[2*t+1];const r=PL(e,o,"float32"),i=PL(s,o,"float32");n[t]=zL(r,i),r.dispose(),i.dispose()}}r+=l*s}"complex64"!==i&&(n[t]=PL(u,o,i))}return n}function HL(e){if(null===e)throw new Error(`Invalid input value: ${JSON.stringify(e)}`);let t=0;const n=[];e.forEach((e=>{if(t+=e.byteLength,n.push(e.byteLength===e.buffer.byteLength?e:new e.constructor(e)),!(e instanceof Float32Array||e instanceof Int32Array||e instanceof Uint8Array))throw new Error(`Unsupported TypedArray subtype: ${e.constructor.name}`)}));const s=new Uint8Array(t);let r=0;return n.forEach((e=>{s.set(new Uint8Array(e.buffer),r),r+=e.byteLength})),s.buffer}const jL="undefined"!=typeof Buffer&&("undefined"==typeof Blob||"undefined"==typeof atob||"undefined"==typeof btoa);function KL(e){return jL?Buffer.byteLength(e):new Blob([e]).size}function qL(e){if(1===e.length)return e[0];let t=0;e.forEach((e=>{t+=e.byteLength}));const n=new Uint8Array(t);let s=0;return e.forEach((e=>{n.set(new Uint8Array(e),s),s+=e.byteLength})),n.buffer}function XL(e){for(e=e.trim();e.endsWith("/");)e=e.slice(0,e.length-1);const t=e.split("/");return t[t.length-1]}function YL(e,t){const n={modelTopology:e.modelTopology,format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy,weightsManifest:t};return null!=e.signature&&(n.signature=e.signature),null!=e.userDefinedMetadata&&(n.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(n.modelInitializer=e.modelInitializer),null!=e.trainingConfig&&(n.trainingConfig=e.trainingConfig),n}function JL(e,t,n){const s={modelTopology:e.modelTopology,format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy};if(null!=e.trainingConfig&&(s.trainingConfig=e.trainingConfig),null!=e.weightsManifest){if(!t)throw new Error("modelJSON has weightsManifest but weightSpecs is null");if(!n)throw new Error("modelJSON has weightsManifest but weightData is null");s.weightSpecs=t,s.weightData=n}return null!=e.signature&&(s.signature=e.signature),null!=e.userDefinedMetadata&&(s.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(s.modelInitializer=e.modelInitializer),s}async function ZL(e,t){let n,s;return null!=e.weightsManifest&&([n,s]=await t(e.weightsManifest)),JL(e,n,s)}function QL(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("Expected JSON model topology, received ArrayBuffer.");return{dateSaved:new Date,modelTopologyType:"JSON",modelTopologyBytes:null==e.modelTopology?0:KL(JSON.stringify(e.modelTopology)),weightSpecsBytes:null==e.weightSpecs?0:KL(JSON.stringify(e.weightSpecs)),weightDataBytes:null==e.weightData?0:e.weightData.byteLength}}function ez(e){const t=[];for(const n of e)t.push(...n.weights);return t}function tz(){const e=function(){const e=e=>{let t=e<<13,n=0;for(;!(8388608&t);)n-=8388608,t<<=1;return t&=-8388609,n+=947912704,t|n},t=new Uint32Array(2048);t[0]=0;for(let n=1;n<1024;n++)t[n]=e(n);for(let e=1024;e<2048;e++)t[e]=939524096+(e-1024<<13);return t}(),t=function(){const e=new Uint32Array(64);e[0]=0,e[31]=1199570944,e[32]=2147483648,e[63]=3347054592;for(let t=1;t<31;t++)e[t]=t<<23;for(let t=33;t<63;t++)e[t]=2147483648+(t-32<<23);return e}(),n=function(){const e=new Uint32Array(64);for(let t=0;t<64;t++)e[t]=1024;return e[0]=e[32]=0,e}();return s=>{const r=new ArrayBuffer(4*s.length),a=new Uint32Array(r);for(let r=0;r<s.length;r++){const i=s[r],o=e[n[i>>10]+(1023&i)]+t[i>>10];a[r]=o}return new Float32Array(r)}}class nz{constructor(){this.saveRouters=[],this.loadRouters=[]}static getInstance(){return null==nz.instance&&(nz.instance=new nz),nz.instance}static registerSaveRouter(e){nz.getInstance().saveRouters.push(e)}static registerLoadRouter(e){nz.getInstance().loadRouters.push(e)}static getSaveHandlers(e){return nz.getHandlers(e,"save")}static getLoadHandlers(e,t){return nz.getHandlers(e,"load",t)}static getHandlers(e,t,n){const s=[];return("load"===t?nz.getInstance().loadRouters:nz.getInstance().saveRouters).forEach((t=>{const r=t(e,n);null!==r&&s.push(r)})),s}}const sz=e=>nz.registerSaveRouter(e),rz=e=>nz.registerLoadRouter(e),az=e=>nz.getSaveHandlers(e),iz=(e,t)=>nz.getLoadHandlers(e,t),oz="tensorflowjs",lz="models_store",uz="model_info_store";function cz(){if(!CM().getBool("IS_BROWSER"))throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");const e="undefined"==typeof window?self:window,t=e.indexedDB||e.mozIndexedDB||e.webkitIndexedDB||e.msIndexedDB||e.shimIndexedDB;if(null==t)throw new Error("The current browser does not appear to support IndexedDB.");return t}function hz(e){const t=e.result;t.createObjectStore(lz,{keyPath:"modelPath"}),t.createObjectStore(uz,{keyPath:"modelPath"})}class pz{constructor(e){if(this.indexedDB=cz(),null==e||!e)throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");this.modelPath=e}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");return this.databaseAction(this.modelPath,e)}async load(){return this.databaseAction(this.modelPath)}databaseAction(e,t){return new Promise(((e,n)=>{const s=this.indexedDB.open(oz,1);s.onupgradeneeded=()=>hz(s),s.onsuccess=()=>{const r=s.result;if(null==t){const t=r.transaction(lz,"readonly"),s=t.objectStore(lz).get(this.modelPath);s.onsuccess=()=>{if(null==s.result)return r.close(),n(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));e(s.result.modelArtifacts)},s.onerror=e=>(r.close(),n(s.error)),t.oncomplete=()=>r.close()}else{const s=QL(t),a=r.transaction(uz,"readwrite");let i=a.objectStore(uz);const o=i.put({modelPath:this.modelPath,modelArtifactsInfo:s});let l;o.onsuccess=()=>{l=r.transaction(lz,"readwrite");const o=l.objectStore(lz).put({modelPath:this.modelPath,modelArtifacts:t,modelArtifactsInfo:s});o.onsuccess=()=>e({modelArtifactsInfo:s}),o.onerror=e=>{i=a.objectStore(uz);const t=i.delete(this.modelPath);t.onsuccess=()=>(r.close(),n(o.error)),t.onerror=e=>(r.close(),n(o.error))}},o.onerror=e=>(r.close(),n(o.error)),a.oncomplete=()=>{null==l?r.close():l.oncomplete=()=>r.close()}}},s.onerror=e=>n(s.error)}))}}pz.URL_SCHEME="indexeddb://";const dz=e=>{return CM().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(pz.URL_SCHEME)?(t=e.slice(pz.URL_SCHEME.length),new pz(t)):null;var t};nz.registerSaveRouter(dz),nz.registerLoadRouter(dz);class fz{constructor(){this.indexedDB=cz()}async listModels(){return new Promise(((e,t)=>{const n=this.indexedDB.open(oz,1);n.onupgradeneeded=()=>hz(n),n.onsuccess=()=>{const s=n.result,r=s.transaction(uz,"readonly"),a=r.objectStore(uz).getAll();a.onsuccess=()=>{const t={};for(const e of a.result)t[e.modelPath]=e.modelArtifactsInfo;e(t)},a.onerror=e=>(s.close(),t(a.error)),r.oncomplete=()=>s.close()},n.onerror=e=>t(n.error)}))}async removeModel(e){var t;return e=(t=e).startsWith(pz.URL_SCHEME)?t.slice(pz.URL_SCHEME.length):t,new Promise(((t,n)=>{const s=this.indexedDB.open(oz,1);s.onupgradeneeded=()=>hz(s),s.onsuccess=()=>{const r=s.result,a=r.transaction(uz,"readwrite"),i=a.objectStore(uz),o=i.get(e);let l;o.onsuccess=()=>{if(null==o.result)return r.close(),n(new Error(`Cannot find model with path '${e}' in IndexedDB.`));{const s=i.delete(e),a=()=>{l=r.transaction(lz,"readwrite");const s=l.objectStore(lz).delete(e);s.onsuccess=()=>t(o.result.modelArtifactsInfo),s.onerror=e=>n(o.error)};s.onsuccess=a,s.onerror=e=>(a(),r.close(),n(o.error))}},o.onerror=e=>(r.close(),n(o.error)),a.oncomplete=()=>{null==l?r.close():l.oncomplete=()=>r.close()}},s.onerror=e=>n(s.error)}))}}const mz="/",gz="tensorflowjs_models",yz="info",bz="model_topology",xz="weight_specs",wz="weight_data",kz="model_metadata";function vz(e){return{info:[gz,e,yz].join(mz),topology:[gz,e,bz].join(mz),weightSpecs:[gz,e,xz].join(mz),weightData:[gz,e,wz].join(mz),modelMetadata:[gz,e,kz].join(mz)}}function Iz(e){for(const t of Object.values(e))window.localStorage.removeItem(t)}function Nz(e){const t=e.split(mz);if(t.length<3)throw new Error(`Invalid key format: ${e}`);return t.slice(1,t.length-1).join(mz)}class Sz{constructor(e){if(!CM().getBool("IS_BROWSER")||"undefined"==typeof window||void 0===window.localStorage)throw new Error("The current environment does not support local storage.");if(this.LS=window.localStorage,null==e||!e)throw new Error("For local storage, modelPath must not be null, undefined or empty.");this.modelPath=e,this.keys=vz(this.modelPath)}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");{const t=JSON.stringify(e.modelTopology),n=JSON.stringify(e.weightSpecs),s=QL(e);try{this.LS.setItem(this.keys.info,JSON.stringify(s)),this.LS.setItem(this.keys.topology,t),this.LS.setItem(this.keys.weightSpecs,n),this.LS.setItem(this.keys.weightData,function(e){if(jL)return Buffer.from(e).toString("base64");const t=new Uint8Array(e);let n="";for(let e=0,s=t.length;e<s;e++)n+=String.fromCharCode(t[e]);return btoa(n)}(e.weightData));const r={format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy,signature:null!=e.signature?e.signature:void 0,userDefinedMetadata:null!=e.userDefinedMetadata?e.userDefinedMetadata:void 0,modelInitializer:null!=e.modelInitializer?e.modelInitializer:void 0,trainingConfig:null!=e.trainingConfig?e.trainingConfig:void 0};return this.LS.setItem(this.keys.modelMetadata,JSON.stringify(r)),{modelArtifactsInfo:s}}catch(e){throw Iz(this.keys),new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${s.modelTopologyBytes}, weightSpecsBytes=${s.weightSpecsBytes}, weightDataBytes=${s.weightDataBytes}.`)}}}async load(){const e=JSON.parse(this.LS.getItem(this.keys.info));if(null==e)throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);if("JSON"!==e.modelTopologyType)throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");const t={},n=JSON.parse(this.LS.getItem(this.keys.topology));if(null==n)throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);t.modelTopology=n;const s=JSON.parse(this.LS.getItem(this.keys.weightSpecs));if(null==s)throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);t.weightSpecs=s;const r=this.LS.getItem(this.keys.modelMetadata);if(null!=r){const e=JSON.parse(r);t.format=e.format,t.generatedBy=e.generatedBy,t.convertedBy=e.convertedBy,null!=e.signature&&(t.signature=e.signature),null!=e.userDefinedMetadata&&(t.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(t.modelInitializer=e.modelInitializer),null!=e.trainingConfig&&(t.trainingConfig=e.trainingConfig)}const a=this.LS.getItem(this.keys.weightData);if(null==a)throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);return t.weightData=function(e){if(jL){const t=Buffer.from(e,"base64");return t.buffer.slice(t.byteOffset,t.byteOffset+t.byteLength)}const t=atob(e),n=new Uint8Array(t.length);for(let e=0;e<t.length;++e)n.set([t.charCodeAt(e)],e);return n.buffer}(a),t}}Sz.URL_SCHEME="localstorage://";const Tz=e=>{return CM().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(Sz.URL_SCHEME)?(t=e.slice(Sz.URL_SCHEME.length),new Sz(t)):null;var t};nz.registerSaveRouter(Tz),nz.registerLoadRouter(Tz);class $z{constructor(){aM(CM().getBool("IS_BROWSER"),(()=>"Current environment is not a web browser")),aM("undefined"==typeof window||void 0!==window.localStorage,(()=>"Current browser does not appear to support localStorage")),this.LS=window.localStorage}async listModels(){const e={},t=gz+mz,n=mz+yz;for(let s=0;s<this.LS.length;++s){const r=this.LS.key(s);r.startsWith(t)&&r.endsWith(n)&&(e[Nz(r)]=JSON.parse(this.LS.getItem(r)))}return e}async removeModel(e){var t;const n=vz(e=(t=e).startsWith(Sz.URL_SCHEME)?t.slice(Sz.URL_SCHEME.length):t);if(null==this.LS.getItem(n.info))throw new Error(`Cannot find model at path '${e}'`);const s=JSON.parse(this.LS.getItem(n.info));return Iz(n),s}}const Ez="://";class Cz{constructor(){this.managers={}}static getInstance(){return null==Cz.instance&&(Cz.instance=new Cz),Cz.instance}static registerManager(e,t){aM(null!=e,(()=>"scheme must not be undefined or null.")),e.endsWith(Ez)&&(e=e.slice(0,e.indexOf(Ez))),aM(e.length>0,(()=>"scheme must not be an empty string."));const n=Cz.getInstance();aM(null==n.managers[e],(()=>`A model store manager is already registered for scheme '${e}'.`)),n.managers[e]=t}static getManager(e){const t=Cz.getInstance().managers[e];if(null==t)throw new Error(`Cannot find model manager for scheme '${e}'`);return t}static getSchemes(){return Object.keys(Cz.getInstance().managers)}}function Rz(e){if(-1===e.indexOf(Ez))throw new Error(`The url string provided does not contain a scheme. Supported schemes are: ${Cz.getSchemes().join(",")}`);return{scheme:e.split(Ez)[0],path:e.split(Ez)[1]}}async function Az(e,t,n=!1){aM(e!==t,(()=>`Old path and new path are the same: '${e}'`));const s=nz.getLoadHandlers(e);aM(s.length>0,(()=>`Copying failed because no load handler is found for source URL ${e}.`)),aM(s.length<2,(()=>`Copying failed because more than one (${s.length}) load handlers for source URL ${e}.`));const r=s[0],a=nz.getSaveHandlers(t);aM(a.length>0,(()=>`Copying failed because no save handler is found for destination URL ${t}.`)),aM(a.length<2,(()=>`Copying failed because more than one (${s.length}) save handlers for destination URL ${t}.`));const i=a[0],o=Rz(e).scheme,l=Rz(e).path,u=o===Rz(e).scheme,c=await r.load();n&&u&&await Cz.getManager(o).removeModel(l);const h=await i.save(c);return n&&!u&&await Cz.getManager(o).removeModel(l),h.modelArtifactsInfo}async function _z(){const e=Cz.getSchemes(),t={};for(const n of e){const e=await Cz.getManager(n).listModels();for(const s in e)t[n+Ez+s]=e[s]}return t}async function Dz(e){const t=Rz(e);return Cz.getManager(t.scheme).removeModel(t.path)}async function Fz(e,t){return Az(e,t,!1)}async function Oz(e,t){return Az(e,t,!0)}class Mz{constructor(){this.messageName="setTimeoutCustom",this.functionRefs=[],this.handledMessageCount=0,this.hasEventListener=!1}fetch(e,t){return fetch(e,t)}now(){return performance.now()}encode(e,t){if("utf-8"!==t&&"utf8"!==t)throw new Error(`Browser's encoder only supports utf-8, but got ${t}`);return null==this.textEncoder&&(this.textEncoder=new TextEncoder),this.textEncoder.encode(e)}decode(e,t){return new TextDecoder(t).decode(e)}setTimeoutCustom(e,t){window&&CM().getBool("USE_SETTIMEOUTCUSTOM")?(this.functionRefs.push(e),setTimeout((()=>{window.postMessage({name:this.messageName,index:this.functionRefs.length-1},"*")}),t),this.hasEventListener||(this.hasEventListener=!0,window.addEventListener("message",(e=>{e.source===window&&e.data.name===this.messageName&&(e.stopPropagation(),(0,this.functionRefs[e.data.index])(),this.handledMessageCount++,this.handledMessageCount===this.functionRefs.length&&(this.functionRefs=[],this.handledMessageCount=0))}),!0))):setTimeout(e,t)}}if(CM().get("IS_BROWSER")){CM().setPlatform("browser",new Mz);try{Cz.registerManager(Sz.URL_SCHEME,new $z)}catch(e){}try{Cz.registerManager(pz.URL_SCHEME,new fz)}catch(e){}}let Lz;function zz(e,t="float32",n){return t=t||"float32",NM(e),new uL(e,t,n)}CM().get("IS_NODE")&&!CM().get("IS_BROWSER")&&CM().setPlatform("node",new class{constructor(){this.util=n(590),this.textEncoder=new this.util.TextEncoder}fetch(e,t){return null!=CM().global.fetch?CM().global.fetch(e,t):(null==Lz&&(Lz=n(817)),Lz(e,t))}now(){const e=process.hrtime();return 1e3*e[0]+e[1]/1e6}encode(e,t){if("utf-8"!==t&&"utf8"!==t)throw new Error(`Node built-in encoder only supports utf-8, but got ${t}`);return this.textEncoder.encode(e)}decode(e,t){return 0===e.length?"":new this.util.TextDecoder(t).decode(e)}});const Bz=LL({cast_:function(e,t){const n=FL(e,"x","cast");if(!function(e){return"bool"===e||"complex64"===e||"float32"===e||"int32"===e||"string"===e}(t))throw new Error(`Failed to cast to unknown dtype ${t}`);if("string"===t&&"string"!==n.dtype||"string"!==t&&"string"===n.dtype)throw new Error("Only strings can be casted to strings");const s={x:n},r={dtype:t};return EL.runKernel(FM,s,r)}}),Pz=LL({clone_:function(e){const t={x:FL(e,"x","clone","string_or_numeric")};return EL.runKernel(MM,t)}});function Wz(e,t=!1){console.log(e.toString(t))}function Vz(e){return new Promise((e=>setTimeout(e))).then(e)}$L(),hL={buffer:zz,cast:Bz,clone:Pz,print:Wz};class Uz{constructor(e){if(!CM().getBool("IS_BROWSER"))throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");e.startsWith(Uz.URL_SCHEME)&&(e=e.slice(Uz.URL_SCHEME.length)),null!=e&&0!==e.length||(e="model"),this.modelJsonFileName=e+".json",this.weightDataFileName=e+".weights.bin"}async save(e){if("undefined"==typeof document)throw new Error("Browser downloads are not supported in this environment since `document` is not present");const t=window.URL.createObjectURL(new Blob([e.weightData],{type:"application/octet-stream"}));if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");{const n=YL(e,[{paths:["./"+this.weightDataFileName],weights:e.weightSpecs}]),s=window.URL.createObjectURL(new Blob([JSON.stringify(n)],{type:"application/json"})),r=null==this.modelJsonAnchor?document.createElement("a"):this.modelJsonAnchor;if(r.download=this.modelJsonFileName,r.href=s,await Vz((()=>r.dispatchEvent(new MouseEvent("click")))),null!=e.weightData){const e=null==this.weightDataAnchor?document.createElement("a"):this.weightDataAnchor;e.download=this.weightDataFileName,e.href=t,await Vz((()=>e.dispatchEvent(new MouseEvent("click"))))}return{modelArtifactsInfo:QL(e)}}}}Uz.URL_SCHEME="downloads://";class Gz{constructor(e){if(null==e||e.length<1)throw new Error(`When calling browserFiles, at least 1 file is required, but received ${e}`);this.jsonFile=e[0],this.weightsFiles=e.slice(1)}async load(){return new Promise(((e,t)=>{const n=new FileReader;n.onload=n=>{const s=JSON.parse(n.target.result),r=s.modelTopology;if(null==r)return void t(new Error(`modelTopology field is missing from file ${this.jsonFile.name}`));if(null==s.weightsManifest)return void t(new Error(`weightManifest field is missing from file ${this.jsonFile.name}`));if(0===this.weightsFiles.length)return void e({modelTopology:r});const a=ZL(s,(e=>this.loadWeights(e)));e(a)},n.onerror=e=>t(`Failed to read model topology and weights manifest JSON from file '${this.jsonFile.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`),n.readAsText(this.jsonFile)}))}loadWeights(e){const t=[],n=[];for(const s of e)t.push(...s.weights),n.push(...s.paths);const s=this.checkManifestAndWeightFiles(e),r=n.map((e=>this.loadWeightsFile(e,s[e])));return Promise.all(r).then((e=>[t,qL(e)]))}loadWeightsFile(e,t){return new Promise(((n,s)=>{const r=new FileReader;r.onload=e=>{const t=e.target.result;n(t)},r.onerror=t=>s(`Failed to weights data from file of path '${e}'.`),r.readAsArrayBuffer(t)}))}checkManifestAndWeightFiles(e){const t=[],n=this.weightsFiles.map((e=>XL(e.name))),s={};for(const r of e)r.paths.forEach((e=>{const r=XL(e);if(-1!==t.indexOf(r))throw new Error(`Duplicate file basename found in weights manifest: '${r}'`);if(t.push(r),-1===n.indexOf(r))throw new Error(`Weight file with basename '${r}' is not provided.`);s[e]=this.weightsFiles[n.indexOf(r)]}));if(t.length!==this.weightsFiles.length)throw new Error(`Mismatch in the number of files in weights manifest (${t.length}) and the number of weight files provided (${this.weightsFiles.length}).`);return s}}function Hz(e){return new Gz(e)}function jz(e,t,n,s){!function(e){aM(null!=e&&Array.isArray(e)&&e.length>0,(()=>"promises must be a none empty array"))}(e),function(e,t){aM(e>=0&&e<=1,(()=>`Progress fraction must be in range [0, 1], but got startFraction ${e}`)),aM(t>=0&&t<=1,(()=>`Progress fraction must be in range [0, 1], but got endFraction ${t}`)),aM(t>=e,(()=>`startFraction must be no more than endFraction, but got startFraction ${e} and endFraction ${t}`))}(n=null==n?0:n,s=null==s?1:s);let r=0;return Promise.all(e.map((a=>(a.then((a=>{const i=n+ ++r/e.length*(s-n);return t(i),a})),a))))}async function Kz(e,t){null==t&&(t={});const n=null==t.fetchFunc?CM().platform.fetch:t.fetchFunc,s=e.map((e=>n(e,t.requestInit,{isBinary:!0}))),r=(null==t.onProgress?await Promise.all(s):await jz(s,t.onProgress,0,.5)).map((e=>e.arrayBuffer()));return null==t.onProgress?await Promise.all(r):await jz(r,t.onProgress,.5,1)}async function qz(e,t="",n,s){return Xz((e=>Kz(e,{requestInit:s})))(e,t,n)}function Xz(e){return async(t,n="",s)=>{const r=t.map((()=>!1)),a={},i=null!=s?s.map((()=>!1)):[],o=[];if(t.forEach(((e,t)=>{let n=0;e.weights.forEach((e=>{const l="quantization"in e?e.quantization.dtype:e.dtype,u=WL[l]*uM(e.shape),c=()=>{r[t]=!0,null==a[t]&&(a[t]=[]),a[t].push({manifestEntry:e,groupOffset:n,sizeBytes:u})};null!=s?s.forEach(((t,n)=>{t===e.name&&(c(),i[n]=!0)})):c(),o.push(e.name),n+=u}))})),!i.every((e=>e))){const e=s.filter(((e,t)=>!i[t]));throw new Error(`Could not find weights in manifest with names: ${e.join(", ")}. \nManifest JSON has weights with names: ${o.join(", ")}.`)}const l=r.reduce(((e,t,n)=>(t&&e.push(n),e)),[]),u=[];l.forEach((e=>{t[e].paths.forEach((e=>{const t=n+(n.endsWith("/")?"":"/")+e;u.push(t)}))}));const c=await e(u),h={};let p=0;return l.forEach((e=>{const n=t[e].paths.length;let s=0;for(let e=0;e<n;e++)s+=c[p+e].byteLength;const r=new ArrayBuffer(s),i=new Uint8Array(r);let o=0;for(let e=0;e<n;e++){const t=new Uint8Array(c[p+e]);i.set(t,o),o+=t.byteLength}a[e].forEach((e=>{const t=GL(r.slice(e.groupOffset,e.groupOffset+e.sizeBytes),[e.manifestEntry]);for(const e in t)h[e]=t[e]})),p+=n})),h}}nz.registerSaveRouter((e=>CM().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(Uz.URL_SCHEME)?function(e="model"){return new Uz(e)}(e.slice(Uz.URL_SCHEME.length)):null));class Yz{constructor(e,t){if(this.DEFAULT_METHOD="POST",null==t&&(t={}),this.weightPathPrefix=t.weightPathPrefix,this.onProgress=t.onProgress,this.weightUrlConverter=t.weightUrlConverter,null!=t.fetchFunc?(aM("function"==typeof t.fetchFunc,(()=>"Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)")),this.fetch=t.fetchFunc):this.fetch=CM().platform.fetch,aM(null!=e&&e.length>0,(()=>"URL path for http must not be null, undefined or empty.")),Array.isArray(e)&&aM(2===e.length,(()=>`URL paths for http must have a length of 2, (actual length is ${e.length}).`)),this.path=e,null!=t.requestInit&&null!=t.requestInit.body)throw new Error("requestInit is expected to have no pre-existing body, but has one.");this.requestInit=t.requestInit||{}}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");const t=Object.assign({method:this.DEFAULT_METHOD},this.requestInit);t.body=new FormData;const n=YL(e,[{paths:["./model.weights.bin"],weights:e.weightSpecs}]);t.body.append("model.json",new Blob([JSON.stringify(n)],{type:"application/json"}),"model.json"),null!=e.weightData&&t.body.append("model.weights.bin",new Blob([e.weightData],{type:"application/octet-stream"}),"model.weights.bin");const s=await this.fetch(this.path,t);if(s.ok)return{modelArtifactsInfo:QL(e),responses:[s]};throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${s.status}.`)}async load(){const e=await this.fetch(this.path,this.requestInit);if(!e.ok)throw new Error(`Request to ${this.path} failed with status code ${e.status}. Please verify this URL points to the model JSON of the model to load.`);let t;try{t=await e.json()}catch(e){let t=`Failed to parse model JSON of response from ${this.path}.`;throw this.path.endsWith(".pb")?t+=" Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.":t+=" Please make sure the server is serving valid JSON for this request.",new Error(t)}const n=t.modelTopology,s=t.weightsManifest;if(null==n&&null==s)throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);return ZL(t,(e=>this.loadWeights(e)))}async loadWeights(e){const t=Array.isArray(this.path)?this.path[1]:this.path,[n,s]=function(e){const t=e.lastIndexOf("/"),n=e.lastIndexOf("?");return[e.substring(0,t)+"/",n>t?e.substring(n):""]}(t),r=this.weightPathPrefix||n,a=ez(e),i=[],o=[];for(const t of e)for(const e of t.paths)null!=this.weightUrlConverter?o.push(this.weightUrlConverter(e)):i.push(r+e+s);return this.weightUrlConverter&&i.push(...await Promise.all(o)),[a,qL(await Kz(i,{requestInit:this.requestInit,fetchFunc:this.fetch,onProgress:this.onProgress}))]}}function Jz(e){return null!=e.match(Yz.URL_SCHEME_REGEX)}Yz.URL_SCHEME_REGEX=/^https?:\/\//;const Zz=(e,t)=>{if("undefined"==typeof fetch&&(null==t||null==t.fetchFunc))return null;{let n=!0;if(n=Array.isArray(e)?e.every((e=>Jz(e))):Jz(e),n)return Qz(e,t)}return null};function Qz(e,t){return new Yz(e,t)}function eB(e,t){return Qz(e,t)}nz.registerSaveRouter(Zz),nz.registerLoadRouter(Zz);class tB{constructor(e){this.modelArtifacts=e}load(){return this.modelArtifacts}}class nB{constructor(e){this.saveHandler=e}save(e){return this.saveHandler(e)}}class sB{constructor(e){e.load&&(this.load=()=>Promise.resolve(e.load())),e.save&&(this.save=t=>Promise.resolve(e.save(t)))}}function rB(e,t,n,s){return new sB(aB(...arguments))}function aB(e,t,n,s){return 1===arguments.length?null!=e.modelTopology||null!=e.weightSpecs?new tB(e):(console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."),new tB({modelTopology:e})):(console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."),new tB({modelTopology:e,weightSpecs:t,weightData:n,trainingConfig:s}))}function iB(e){return new nB(e)}function oB(e){return new nB(e)}const lB=LL({abs_:function(e){const t=FL(e,"x","abs");if("complex64"===t.dtype){const e={x:t};return EL.runKernel("ComplexAbs",e)}{const e={x:t};return EL.runKernel("Abs",e)}}}),uB=LL({acos_:function(e){const t={x:FL(e,"x","acos")};return EL.runKernel("Acos",t)}}),cB=LL({acosh_:function(e){const t={x:FL(e,"x","acosh")};return EL.runKernel("Acosh",t)}}),hB=LL({add_:function(e,t){let n=FL(e,"a","add"),s=FL(t,"b","add");[n,s]=kL(n,s);const r={a:n,b:s};return EL.runKernel("Add",r)}}),pB=LL({addN_:function(e){aM(Array.isArray(e),(()=>"The argument passed to tf.addN() must be a list of tensors")),aM(e.length>=1,(()=>`Must pass at least one tensor to tf.addN(), but got ${e.length}`));const t=e.map(((e,t)=>FL(e,`tensors${t}`,"addN"))),n=t[0];t.forEach((e=>{if(e.dtype!==n.dtype)throw new Error("All tensors passed to tf.addN() must have the same dtype")})),t.forEach((e=>{if(!cM(e.shape,n.shape))throw new Error("All tensors passed to tf.addN() must have the same shape")}));const s=t;return EL.runKernel("AddN",s)}}),dB=LL({all_:function(e,t=null,n=!1){const s={x:FL(e,"x","all","bool")},r={axis:t,keepDims:n};return EL.runKernel("All",s,r)}}),fB=LL({any_:function(e,t=null,n=!1){const s={x:FL(e,"x","any","bool")},r={axis:t,keepDims:n};return EL.runKernel("Any",s,r)}}),mB=LL({argMax_:function(e,t=0){const n={x:FL(e,"x","argMax")},s={axis:t};return EL.runKernel("ArgMax",n,s)}}),gB=LL({argMin_:function(e,t=0){const n={x:FL(e,"x","argMin")},s={axis:t};return EL.runKernel("ArgMin",n,s)}}),yB=LL({asin_:function(e){const t={x:FL(e,"x","asin")};return EL.runKernel("Asin",t)}}),bB=LL({asinh_:function(e){const t={x:FL(e,"x","asinh")};return EL.runKernel("Asinh",t)}}),xB=LL({atan_:function(e){const t={x:FL(e,"x","atan")};return EL.runKernel("Atan",t)}}),wB=LL({atan2_:function(e,t){let n=FL(e,"a","atan2"),s=FL(t,"b","atan2");[n,s]=kL(n,s);const r={a:n,b:s};return EL.runKernel("Atan2",r)}}),kB=LL({atanh_:function(e){const t={x:FL(e,"x","atanh")};return EL.runKernel("Atanh",t)}});function vB(e,t,n,s,r,a,i=!1,o="channelsLast"){let[l,u,c,h]=[-1,-1,-1,-1];if("channelsLast"===o)[l,u,c,h]=e;else{if("channelsFirst"!==o)throw new Error(`Unknown dataFormat ${o}`);[l,h,u,c]=e}const[p,d,,f]=t,[m,g]=IB(n),[y,b]=IB(s),x=NB(p,y),w=NB(d,b),{padInfo:k,outHeight:v,outWidth:I}=function(e,t,n,s,r,a,i,o,l){let u,c,h;if("number"==typeof e){u={top:e,bottom:e,left:e,right:e,type:0===e?"VALID":"NUMBER"};const r=function(e,t,n,s,r){null==s&&(s=function(e,t,n,s=1){const r=NB(t,s);return Math.floor((e[0]*(n-1)-n+r)/2)}(e,t,n));const a=e[1];return[SB((e[0]-t+2*s)/n+1,r),SB((a-t+2*s)/n+1,r)]}([t,n],a,s,e,o);c=r[0],h=r[1]}else if("same"===e){c=Math.ceil(t/s),h=Math.ceil(n/r);const e=Math.max(0,(c-1)*s+a-t),o=Math.max(0,(h-1)*r+i-n),l=Math.floor(e/2),p=e-l,d=Math.floor(o/2);u={top:l,bottom:p,left:d,right:o-d,type:"SAME"}}else if("valid"===e)u={top:0,bottom:0,left:0,right:0,type:"VALID"},c=Math.ceil((t-a+1)/s),h=Math.ceil((n-i+1)/r);else{if("object"!=typeof e)throw Error(`Unknown padding parameter: ${e}`);{const p="channelsLast"===l?e[1][0]:e[2][0],d="channelsLast"===l?e[1][1]:e[2][1],f="channelsLast"===l?e[2][0]:e[3][0],m="channelsLast"===l?e[2][1]:e[3][1];u={top:p,bottom:d,left:f,right:m,type:0===p&&0===d&&0===f&&0===m?"VALID":"EXPLICIT"},c=SB((t-a+p+d)/s+1,o),h=SB((n-i+f+m)/r+1,o)}}return{padInfo:u,outHeight:c,outWidth:h}}(r,u,c,m,g,x,w,a,o),N=i?f*h:f;let S;return"channelsFirst"===o?S=[l,N,v,I]:"channelsLast"===o&&(S=[l,v,I,N]),{batchSize:l,dataFormat:o,inHeight:u,inWidth:c,inChannels:h,outHeight:v,outWidth:I,outChannels:N,padInfo:k,strideHeight:m,strideWidth:g,filterHeight:p,filterWidth:d,effectiveFilterHeight:x,effectiveFilterWidth:w,dilationHeight:y,dilationWidth:b,inShape:e,outShape:S,filterShape:t}}function IB(e){return"number"==typeof e?[e,e,e]:2===e.length?[e[0],e[1],1]:e}function NB(e,t){return t<=1?e:e+(e-1)*(t-1)}function SB(e,t){if(!t)return Math.trunc(e);switch(t){case"round":return Math.round(e);case"ceil":return Math.ceil(e);case"floor":return Math.floor(e);default:throw new Error(`Unknown roundingMode ${t}`)}}function TB(e){const[t,n,s]=IB(e);return 1===t&&1===n&&1===s}function $B(e,t){return TB(e)||TB(t)}function EB(e,t,n){if(null!=n){if("string"==typeof t)throw Error(`Error in ${e}: pad must be an integer when using dimRoundingMode ${n} but got pad ${t}.`);if("number"==typeof t)aM(hM(t),(()=>`Error in ${e}: pad must be an integer when using dimRoundingMode ${n} but got pad ${t}.`));else{if("object"!=typeof t)throw Error(`Error in ${e}: Unknown padding parameter: ${t}`);t.forEach((t=>{t.forEach((t=>{aM(hM(t),(()=>`Error in ${e}: pad must be an integer when using dimRoundingMode ${n} but got pad ${t}.`))}))}))}}}const CB=LL({reshape_:function(e,t){const n={x:FL(e,"x","reshape","string_or_numeric")},s={shape:t};return EL.runKernel("Reshape",n,s)}}),RB=LL({avgPool_:function(e,t,n,s,r){const a=FL(e,"x","avgPool","float32");aM($B(n,1),(()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`));let i=a,o=!1;3===a.rank&&(o=!0,i=CB(a,[1,a.shape[0],a.shape[1],a.shape[2]])),aM(4===i.rank,(()=>`Error in avgPool: x must be rank 4 but got rank ${i.rank}.`)),EB("avgPool",s,r);const l={x:i},u={filterSize:t,strides:n,pad:s,dimRoundingMode:r};let c=EL.runKernel("AvgPool",l,u);return c=Bz(c,a.dtype),o?CB(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),AB=LL({avgPool3d_:function(e,t,n,s,r,a="NDHWC"){const i=FL(e,"x","avgPool3d","float32");let o=i,l=!1;4===i.rank&&(l=!0,o=CB(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),aM(5===o.rank,(()=>`Error in avgPool3d: x must be rank 5 but got rank ${o.rank}.`)),aM("NDHWC"===a,(()=>`Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${a}`)),EB("avgPool3d",s,r);const u={x:o},c={filterSize:t,strides:n,pad:s,dimRoundingMode:r,dataFormat:a};let h=EL.runKernel("AvgPool3D",u,c);return h=Bz(h,o.dtype),l?CB(h,[h.shape[1],h.shape[2],h.shape[3],h.shape[4]]):h}}),_B=LL({concat_:function(e,t=0){aM(e.length>=1,(()=>"Pass at least one tensor to concat"));const n=OL(e,"tensors","concat","string_or_numeric");if("complex64"===n[0].dtype&&n.forEach((e=>{if("complex64"!==e.dtype)throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${e.dtype}. `)})),1===n.length)return Pz(n[0]);const s=n,r={axis:t};return EL.runKernel("Concat",s,r)}}),DB=LL({matMul_:function(e,t,n=!1,s=!1){let r=FL(e,"a","matMul"),a=FL(t,"b","matMul");[r,a]=kL(r,a);const i={a:r,b:a},o={transposeA:n,transposeB:s};return EL.runKernel("BatchMatMul",i,o)}}),FB=LL({mul_:function(e,t){let n=FL(e,"a","mul"),s=FL(t,"b","mul");[n,s]=kL(n,s);const r={a:n,b:s};return EL.runKernel("Multiply",r)}}),OB=LL({sigmoid_:function(e){const t={x:FL(e,"x","sigmoid","float32")};return EL.runKernel("Sigmoid",t)}}),MB=LL({slice_:function(e,t,n){const s=FL(e,"x","slice","string_or_numeric");if(0===s.rank)throw new Error("Slicing scalar is not possible");const r={x:s},a={begin:t,size:n};return EL.runKernel("Slice",r,a)}}),LB=LL({tanh_:function(e){const t={x:FL(e,"x","tanh","float32")};return EL.runKernel("Tanh",t)}}),zB=LL({basicLSTMCell_:function(e,t,n,s,r,a){const i=FL(e,"forgetBias","basicLSTMCell"),o=FL(t,"lstmKernel","basicLSTMCell"),l=FL(n,"lstmBias","basicLSTMCell"),u=FL(s,"data","basicLSTMCell"),c=FL(r,"c","basicLSTMCell"),h=FL(a,"h","basicLSTMCell"),p=_B([u,h],1),d=DB(p,o),f=hB(d,l),m=f.shape[0],g=f.shape[1]/4,y=[m,g],b=MB(f,[0,0],y),x=MB(f,[0,g],y),w=MB(f,[0,2*g],y),k=MB(f,[0,3*g],y),v=hB(FB(OB(b),LB(x)),FB(c,OB(hB(i,w))));return[v,FB(LB(v),OB(k))]}}),BB=LL({batchToSpaceND_:function(e,t,n){const s=FL(e,"x","batchToSpaceND"),r=t.reduce(((e,t)=>e*t));aM(s.rank>=1+t.length,(()=>`input rank is ${s.rank} but should be > than blockShape.length ${t.length}`)),aM(n.length===t.length,(()=>`crops.length is ${n.length} but should be equal to blockShape.length  ${t.length}`)),aM(s.shape[0]%r==0,(()=>`input tensor batch is ${s.shape[0]} but is not divisible by the product of the elements of blockShape ${t.join(" * ")} === ${r}`));const a={x:s},i={blockShape:t,crops:n};return EL.runKernel("BatchToSpaceND",a,i)}}),PB=LL({batchNorm_:function(e,t,n,s,r,a){null==a&&(a=.001);const i=FL(e,"x","batchNorm"),o=FL(t,"mean","batchNorm"),l=FL(n,"variance","batchNorm");let u,c;null!=r&&(u=FL(r,"scale","batchNorm")),null!=s&&(c=FL(s,"offset","batchNorm")),aM(o.rank===l.rank,(()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),aM(null==c||o.rank===c.rank,(()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),aM(null==u||o.rank===u.rank,(()=>"Batch normalization gradient requires mean and scale to have equal ranks."));const h={x:function(e){let t;return t=0===e.rank||1===e.rank?CB(e,[1,1,1,e.size]):2===e.rank?CB(e,[1,1,e.shape[0],e.shape[1]]):3===e.rank?CB(e,[1,e.shape[0],e.shape[1],e.shape[2]]):e,t}(i),scale:u,offset:c,mean:o,variance:l},p={varianceEpsilon:a},d=EL.runKernel("FusedBatchNorm",h,p);return CB(d,i.shape)}}),WB=LL({batchNorm2d_:function(e,t,n,s,r,a){const i=FL(e,"x","batchNorm"),o=FL(t,"mean","batchNorm"),l=FL(n,"variance","batchNorm");let u,c;return null!=r&&(u=FL(r,"scale","batchNorm")),null!=s&&(c=FL(s,"offset","batchNorm")),aM(2===i.rank,(()=>`Error in batchNorm2D: x must be rank 2 but got rank ${i.rank}.`)),aM(2===o.rank||1===o.rank,(()=>`Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${o.rank}.`)),aM(2===l.rank||1===l.rank,(()=>`Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${l.rank}.`)),null!=u&&aM(2===u.rank||1===u.rank,(()=>`Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${u.rank}.`)),null!=c&&aM(2===c.rank||1===c.rank,(()=>`Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${c.rank}.`)),PB(i,o,l,c,u,a)}}),VB=LL({batchNorm3d_:function(e,t,n,s,r,a){const i=FL(e,"x","batchNorm"),o=FL(t,"mean","batchNorm"),l=FL(n,"variance","batchNorm");let u,c;return null!=r&&(u=FL(r,"scale","batchNorm")),null!=s&&(c=FL(s,"offset","batchNorm")),aM(3===i.rank,(()=>`Error in batchNorm3D: x must be rank 3 but got rank ${i.rank}.`)),aM(3===o.rank||1===o.rank,(()=>`Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${o.rank}.`)),aM(3===l.rank||1===l.rank,(()=>`Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${l.rank}.`)),null!=u&&aM(3===u.rank||1===u.rank,(()=>`Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${u.rank}.`)),null!=c&&aM(3===c.rank||1===c.rank,(()=>`Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${c.rank}.`)),PB(i,o,l,c,u,a)}}),UB=LL({batchNorm4d_:function(e,t,n,s,r,a){const i=FL(e,"x","batchNorm"),o=FL(t,"mean","batchNorm"),l=FL(n,"variance","batchNorm");let u,c;return null!=r&&(u=FL(r,"scale","batchNorm")),null!=s&&(c=FL(s,"offset","batchNorm")),aM(4===i.rank,(()=>`Error in batchNorm4D: x must be rank 4 but got rank ${i.rank}.`)),aM(4===o.rank||1===o.rank,(()=>`Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${o.rank}.`)),aM(4===l.rank||1===l.rank,(()=>`Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${l.rank}.`)),null!=u&&aM(4===u.rank||1===u.rank,(()=>`Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${u.rank}.`)),null!=c&&aM(4===c.rank||1===c.rank,(()=>`Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${c.rank}.`)),PB(i,o,l,c,u,a)}}),GB=LL({bincount_:function(e,t,n){const s=FL(e,"x","bincount"),r=FL(t,"weights","bincount");aM("int32"===s.dtype,(()=>`Error in bincount: input dtype must be int32, but got ${s.dtype}`)),aM(n>=0,(()=>`size must be non-negative, but got ${n}.`)),aM(r.size===s.size||0===r.size,(()=>`Error in bincount: weights must have the same size as input or0-length, but got input shape: ${s.shape}, weights shape: ${r.shape}.`));const a={x:s,weights:r},i={size:n};return EL.runKernel("Bincount",a,i)}}),HB=LL({broadcastArgs_:function(e,t){const n=FL(e,"s0","broadcastArgs","int32"),s=FL(t,"s1","broadcastArgs","int32");if(1!==n.rank)throw new Error(`broadcastArgs(): first input must be a vector (rank=1). Has rank ${n.rank}`);if(1!==s.rank)throw new Error(`broadcastArgs(): second input must be a vector (rank=1). Has rank ${s.rank}`);const r={s0:n,s1:s};return EL.runKernel("BroadcastArgs",r)}}),jB=LL({broadcastTo_:function(e,t){let n=FL(e,"broadcastTo","x");const s=n.shape;if(t.some((e=>!(e>0)||e%1!=0)))throw new Error(`broadcastTo(): Invalid broadcast shape [${t}].`);if(t.length<n.rank)throw new Error(`broadcastTo(): shape.length=${t.length} < input.rank=${n.rank}.`);if(t.length>n.rank){const e=n.shape.slice();for(;e.length<t.length;)e.unshift(1);n=CB(n,e)}const r=n.shape,a=Array.from(t);for(let e=t.length-1;e>=0;e--)if(r[e]===t[e])a[e]=1;else if(1!==n.shape[e])throw new Error(`broadcastTo(): [${s}] cannot be broadcast to [${t}].`);if(0===a.map(((e,t)=>e>1?t:-1)).filter((e=>e>=0)).length)return Pz(n);const i={x:n},o={reps:a};return EL.runKernel(BM,i,o)}}),KB=LL({ceil_:function(e){const t={x:FL(e,"x","ceil","float32")};return EL.runKernel("Ceil",t)}});function qB(e,t,n){const s={shape:e,value:t,dtype:n};return EL.runKernel(OM,{},s)}const XB=LL({clipByValue_:function(e,t,n){const s=FL(e,"x","clipByValue");if(aM(t<=n,(()=>`Error in clip: min (${t}) must be less than or equal to max (${n}).`)),t===n)return qB(s.shape,t,s.dtype);const r={x:s},a={clipValueMin:t,clipValueMax:n};return EL.runKernel("ClipByValue",r,a)}}),YB=LL({concat1d_:function(e){return _B(e,0)}}),JB=LL({concat2d_:function(e,t){return _B(e,t)}}),ZB=LL({concat3d_:function(e,t){return _B(e,t)}}),QB=LL({concat4d_:function(e,t){return _B(e,t)}}),eP=LL({conv2d_:function(e,t,n,s,r="NHWC",a=[1,1],i){const o=FL(e,"x","conv2d","float32"),l=FL(t,"filter","conv2d","float32");let u=o,c=!1;3===o.rank&&(c=!0,u=CB(o,[1,o.shape[0],o.shape[1],o.shape[2]])),aM(4===u.rank,(()=>`Error in conv2d: input must be rank 4, but got rank ${u.rank}.`)),aM(4===l.rank,(()=>`Error in conv2d: filter must be rank 4, but got rank ${l.rank}.`)),EB("conv2d",s,i);const h="NHWC"===r?u.shape[3]:u.shape[1];aM(h===l.shape[2],(()=>`Error in conv2d: depth of input (${h}) must match input depth for filter ${l.shape[2]}.`)),aM($B(n,a),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`));const p={x:u,filter:l},d={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i},f=EL.runKernel("Conv2D",p,d);return c?CB(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),tP=LL({conv1d_:function(e,t,n,s,r="NWC",a=1,i){const o=FL(e,"x","conv1d"),l=FL(t,"filter","conv1d");let u=o,c=!1;2===o.rank&&(c=!0,u=CB(o,[1,o.shape[0],o.shape[1]])),aM(3===u.rank,(()=>`Error in conv1d: input must be rank 3, but got rank ${u.rank}.`)),aM(3===l.rank,(()=>`Error in conv1d: filter must be rank 3, but got rank ${l.rank}.`)),EB("conv1d",s,i),aM(u.shape[2]===l.shape[1],(()=>`Error in conv1d: depth of input (${u.shape[2]}) must match input depth for filter ${l.shape[1]}.`)),aM($B(n,a),(()=>`Error in conv1D: Either stride or dilation must be 1. Got stride ${n} and dilation '${a}'`)),aM("NWC"===r,(()=>`Error in conv1d: got dataFormat of ${r} but only NWC is currently supported.`));const h=CB(l,[1,l.shape[0],l.shape[1],l.shape[2]]),p=CB(u,[u.shape[0],1,u.shape[1],u.shape[2]]),d=eP(p,h,[1,n],s,"NHWC",[1,a],i);return CB(d,c?[d.shape[2],d.shape[3]]:[d.shape[0],d.shape[2],d.shape[3]])}}),nP=LL({conv2DBackpropInput_:function(e,t,n,s,r,a="NHWC",i){aM(e.length===t.rank,(()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`));let o=e,l=t,u=!1;3===t.rank&&(u=!0,l=CB(t,[1,t.shape[0],t.shape[1],t.shape[2]]),o=[1,e[0],e[1],e[2]]),aM(4===o.length,(()=>`Error in conv2dDerInput: inShape must be length 4, but got length ${o.length}.`)),aM(4===l.rank,(()=>`Error in conv2dDerInput: dy must be rank 4, but got rank ${l.rank}`)),aM(4===n.rank,(()=>`Error in conv2dDerInput: filter must be rank 4, but got rank ${n.rank}`));const c="NHWC"===a?o[3]:o[1],h="NHWC"===a?l.shape[3]:l.shape[1];aM(c===n.shape[2],(()=>`Error in conv2dDerInput: depth of input (${c}) must match input depth for filter ${n.shape[2]}.`)),aM(h===n.shape[3],(()=>`Error in conv2dDerInput: depth of output (${h}) must match output depth for filter ${n.shape[3]}.`)),EB("conv2dDerInput",r,i);const p={dy:l,filter:n},d={strides:s,pad:r,dataFormat:a,dimRoundingMode:i,inputShape:o},f=EL.runKernel("Conv2DBackpropInput",p,d);return u?CB(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),sP=LL({conv2dTranspose_:function(e,t,n,s,r,a){const i=FL(e,"x","conv2dTranspose"),o=FL(t,"filter","conv2dTranspose");return nP(n,i,o,s,r,"NHWC",a)}}),rP=LL({conv3d_:function(e,t,n,s,r="NDHWC",a=[1,1,1]){const i=FL(e,"x","conv3d"),o=FL(t,"filter","conv3d");let l=i,u=!1;4===i.rank&&(u=!0,l=CB(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),aM(5===l.rank,(()=>`Error in conv3d: input must be rank 5, but got rank ${l.rank}.`)),aM(5===o.rank,(()=>`Error in conv3d: filter must be rank 5, but got rank ${o.rank}.`)),aM(l.shape[4]===o.shape[3],(()=>`Error in conv3d: depth of input (${l.shape[4]}) must match input depth for filter ${o.shape[3]}.`)),aM($B(n,a),(()=>`Error in conv3D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`)),aM("NDHWC"===r,(()=>`Error in conv3d: got dataFormat of ${r} but only NDHWC is currently supported.`));const c={x:l,filter:o},h={strides:n,pad:s,dataFormat:r,dilations:a},p=EL.runKernel("Conv3D",c,h);return u?CB(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}}),aP=LL({conv3DBackpropInput_:function(e,t,n,s,r){aM(e.length===t.rank,(()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`));let a=e,i=t,o=!1;4===t.rank&&(o=!0,i=CB(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]]),a=[1,e[0],e[1],e[2],e[3]]);const l=a[4],u=i.shape[4];aM(5===a.length,(()=>`Error in conv3dDerInput: inShape must be length 5, but got length ${a.length}.`)),aM(5===i.rank,(()=>`Error in conv3dDerInput: dy must be rank 5, but got rank ${i.rank}`)),aM(5===n.rank,(()=>`Error in conv3dDerInput: filter must be rank 5, but got rank ${n.rank}`)),aM(l===n.shape[3],(()=>`Error in conv3dDerInput: depth of input (${l}) must match input depth for filter ${n.shape[3]}.`)),aM(u===n.shape[4],(()=>`Error in conv3dDerInput: depth of output (${u}) must match output depth for filter ${n.shape[4]}.`));const c={dy:i,filter:n},h={pad:r,strides:s,inputShape:a},p=EL.runKernel("Conv3DBackpropInputV2",c,h);return o?CB(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}}),iP=LL({conv3dTranspose_:function(e,t,n,s,r){const a=FL(e,"x","conv3dTranspose"),i=FL(t,"filter","conv3dTranspose");return aP(n,a,i,s,r)}}),oP=LL({cos_:function(e){const t={x:FL(e,"x","cos","float32")};return EL.runKernel("Cos",t)}}),lP=LL({cosh_:function(e){const t={x:FL(e,"x","cosh","float32")};return EL.runKernel("Cosh",t)}}),uP=LL({cumprod_:function(e,t=0,n=!1,s=!1){const r={x:FL(e,"x","cumprod")},a={axis:t,exclusive:n,reverse:s};return EL.runKernel("Cumprod",r,a)}}),cP=LL({cumsum_:function(e,t=0,n=!1,s=!1){const r={x:FL(e,"x","cumsum")},a={axis:t,exclusive:n,reverse:s};return EL.runKernel("Cumsum",r,a)}}),hP=LL({denseBincount_:function(e,t,n,s=!1){const r=FL(e,"x","denseBincount"),a=FL(t,"weights","denseBincount");aM("int32"===r.dtype,(()=>`Error in denseBincount: input dtype must be int32, but got ${r.dtype}`)),aM(r.rank<=2,(()=>`Error in denseBincount: input must be at most rank 2, but got rank ${r.rank}.`)),aM(n>=0,(()=>`size must be non-negative, but got ${n}.`)),aM(a.size===r.size||0===a.size,(()=>`Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${r.shape}, weights shape: ${a.shape}.`));const i={x:r,weights:a},o={size:n,binaryOutput:s};return EL.runKernel("DenseBincount",i,o)}}),pP=LL({depthToSpace_:function(e,t,n="NHWC"){const s=FL(e,"x","depthToSpace","float32"),r="NHWC"===n?s.shape[1]:s.shape[2],a="NHWC"===n?s.shape[2]:s.shape[3],i="NHWC"===n?s.shape[3]:s.shape[1];aM(t>1,(()=>`blockSize should be > 1 for depthToSpace, but was: ${t}`)),aM(r*t>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${r} and ${t}  for depthToSpace with input shape\n    ${s.shape}`)),aM(a*t>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${a} and ${t} for depthToSpace with input shape\n        ${s.shape}`)),aM(i%(t*t)==0,(()=>`Dimension size must be evenly divisible by ${t*t} but is ${i} for depthToSpace with input shape ${s.shape}`));const o={x:s},l={blockSize:t,dataFormat:n};return EL.runKernel("DepthToSpace",o,l)}}),dP=LL({depthwiseConv2d_:function(e,t,n,s,r="NHWC",a=[1,1],i){const o=FL(e,"x","depthwiseConv2d","float32"),l=FL(t,"filter","depthwiseConv2d","float32");let u=o,c=!1;3===o.rank&&(c=!0,u=CB(o,[1,o.shape[0],o.shape[1],o.shape[2]])),aM(4===u.rank,(()=>`Error in depthwiseConv2d: input must be rank 4, but got rank ${u.rank}.`)),aM(4===l.rank,(()=>`Error in depthwiseConv2d: filter must be rank 4, but got rank ${l.rank}.`));const h="NHWC"===r?u.shape[3]:u.shape[1];aM(h===l.shape[2],(()=>`Error in depthwiseConv2d: number of input channels (${h}) must match the inChannels dimension in filter ${l.shape[2]}.`)),EB("depthwiseConv2d",s,i);const p={x:u,filter:l},d={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i},f=EL.runKernel("DepthwiseConv2dNative",p,d);return c?CB(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),fP=LL({diag_:function(e){const t={x:FL(e,"x","diag")};return EL.runKernel("Diag",t)}}),mP=LL({dilation2d_:function(e,t,n,s,r=[1,1],a="NHWC"){const i=FL(e,"x","dilation2d"),o=FL(t,"filter","dilation2d");aM(3===i.rank||4===i.rank,(()=>`Error in dilation2d: input must be rank 3 or 4, but got rank ${i.rank}.`)),aM(3===o.rank,(()=>`Error in dilation2d: filter must be rank 3, but got rank ${o.rank}.`)),aM("NHWC"===a,(()=>`Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${a}`));let l=i,u=!1;3===i.rank&&(l=CB(i,[1,i.shape[0],i.shape[1],i.shape[2]]),u=!0);const c={x:l,filter:o},h={strides:n,pad:s,dilations:r},p=EL.runKernel("Dilation2D",c,h);return u?CB(p,[p.shape[1],p.shape[2],p.shape[3]]):p}}),gP=LL({floorDiv_:function(e,t){let n=FL(e,"a","floorDiv"),s=FL(t,"b","floorDiv");[n,s]=kL(n,s);const r={a:n,b:s};return EL.runKernel("FloorDiv",r)}}),yP=LL({div_:function(e,t){let n=FL(e,"a","div"),s=FL(t,"b","div");if([n,s]=kL(n,s),"int32"===n.dtype&&"int32"===s.dtype)return gP(n,s);const r={a:n,b:s};return EL.runKernel("RealDiv",r,{})}});function bP(e,t){const n=[],s=Math.max(e.length,t.length);for(let r=0;r<s;r++){let s=e[e.length-r-1];null==s&&(s=1);let a=t[t.length-r-1];if(null==a&&(a=1),1===s)n.unshift(a);else if(1===a)n.unshift(s);else{if(s!==a)throw Error(`Operands could not be broadcast together with shapes ${e} and ${t}.`);n.unshift(s)}}return n}const xP=LL({equal_:function(e,t){let n=FL(e,"a","equal","string_or_numeric"),s=FL(t,"b","equal","string_or_numeric");[n,s]=kL(n,s),bP(n.shape,s.shape);const r={a:n,b:s};return EL.runKernel("Equal",r)}}),wP=LL({where_:function(e,t,n){const s=FL(t,"a","where"),r=FL(n,"b","where"),a=FL(e,"condition","where","bool"),i=bP(bP(a.shape,s.shape),r.shape),o={condition:jB(a,i),t:jB(s,i),e:jB(r,i)};return EL.runKernel("Select",o)}}),kP=LL({zerosLike_:function(e){const t={x:FL(e,"x","zerosLike")};return EL.runKernel("ZerosLike",t)}}),vP=LL({divNoNan_:function(e,t){let n=FL(e,"a","div"),s=FL(t,"b","div");[n,s]=kL(n,s);const r=yP(n,s),a=kP(r),i=xP(s,a);return wP(i,a,r)}}),IP=LL({dot_:function(e,t){const n=FL(e,"t1","dot"),s=FL(t,"t2","dot");aM(!(1!==n.rank&&2!==n.rank||1!==s.rank&&2!==s.rank),(()=>`Error in dot: inputs must all be rank 1 or 2, but got ranks ${n.rank} and ${s.rank}.`));const r=1===n.rank?n.size:n.shape[1],a=1===s.rank?s.size:s.shape[0];if(aM(r===a,(()=>`Error in dot: inner dimensions of inputs must match, but got ${r} and ${a}.`)),1===n.rank&&1===s.rank){const e=CB(n,[1,-1]),t=CB(s,[-1,1]),r=DB(e,t);return CB(r,[])}if(1===n.rank&&2===s.rank){const e=CB(n,[1,-1]),t=CB(s,[s.shape[0],s.shape[1]]),r=DB(e,t);return CB(r,[r.size])}if(2===n.rank&&1===s.rank){const e=CB(s,[-1,1]),t=DB(n,e);return CB(t,[t.size])}{const e=CB(s,[s.shape[0],s.shape[1]]);return DB(n,e)}}}),NP=LL({einsum_:function(e,...t){const n=t.map(((e,t)=>FL(e,`tensors${t}`,"einsum"))),s={equation:e};return EL.runKernel("Einsum",n,s)}}),SP=LL({elu_:function(e){const t={x:FL(e,"x","elu","float32")};return EL.runKernel("Elu",t)}}),TP=LL({erf_:function(e){let t=FL(e,"x","erf");aM("int32"===t.dtype||"float32"===t.dtype,(()=>"Input dtype must be `int32` or `float32`.")),"int32"===t.dtype&&(t=Bz(t,"float32"));const n={x:t};return EL.runKernel("Erf",n)}});function $P(e,t){return function(e,t,n){const s=e.length+t.length,r=[];let a=0,i=0;for(let o=0;o<s;o++)-1===n.indexOf(o)?r.push(e[a++]):r.push(t[i++]);return r}(e,t.map((e=>1)),t)}const EP=LL({max_:function(e,t=null,n=!1){const s={x:FL(e,"x","max")},r={reductionIndices:t,keepDims:n};return EL.runKernel("Max",s,r)}}),CP=LL({min_:function(e,t=null,n=!1){const s={x:FL(e,"x","min")},r={axis:t,keepDims:n};return EL.runKernel("Min",s,r)}}),RP=LL({pow_:function(e,t){let n=FL(e,"base","pow"),s=FL(t,"exp","pow");[n,s]=kL(n,s);const r={a:n,b:s};return EL.runKernel("Pow",r)}});function AP(e,t){if((fM(e)&&"string"!==t||Array.isArray(e))&&"complex64"!==t)throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");if("string"===t&&fM(e)&&!(e instanceof Uint8Array))throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");return BL(e,[],[],t)}const _P=LL({sqrt_:function(e){const t={x:FL(e,"x","sqrt","float32")};return EL.runKernel("Sqrt",t)}}),DP=LL({square_:function(e){const t=FL(e,"x","square");return EL.runKernel("Square",{x:t},{})}}),FP=LL({sum_:function(e,t=null,n=!1){let s=FL(e,"x","sum");"bool"===s.dtype&&(s=Bz(s,"int32"));const r={x:s},a={axis:t,keepDims:n};return EL.runKernel("Sum",r,a)}});function OP(e,t,n=null){if(0===e.rank)return lB(e);if(1!==e.rank&&null===n)return OP(CB(e,[-1]),t,n);if(1===e.rank||"number"==typeof n||Array.isArray(n)&&1===n.length){if(1===t)return FP(lB(e),n);if(t===1/0)return EP(lB(e),n);if(t===-1/0)return CP(lB(e),n);if("euclidean"===t||2===t)return _P(FP(RP(lB(e),AP(2,"int32")),n));throw new Error(`Error in norm: invalid ord value: ${t}`)}if(Array.isArray(n)&&2===n.length){if(1===t)return EP(FP(lB(e),n[0]),n[1]-1);if(t===1/0)return EP(FP(lB(e),n[1]),n[0]);if(t===-1/0)return CP(FP(lB(e),n[1]),n[0]);if("fro"===t||"euclidean"===t)return _P(FP(DP(e),n));throw new Error(`Error in norm: invalid ord value: ${t}`)}throw new Error(`Error in norm: invalid axis: ${n}`)}const MP=LL({norm_:function(e,t="euclidean",n=null,s=!1){const r=OP(e=FL(e,"x","norm"),t,n);let a=r.shape;if(s){const t=dM(n,e.shape);a=$P(r.shape,t)}return CB(r,a)}}),LP=LL({euclideanNorm_:function(e,t=null,n=!1){return MP(e,"euclidean",t,n)}}),zP=LL({exp_:function(e){const t={x:FL(e,"x","exp")};return EL.runKernel("Exp",t)}}),BP=LL({expandDims_:function(e,t=0){const n=FL(e,"x","expandDims","string_or_numeric");aM(t<=n.rank,(()=>"Axis must be <= rank of the tensor"));const s={input:n},r={dim:t};return EL.runKernel("ExpandDims",s,r)}}),PP=LL({expm1_:function(e){const t={x:FL(e,"x","expm1")};return EL.runKernel("Expm1",t)}}),WP=LL({tile_:function(e,t){const n=FL(e,"x","tile","string_or_numeric");aM(n.rank===t.length,(()=>`Error in transpose: rank of input ${n.rank} must match length of reps ${t}.`));const s={x:n},r={reps:t};return EL.runKernel(BM,s,r)}}),VP=LL({eye_:function(e,t,n,s="float32"){null==t&&(t=e);const r=zz([e,t],s),a=e<=t?e:t;for(let e=0;e<a;++e)r.set(1,e,e);const i=CB(r.toTensor(),[e,t]);if(null==n)return i;if(1===n.length)return WP(BP(i,0),[n[0],1,1]);if(2===n.length)return WP(BP(BP(i,0),0),[n[0],n[1],1,1]);if(3===n.length)return WP(BP(BP(BP(i,0),0),0),[n[0],n[1],n[2],1,1]);throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${n.length}D.`)}}),UP=LL({floor_:function(e){const t={x:FL(e,"x","floor","float32")};return EL.runKernel("Floor",t)}}),GP=LL({gather_:function(e,t,n=0,s=0){const r={x:FL(e,"x","gather"),indices:FL(t,"indices","gather","int32")},a={axis:n,batchDims:s};return EL.runKernel("GatherV2",r,a)}}),HP=LL({greater_:function(e,t){let n=FL(e,"a","greater","string_or_numeric"),s=FL(t,"b","greater","string_or_numeric");[n,s]=kL(n,s),bP(n.shape,s.shape);const r={a:n,b:s};return EL.runKernel("Greater",r)}}),jP=LL({greaterEqual_:function(e,t){let n=FL(e,"a","greaterEqual","string_or_numeric"),s=FL(t,"b","greaterEqual","string_or_numeric");[n,s]=kL(n,s),bP(n.shape,s.shape);const r={a:n,b:s};return EL.runKernel("GreaterEqual",r)}}),KP=LL({imag_:function(e){const t={input:FL(e,"input","imag")};return EL.runKernel("Imag",t)}}),qP=LL({isFinite_:function(e){const t={x:FL(e,"x","isFinite")};return EL.runKernel("IsFinite",t)}}),XP=LL({isInf_:function(e){const t={x:FL(e,"x","isInf")};return EL.runKernel("IsInf",t)}}),YP=LL({isNaN_:function(e){const t={x:FL(e,"x","isNaN")};return EL.runKernel("IsNan",t)}}),JP=LL({leakyRelu_:function(e,t=.2){const n={x:FL(e,"x","leakyRelu")},s={alpha:t};return EL.runKernel("LeakyRelu",n,s)}}),ZP=LL({less_:function(e,t){let n=FL(e,"a","less","string_or_numeric"),s=FL(t,"b","less","string_or_numeric");[n,s]=kL(n,s),bP(n.shape,s.shape);const r={a:n,b:s};return EL.runKernel("Less",r)}}),QP=LL({lessEqual_:function(e,t){let n=FL(e,"a","lessEqual","string_or_numeric"),s=FL(t,"b","lessEqual","string_or_numeric");[n,s]=kL(n,s),bP(n.shape,s.shape);const r={a:n,b:s};return EL.runKernel("LessEqual",r)}});function eW(e,t,n){if(n<=0)throw new Error("The number of values should be positive.");const s={start:e,stop:t,num:n};return EL.runKernel(LM,{},s)}const tW=LL({localResponseNormalization_:function(e,t=5,n=1,s=1,r=.5){const a=FL(e,"x","localResponseNormalization");aM(4===a.rank||3===a.rank,(()=>`Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ${a.rank}.`)),aM(hM(t),(()=>`Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${t}.`));let i=a,o=!1;3===a.rank&&(o=!0,i=CB(a,[1,a.shape[0],a.shape[1],a.shape[2]]));const l={x:i},u={depthRadius:t,bias:n,alpha:s,beta:r},c=EL.runKernel("LRN",l,u);return o?CB(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),nW=LL({log_:function(e){const t={x:FL(e,"x","log","float32")};return EL.runKernel("Log",t)}}),sW=LL({log1p_:function(e){const t={x:FL(e,"x","log1p")};return EL.runKernel("Log1p",t)}});function rW(e){return EL.customGrad(e)}const aW=LL({neg_:function(e){const t={x:FL(e,"x","neg")};return EL.runKernel("Neg",t)}}),iW=LL({softplus_:function(e){const t={x:FL(e,"x","softplus")};return EL.runKernel("Softplus",t)}}),oW=LL({logSigmoid_:function(e){const t=FL(e,"x","logSigmoid");return rW((e=>({value:aW(iW(aW(e))),gradFunc:t=>FB(t,OB(aW(e)))})))(t)}}),lW=LL({sub_:function(e,t){let n=FL(e,"a","sub"),s=FL(t,"b","sub");[n,s]=kL(n,s);const r={a:n,b:s};return EL.runKernel("Sub",r)}}),uW=LL({logSoftmax_:function(e,t=-1){const n=FL(e,"logits","logSoftmax");if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and axis was ${t}`);const s=rW(((e,n)=>{const s=EP(e,t,!0),r=lW(e,s),a=lW(Bz(r,"float32"),nW(FP(zP(r),t,!0)));return n([a]),{value:a,gradFunc:(e,n)=>{const[s]=n,r=zP(s);return lW(e,FB(FP(e,t,!0),r))}}}));return s(n)}}),cW=LL({logSumExp_:function(e,t=null,n=!1){const s=FL(e,"x","logSumExp"),r=dM(t,s.shape),a=EP(s,r,!0),i=lW(s,a),o=zP(i),l=FP(o,r),u=nW(l),c=hB(CB(a,u.shape),u);if(n){const e=$P(c.shape,r);return CB(c,e)}return c}}),hW=LL({logicalAnd_:function(e,t){const n=FL(e,"a","logicalAnd","bool"),s=FL(t,"b","logicalAnd","bool");bP(n.shape,s.shape);const r={a:n,b:s};return EL.runKernel("LogicalAnd",r)}}),pW=LL({logicalNot_:function(e){const t={x:FL(e,"x","logicalNot","bool")};return EL.runKernel("LogicalNot",t)}}),dW=LL({logicalOr_:function(e,t){const n=FL(e,"a","logicalOr","bool"),s=FL(t,"b","logicalOr","bool");bP(n.shape,s.shape);const r={a:n,b:s};return EL.runKernel("LogicalOr",r)}}),fW=LL({logicalXor_:function(e,t){const n=FL(e,"a","logicalXor","bool"),s=FL(t,"b","logicalXor","bool");return bP(n.shape,s.shape),hW(dW(e,t),pW(hW(e,t)))}}),mW=2147483648,gW=LL({searchSorted_:function(e,t,n="left"){const s=FL(e,"sortedSequence","searchSorted"),r=FL(t,"values","searchSorted"),a=s.shape[s.shape.length-1],i=r.shape[r.shape.length-1],o=CB(s,[-1,a]),l=CB(r,[-1,i]);if(o.rank<2)throw new Error("Sorted input argument must be at least 2-dimensional");if(o.shape[0]!==l.shape[0])throw new Error("Leading dimension of 'sortedSequence' and 'values' must match.");if(uM(l.shape)>=mW)throw new Error("values tensor size must less than 2147483648");if(o.shape[1]>=mW)throw new Error(`trailing dim_size must less than 2147483648 for int32 output type, was ${o.shape[1]}`);const u={sortedSequence:o,values:l},c={side:n};return EL.runKernel("SearchSorted",u,c)}});function yW(e,t){return gW(e,t,"left")}const bW=LL({maxPool_:function(e,t,n,s,r){const a=FL(e,"x","maxPool");let i=a,o=!1;3===a.rank&&(o=!0,i=CB(a,[1,a.shape[0],a.shape[1],a.shape[2]])),aM(4===i.rank,(()=>`Error in maxPool: input must be rank 4 but got rank ${i.rank}.`)),aM($B(n,1),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`)),EB("maxPool",s,r);const l={x:i},u={filterSize:t,strides:n,pad:s,dimRoundingMode:r},c=EL.runKernel("MaxPool",l,u);return o?CB(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),xW=LL({maxPool3d_:function(e,t=[1,1,1],n,s,r,a="NDHWC"){const i=FL(e,"x","maxPool3d");let o=i,l=!1;4===i.rank&&(l=!0,o=CB(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),aM(5===o.rank,(()=>`Error in maxPool3d: x must be rank 5 but got rank ${o.rank}.`)),aM("NDHWC"===a,(()=>`Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${a}`)),EB("maxPool3d",s,r);const u={x:o},c={filterSize:t,strides:n,pad:s,dimRoundingMode:r,dataFormat:a},h=EL.runKernel("MaxPool3D",u,c);return l?CB(h,[h.shape[1],h.shape[2],h.shape[3],h.shape[4]]):h}}),wW=LL({maxPoolWithArgmax_:function(e,t,n,s,r=!1){const a={x:FL(e,"x","maxPoolWithArgmax")},i={filterSize:t,strides:n,pad:s,includeBatchInIndex:r},o=EL.runKernel("MaxPoolWithArgmax",a,i);return{result:o[0],indexes:o[1]}}}),kW=LL({maximum_:function(e,t){let n=FL(e,"a","maximum"),s=FL(t,"b","maximum");[n,s]=kL(n,s),"bool"===n.dtype&&(n=Bz(n,"int32"),s=Bz(s,"int32")),bP(n.shape,s.shape);const r={a:n,b:s};return EL.runKernel("Maximum",r)}}),vW=LL({mean_:function(e,t=null,n=!1){const s={x:FL(e,"x","mean")},r={axis:t,keepDims:n};return EL.runKernel("Mean",s,r)}});function IW(e,t="float32"){if("complex64"===t){const t=IW(e,"float32"),n=IW(e,"float32");return zL(t,n)}const n=IM(uM(e),t);return EL.makeTensor(n,e,t)}function NW(e,t="float32"){if("complex64"===t){const t=NW(e,"float32"),n=IW(e,"float32");return zL(t,n)}const n=vM(uM(e),t);return EL.makeTensor(n,e,t)}function SW(e,t,{indexing:n="xy"}={}){if("xy"!==n&&"ij"!==n)throw new TypeError(`${n} is not a valid third argument to meshgrid`);if(void 0===e)return[];let s=FL(e,"x","meshgrid",e instanceof dL?e.dtype:"float32");if(void 0===t)return[s];let r=FL(t,"y","meshgrid",t instanceof dL?t.dtype:"float32");const a=uM(s.shape),i=uM(r.shape);return"xy"===n?(s=CB(s,[1,-1]),r=CB(r,[-1,1]),[DB(NW([i,1],s.dtype),s),DB(r,NW([1,a],r.dtype))]):(s=CB(s,[-1,1]),r=CB(r,[1,-1]),[DB(s,NW([1,i],s.dtype)),DB(NW([a,1],r.dtype),r)])}const TW=LL({minimum_:function(e,t){let n=FL(e,"a","minimum"),s=FL(t,"b","minimum");[n,s]=kL(n,s),"bool"===n.dtype&&(n=Bz(n,"int32"),s=Bz(s,"int32")),bP(n.shape,s.shape);const r={a:n,b:s};return EL.runKernel("Minimum",r)}}),$W=LL({mirrorPad_:function(e,t,n){aM("reflect"===n||"symmetric"===n,(()=>`Invalid mode. Mode must be either reflect or symmetric. Got ${n}.`));const s=FL(e,"x","mirrorPad");if(0===s.rank)throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");aM(t.length===s.rank,(()=>`Padding doesn't match input. Must be ${s.rank}. Got ${t.length}.`));const r="reflect"===n?1:0;for(let e=0;e<s.rank;e++)aM(2===t[e].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),aM(t[e][0]>=0&&t[e][0]<=s.shape[e]-r&&t[e][1]>=0&&t[e][1]<=s.shape[e]-r,(()=>`Padding in dimension ${e} cannot be greater than or equal to ${s.shape[e]-r} or less than 0 for input of shape ${s.shape}`));const a={paddings:t,mode:n},i={x:s};return EL.runKernel("MirrorPad",i,a)}}),EW=LL({mod_:function(e,t){let n=FL(e,"a","mod"),s=FL(t,"b","mod");[n,s]=kL(n,s);const r={a:n,b:s};return EL.runKernel("Mod",r)}}),CW=LL({moments_:function(e,t=null,n=!1){const s=dM(t,(e=FL(e,"x","moments")).shape),r=vW(e,s,n);let a=r.shape;n||(a=$P(r.shape,s));const i=DP(lW(Bz(e,"float32"),CB(r,a)));return{mean:r,variance:vW(i,s,n)}}}),RW=LL({multiRNNCell_:function(e,t,n,s){const r=FL(t,"data","multiRNNCell"),a=OL(n,"c","multiRNNCell"),i=OL(s,"h","multiRNNCell");let o=r;const l=[];for(let t=0;t<e.length;t++){const n=e[t](o,a[t],i[t]);l.push(n[0]),l.push(n[1]),o=n[1]}const u=[],c=[];for(let e=0;e<l.length;e+=2)u.push(l[e]),c.push(l[e+1]);return[u,c]}}),AW=LL({multinomial_:function(e,t,n,s=!1){const r=FL(e,"logits","multinomial"),a=r.size,i=r.rank;if(a<2)throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${a}.`);if(i>2)throw new Error(`Rank of probabilities must be 1 or 2, but is ${i}`);n=n||Math.random();const o={logits:1===i?CB(r,[1,-1]):r},l={numSamples:t,seed:n,normalized:s},u=EL.runKernel("Multinomial",o,l);return 1===i?CB(u,[u.size]):u}}),_W=LL({notEqual_:function(e,t){let n=FL(e,"a","notEqual","string_or_numeric"),s=FL(t,"b","notEqual","string_or_numeric");[n,s]=kL(n,s),bP(n.shape,s.shape);const r={a:n,b:s};return EL.runKernel("NotEqual",r)}}),DW=LL({oneHot_:function(e,t,n=1,s=0,r="int32"){if(t<2)throw new Error(`Error in oneHot: depth must be >=2, but it is ${t}`);const a={indices:FL(e,"indices","oneHot","int32")},i={dtype:r,depth:t,onValue:n,offValue:s};return EL.runKernel("OneHot",a,i)}}),FW=LL({onesLike_:function(e){const t={x:FL(e,"x","onesLike")};return EL.runKernel("OnesLike",t)}}),OW=LL({outerProduct_:function(e,t){const n=FL(e,"v1","outerProduct"),s=FL(t,"v2","outerProduct");aM(1===n.rank&&1===s.rank,(()=>`Error in outerProduct: inputs must be rank 1, but got ranks ${n.rank} and ${s.rank}.`));const r=CB(n,[-1,1]),a=CB(s,[1,-1]);return DB(r,a)}}),MW=LL({pad_:function(e,t,n=0){const s=FL(e,"x","pad");if(0===s.rank)throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");const r={paddings:t,constantValue:n},a={x:s};return EL.runKernel("PadV2",a,r)}}),LW=LL({pad1d_:function(e,t,n=0){return aM(2===t.length,(()=>"Invalid number of paddings. Must be length of 2.")),MW(e,[t],n)}}),zW=LL({pad2d_:function(e,t,n=0){return aM(2===t.length&&2===t[0].length&&2===t[1].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),MW(e,t,n)}}),BW=LL({pad3d_:function(e,t,n=0){return aM(3===t.length&&2===t[0].length&&2===t[1].length&&2===t[2].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),MW(e,t,n)}}),PW=LL({pad4d_:function(e,t,n=0){return aM(4===t.length&&2===t[0].length&&2===t[1].length&&2===t[2].length&&2===t[3].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),MW(e,t,n)}}),WW=LL({spaceToBatchND_:function(e,t,n){const s=FL(e,"x","spaceToBatchND");aM(s.rank>=1+t.length,(()=>`input rank ${s.rank} should be > than [blockShape] ${t.length}`)),aM(n.length===t.length,(()=>`paddings.shape[0] ${n.length} must be equal to [blockShape] ${t.length}`)),aM(s.shape.reduce(((e,s,r)=>r>0&&r<=t.length?e&&(s+n[r-1][0]+n[r-1][1])%t[r-1]==0:e),!0),(()=>`input spatial dimensions ${s.shape.slice(1)} with paddings ${n.toString()} must be divisible by blockShapes ${t.toString()}`));const r={x:s},a={blockShape:t,paddings:n};return EL.runKernel("SpaceToBatchND",r,a)}}),VW=LL({pool_:function(e,t,n,s,r,a,i){null==r&&(r=[1,1]),null==a&&(a=1),0===s&&(s="valid");const o=FL(e,"x","maxPool");let l=o,u=!1;3===o.rank&&(u=!0,l=CB(o,[1,o.shape[0],o.shape[1],o.shape[2]])),aM($B(a,r),(()=>`Error in pool: Either strides or dilations must be 1. Got strides ${a} and dilations '${r}'`));const c=function(e,t,n,s,r,a,i="channelsLast"){const[o,l]=IB(t);let u;if("channelsLast"===i)u=[o,l,e[3],e[3]];else{if("channelsFirst"!==i)throw new Error(`Unknown dataFormat ${i}`);u=[o,l,e[1],e[1]]}return vB(e,u,n,s,r,a,!1,i)}(l.shape,t,a,r,s),h=[c.dilationHeight,c.dilationWidth];let p;p="same"===s?function(e,t){const n=e.map(((e,n)=>e+(e-1)*(t[n]-1))).map((e=>e-1)),s=n.map((e=>Math.floor(e/2))),r=n.map(((e,t)=>e-s[t]));return n.map(((e,t)=>[s[t],r[t]]))}([c.filterHeight,c.filterWidth],h):[[0,0],[0,0]];const d=1===h[0]&&1===h[1],[f,m]=function(e,t,n){const s=n.map((e=>e[0])),r=n.map((e=>e[1])),a=e.concat(s,r),i=t.map(((e,t)=>(e-a[t]%e)%e)),o=r.map(((e,t)=>e+i[t]));return[t.map(((e,t)=>[s[t],o[t]])),t.map(((e,t)=>[0,i[t]]))]}([c.inHeight,c.inWidth],h,p),g=d?s:"valid",y=d?l:WW(l,h,f),b=("avg"===n?()=>RB(y,t,a,g,i):()=>bW(y,t,a,g,i))(),x=d?b:BB(b,h,m);return u?CB(x,[x.shape[1],x.shape[2],x.shape[3]]):x}}),UW=LL({prelu_:function(e,t){const n={x:FL(e,"x","prelu"),alpha:FL(t,"alpha","prelu")};return EL.runKernel("Prelu",n)}}),GW=LL({prod_:function(e,t=null,n=!1){let s=FL(e,"x","prod");"bool"===s.dtype&&(s=Bz(s,"int32"));const r={x:s},a={axis:t,keepDims:n};return EL.runKernel("Prod",r,a)}}),HW=LL({raggedGather_:function(e,t,n,s){const r={paramsNestedSplits:e.map(((e,t)=>FL(e,`tensors${t}`,"raggedGather","int32"))),paramsDenseValues:FL(t,"paramsDenseValues","raggedGather"),indices:FL(n,"indices","raggedGather","int32")},a={outputRaggedRank:s},i=EL.runKernel("RaggedGather",r,a);return{outputNestedSplits:i.slice(0,i.length-1),outputDenseValues:i[i.length-1]}}}),jW=LL({raggedTensorToTensor_:function(e,t,n,s,r){const a=FL(e,"shape","raggedTensorToTensor","int32"),i=FL(t,"values","raggedTensorToTensor"),o={shape:a,values:i,defaultValue:FL(n,"defaultValue","raggedTensorToTensor",i.dtype),rowPartitionTensors:s.map(((e,t)=>FL(e,`tensors${t}`,"raggedTensorToTensor","int32")))},l={rowPartitionTypes:r};return EL.runKernel("RaggedTensorToTensor",o,l)}}),KW=LL({rand_:function(e,t,n){const s=uM(e);let r=null;if(null==n||"float32"===n)r=new Float32Array(s);else if("int32"===n)r=new Int32Array(s);else{if("bool"!==n)throw new Error(`Unknown data type ${n}`);r=new Uint8Array(s)}for(let e=0;e<s;e++)r[e]=t();return EL.makeTensor(r,e,n)}});class qW{constructor(e,t,n,s,r){this.mean=e,this.stdDev=t,this.dtype=n,this.nextVal=NaN,this.truncated=s,this.truncated&&(this.upper=this.mean+2*this.stdDev,this.lower=this.mean-2*this.stdDev);const a=r||Math.random();this.random=Tl.alea(a.toString())}nextValue(){if(!isNaN(this.nextVal)){const e=this.nextVal;return this.nextVal=NaN,e}let e,t,n=!1;for(;!n;){let s,r,a;do{s=2*this.random()-1,r=2*this.random()-1,a=s*s+r*r}while(a>=1||0===a);const i=Math.sqrt(-2*Math.log(a)/a);e=this.mean+this.stdDev*s*i,t=this.mean+this.stdDev*r*i,this.truncated&&!this.isValidTruncated(e)||(n=!0)}return this.truncated&&!this.isValidTruncated(t)||(this.nextVal=this.convertValue(t)),this.convertValue(e)}convertValue(e){return null==this.dtype||"float32"===this.dtype?e:Math.round(e)}isValidTruncated(e){return e<=this.upper&&e>=this.lower}}class XW{constructor(e,t,n,s){this.alpha=e,this.beta=1/t,this.dtype=n;const r=s||Math.random();this.randu=Tl.alea(r.toString()),this.randn=new qW(0,1,n,!1,this.randu()),this.d=e<1?e+2/3:e-1/3,this.c=1/Math.sqrt(9*this.d)}nextValue(){let e,t,n,s,r,a;for(;;){do{s=this.randn.nextValue(),a=1+this.c*s}while(a<=0);if(a*=a*a,e=s*s,t=1-.331*e*e,n=.5*e+this.d*(1-a+Math.log(a)),r=this.randu(),r<t||Math.log(r)<n)break}return a=1/this.beta*this.d*a,this.alpha<1&&(a*=Math.pow(this.randu(),1/this.alpha)),this.convertValue(a)}convertValue(e){return"float32"===this.dtype?e:Math.round(e)}}class YW{constructor(e=0,t=1,n,s){if(this.canReturnFloat=()=>null==this.dtype||"float32"===this.dtype,this.min=e,this.range=t-e,this.dtype=n,null==s&&(s=Math.random()),"number"==typeof s&&(s=s.toString()),!this.canReturnFloat()&&this.range<=1)throw new Error(`The difference between ${e} - ${t} <= 1 and dtype is not float`);this.random=Tl.alea(s)}convertValue(e){return this.canReturnFloat()?e:Math.round(e)}nextValue(){return this.convertValue(this.min+this.range*this.random())}}const JW=LL({randomGamma_:function(e,t,n=1,s="float32",r){if(null==n&&(n=1),null==s&&(s="float32"),"float32"!==s&&"int32"!==s)throw new Error(`Unsupported data type ${s}`);const a=new XW(t,n,s,r),i=zz(e,s);for(let e=0;e<i.values.length;e++)i.values[e]=a.nextValue();return i.toTensor()}}),ZW=LL({randomNormal_:function(e,t=0,n=1,s,r){if(null!=s&&"bool"===s)throw new Error(`Unsupported data type ${s}`);const a=new qW(t,n,s,!1,r),i=zz(e,s);for(let e=0;e<i.values.length;e++)i.values[e]=a.nextValue();return i.toTensor()}}),QW=LL({randomStandardNormal_:function(e,t,n){if(null!=t&&"bool"===t)throw new Error(`Unsupported data type ${t}`);return ZW(e,0,1,t,n)}}),eV=LL({randomUniform_:function(e,t=0,n=1,s="float32",r){const a=zz(e,s),i=new YW(t,n,null,r);for(let e=0;e<a.values.length;e++)a.values[e]=i.nextValue();return a.toTensor()}});function tV(e,t,n=1,s="float32"){if(0===n)throw new Error("Cannot have a step of zero");const r={start:e,stop:t,step:n,dtype:s};return EL.runKernel(zM,{},r)}const nV=LL({real_:function(e){const t={input:FL(e,"input","real")};return EL.runKernel("Real",t)}}),sV=LL({reciprocal_:function(e){const t={x:FL(e,"x","reciprocal")};return EL.runKernel("Reciprocal",t)}}),rV=LL({relu_:function(e){const t={x:FL(e,"x","relu")};return EL.runKernel("Relu",t)}}),aV=LL({relu6_:function(e){const t={x:FL(e,"x","relu6")};return EL.runKernel("Relu6",t)}}),iV=LL({reverse_:function(e,t){const n={x:FL(e,"x","reverse")},s={dims:t};return EL.runKernel("Reverse",n,s)}}),oV=LL({reverse1d_:function(e){const t=FL(e,"x","reverse");return aM(1===t.rank,(()=>`Error in reverse1D: x must be rank 1 but got rank ${t.rank}.`)),iV(t,0)}}),lV=LL({reverse2d_:function(e,t){const n=FL(e,"x","reverse");return aM(2===n.rank,(()=>`Error in reverse2D: x must be rank 2 but got rank ${n.rank}.`)),iV(n,t)}}),uV=LL({reverse3d_:function(e,t){const n=FL(e,"x","reverse");return aM(3===n.rank,(()=>`Error in reverse3D: x must be rank 3 but got rank ${n.rank}.`)),iV(n,t)}}),cV=LL({reverse4d_:function(e,t){const n=FL(e,"x","reverse");return aM(4===n.rank,(()=>`Error in reverse4D: x must be rank 4 but got rank ${n.rank}.`)),iV(n,t)}}),hV=LL({round_:function(e){const t={x:FL(e,"x","round")};return EL.runKernel("Round",t)}}),pV=LL({rsqrt_:function(e){const t={x:FL(e,"x","rsqrt","float32")};return EL.runKernel("Rsqrt",t)}}),dV=LL({selu_:function(e){const t={x:FL(e,"x","selu")};return EL.runKernel("Selu",t)}}),fV=LL({separableConv2d_:function(e,t,n,s,r,a=[1,1],i="NHWC"){const o=FL(e,"x","separableConv2d"),l=FL(t,"depthwiseFilter","separableConv2d"),u=FL(n,"pointwiseFilter","separableConv2d");let c=o,h=!1;if(3===o.rank&&(h=!0,c=CB(o,[1,o.shape[0],o.shape[1],o.shape[2]])),"NCHW"===i)throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");aM(4===c.rank,(()=>`Error in separableConv2d: input must be rank 4, but got rank ${c.rank}.`)),aM(4===l.rank,(()=>`Error in separableConv2d: depthwise filter must be rank 4, but got rank ${l.rank}.`)),aM(4===u.rank,(()=>`Error in separableConv2d: pointwise filter must be rank 4, but got rank ${l.rank}.`)),aM(1===u.shape[0],(()=>`Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${u.shape[0]}.`)),aM(1===u.shape[1],(()=>`Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${u.shape[1]}.`));const p=l.shape[2],d=l.shape[3];aM(u.shape[2]===p*d,(()=>`Error in separableConv2d: the third dimension of pointwise filter must be ${p*d}, but got ${u.shape[2]}.`));const f=dP(c,l,s,r,i,a),m=eP(f,u,1,"valid",i);return h?CB(m,[m.shape[1],m.shape[2],m.shape[3]]):m}}),mV=async function(e,t){const n=FL(e,"x","setdiff1d"),s=FL(t,"y","setdiff1d");aM(n.dtype===s.dtype,(()=>`x and y should have the same dtype, but got x (${n.dtype}) and y (${s.dtype}).`)),aM(1===n.rank,(()=>`x should be 1D tensor, but got x (${n.shape}).`)),aM(1===s.rank,(()=>`y should be 1D tensor, but got y (${s.shape}).`));const r=await n.data(),a=await s.data(),i=new Set(a);let o=0;for(let e=0;e<r.length;e++)i.has(r[e])||o++;const l=new uL([o],n.dtype),u=new uL([o],"int32");for(let e=0,t=0;e<r.length;e++)i.has(r[e])||(l.values[t]=r[e],u.values[t]=e,t++);return[l.toTensor(),u.toTensor()]},gV=LL({sign_:function(e){const t={x:FL(e,"x","sign")};return EL.runKernel("Sign",t)}}),yV=LL({sin_:function(e){const t={x:FL(e,"x","sin","float32")};return EL.runKernel("Sin",t)}}),bV=LL({sinh_:function(e){const t={x:FL(e,"x","sinh")};return EL.runKernel("Sinh",t)}}),xV=LL({slice1d_:function(e,t,n){const s=FL(e,"x","slice1d");return aM(1===s.rank,(()=>`slice1d expects a rank-1 tensor, but got a rank-${s.rank} tensor`)),MB(s,[t],[n])}}),wV=LL({slice2d_:function(e,t,n){const s=FL(e,"x","slice2d");return aM(2===s.rank,(()=>`slice2d expects a rank-2 tensor, but got a rank-${s.rank} tensor`)),MB(s,t,n)}}),kV=LL({slice3d_:function(e,t,n){const s=FL(e,"x","slice3d");return aM(3===s.rank,(()=>`slice3d expects a rank-3 tensor, but got a rank-${s.rank} tensor`)),MB(s,t,n)}}),vV=LL({slice4d_:function(e,t,n){const s=FL(e,"x","slice4d");return aM(4===s.rank,(()=>`slice4d expects a rank-4 tensor, but got a rank-${s.rank} tensor`)),MB(s,t,n)}}),IV=LL({softmax_:function(e,t=-1){const n=FL(e,"logits","softmax","float32");if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and dim was ${t}`);const s={logits:n},r={dim:t};return EL.runKernel("Softmax",s,r)}}),NV=LL({fft_:function(e){aM("complex64"===e.dtype,(()=>`The dtype for tf.spectral.fft() must be complex64 but got ${e.dtype}.`));const t={input:e};return EL.runKernel("FFT",t)}}),SV=LL({ifft_:function(e){aM("complex64"===e.dtype,(()=>`The dtype for tf.spectral.ifft() must be complex64 but got ${e.dtype}.`));const t={input:e};return EL.runKernel("IFFT",t)}}),TV=LL({irfft_:function(e){const t=e.shape[e.shape.length-1],n=e.size/t;let s;if(t<=2){const r=CB(e,[n,t]);s=SV(r)}else{const r=[n,2*(t-1)],a=CB(nV(e),[n,t]),i=CB(KP(e),[n,t]),o=iV(MB(a,[0,1],[n,t-2]),1),l=FB(iV(MB(i,[0,1],[n,t-2]),1),AP(-1)),u=_B([a,o],1),c=_B([i,l],1),h=CB(zL(u,c),[r[0],r[1]]);s=SV(h)}if(s=nV(s),3===e.rank&&0!==e.shape[0]){const t=s,n=e.shape[0];s=CB(s,[n,s.shape[0]/n,s.shape[1]]),t.dispose()}return s}}),$V=LL({split_:function(e,t,n=0){const s={x:FL(e,"x","split")},r={numOrSizeSplits:t,axis:n};return EL.runKernel("SplitV",s,r)}}),EV=LL({rfft_:function(e,t){aM("float32"===e.dtype,(()=>`The dtype for rfft() must be real value but got ${e.dtype}`));let n=e.shape[e.shape.length-1];const s=e.size/n;let r;if(null!=t&&t<n){const s=e.shape.map((e=>0)),a=e.shape.map((e=>e));a[e.shape.length-1]=t,r=MB(e,s,a),n=t}else if(null!=t&&t>n){const s=e.shape.map((e=>e));s[e.shape.length-1]=t-n,r=_B([e,IW(s)],e.shape.length-1),n=t}else r=e;const a=kP(r),i=CB(zL(r,a),[s,n]),o=NV(i),l=Math.floor(n/2)+1,u=nV(o),c=KP(o),h=$V(u,[l,n-l],u.shape.length-1),p=$V(c,[l,n-l],c.shape.length-1),d=r.shape.slice();return d[r.shape.length-1]=l,CB(zL(h[0],p[0]),d)}}),CV=LL({squaredDifference_:function(e,t){let n=FL(e,"a","squaredDifference"),s=FL(t,"b","squaredDifference");[n,s]=kL(n,s),bP(n.shape,s.shape);const r={a:n,b:s};return EL.runKernel("SquaredDifference",r,{})}}),RV=LL({squeeze_:function(e,t){const n=FL(e,"x","squeeze","string_or_numeric");return CB(n,function(e,t){const n=[],s=[],r=null!=t&&Array.isArray(t)&&0===t.length,a=null==t||r?null:dM(t,e).sort();let i=0;for(let t=0;t<e.length;++t){if(null!=a){if(a[i]===t&&1!==e[t])throw new Error(`Can't squeeze axis ${t} since its dim '${e[t]}' is not 1`);(null==a[i]||a[i]>t)&&1===e[t]&&(n.push(e[t]),s.push(t)),a[i]<=t&&i++}1!==e[t]&&(n.push(e[t]),s.push(t))}return{newShape:n,keptDims:s}}(n.shape,t).newShape)}}),AV=LL({stack_:function(e,t=0){const n=OL(e,"tensors","stack","string_or_numeric");aM(n.length>=1,(()=>"Pass at least one tensor to tf.stack")),n.length>0&&aM(t<=n[0].rank,(()=>"Axis must be <= rank of the tensor"));const s=n,r={axis:t};return EL.runKernel("Pack",s,r)}}),_V=LL({step_:function(e,t=0){const n={x:FL(e,"x","step")},s={alpha:t};return EL.runKernel("Step",n,s)}}),DV=LL({stridedSlice_:function(e,t,n,s,r=0,a=0,i=0,o=0,l=0){const u={x:FL(e,"x","stridedSlice","string_or_numeric")},c={begin:t,end:n,strides:s,beginMask:r,endMask:a,ellipsisMask:i,newAxisMask:o,shrinkAxisMask:l};return EL.runKernel("StridedSlice",u,c)}}),FV=LL({tan_:function(e){const t={x:FL(e,"x","tan","float32")};return EL.runKernel("Tan",t)}});function OV(e,t){oM(e);const n=AL(e,t);if(1!==n.length)throw new Error("tensor1d() requires values to be a flat/TypedArray");return BL(e,null,n,t)}function MV(e,t,n){if(oM(e),null!=t&&2!==t.length)throw new Error("tensor2d() requires shape to have two numbers");const s=AL(e,n);if(2!==s.length&&1!==s.length)throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");if(1===s.length&&null==t)throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");return BL(e,t,s,n)}function LV(e,t,n){if(oM(e),null!=t&&3!==t.length)throw new Error("tensor3d() requires shape to have three numbers");const s=AL(e,n);if(3!==s.length&&1!==s.length)throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");if(1===s.length&&null==t)throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");return BL(e,t,s,n)}function zV(e,t,n){if(oM(e),null!=t&&4!==t.length)throw new Error("tensor4d() requires shape to have four numbers");const s=AL(e,n);if(4!==s.length&&1!==s.length)throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");if(1===s.length&&null==t)throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");return BL(e,t,s,n)}function BV(e,t,n){if(oM(e),null!=t&&5!==t.length)throw new Error("tensor5d() requires shape to have five numbers");const s=AL(e,n);if(5!==s.length&&1!==s.length)throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");if(1===s.length&&null==t)throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");return BL(e,t,s,n)}function PV(e,t,n){if(oM(e),null!=t&&6!==t.length)throw new Error("tensor6d() requires shape to have six numbers");const s=AL(e,n);if(6!==s.length&&1!==s.length)throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");if(1===s.length&&null==t)throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");return BL(e,t=t||s,s,n)}const WV=LL({topk_:function(e,t=1,n=!0){const s=FL(e,"x","topk");if(0===s.rank)throw new Error("topk() expects the input to be of rank 1 or higher");const r=s.shape[s.shape.length-1];if(t<0)throw new Error(`'k' passed to topk() must be >= 0 but got ${t}`);if(t>r)throw new Error(`'k' passed to topk() must be <= the last dimension (${r}) but got ${t}`);const a={x:s},i={k:t,sorted:n},[o,l]=EL.runKernel("TopK",a,i);return{values:o,indices:l}}}),VV=LL({truncatedNormal_:function(e,t=0,n=1,s,r){if(null!=s&&"bool"===s)throw new Error("Unsupported data type $ { dtype }");const a=new qW(t,n,s,!0,r),i=zz(e,s);for(let e=0;e<i.values.length;e++)i.values[e]=a.nextValue();return i.toTensor()}}),UV=LL({unique_:function(e,t=0){const n=FL(e,"x","unique","string_or_numeric");aM(n.rank>0,(()=>"The input tensor must be at least 1D"));const s={x:n},r={axis:t},[a,i]=EL.runKernel("Unique",s,r);return{values:a,indices:i}}}),GV=LL({unsortedSegmentSum_:function(e,t,n){const s=FL(e,"x","unsortedSegmentSum"),r=FL(t,"segmentIds","unsortedSegmentSum","int32");aM(hM(n),(()=>"numSegments must be of dtype int"));const a={x:s,segmentIds:r},i={numSegments:n};return EL.runKernel("UnsortedSegmentSum",a,i)}}),HV=LL({unstack_:function(e,t=0){const n=FL(e,"x","unstack","string_or_numeric");aM(t>=-n.shape.length&&t<n.shape.length,(()=>`Axis = ${t} is not in [-${n.shape.length}, ${n.shape.length})`));const s={value:n},r={axis:t};return EL.runKernel("Unpack",s,r)}});function jV(e,t){return gW(e,t,"right")}function KV(e,t=!0,n,s){return EL.makeVariable(e,t,n,s)}const qV=async function(e){const t=FL(e,"condition","whereAsync","bool"),n=await t.data(),s=function(e,t){const n=[];for(let e=0;e<t.length;e++)t[e]&&n.push(e);const s=zz(e,"int32"),r=zz([n.length,e.length],"int32");for(let t=0;t<n.length;t++){const a=s.indexToLoc(n[t]),i=t*e.length;r.values.set(a,i)}return r.toTensor()}(t.shape,n);return e!==t&&t.dispose(),s},XV=async function(e,t,n){const s=FL(e,"tensor","boolMask"),r=FL(t,"mask","boolMask","bool"),a=null==n?0:n,i=r.rank,o=s.shape;aM(i>0,(()=>"mask cannot be scalar")),iM(o.slice(a,a+i),r.shape,"mask's shape must match the first K dimensions of tensor's shape,");let l=1;for(let e=a;e<a+i;e++)l*=o[e];const u=o.slice(0,a).concat([l],o.slice(a+i)),c=CB(s,u),h=CB(r,[-1]),p=await qV(h),d=RV(p,[1]),f=GP(c,d,a);return e!==s&&s.dispose(),t!==r&&r.dispose(),d.dispose(),c.dispose(),h.dispose(),p.dispose(),f};function YV(e,t){return EL.tidy(e,t)}function JV(e){return EL.keep(e)}pL=function(e){CM().getBool("DEPRECATION_WARNINGS_ENABLED")&&console.warn(e+" You can disable deprecation warnings with tf.disableDeprecationWarnings().")};const ZV=LL({transpose_:function(e,t,n){const s=FL(e,"x","transpose");if(null==t&&(t=s.shape.map(((e,t)=>t)).reverse()),aM(s.rank===t.length,(()=>`Error in transpose: rank of input ${s.rank} must match length of perm ${t}.`)),t.forEach((e=>{aM(e>=0&&e<s.rank,(()=>"All entries in 'perm' must be between 0 and "+(s.rank-1)+` but got ${t}`))})),s.rank<=1)return s.clone();const r={x:s},a={perm:t};return"complex64"===s.dtype?YV((()=>{let e=nV(s),t=KP(s);return e=EL.runKernel(PM,{x:e},a),t=EL.runKernel(PM,{x:t},a),n&&(t=aW(t)),zL(e,t)})):EL.runKernel(PM,r,a)}}),QV=LL({movingAverage_:function(e,t,n,s,r=!0){const a=FL(e,"v","movingAverage"),i=FL(t,"x","movingAverage"),o=FL(n,"decay","movingAverage");var l,u;u=i,aM((l=a).dtype===u.dtype,(()=>`The dtypes of the first(${l.dtype}) and second(${u.dtype}) input must match`)),aM(cM(a.shape,i.shape),(()=>"Shape mismatch in v and x"));const c=AP(1),h=lW(c,o);let p=FB(lW(i,a),h);if(r){aM(null!=s,(()=>"When using zeroDebias: true, step is required."));const e=FL(s,"step","movingAverage");p=yP(p,lW(c,RP(o,e)))}return hB(a,p)}});const eU=LL({scatterND_:function(e,t,n){const s=FL(e,"indices","scatterND","int32"),r=FL(t,"updates","scatterND");!function(e,t,n){if(t.rank<1)throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${t.rank}.`);if(e.rank<1)throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${e.rank}.`);if("int32"!==t.dtype)throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${t.dtype}`);if(n.length<1)throw new Error(`Output rank must be greater or equal to 1, but got shape: ${n}`);if(0===n.length){if(0===t.size)throw new Error(`Indices specified for empty output. indices shape: ${t.shape}`);if(0===e.size)throw new Error(`Updates specified for empty output. updates shape: ${e.shape}`)}!function(e,t,n){const s=t.rank>1?t.shape[t.rank-1]:1,r=t.rank>1?t.rank-1:1,a=`Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${n.shape}, indices.shape: ${t.shape}, shape: ${e}, sliceDim: ${s}, and batchDim: ${r}.`;if(n.rank<r)throw new Error(a+` update.rank < ${r}. `);if(e.length<s+(n.rank-r))throw new Error(a+` Output shape length < ${s+(n.rank-r)}`);if(n.rank!==r+e.length-s)throw new Error(a+" update.rank != "+(r+e.length-s));for(let e=0;e<r;++e)if(n.shape[e]!==t.shape[e])throw new Error(a+` updates.shape[${e}] (${n.shape[e]}) != indices.shape[${e}] (${t.shape[e]}).`);for(let t=0;t<n.rank-r;++t)if(n.shape[t+r]!==e[t+s])throw new Error(a+` updates.shape[${t+r}] (${n.shape[t+r]}) != shape[${t+r}] (${e[t+r]})`)}(n,t,e)}(r,s,n);const a={indices:s,updates:r},i={shape:n};return EL.runKernel("ScatterNd",a,i)}}),tU=LL({sparseToDense_:function(e,t,n,s=0){const r=FL(e,"sparseIndices","sparseToDense","int32"),a=FL(t,"sparseValues","sparseToDense","string_or_numeric"),i=FL(s,"defaultValue","sparseToDense",a.dtype);!function(e,t,n,s){if("int32"!==e.dtype)throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${e.dtype}.`);if(e.rank>2)throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${e.shape}.`);const r=e.rank>0?e.shape[0]:1,a=e.rank>1?e.shape[1]:1;if(n.length!==a)throw new Error(`outputShape has incorrect number of elements:, ${n.length}, should be: ${a}.`);const i=t.size;if(0!==t.rank&&(1!==t.rank||i!==r))throw new Error(`sparseValues has incorrect shape ${t.shape}, should be [] or [${r}]`);if(t.dtype!==s.dtype)throw new Error("sparseValues.dtype must match defaultValues.dtype")}(r,a,n,i);const o={sparseIndices:r,sparseValues:a,defaultValue:i},l={outputShape:n};return EL.runKernel("SparseToDense",o,l)}}),nU=LL({gatherND_:function(e,t){const n=FL(t,"indices","gatherND","int32"),s={params:FL(e,"x","gatherND","string_or_numeric"),indices:n};return EL.runKernel("GatherNd",s)}}),sU=LL({dropout_:function(e,t,n,s){const r=FL(e,"x","dropout");if(aM("float32"===r.dtype,(()=>`x has to be a floating point tensor since it's going to be scaled, but got a ${r.dtype} tensor instead.`)),aM(t>=0&&t<1,(()=>`rate must be a float in the range [0, 1), but got ${t}.`)),0===t)return e instanceof dL?r.clone():r;const a=function(e,t){if(null==t)return e.shape.slice();if(cM(e.shape,t))return t;if(e.shape.length===t.length){const n=[];for(let s=0;s<e.shape.length;s++)null==t[s]&&null!=e.shape[s]?n.push(e.shape[s]):n.push(t[s]);return n}return t}(r,n),i=1-t,o=yP(UP(hB(eV(a,0,1,"float32",s),i)),i);return FB(r,o)}});function rU(e){return Math.floor(Math.pow(2,Math.ceil(Math.log(e)/Math.log(2))))}function aU(e,t,n){const s=1-e%2,r=new Float32Array(e);for(let a=0;a<e;++a){const i=2*Math.PI*a/(e+s-1);r[a]=t-n*Math.cos(i)}return OV(r,"float32")}const iU=async function(e,t,n=1){const s=FL(e,"predictions","inTopK"),r=FL(t,"targets","inTopK");aM(s.rank>1,(()=>`inTopK() expects the predictions to be of rank 2 or higher, but got ${s.rank}`)),aM(s.rank-1===r.rank,(()=>`predictions rank should be 1 larger than targets rank, but got predictions rank ${s.rank} and targets rank ${r.rank}`)),iM(s.shape.slice(0,s.shape.length-1),r.shape,"predictions's shape should be align with the targets' shape, except the last dimension.");const a=s.shape[s.shape.length-1];aM(n>0&&n<=a,(()=>`'k' passed to inTopK() must be > 0 && <= the predictions last dimension (${a}), but got ${n}`));const i=await s.data(),o=await r.data(),[l,u]=[i.length/a,a],c=function(e,t){let n=null;return n=new Uint8Array(t),n}(0,l);for(let e=0;e<l;e++){const t=e*u,s=i.subarray(t,t+u),r=[];for(let e=0;e<s.length;e++)r.push({value:s[e],index:e});r.sort(((e,t)=>t.value-e.value)),c[e]=0;for(let t=0;t<n;t++)if(r[t].index===o[e]){c[e]=1;break}}return e!==s&&s.dispose(),t!==r&&r.dispose(),PL(c,r.shape,"bool")},oU=LL({conv2DBackpropFilter_:function(e,t,n,s,r,a="NHWC",i){let o=e;3===e.rank&&(o=CB(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let l=t;3===l.rank&&(l=CB(t,[1,t.shape[0],t.shape[1],t.shape[2]])),aM(4===o.rank,(()=>`Error in conv2dDerFilter: input must be rank 4, but got shape ${o.shape}.`)),aM(4===l.rank,(()=>`Error in conv2dDerFilter: dy must be rank 4, but got shape ${l.shape}.`)),aM(4===n.length,(()=>`Error in conv2dDerFilter: filterShape must be length 4, but got ${n}.`));const u="NHWC"===a?o.shape[3]:o.shape[1],c="NHWC"===a?l.shape[3]:l.shape[1];aM(u===n[2],(()=>`Error in conv2dDerFilter: depth of input ${u}) must match input depth in filter (${n[2]}.`)),aM(c===n[3],(()=>`Error in conv2dDerFilter: depth of dy (${c}) must match output depth for filter (${n[3]}).`)),EB("conv2dDerFilter",r,i);const h={x:o,dy:l},p={strides:s,pad:r,dataFormat:a,dimRoundingMode:i,filterShape:n};return EL.runKernel("Conv2DBackpropFilter",h,p)}});function lU(e,t,n){if(null==n||"linear"===n)return e;if("relu"===n)return FB(e,_V(t));throw new Error(`Cannot compute gradient for fused activation ${n}.`)}function uU(e,t){let n=t;const s=function(e,t){const n=[];for(let s=0;s<t.length;s++){const r=e[e.length-s-1],a=t.length-s-1,i=t[a];(null==r||1===r&&i>1)&&n.unshift(a)}return n}(e.shape,t.shape);return s.length>0&&(n=FP(n,s)),CB(n,e.shape)}function cU(e,t,n,s){if("linear"===t)return e;if("relu"===t)return rV(e);if("elu"===t)return SP(e);if("relu6"===t)return aV(e);if("prelu"===t)return UW(e,n);if("leakyrelu"===t)return JP(e,s);if("sigmoid"===t)return OB(e);throw new Error(`Unknown fused activation ${t}.`)}const hU=(e,t)=>!(e>0)||"linear"===t,pU=LL({fusedConv2d_:function({x:e,filter:t,strides:n,pad:s,dataFormat:r="NHWC",dilations:a=[1,1],dimRoundingMode:i,bias:o,activation:l="linear",preluActivationWeights:u,leakyreluAlpha:c}){if(l=l||"linear",!1===hU(EL.state.gradientDepth,l)){aM("NHWC"===r,(()=>`Error in fused conv2d: got dataFormat of ${r} but only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.`));let h=eP(e,t,n,s,r,a,i);return null!=o&&(h=hB(h,o)),cU(h,l,u,c)}const h=FL(e,"x","conv2d","float32"),p=FL(t,"filter","conv2d","float32");let d=h,f=!1;3===h.rank&&(f=!0,d=CB(h,[1,h.shape[0],h.shape[1],h.shape[2]])),aM(4===d.rank,(()=>`Error in fused conv2d: input must be rank 4, but got rank ${d.rank}.`)),aM(4===p.rank,(()=>`Error in fused conv2d: filter must be rank 4, but got rank ${p.rank}.`)),EB("fused conv2d",s,i);const m="NHWC"===r?d.shape[3]:d.shape[1];aM(p.shape[2]===m,(()=>`Error in conv2d: depth of input (${m}) must match input depth for filter ${p.shape[2]}.`)),aM($B(n,a),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`));const g=vB(d.shape,p.shape,n,a,s,i);let y,b;if(null!=o&&(y=FL(o,"bias","fused conv2d"),[y]=kL(y,h),"NHWC"===r?bP(g.outShape,y.shape):(aM(y.shape.length<=1,(()=>`Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of rank-${y.shape.length}.`)),aM(0===y.shape.length||y.shape[0]===g.outChannels||1===y.shape[0],(()=>`Error in fused conv2d: bias shape (${y.shape}) is not compatible with the number of output channels (${g.outChannels})`)))),null!=u){const e=u.shape;if(aM(e.length<=1||3===e.length,(()=>`Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of rank-${e.length}.`)),1===e.length)aM(1===e[0]||e[0]===g.outChannels,(()=>`Error in fused conv2d: PReLU activation weights (${e}) is not compatible with the number of output channels (${g.outChannels}).`));else if(3===e.length)try{bP(e,g.outShape)}catch(t){const n=`Error in fused conv2d: PReLU activation weights (${e}) is not compatible with the output shape of the conv2d (${g.outShape}).`;throw Error(n)}b=FL(u,"prelu weights","fused conv2d")}const x=(e,t)=>{aM("NHWC"===r,(()=>`Error in gradient of fused conv2D: got dataFormat of ${r} but only NHWC is currently supported.`));const[i,o,u,c]=t,h=lU(e,u,l);aM(TB(a),(()=>`Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${a}'`));const p=[nP(o.shape,h,i,n,s),oU(o,h,i.shape,n,s)];if(null!=c){const e=uU(c,h);p.push(e)}return p},w={x:d,filter:p,bias:y,preluActivationWeights:b},k={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i,activation:l,leakyreluAlpha:c};if(null==o){const e=rW(((e,t,n)=>{let s=EL.runKernel(VM,w,k);return n([t,e,s]),f&&(s=CB(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:x}}));return e(d,p)}{const e=rW(((e,t,n,s)=>{let r=EL.runKernel(VM,w,k);return s([t,e,r,n]),f&&(r=CB(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:x}}));return e(d,p,y)}}}),dU=LL({depthwiseConv2dNativeBackpropFilter_:function(e,t,n,s,r,a=[1,1],i){let o=e;3===e.rank&&(o=CB(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let l=t;3===l.rank&&(l=CB(t,[1,t.shape[0],t.shape[1],t.shape[2]]));const u={x:o,dy:l},c={strides:s,pad:r,dimRoundingMode:i,dilations:a,filterShape:n};return EL.runKernel("DepthwiseConv2dNativeBackpropFilter",u,c)}}),fU=LL({depthwiseConv2dNativeBackpropInput_:function(e,t,n,s,r,a=[1,1],i){let o=t,l=!1;3===t.rank&&(l=!0,o=CB(t,[1,t.shape[0],t.shape[1],t.shape[2]]));const u={dy:o,filter:n},c={strides:s,pad:r,dimRoundingMode:i,dilations:a,inputShape:e},h=EL.runKernel("DepthwiseConv2dNativeBackpropInput",u,c);return l?CB(h,[h.shape[1],h.shape[2],h.shape[3]]):h}}),mU=LL({fusedDepthwiseConv2d_:function({x:e,filter:t,strides:n,pad:s,dataFormat:r="NHWC",dilations:a=[1,1],dimRoundingMode:i,bias:o,activation:l="linear",preluActivationWeights:u,leakyreluAlpha:c}){if(!1===hU(EL.state.gradientDepth,l)){let h=dP(e,t,n,s,r,a,i);return null!=o&&(h=hB(h,o)),cU(h,l,u,c)}const h=FL(e,"x","depthwiseConv2d","float32"),p=FL(t,"filter","depthwiseConv2d","float32");let d=h,f=!1;3===h.rank&&(f=!0,d=CB(h,[1,h.shape[0],h.shape[1],h.shape[2]])),aM(4===d.rank,(()=>`Error in fused depthwiseConv2d: input must be rank 4, but got rank ${d.rank}.`)),aM(4===p.rank,(()=>`Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${p.rank}.`)),aM(d.shape[3]===p.shape[2],(()=>`Error in fused depthwiseConv2d: number of input channels (${d.shape[3]}) must match the inChannels dimension in filter ${p.shape[2]}.`)),null==a&&(a=[1,1]),aM($B(n,a),(()=>`Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`)),EB("fused depthwiseConv2d",s,i);const m=vB(d.shape,p.shape,n,a,s,i,!0);let g,y;null!=o&&(g=FL(o,"bias","fused conv2d"),[g]=kL(g,h),bP(m.outShape,g.shape)),null!=u&&(y=FL(u,"prelu weights","fused depthwiseConv2d"));const b=(e,t)=>{aM(TB(a),(()=>`Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${a}'`));const[r,o,u,c]=t,h=lU(e,u,l),p=fU(o.shape,h,r,n,s,a,i),d=dU(o,h,r.shape,n,s,a,i);return null!=c?[p,d,uU(g,h)]:[p,d]},x={x:d,filter:p,bias:g,preluActivationWeights:y},w={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i,activation:l,leakyreluAlpha:c};if(null==o){const e=rW(((e,t,n)=>{let s=EL.runKernel(UM,x,w);return n([t,e,s]),f&&(s=CB(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:b}}));return e(d,p)}{const e=rW(((e,t,n,s)=>{let r=EL.runKernel(UM,x,w);return s([t,e,r,n]),f&&(r=CB(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:b}}));return e(d,p,g)}}}),gU=LL({fusedMatMul_:function({a:e,b:t,transposeA:n=!1,transposeB:s=!1,bias:r,activation:a="linear",preluActivationWeights:i,leakyreluAlpha:o=.2}){if(!1===hU(EL.state.gradientDepth,a)){let l=DB(e,t,n,s);return null!=r&&(l=hB(l,r)),cU(l,a,i,o)}let l=FL(e,"a","fused matMul"),u=FL(t,"b","fused matMul");[l,u]=kL(l,u);const c=n?l.shape[l.rank-2]:l.shape[l.rank-1],h=s?u.shape[u.rank-1]:u.shape[u.rank-2],p=n?l.shape[l.rank-1]:l.shape[l.rank-2],d=s?u.shape[u.rank-2]:u.shape[u.rank-1],f=l.shape.slice(0,-2),m=u.shape.slice(0,-2),g=uM(f),y=uM(m);aM(c===h,(()=>`Error in fused matMul: inner shapes (${c}) and (${h}) of Tensors with shapes ${l.shape} and ${u.shape} and transposeA=${n} and transposeB=${s} must match.`));const b=bP(l.shape.slice(0,-2),u.shape.slice(0,-2)).concat([p,d]),x=CB(l,n?[g,c,p]:[g,p,c]),w=CB(u,s?[y,d,h]:[y,h,d]);let k,v;null!=r&&(k=FL(r,"bias","fused matMul"),[k]=kL(k,l),bP(b,k.shape)),null!=i&&(v=FL(i,"prelu weights","fused matMul"));const I=(e,t)=>{const[i,o,l,u]=t,c=lU(CB(e,l.shape),l,a);let h,p;return n||s?!n&&s?(h=DB(c,o,!1,!1),p=DB(c,i,!0,!1)):n&&!s?(h=DB(o,c,!1,!0),p=DB(i,c,!1,!1)):(h=DB(o,c,!0,!0),p=DB(c,i,!0,!0)):(h=DB(c,o,!1,!0),p=DB(i,c,!0,!1)),null!=r?[h,p,uU(u,c)]:[h,p]},N={a:x,b:w,bias:k,preluActivationWeights:v},S={transposeA:n,transposeB:s,activation:a,leakyreluAlpha:o};if(null==r){const e=rW(((e,t,n)=>{const s=EL.runKernel(WM,N,S);return n([e,t,s]),{value:CB(s,b),gradFunc:I}}));return e(x,w)}{const e=rW(((e,t,n,s)=>{const r=EL.runKernel(WM,N,S);return s([e,t,r,n]),{value:CB(r,b),gradFunc:I}}));return e(x,w,k)}}}),yU=LL({hammingWindow_:function(e){return aU(e,.54,.46)}}),bU=LL({hannWindow_:function(e){return aU(e,.5,.5)}}),xU=LL({frame_:function(e,t,n,s=!1,r=0){let a=0;const i=[];for(;a+t<=e.size;)i.push(MB(e,a,t)),a+=n;if(s)for(;a<e.size;){const s=a+t-e.size,o=_B([MB(e,a,t-s),qB([s],r)]);i.push(o),a+=n}return 0===i.length?MV([],[0,t]):CB(_B(i),[i.length,t])}}),wU=LL({stft_:function(e,t,n,s,r=bU){null==s&&(s=rU(t));const a=xU(e,t,n),i=FB(a,r(t));return EV(i,s)}}),kU=LL({cropAndResize_:function(e,t,n,s,r="bilinear",a=0){const i=FL(e,"image","cropAndResize"),o=FL(t,"boxes","cropAndResize","float32"),l=FL(n,"boxInd","cropAndResize","int32"),u=o.shape[0];aM(4===i.rank,(()=>`Error in cropAndResize: image must be rank 4,but got rank ${i.rank}.`)),aM(2===o.rank&&4===o.shape[1],(()=>`Error in cropAndResize: boxes must be have size [${u},4] but had shape ${o.shape}.`)),aM(1===l.rank&&l.shape[0]===u,(()=>`Error in cropAndResize: boxInd must be have size [${u}] but had shape ${o.shape}.`)),aM(2===s.length,(()=>`Error in cropAndResize: cropSize must be of length 2, but got length ${s.length}.`)),aM(s[0]>=1&&s[1]>=1,(()=>`cropSize must be atleast [1,1], but was ${s}`)),aM("bilinear"===r||"nearest"===r,(()=>`method must be bilinear or nearest, but was ${r}`));const c={image:i,boxes:o,boxInd:l},h={method:r,extrapolationValue:a,cropSize:s};return EL.runKernel("CropAndResize",c,h)}}),vU=LL({flipLeftRight_:function(e){const t=FL(e,"image","flipLeftRight","float32");aM(4===t.rank,(()=>`Error in flipLeftRight: image must be rank 4,but got rank ${t.rank}.`));const n={image:t};return EL.runKernel("FlipLeftRight",n,{})}}),IU=LL({grayscaleToRGB_:function(e){const t=FL(e,"image","grayscaleToRGB"),n=t.rank-1,s=t.shape[n];aM(t.rank>=2,(()=>`Error in grayscaleToRGB: images must be at least rank 2, but got rank ${t.rank}.`)),aM(1===s,(()=>`Error in grayscaleToRGB: last dimension of a grayscale image should be size 1, but got size ${s}.`));const r=new Array(t.rank);return r.fill(1,0,n),r[n]=3,WP(t,r)}}),NU=LL({rotateWithOffset_:function(e,t,n=0,s=.5){const r=FL(e,"image","rotateWithOffset","float32");aM(4===r.rank,(()=>`Error in rotateWithOffset: image must be rank 4,but got rank ${r.rank}.`));const a={image:r},i={radians:t,fillValue:n,center:s};return EL.runKernel("RotateWithOffset",a,i)}});function SU(e,t,n,s,r,a){null==s&&(s=.5),null==r&&(r=Number.NEGATIVE_INFINITY),null==a&&(a=0);const i=e.shape[0];return n=Math.min(n,i),aM(0<=s&&s<=1,(()=>`iouThreshold must be in [0, 1], but was '${s}'`)),aM(2===e.rank,(()=>`boxes must be a 2D tensor, but was of rank '${e.rank}'`)),aM(4===e.shape[1],(()=>`boxes must have 4 columns, but 2nd dimension was ${e.shape[1]}`)),aM(1===t.rank,(()=>"scores must be a 1D tensor")),aM(t.shape[0]===i,(()=>`scores has incompatible shape with boxes. Expected ${i}, but was ${t.shape[0]}`)),aM(0<=a&&a<=1,(()=>`softNmsSigma must be in [0, 1], but was '${a}'`)),{maxOutputSize:n,iouThreshold:s,scoreThreshold:r,softNmsSigma:a}}const TU=LL({nonMaxSuppression_:function(e,t,n,s=.5,r=Number.NEGATIVE_INFINITY){const a=FL(e,"boxes","nonMaxSuppression","float32"),i=FL(t,"scores","nonMaxSuppression","float32"),o=SU(a,i,n,s,r),l={maxOutputSize:n=o.maxOutputSize,iouThreshold:s=o.iouThreshold,scoreThreshold:r=o.scoreThreshold};return EL.runKernel("NonMaxSuppressionV3",{boxes:a,scores:i},l)}});function $U(e,t,n){const s=function(e,t,n){return function(e,t,n){let s=0,r=e.length,a=0,i=!1;for(;s<r;){a=s+(r-s>>>1);const o=n(t,e[a]);o>0?s=a+1:(r=a,i=!o)}return i?s:-s-1}(e,t,n||EU)}(e,t,n),r=s<0?-(s+1):s;e.splice(r,0,t)}function EU(e,t){return e>t?1:e<t?-1:0}function CU(e,t,n,s,r,a,i=!1,o=!1,l=!1){const u=[];for(let e=0;e<t.length;e++)t[e]>r&&u.push({score:t[e],boxIndex:e,suppressBeginIndex:0});u.sort(_U);const c=a>0?-.5/a:0,h=[],p=[];for(;h.length<n&&u.length>0;){const t=u.pop(),{score:n,boxIndex:a,suppressBeginIndex:i}=t;if(n<r)break;let o=!1;for(let n=h.length-1;n>=i;--n){const i=RU(e,a,h[n]);if(i>=s){o=!0;break}if(t.score=t.score*AU(s,c,i),t.score<=r)break}t.suppressBeginIndex=h.length,o||(t.score===n?(h.push(a),p.push(t.score)):t.score>r&&$U(u,t,_U))}const d=h.length,f=n-d;o&&f>0&&(h.push(...new Array(f).fill(0)),p.push(...new Array(f).fill(0)));const m={selectedIndices:h};return i&&(m.selectedScores=p),l&&(m.validOutputs=d),m}function RU(e,t,n){const s=e.subarray(4*t,4*t+4),r=e.subarray(4*n,4*n+4),a=Math.min(s[0],s[2]),i=Math.min(s[1],s[3]),o=Math.max(s[0],s[2]),l=Math.max(s[1],s[3]),u=Math.min(r[0],r[2]),c=Math.min(r[1],r[3]),h=Math.max(r[0],r[2]),p=Math.max(r[1],r[3]),d=(o-a)*(l-i),f=(h-u)*(p-c);if(d<=0||f<=0)return 0;const m=Math.max(a,u),g=Math.max(i,c),y=Math.min(o,h),b=Math.min(l,p),x=Math.max(y-m,0)*Math.max(b-g,0);return x/(d+f-x)}function AU(e,t,n){const s=Math.exp(t*n*n);return n<=e?s:0}function _U(e,t){return e.score-t.score||e.score===t.score&&t.boxIndex-e.boxIndex}const DU=LL({nonMaxSuppressionWithScore_:function(e,t,n,s=.5,r=Number.NEGATIVE_INFINITY,a=0){const i=FL(e,"boxes","nonMaxSuppression"),o=FL(t,"scores","nonMaxSuppression"),l=SU(i,o,n,s,r,a),u={boxes:i,scores:o},c={maxOutputSize:n=l.maxOutputSize,iouThreshold:s=l.iouThreshold,scoreThreshold:r=l.scoreThreshold,softNmsSigma:a=l.softNmsSigma},h=EL.runKernel("NonMaxSuppressionV5",u,c);return{selectedIndices:h[0],selectedScores:h[1]}}}),FU=LL({nonMaxSuppressionPadded_:function(e,t,n,s=.5,r=Number.NEGATIVE_INFINITY,a=!1){const i=FL(e,"boxes","nonMaxSuppression"),o=FL(t,"scores","nonMaxSuppression"),l=SU(i,o,n,s,r,null),u={boxes:i,scores:o},c={maxOutputSize:l.maxOutputSize,iouThreshold:l.iouThreshold,scoreThreshold:l.scoreThreshold,padToMaxOutputSize:a},h=EL.runKernel("NonMaxSuppressionV4",u,c);return{selectedIndices:h[0],validOutputs:h[1]}}}),OU=LL({resizeBilinear_:function(e,t,n=!1,s=!1){const r=FL(e,"images","resizeBilinear");aM(3===r.rank||4===r.rank,(()=>`Error in resizeBilinear: x must be rank 3 or 4, but got rank ${r.rank}.`)),aM(2===t.length,(()=>`Error in resizeBilinear: new shape must 2D, but got shape ${t}.`)),aM(!1===s||!1===n,(()=>"Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false."));let a=r,i=!1;3===r.rank&&(i=!0,a=CB(r,[1,r.shape[0],r.shape[1],r.shape[2]]));const[]=t,o={images:a},l={alignCorners:n,halfPixelCenters:s,size:t},u=EL.runKernel("ResizeBilinear",o,l);return i?CB(u,[u.shape[1],u.shape[2],u.shape[3]]):u}}),MU=LL({resizeNearestNeighbor_:function(e,t,n=!1,s=!1){const r=FL(e,"images","resizeNearestNeighbor");aM(3===r.rank||4===r.rank,(()=>`Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${r.rank}.`)),aM(2===t.length,(()=>`Error in resizeNearestNeighbor: new shape must 2D, but got shape ${t}.`)),aM("float32"===r.dtype||"int32"===r.dtype,(()=>"`images` must have `int32` or `float32` as dtype")),aM(!1===s||!1===n,(()=>"Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false."));let a=r,i=!1;3===r.rank&&(i=!0,a=CB(r,[1,r.shape[0],r.shape[1],r.shape[2]]));const[]=t,o={images:a},l={alignCorners:n,halfPixelCenters:s,size:t},u=EL.runKernel("ResizeNearestNeighbor",o,l);return i?CB(u,[u.shape[1],u.shape[2],u.shape[3]]):u}}),LU=LL({threshold_:function(e,t="binary",n=!1,s=.5){const r=FL(e,"image","threshold"),a=r.shape[0]*r.shape[1];let i,o,l,u,c=FB(OV([s]),255);if(aM(3===r.rank,(()=>`Error in threshold: image must be rank 3,but got rank ${r.rank}.`)),aM(3===r.shape[2]||1===r.shape[2],(()=>`Error in threshold: image color channel must be equal to 3 or 1but got ${r.shape[2]}.`)),aM("int32"===r.dtype||"float32"===r.dtype,(()=>`Error in dtype: image dtype must be int32 or float32,but got dtype ${r.dtype}.`)),aM("otsu"===t||"binary"===t,(()=>`Method must be binary or otsu, but was ${t}`)),3===r.shape[2]){[i,o,l]=$V(r,[1,1,1],-1);const e=FB(i,.2989),t=FB(o,.587),n=FB(l,.114);u=hB(hB(e,t),n)}else u=e;"otsu"===t&&(c=function(e,t){let n,s,r,a,i,o,l=OV([-1]),u=OV([0]),c=OV([0]);for(let h=0;h<e.size-1;h++){n=MB(e,0,h+1),s=MB(e,h+1),i=yP(FP(n),t),o=yP(FP(s),t);const p=FP(FB(n,tV(0,n.size)));r=yP(p,FP(n));const d=qB(s.shape,n.size),f=hB(tV(0,s.size),d),m=FB(s,f);a=yP(FP(m),FP(s));const g=lW(r,a),y=lW(r,a),b=FB(i,o);c=FB(FB(b,g),y);const x=HP(c,u);u=wP(x,c,u),l=wP(x,OV([h]),l)}return l}(GB(Bz(hV(u),"int32"),PL([]),256),a));const h=n?QP(u,c):HP(u,c);return Bz(FB(h,255),"int32")}}),zU=LL({transform_:function(e,t,n="nearest",s="constant",r=0,a){const i=FL(e,"image","transform","float32"),o=FL(t,"transforms","transform","float32");aM(4===i.rank,(()=>`Error in transform: image must be rank 4,but got rank ${i.rank}.`)),aM(2===o.rank&&(o.shape[0]===i.shape[0]||1===o.shape[0])&&8===o.shape[1],(()=>"Error in transform: Input transform should be batch x 8 or 1 x 8")),aM(null==a||2===a.length,(()=>`Error in transform: outputShape must be [height, width] or null, but got ${a}.`));const l={image:i,transforms:o},u={interpolation:n,fillMode:s,fillValue:r,outputShape:a};return EL.runKernel("Transform",l,u)}}),BU=LL({bandPart_:function(e,t,n){aM(t%1==0,(()=>`bandPart(): numLower must be an integer, got ${t}.`)),aM(n%1==0,(()=>`bandPart(): numUpper must be an integer, got ${n}.`));const s=FL(e,"a","bandPart");aM(s.rank>=2,(()=>`bandPart(): Rank must be at least 2, got ${s.rank}.`));const r=s.shape,[a,i]=s.shape.slice(-2);if(!(t<=a))throw new Error(`bandPart(): numLower (${t}) must not be greater than the number of rows (${a}).`);if(!(n<=i))throw new Error(`bandPart(): numUpper (${n}) must not be greater than the number of columns (${i}).`);t<0&&(t=a),n<0&&(n=i);const o=CB(tV(0,a,1,"int32"),[-1,1]),l=tV(0,i,1,"int32"),u=lW(o,l),c=hW(QP(u,AP(+t,"int32")),jP(u,AP(-n,"int32"))),h=IW([a,i],s.dtype);return CB(AV(HV(CB(s,[-1,a,i])).map((e=>wP(c,e,h)))),r)}}),PU=LL({gramSchmidt_:function(e){let t;if(Array.isArray(e)){t=!1,aM(null!=e&&e.length>0,(()=>"Gram-Schmidt process: input must not be null, undefined, or empty"));const n=e[0].shape[0];for(let t=1;t<e.length;++t)aM(e[t].shape[0]===n,(()=>`Gram-Schmidt: Non-unique lengths found in the input vectors: (${e[t].shape[0]} vs. ${n})`))}else t=!0,e=$V(e,e.shape[0],0).map((e=>RV(e,[0])));aM(e.length<=e[0].shape[0],(()=>`Gram-Schmidt: Number of vectors (${e.length}) exceeds number of dimensions (${e[0].shape[0]}).`));const n=[],s=e;for(let t=0;t<e.length;++t)n.push(EL.tidy((()=>{let e=s[t];if(t>0)for(let s=0;s<t;++s){const t=FB(FP(FB(n[s],e)),n[s]);e=lW(e,t)}return yP(e,MP(e,"euclidean"))})));return t?AV(n,0):n}});function WU(e,t=!1){return EL.tidy((()=>{aM(2===e.shape.length,(()=>`qr2d() requires a 2D Tensor, but got a ${e.shape.length}D Tensor.`));const n=e.shape[0],s=e.shape[1];let r=VP(n),a=Pz(e);const i=MV([[1]],[1,1]);let o=Pz(i);const l=n>=s?s:n;for(let e=0;e<l;++e){const t=a,l=o,u=r;[o,a,r]=EL.tidy((()=>{const t=MB(a,[e,e],[n-e,1]),l=MP(t),u=MB(a,[e,e],[1,1]),c=wP(HP(u,0),MV([[-1]]),MV([[1]])),h=lW(u,FB(c,l)),p=yP(t,h);o=1===p.shape[0]?Pz(i):_B([i,MB(p,[1,0],[p.shape[0]-1,p.shape[1]])],0);const d=aW(yP(DB(c,h),l)),f=MB(a,[e,0],[n-e,s]),m=FB(d,o),g=ZV(o);if(0===e)a=lW(f,DB(m,DB(g,f)));else{const t=lW(f,DB(m,DB(g,f)));a=_B([MB(a,[0,0],[e,s]),t],0)}const y=ZV(m),b=MB(r,[0,e],[n,r.shape[1]-e]);if(0===e)r=lW(b,DB(DB(b,o),y));else{const t=lW(b,DB(DB(b,o),y));r=_B([MB(r,[0,0],[n,e]),t],1)}return[o,a,r]})),vL([t,l,u]).forEach((e=>e.dispose()))}return!t&&n>s&&(r=MB(r,[0,0],[n,s]),a=MB(a,[0,0],[s,s])),[r,a]}))}const VU=LL({qr_:function(e,t=!1){if(aM(e.rank>=2,(()=>`qr() requires input tensor to have a rank >= 2, but got rank ${e.rank}`)),2===e.rank)return WU(e,t);{const n=e.shape.slice(0,e.shape.length-2).reduce(((e,t)=>e*t)),s=HV(CB(e,[n,e.shape[e.shape.length-2],e.shape[e.shape.length-1]]),0),r=[],a=[];return s.forEach((e=>{const[n,s]=WU(e,t);r.push(n),a.push(s)})),[CB(AV(r,0),e.shape),CB(AV(a,0),e.shape)]}}});var UU;!function(e){e[e.NONE=0]="NONE",e[e.MEAN=1]="MEAN",e[e.SUM=2]="SUM",e[e.SUM_BY_NONZERO_WEIGHTS=3]="SUM_BY_NONZERO_WEIGHTS"}(UU||(UU={}));const GU=LL({computeWeightedLoss_:function(e,t,n=UU.SUM_BY_NONZERO_WEIGHTS){const s=FL(e,"losses","computeWeightedLoss");let r=null;null!=t&&(r=FL(t,"weights","computeWeightedLoss"));const a=null==r?s:FB(s,r);if(n===UU.NONE)return a;if(n===UU.SUM)return FP(a);if(n===UU.MEAN){if(null==r)return vW(a);{const e=s.size/r.size,t=yP(FP(a),FP(r));return e>1?yP(t,AP(e)):t}}if(n===UU.SUM_BY_NONZERO_WEIGHTS){if(null==r)return yP(FP(a),AP(s.size));{const e=FB(r,NW(s.shape)),t=Bz(FP(_W(e,AP(0))),"float32");return yP(FP(a),t)}}throw Error(`Unknown reduction: ${n}`)}}),HU=LL({absoluteDifference_:function(e,t,n,s=UU.SUM_BY_NONZERO_WEIGHTS){const r=FL(e,"labels","absoluteDifference"),a=FL(t,"predictions","absoluteDifference");let i=null;null!=n&&(i=FL(n,"weights","absoluteDifference")),iM(r.shape,a.shape,"Error in absoluteDifference: ");const o=lB(lW(r,a));return GU(o,i,s)}}),jU=LL({cosineDistance_:function(e,t,n,s,r=UU.SUM_BY_NONZERO_WEIGHTS){const a=FL(e,"labels","cosineDistance"),i=FL(t,"predictions","cosineDistance");let o=null;null!=s&&(o=FL(s,"weights","cosineDistance")),iM(a.shape,i.shape,"Error in cosineDistance: ");const l=AP(1),u=lW(l,FP(FB(a,i),n,!0));return GU(u,o,r)}}),KU=LL({hingeLoss_:function(e,t,n,s=UU.SUM_BY_NONZERO_WEIGHTS){let r=FL(e,"labels","hingeLoss");const a=FL(t,"predictions","hingeLoss");let i=null;null!=n&&(i=FL(n,"weights","hingeLoss")),iM(r.shape,a.shape,"Error in hingeLoss: ");const o=AP(1);r=lW(FB(AP(2),r),o);const l=rV(lW(o,FB(r,a)));return GU(l,i,s)}}),qU=LL({huberLoss_:function(e,t,n,s=1,r=UU.SUM_BY_NONZERO_WEIGHTS){const a=FL(e,"labels","huberLoss"),i=FL(t,"predictions","huberLoss");let o=null;null!=n&&(o=FL(n,"weights","huberLoss")),iM(a.shape,i.shape,"Error in huberLoss: ");const l=AP(s),u=lB(lW(i,a)),c=TW(u,l),h=lW(u,c),p=hB(FB(AP(.5),DP(c)),FB(l,h));return GU(p,o,r)}}),XU=LL({logLoss_:function(e,t,n,s=1e-7,r=UU.SUM_BY_NONZERO_WEIGHTS){const a=FL(e,"labels","logLoss"),i=FL(t,"predictions","logLoss");let o=null;null!=n&&(o=FL(n,"weights","logLoss")),iM(a.shape,i.shape,"Error in logLoss: ");const l=AP(1),u=AP(s),c=aW(FB(a,nW(hB(i,u)))),h=FB(lW(l,a),nW(hB(lW(l,i),u))),p=lW(c,h);return GU(p,o,r)}}),YU=LL({meanSquaredError_:function(e,t,n,s=UU.SUM_BY_NONZERO_WEIGHTS){const r=FL(e,"labels","meanSquaredError"),a=FL(t,"predictions","meanSquaredError");let i=null;null!=n&&(i=FL(n,"weights","meanSquaredError")),iM(r.shape,a.shape,"Error in meanSquaredError: ");const o=CV(r,a);return GU(o,i,s)}}),JU=LL({sigmoidCrossEntropy_:function(e,t,n,s=0,r=UU.SUM_BY_NONZERO_WEIGHTS){let a=FL(e,"multiClassLabels","sigmoidCrossEntropy");const i=FL(t,"logits","sigmoidCrossEntropy");let o=null;if(null!=n&&(o=FL(n,"weights","sigmoidCrossEntropy")),iM(a.shape,i.shape,"Error in sigmoidCrossEntropy: "),s>0){const e=AP(s),t=AP(1),n=AP(.5);a=hB(FB(a,lW(t,e)),FB(n,e))}const l=function(e,t){const n=FL(e,"labels","sigmoidCrossEntropyWithLogits"),s=FL(t,"logits","sigmoidCrossEntropyWithLogits");iM(n.shape,s.shape,"Error in sigmoidCrossEntropyWithLogits: ");const r=rV(s),a=FB(s,n),i=sW(zP(aW(lB(s))));return hB(lW(r,a),i)}(a,i);return GU(l,o,r)}}),ZU=LL({softmaxCrossEntropy_:function(e,t,n,s=0,r=UU.SUM_BY_NONZERO_WEIGHTS){let a=FL(e,"onehotLabels","softmaxCrossEntropy");const i=FL(t,"logits","softmaxCrossEntropy");let o=null;if(null!=n&&(o=FL(n,"weights","softmaxCrossEntropy")),iM(a.shape,i.shape,"Error in softmaxCrossEntropy: "),s>0){const e=AP(s),t=AP(1),n=AP(a.shape[1]);a=hB(FB(a,lW(t,e)),yP(e,n))}const l=function(e,t,n=-1){if(-1===n&&(n=t.rank-1),n!==t.rank-1)throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${t.rank} and dim was ${n}`);const s=rW(((e,t,s)=>{const r=cW(t,[n],!0),a=lW(Bz(t,"float32"),r);s([e,a]);const i=aW(FB(a,e));return{value:FP(i,[n]),gradFunc:(e,t)=>{const[s,r]=t,a=$P(e.shape,[n]);return[FB(CB(e,a),lW(Bz(s,"float32"),zP(r))),FB(CB(e,a),lW(zP(r),Bz(s,"float32")))]}}}));return s(e,t)}(a,i);return GU(l,o,r)}}),QU=LL({sparseFillEmptyRows_:function(e,t,n,s){const r=FL(e,"indices","sparseFillEmptyRows","int32"),a=FL(t,"values","sparseFillEmptyRows"),i=FL(n,"denseShape","sparseFillEmptyRows","int32"),o=FL(s,"defaultValue","sparseFillEmptyRows",a.dtype);if(2!==r.rank)throw new Error(`Indices should be Tensor2D but received shape\n        ${r.shape}`);if(1!==a.rank)throw new Error(`Values should be Tensor1D but received shape ${a.shape}`);if(1!==i.rank)throw new Error(`Dense shape should be Tensor1D but received shape ${i.shape}`);if(0!==o.rank)throw new Error(`Default value should be a scalar but received shape ${o.shape}`);const l={indices:r,values:a,denseShape:i,defaultValue:o},u=EL.runKernel("SparseFillEmptyRows",l);return{outputIndices:u[0],outputValues:u[1],emptyRowIndicator:u[2],reverseIndexMap:u[3]}}}),eG=LL({sparseReshape_:function(e,t,n){const s=FL(e,"inputIndices","sparseReshape","int32"),r=FL(t,"inputShape","sparseReshape","int32"),a=FL(n,"newShape","sparseReshape","int32");if(2!==s.rank)throw new Error(`Input indices should be Tensor2D but received shape\n        ${s.shape}`);if(1!==r.rank)throw new Error(`Input shape should be Tensor1D but received shape ${r.shape}`);if(1!==a.rank)throw new Error(`New shape should be Tensor1D but received shape ${a.shape}`);const i={inputIndices:s,inputShape:r,newShape:a},o=EL.runKernel("SparseReshape",i);return{outputIndices:o[0],outputShape:o[1]}}}),tG=LL({sparseSegmentMean_:function(e,t,n){const s=FL(e,"data","sparseSegmentMean"),r=FL(t,"indices","sparseSegmentMean","int32"),a=FL(n,"segmentIds","sparseSegmentMean","int32");if(s.rank<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==r.rank)throw new Error(`Indices should be Tensor1D but received shape\n          ${r.shape}`);if(1!==a.rank)throw new Error(`Segment ids should be Tensor1D but received shape\n          ${a.shape}`);const i={data:s,indices:r,segmentIds:a};return EL.runKernel("SparseSegmentMean",i)}}),nG=LL({sparseSegmentSum_:function(e,t,n){const s=FL(e,"data","sparseSegmentSum"),r=FL(t,"indices","sparseSegmentSum","int32"),a=FL(n,"segmentIds","sparseSegmentSum","int32");if(s.rank<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==r.rank)throw new Error(`Indices should be Tensor1D but received shape\n         ${r.shape}`);if(1!==a.rank)throw new Error(`Segment ids should be Tensor1D but received shape\n         ${a.shape}`);const i={data:s,indices:r,segmentIds:a};return EL.runKernel("SparseSegmentSum",i)}}),sG=LL({stringNGrams_:function(e,t,n,s,r,a,i,o){const l=FL(e,"data","stringNGrams","string");if("string"!==l.dtype)throw new Error("Data must be of datatype string");if(1!==l.shape.length)throw new Error(`Data must be a vector, saw: ${l.shape}`);const u=FL(t,"dataSplits","stringNGrams");if("int32"!==u.dtype)throw new Error("Data splits must be of datatype int32");const c={separator:n,nGramWidths:s,leftPad:r,rightPad:a,padWidth:i,preserveShortSequences:o},h={data:l,dataSplits:u},p=EL.runKernel("StringNGrams",h,c);return{nGrams:p[0],nGramsSplits:p[1]}}}),rG=LL({stringSplit_:function(e,t,n=!0){const s=FL(e,"input","stringSplit","string"),r=FL(t,"delimiter","stringSplit","string");if(1!==s.rank)throw new Error(`Input should be Tensor1D but received shape ${s.shape}`);if(0!==r.rank)throw new Error(`Delimiter should be a scalar but received shape ${r.shape}`);const a={skipEmpty:n},i={input:s,delimiter:r},o=EL.runKernel("StringSplit",i,a);return{indices:o[0],values:o[1],shape:o[2]}}}),aG=LL({stringToHashBucketFast_:function(e,t){const n=FL(e,"input","stringToHashBucketFast","string"),s={numBuckets:t};if(t<=0)throw new Error("Number of buckets must be at least 1");const r={input:n};return EL.runKernel("StringToHashBucketFast",r,s)}}),iG={fft:NV,ifft:SV,rfft:EV,irfft:TV},oG={hammingWindow:yU,hannWindow:bU,frame:xU,stft:wU},lG={flipLeftRight:vU,grayscaleToRGB:IU,resizeNearestNeighbor:MU,resizeBilinear:OU,rotateWithOffset:NU,cropAndResize:kU,nonMaxSuppression:TU,nonMaxSuppressionAsync:async function(e,t,n,s=.5,r=Number.NEGATIVE_INFINITY){const a=FL(e,"boxes","nonMaxSuppressionAsync"),i=FL(t,"scores","nonMaxSuppressionAsync"),o=SU(a,i,n,s,r);n=o.maxOutputSize,s=o.iouThreshold,r=o.scoreThreshold;const l=await Promise.all([a.data(),i.data()]),u=l[0],c=l[1],{selectedIndices:h}=function(e,t,n,s,r){return CU(e,t,n,s,r,0)}(u,c,n,s,r);return a!==e&&a.dispose(),i!==t&&i.dispose(),OV(h,"int32")},nonMaxSuppressionWithScore:DU,nonMaxSuppressionWithScoreAsync:async function(e,t,n,s=.5,r=Number.NEGATIVE_INFINITY,a=0){const i=FL(e,"boxes","nonMaxSuppressionAsync"),o=FL(t,"scores","nonMaxSuppressionAsync"),l=SU(i,o,n,s,r,a);n=l.maxOutputSize,s=l.iouThreshold,r=l.scoreThreshold,a=l.softNmsSigma;const u=await Promise.all([i.data(),o.data()]),c=u[0],h=u[1],{selectedIndices:p,selectedScores:d}=function(e,t,n,s,r,a){return CU(e,t,n,s,r,a,!0)}(c,h,n,s,r,a);return i!==e&&i.dispose(),o!==t&&o.dispose(),{selectedIndices:OV(p,"int32"),selectedScores:OV(d)}},nonMaxSuppressionPadded:FU,nonMaxSuppressionPaddedAsync:async function(e,t,n,s=.5,r=Number.NEGATIVE_INFINITY,a=!1){const i=FL(e,"boxes","nonMaxSuppressionAsync"),o=FL(t,"scores","nonMaxSuppressionAsync"),l=SU(i,o,n,s,r,null),u=l.maxOutputSize,c=l.iouThreshold,h=l.scoreThreshold,[p,d]=await Promise.all([i.data(),o.data()]),{selectedIndices:f,validOutputs:m}=function(e,t,n,s,r,a){return CU(e,t,n,s,r,0,!1,a,!0)}(p,d,u,c,h,a);return i!==e&&i.dispose(),o!==t&&o.dispose(),{selectedIndices:OV(f,"int32"),validOutputs:AP(m,"int32")}},threshold:LU,transform:zU},uG={bandPart:BU,gramSchmidt:PU,qr:VU},cG={absoluteDifference:HU,computeWeightedLoss:GU,cosineDistance:jU,hingeLoss:KU,huberLoss:qU,logLoss:XU,meanSquaredError:YU,sigmoidCrossEntropy:JU,softmaxCrossEntropy:ZU},hG={sparseFillEmptyRows:QU,sparseReshape:eG,sparseSegmentMean:tG,sparseSegmentSum:nG},pG={stringNGrams:sG,stringSplit:rG,stringToHashBucketFast:aG};var dG,fG;CM().registerFlag("KEEP_INTERMEDIATE_TENSORS",(()=>!1),(e=>{e&&console.warn("Keep intermediate tensors is ON. This will print the values of all intermediate tensors during model inference. Not all models support this mode. For details, check e2e/benchmarks/ model_config.js. This significantly impacts performance.")})),function(e){e[e.DT_INVALID=0]="DT_INVALID",e[e.DT_FLOAT=1]="DT_FLOAT",e[e.DT_DOUBLE=2]="DT_DOUBLE",e[e.DT_INT32=3]="DT_INT32",e[e.DT_UINT8=4]="DT_UINT8",e[e.DT_INT16=5]="DT_INT16",e[e.DT_INT8=6]="DT_INT8",e[e.DT_STRING=7]="DT_STRING",e[e.DT_COMPLEX64=8]="DT_COMPLEX64",e[e.DT_INT64=9]="DT_INT64",e[e.DT_BOOL=10]="DT_BOOL",e[e.DT_QINT8=11]="DT_QINT8",e[e.DT_QUINT8=12]="DT_QUINT8",e[e.DT_QINT32=13]="DT_QINT32",e[e.DT_BFLOAT16=14]="DT_BFLOAT16",e[e.DT_QINT16=15]="DT_QINT16",e[e.DT_QUINT16=16]="DT_QUINT16",e[e.DT_UINT16=17]="DT_UINT16",e[e.DT_COMPLEX128=18]="DT_COMPLEX128",e[e.DT_HALF=19]="DT_HALF",e[e.DT_RESOURCE=20]="DT_RESOURCE",e[e.DT_VARIANT=21]="DT_VARIANT",e[e.DT_UINT32=22]="DT_UINT32",e[e.DT_UINT64=23]="DT_UINT64",e[e.DT_FLOAT_REF=101]="DT_FLOAT_REF",e[e.DT_DOUBLE_REF=102]="DT_DOUBLE_REF",e[e.DT_INT32_REF=103]="DT_INT32_REF",e[e.DT_UINT8_REF=104]="DT_UINT8_REF",e[e.DT_INT16_REF=105]="DT_INT16_REF",e[e.DT_INT8_REF=106]="DT_INT8_REF",e[e.DT_STRING_REF=107]="DT_STRING_REF",e[e.DT_COMPLEX64_REF=108]="DT_COMPLEX64_REF",e[e.DT_INT64_REF=109]="DT_INT64_REF",e[e.DT_BOOL_REF=110]="DT_BOOL_REF",e[e.DT_QINT8_REF=111]="DT_QINT8_REF",e[e.DT_QUINT8_REF=112]="DT_QUINT8_REF",e[e.DT_QINT32_REF=113]="DT_QINT32_REF",e[e.DT_BFLOAT16_REF=114]="DT_BFLOAT16_REF",e[e.DT_QINT16_REF=115]="DT_QINT16_REF",e[e.DT_QUINT16_REF=116]="DT_QUINT16_REF",e[e.DT_UINT16_REF=117]="DT_UINT16_REF",e[e.DT_COMPLEX128_REF=118]="DT_COMPLEX128_REF",e[e.DT_HALF_REF=119]="DT_HALF_REF",e[e.DT_RESOURCE_REF=120]="DT_RESOURCE_REF",e[e.DT_VARIANT_REF=121]="DT_VARIANT_REF",e[e.DT_UINT32_REF=122]="DT_UINT32_REF",e[e.DT_UINT64_REF=123]="DT_UINT64_REF"}(dG||(dG={})),function(e){let t;!function(e){e[e.LEGACY=0]="LEGACY",e[e.V1=1]="V1",e[e.V2=2]="V2"}(t=e.CheckpointFormatVersion||(e.CheckpointFormatVersion={}))}(fG||(fG={}));const mG={};function gG(e){return mG[e]}function yG(e,t,n,s,r){const a=t.inputParams[e];if(a&&void 0!==a.inputIndexStart){const e=a.inputIndexStart,i=0===a.inputIndexEnd?void 0:void 0===a.inputIndexEnd?e+1:a.inputIndexEnd;if("tensor"===a.type)return bG(t.inputNames[a.inputIndexStart],n,s,r);if("tensors"===a.type)return t.inputNames.slice(e,i).map((e=>bG(e,n,s,r)));const o=bG(t.inputNames.slice(e)[0],n,s,r),l=o.dataSync();return"number"===a.type?l[0]:kM(o.shape,l)}const i=t.attrParams[e];return i&&i.value}function bG(e,t,n,s){const[r,a]=kG(e);if(null!=s){const e=s.getHashTableHandleByName(r);if(null!=e)return e}const i=n.currentContextIds.find((e=>!!t[wG(r,e)]));return void 0!==i?t[wG(r,i)][a]:void 0}function xG(e,t){const[n,s,r]=kG(e);return[wG(n,t&&t.currentContextId),s,r]}function wG(e,t){return t?`${e}-${t}`:e}function kG(e){const t=e.split(":");if(1===t.length)return[e,0,void 0];const n=t[0],s=3===t.length?t[1]:void 0;return[n,Number(t[t.length-1]),s]}function vG(e,t,n){let s=yG("pad",e,t,n);if("explicit"===s){s=yG("explicitPaddings",e,t,n);const r=[[0,0],[0,0],[0,0],[0,0]];for(let e=0;e<4;e++)r[e][0]=s[2*e],r[e][1]=s[2*e+1];return r}return s}function IG(e){return e.kept?e:Pz(e)}const NG=[{tfOpName:"Add",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AddV2",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AddN",category:"arithmetic",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"BiasAdd",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"Sub",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"RealDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Div",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"DivNoNan",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"FloorDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Mul",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Maximum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Minimum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Pow",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SquaredDifference",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Mod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"FloorMod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],SG=[{tfOpName:"Abs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Acos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Asin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atan2",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Ceil",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ClipByValue",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"clipValueMin",type:"number"},{start:2,name:"clipValueMax",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Complex",category:"basic_math",inputs:[{start:0,name:"real",type:"tensor"},{start:1,name:"imag",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ComplexAbs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Cos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Cosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Elu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Exp",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Floor",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Log",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Imag",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:!0}]},{tfOpName:"Neg",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Real",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:!0}]},{tfOpName:"Prelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"alpha",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Relu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Relu6",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Selu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sigmoid",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Rsqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Square",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Tan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Tanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sign",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Round",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Expm1",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Log1p",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Reciprocal",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Softplus",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Asinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Acosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Erf",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Prod",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axes",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool",notSupported:!0},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LeakyRelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"alpha",name:"alpha",type:"number",defaultValue:.2},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"IsNan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],TG=[{tfOpName:"EmptyTensorList",category:"control",inputs:[{start:0,name:"elementShape",type:"shape"},{start:1,name:"maxNumElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"LoopCond",category:"control",inputs:[{start:0,name:"pred",type:"tensor"}]},{tfOpName:"Switch",category:"control",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"pred",type:"tensor"}]},{tfOpName:"Merge",category:"control",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"Enter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"frame_name",name:"frameName",type:"string"},{tfName:"is_constant",name:"isConstant",type:"bool"}]},{tfOpName:"Exit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"NextIteration",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayV3",category:"control",inputs:[{start:0,name:"size",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"dynamic_size",name:"dynamicSize",type:"bool"},{tfName:"clear_after_read",name:"clearAfterRead",type:"bool"},{tfName:"identical_element_shapes",name:"identicalElementShapes",type:"bool"},{tfName:"tensor_array_name",name:"name",type:"string"}]},{tfOpName:"TensorArrayWriteV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayReadV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayGatherV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"}]},{tfOpName:"TensorArrayScatterV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArrayConcatV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape_except0",name:"elementShapeExcept0",type:"shape",notSupported:!0}]},{tfOpName:"TensorArraySplitV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"tensor",type:"tensor"},{start:2,name:"lengths",type:"number[]"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArraySizeV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}]},{tfOpName:"TensorArrayCloseV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"}]},{tfOpName:"StatelessIf",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"If",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"StatelessWhile",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"While",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"TensorListScatter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListScatterV2",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"},{start:3,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGather",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListSetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListReserve",category:"control",inputs:[{start:0,name:"elementShape",type:"shape"},{start:1,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListFromTensor",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListStack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"},{tfName:"num_elements",name:"numElements",type:"dtype"}]},{tfOpName:"TensorListSplit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"},{start:2,name:"lengths",type:"number[]"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListConcat",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"}],attrs:[{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListConcatV2",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"}],attrs:[{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPopBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPushBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListLength",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"}]},{tfOpName:"TensorListResize",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"size",type:"number"}]}],$G=[{tfOpName:"AvgPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[],notSupported:!0},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPoolWithArgmax",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"include_batch_in_index",name:"includeBatchInIndex",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AvgPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Conv1D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"stride",name:"stride",type:"number"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NWC"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"dilation",name:"dilation",type:"number",defaultValue:1}]},{tfOpName:"Conv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"useCudnnOnGpu",name:"useCudnnOnGpu",type:"bool"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"_FusedConv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"use_cudnn_on_gpu",name:"useCudnnOnGpu",type:"bool",defaultValue:!0},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4},{tfName:"leakyrelu_alpha",name:"leakyreluAlpha",type:"number",defaultValue:.2}]},{tfOpName:"Conv2DBackpropInput",category:"convolution",inputs:[{start:2,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:0,name:"outputShape",type:"number[]"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]",notSupported:!0}]},{tfOpName:"DepthwiseConv2d",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"DepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"FusedDepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]}]},{tfOpName:"Conv3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"Dilation2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"rates",name:"dilations",type:"number[]"},{tfName:"padding",name:"pad",type:"string"}]}],EG=[{tfOpName:"Fill",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"},{start:1,name:"value",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"LinSpace",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"num",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"OneHot",category:"creation",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"depth",type:"number"},{start:2,name:"onValue",type:"number",defaultValue:1},{start:3,name:"offValue",type:"number",defaultValue:0}],attrs:[{tfName:"axis",name:"axis",type:"number",notSupported:!0},{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"Ones",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"OnesLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"RandomStandardNormal",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"seed",name:"seed",type:"number",defaultValue:0},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"RandomUniform",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"minval",name:"minval",type:"number",defaultValue:0},{tfName:"maxval",name:"maxval",type:"number",defaultValue:1},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"seed",name:"seed",type:"number",defaultValue:0},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"Range",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"step",type:"number",defaultValue:0}],attrs:[{tfName:"Tidx",name:"dtype",type:"dtype"}]},{tfOpName:"TruncatedNormal",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"means",name:"mean",type:"number",defaultValue:0},{tfName:"stddev",name:"stdDev",type:"number",defaultValue:1},{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"Zeros",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"ZerosLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"Multinomial",category:"creation",inputs:[{start:0,name:"logits",type:"tensor"},{start:1,name:"numSamples",type:"number"}],attrs:[{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number"},{tfName:"T",name:"dtype",type:"dtype"},{tfName:"output_dtype",name:"output_dtype",type:"dtype"}]}],CG=[{tfOpName:"NonMaxSuppressionV2",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV3",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV4",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"T_threshold",name:"threshold",type:"dtype",notSupported:!0},{tfName:"pad_to_max_output_size",name:"padToMaxOutputSize",type:"bool"}]},{tfOpName:"NonMaxSuppressionV5",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"},{start:5,name:"softNmsSigma",type:"number"}]},{tfOpName:"Where",category:"dynamic",inputs:[{start:0,name:"condition",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ListDiff",category:"dynamic",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],RG=[{tfOpName:"LowerBound",category:"evaluation",inputs:[{start:0,name:"sortedSequence",type:"tensor"},{start:1,name:"values",type:"tensor"}]},{tfOpName:"TopKV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"k",type:"number"}],attrs:[{tfName:"sorted",name:"sorted",type:"bool"}]},{tfOpName:"UpperBound",category:"evaluation",inputs:[{start:0,name:"sortedSequence",type:"tensor"},{start:1,name:"values",type:"tensor"}]},{tfOpName:"Unique",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"UniqueV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]}],AG=[{tfOpName:"PlaceholderWithDefault",category:"graph",inputs:[{start:0,name:"default",type:"tensor"}],attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Placeholder",category:"graph",attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Const",category:"graph"},{tfOpName:"Identity",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IdentityN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Snapshot",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Rank",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Size",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Shape",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"ShapeN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Print",category:"graph",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"data",type:"tensors"}],attrs:[{tfName:"message",name:"message",type:"string"},{tfName:"first_n",name:"firstN",type:"number",notSupported:!0},{tfName:"summarize",name:"summarize",type:"number",defaultValue:3}]},{tfOpName:"NoOp",category:"graph",inputs:[]},{tfOpName:"StopGradient",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"FakeQuantWithMinMaxVars",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"min",name:"min",type:"number"},{tfName:"max",name:"max",type:"number"}]}],_G=[{tfOpName:"HashTable",category:"hash_table",inputs:[],attrs:[{tfName:"shared_name",name:"sharedName",type:"string"},{tfName:"use_node_name_sharing",name:"useNodeNameSharing",type:"bool"},{tfName:"key_dtype",name:"keyDType",type:"dtype"},{tfName:"value_dtype",name:"valueDType",type:"dtype"}]},{tfOpName:"HashTableV2",category:"hash_table",inputs:[],attrs:[{tfName:"shared_name",name:"sharedName",type:"string"},{tfName:"use_node_name_sharing",name:"useNodeNameSharing",type:"bool"},{tfName:"key_dtype",name:"keyDType",type:"dtype"},{tfName:"value_dtype",name:"valueDType",type:"dtype"}]},{tfOpName:"LookupTableImport",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableImportV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableFind",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableFindV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableSize",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"}]},{tfOpName:"LookupTableSizeV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"}]}],DG=[{tfOpName:"ResizeBilinear",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"half_pixel_centers",name:"halfPixelCenters",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ResizeNearestNeighbor",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"half_pixel_centers",name:"halfPixelCenters",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"CropAndResize",category:"image",inputs:[{start:0,name:"image",type:"tensor"},{start:1,name:"boxes",type:"tensor"},{start:2,name:"boxInd",type:"tensor"},{start:3,name:"cropSize",type:"number[]"}],attrs:[{tfName:"method",name:"method",type:"string"},{tfName:"extrapolation_value",name:"extrapolationValue",type:"number"}]},{tfOpName:"ImageProjectiveTransformV3",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"transforms",type:"tensor"},{start:2,name:"outputShape",type:"number[]"},{start:3,name:"fillValue",type:"number"}],attrs:[{tfName:"interpolation",name:"interpolation",type:"string"},{tfName:"fill_mode",name:"fillMode",type:"string"}]}],FG=[{tfOpName:"Equal",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"NotEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Greater",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"GreaterEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Less",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LessEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalAnd",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalNot",category:"logical",inputs:[{start:0,name:"a",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalOr",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Select",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SelectV2",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],OG=[{tfOpName:"_FusedMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4},{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"leakyrelu_alpha",name:"leakyreluAlpha",type:"number",defaultValue:.2},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"BatchMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"BatchMatMulV2",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Transpose",category:"matrices",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"perm",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Einsum",category:"matrices",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}],attrs:[{tfName:"equation",name:"equation",type:"string"},{tfName:"N",name:"n",type:"number",defaultValue:2},{tfName:"T",name:"dtype",type:"dtype"}]}],MG=[{tfOpName:"EuclideanNorm",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool",defaultValue:!1}]},{tfOpName:"FusedBatchNorm",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"FusedBatchNormV2",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"FusedBatchNormV3",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"LRN",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"depth_radius",name:"radius",type:"number",defaultValue:5},{tfName:"bias",name:"bias",type:"number",defaultValue:1},{tfName:"alpha",name:"alpha",type:"number",defaultValue:1},{tfName:"beta",name:"beta",type:"number",defaultValue:.5}]},{tfOpName:"Softmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"LogSoftmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"SparseToDense",category:"normalization",inputs:[{start:0,name:"sparseIndices",type:"tensor"},{start:1,name:"outputShape",type:"number[]"},{start:2,name:"sparseValues",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",defaultValue:!0,notSupported:!0}]}],LG=[{tfOpName:"Bincount",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"size",type:"number"},{start:2,name:"weights",type:"tensor"}]},{tfOpName:"DenseBincount",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"size",type:"number"},{start:2,name:"weights",type:"tensor"}],attrs:[{tfName:"binary_output",name:"binaryOutput",type:"bool"}]},{tfOpName:"Max",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Mean",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Min",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Sum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"All",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Any",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"ArgMax",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"ArgMin",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"Prod",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Cumprod",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}],attrs:[{tfName:"exclusive",name:"exclusive",type:"bool"},{tfName:"reverse",name:"reverse",type:"bool"}]},{tfOpName:"Cumsum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}],attrs:[{tfName:"exclusive",name:"exclusive",type:"bool"},{tfName:"reverse",name:"reverse",type:"bool"}]}],zG=[{tfOpName:"ConcatV2",category:"slice_join",inputs:[{start:0,end:-1,name:"tensors",type:"tensors"},{start:-1,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"Concat",category:"slice_join",inputs:[{start:1,end:0,name:"tensors",type:"tensors"},{start:0,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"GatherV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"axis",type:"number",defaultValue:0}],attrs:[{tfName:"batch_dims",name:"batchDims",type:"number",defaultValue:0}]},{tfOpName:"Gather",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",notSupported:!0}]},{tfOpName:"Reverse",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"dims",type:"bool[]"}]},{tfOpName:"ReverseV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}]},{tfOpName:"Slice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"size",type:"number[]"}]},{tfOpName:"StridedSlice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"end",type:"number[]"},{start:3,name:"strides",type:"number[]"}],attrs:[{tfName:"begin_mask",name:"beginMask",type:"number",defaultValue:0},{tfName:"end_mask",name:"endMask",type:"number",defaultValue:0},{tfName:"new_axis_mask",name:"newAxisMask",type:"number",defaultValue:0},{tfName:"ellipsis_mask",name:"ellipsisMask",type:"number",defaultValue:0},{tfName:"shrink_axis_mask",name:"shrinkAxisMask",type:"number",defaultValue:0}]},{tfOpName:"Pack",category:"slice_join",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0}]},{tfOpName:"Unpack",category:"slice_join",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0},{tfName:"num",name:"num",type:"number",defaultValue:0,notSupported:!0}]},{tfOpName:"Tile",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"reps",type:"number[]"}]},{tfOpName:"Split",category:"slice_join",inputs:[{start:0,name:"axis",type:"number",defaultValue:0},{start:1,name:"x",type:"tensor"}],attrs:[{tfName:"num_split",name:"numOrSizeSplits",type:"number",defaultValue:1}]},{tfOpName:"SplitV",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"numOrSizeSplits",type:"number[]"},{start:2,name:"axis",type:"number",defaultValue:0}]},{tfOpName:"ScatterNd",category:"slice_join",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"values",type:"tensor"},{start:2,name:"shape",type:"number[]"}]},{tfOpName:"GatherNd",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}]},{tfOpName:"SparseToDense",category:"slice_join",inputs:[{start:0,name:"sparseIndices",type:"tensor"},{start:1,name:"outputShape",type:"number[]"},{start:2,name:"sparseValues",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",defaultValue:!1,notSupported:!0}]}],BG=[{tfOpName:"SparseFillEmptyRows",category:"sparse",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"values",type:"tensor"},{start:2,name:"denseShape",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}]},{tfOpName:"SparseReshape",category:"sparse",inputs:[{start:0,name:"inputIndices",type:"tensor"},{start:1,name:"inputShape",type:"tensor"},{start:2,name:"newShape",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SparseSegmentMean",category:"sparse",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"segmentIds",type:"tensor"}]},{tfOpName:"SparseSegmentSum",category:"sparse",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"segmentIds",type:"tensor"}]}],PG=[{tfOpName:"FFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"RFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:!0}]},{tfOpName:"IRFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:!0}]}],WG=[{tfOpName:"StringNGrams",category:"string",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"dataSplits",type:"tensor"}],attrs:[{tfName:"separator",name:"separator",type:"string"},{tfName:"ngram_widths",name:"nGramWidths",type:"number[]"},{tfName:"left_pad",name:"leftPad",type:"string"},{tfName:"right_pad",name:"rightPad",type:"string"},{tfName:"pad_width",name:"padWidth",type:"number"},{tfName:"preserve_short_sequences",name:"preserveShortSequences",type:"bool"}],outputs:["ngrams","ngrams_splits"]},{tfOpName:"StringSplit",category:"string",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"delimiter",type:"tensor"}],attrs:[{tfName:"skip_empty",name:"skipEmpty",type:"bool"}],outputs:["indices","values","shape"]},{tfOpName:"StringToHashBucketFast",category:"string",inputs:[{start:0,name:"input",type:"tensor"}],attrs:[{tfName:"num_buckets",name:"numBuckets",type:"number"}]}],VG=[{tfOpName:"Cast",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"SrcT",name:"sdtype",type:"dtype",notSupported:!0},{tfName:"DstT",name:"dtype",type:"dtype"}]},{tfOpName:"ExpandDims",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"MirrorPad",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"}],attrs:[{tfName:"mode",name:"mode",type:"string"}]},{tfOpName:"Pad",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"}],attrs:[{tfName:"constant_value",name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"PadV2",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"},{start:2,name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"Reshape",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}]},{tfOpName:"Squeeze",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"axis",tfDeprecatedName:"squeeze_dims",name:"axis",type:"number[]"}]},{tfOpName:"SpaceToBatchND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"paddings",type:"number[]"}]},{tfOpName:"BatchToSpaceND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"crops",type:"number[]"}]},{tfOpName:"DepthToSpace",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"block_size",name:"blockSize",type:"number"},{tfName:"data_format",name:"dataFormat",type:"string"}]},{tfOpName:"BroadcastTo",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}],attrs:[]},{tfOpName:"BroadcastArgs",category:"transformation",inputs:[{start:0,name:"s0",type:"tensor"},{start:1,name:"s1",type:"tensor"}],attrs:[]}];class UG{static get Instance(){return this._instance||(this._instance=new this)}constructor(){const e=[].concat(...[o,l,u,c,h,p,d,f,m,g,y,b,x,w,k,v,I,N,S].map((e=>e.json)));this.opMappers=e.reduce(((e,t)=>(e[t.tfOpName]=t,e)),{})}transformGraph(e,t={}){const n=e.node,s=[],r=[],a=[],i=n.reduce(((e,t)=>(e[t.name]=this.mapNode(t),t.op.startsWith("Placeholder")?s.push(e[t.name]):"Const"===t.op?r.push(e[t.name]):null!=t.input&&0!==t.input.length||a.push(e[t.name]),e)),{});let o=[];const l=[];let u={},c={};null!=t&&(u=this.mapSignatureEntries(t.inputs),c=this.mapSignatureEntries(t.outputs));const h=Object.keys(i);h.forEach((e=>{const t=i[e];t.inputNames.forEach(((e,n)=>{const[s,,r]=xG(e),a=i[s];if(null!=a.outputs){const e=a.outputs.indexOf(r);if(-1!==e){const r=`${s}:${e}`;t.inputNames[n]=r}}t.inputs.push(a),a.children.push(t)}))})),0===Object.keys(c).length?h.forEach((e=>{const t=i[e];0===t.children.length&&l.push(t)})):Object.keys(c).forEach((e=>{const[t]=xG(e),n=i[t];null!=n&&(n.signatureKey=c[e],l.push(n))})),Object.keys(u).length>0?Object.keys(u).forEach((e=>{const[t]=xG(e),n=i[t];n&&(n.signatureKey=u[e],o.push(n))})):o=s;let p={};null!=e.library&&null!=e.library.function&&(p=e.library.function.reduce(((e,t)=>(e[t.signature.name]=this.mapFunction(t),e)),{}));const d={nodes:i,inputs:o,outputs:l,weights:r,placeholders:s,signature:t,functions:p};return a.length>0&&(d.initNodes=a),d}mapSignatureEntries(e){return Object.keys(e||{}).reduce(((t,n)=>(t[e[n].name]=n,t)),{})}mapNode(e){const t=gG(e.op)||this.opMappers[e.op]||{};null==e.attr&&(e.attr={});const n={name:e.name,op:e.op,category:t.category,inputNames:(e.input||[]).map((e=>e.startsWith("^")?e.slice(1):e)),inputs:[],children:[],inputParams:{},attrParams:{},rawAttrs:e.attr,outputs:t.outputs};return null!=t.inputs&&(n.inputParams=t.inputs.reduce(((e,t)=>(e[t.name]={type:t.type,inputIndexStart:t.start,inputIndexEnd:t.end},e)),{})),null!=t.attrs&&(n.attrParams=t.attrs.reduce(((t,n)=>{const s=n.type;let r;switch(n.type){case"string":r=HG(e.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=HG(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"string[]":r=tH(e.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=tH(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"number":r=KG(e.attr,n.tfName,n.defaultValue||0),void 0===r&&n.tfDeprecatedName&&(r=KG(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"number[]":r=eH(e.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=eH(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"bool":r=jG(e.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=jG(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"bool[]":r=sH(e.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=sH(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"shape":r=QG(e.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=QG(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"shape[]":r=nH(e.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=nH(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"dtype":r=YG(e.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=YG(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"dtype[]":r=JG(e.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=JG(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"func":r=XG(e.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=XG(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"tensor":case"tensors":break;default:throw new Error(`Unsupported param type: ${n.type} for op: ${e.op}`)}return t[n.name]={value:r,type:s},t}),{})),n}mapFunction(e){const t=e.nodeDef,n=[];let s={};null!=t&&(s=t.reduce(((e,t)=>(e[t.name]=this.mapNode(t),"Const"===t.op&&n.push(e[t.name]),e)),{}));const r=[],a=[];e.signature.inputArg.forEach((e=>{const[t]=xG(e.name),n={name:t,op:"Placeholder",inputs:[],inputNames:[],category:"graph",inputParams:{},attrParams:{dtype:{value:qG(e.type),type:"dtype"}},children:[]};n.signatureKey=e.name,r.push(n),s[t]=n})),Object.keys(s).forEach((e=>{const t=s[e];t.inputNames.forEach(((e,n)=>{const[r,,a]=xG(e),i=s[r];if(null!=i.outputs){const e=i.outputs.indexOf(a);if(-1!==e){const s=`${r}:${e}`;t.inputNames[n]=s}}t.inputs.push(i),i.children.push(t)}))}));const i=e.ret;e.signature.outputArg.forEach((e=>{const[t,n]=xG(i[e.name]),r=s[t];null!=r&&(r.defaultOutput=n,a.push(r))}));const o=this.mapArgsToSignature(e);return{nodes:s,inputs:r,outputs:a,weights:n,placeholders:[],signature:o}}mapArgsToSignature(e){return{methodName:e.signature.name,inputs:e.signature.inputArg.reduce(((e,t)=>(e[t.name]=this.mapArgToTensorInfo(t),e)),{}),outputs:e.signature.outputArg.reduce(((t,n)=>(t[n.name]=this.mapArgToTensorInfo(n,e.ret),t)),{})}}mapArgToTensorInfo(e,t){let n=e.name;return null!=t&&(n=t[n]),{name:n,dtype:e.type}}}function GG(e,t){const n=Array.isArray(e)?String.fromCharCode.apply(null,e):function(e){const t=CM().global;if(void 0!==t.atob)return t.atob(e);if("undefined"!=typeof Buffer)return new Buffer(e,"base64").toString();throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()")}(e);return t?n:n.toLowerCase()}function HG(e,t,n,s=!1){const r=e[t];return null!=r?GG(r.s,s):n}function jG(e,t,n){const s=e[t];return s?s.b:n}function KG(e,t,n){const s=e[t]||{},r=null!=s.i?s.i:null!=s.f?s.f:n;return"number"==typeof r?r:parseInt(r,10)}function qG(e){switch("string"==typeof e&&(e=dG[e]),e){case dG.DT_FLOAT:case dG.DT_HALF:return"float32";case dG.DT_INT32:case dG.DT_INT64:case dG.DT_INT8:case dG.DT_UINT8:return"int32";case dG.DT_BOOL:return"bool";case dG.DT_DOUBLE:return"float32";case dG.DT_STRING:return"string";default:return null}}function XG(e,t,n){const s=e[t];return s&&s.func?s.func.name:n}function YG(e,t,n){const s=e[t];return s&&s.type?qG(s.type):n}function JG(e,t,n){const s=e[t];return s&&s.list&&s.list.type?s.list.type.map((e=>qG(e))):n}function ZG(e){if(!e.unknownRank)return null!=e.dim?e.dim.map((e=>"number"==typeof e.size?e.size:parseInt(e.size,10))):[]}function QG(e,t,n){const s=e[t];return s&&s.shape?ZG(s.shape):n}function eH(e,t,n){const s=e[t];return s?((s.list.f&&s.list.f.length?s.list.f:s.list.i)||[]).map((e=>"number"==typeof e?e:parseInt(e,10))):n}function tH(e,t,n,s=!1){const r=e[t];return r&&r.list&&r.list.s?r.list.s.map((e=>GG(e,s))):n}function nH(e,t,n){const s=e[t];return s&&s.list&&s.list.shape?s.list.shape.map((e=>ZG(e))):n}function sH(e,t,n){const s=e[t];return s&&s.list&&s.list.b?s.list.b:n}class rH{constructor(e,t,n){this.node=e,this.tensorMap=t,this.context=n,this.inputs=[],this.attrs={},this.inputs=e.inputNames.map((e=>this.getInput(e))),null!=e.rawAttrs&&(this.attrs=Object.keys(e.rawAttrs).reduce(((e,t)=>(e[t]=this.getAttr(t),e)),{}))}getInput(e){return bG(e,this.tensorMap,this.context)}getAttr(e,t){const n=this.node.rawAttrs[e];if(null!=n.tensor)return bG(e,this.tensorMap,this.context);if(null!=n.i||null!=n.f)return KG(this.node.rawAttrs,e,t);if(null!=n.s)return HG(this.node.rawAttrs,e,t);if(null!=n.b)return jG(this.node.rawAttrs,e,t);if(null!=n.shape)return QG(this.node.rawAttrs,e,t);if(null!=n.type)return YG(this.node.rawAttrs,e,t);if(null!=n.list){if(null!=n.list.i||null!=n.list.f)return eH(this.node.rawAttrs,e,t);if(null!=n.list.s)return tH(this.node.rawAttrs,e,t);if(null!=n.list.shape)return nH(this.node.rawAttrs,e,t);if(null!=n.list.b)return sH(this.node.rawAttrs,e,t);if(null!=n.list.type)return JG(this.node.rawAttrs,e,t)}return t}}function aH(e,t,n=""){if("number"!=typeof e&&"number"!=typeof t){aM(e.length===t.length,(()=>n+` Shapes ${e} and ${t} must match`));for(let s=0;s<e.length;s++){const r=e[s],a=t[s];aM(r<0||a<0||r===a,(()=>n+` Shapes ${e} and ${t} must match`))}}}function iH(e){return"number"!=typeof e&&!e.some((e=>e<0))}function oH(e,t,n){let s=lH(e,n);const r=!iH(s);if(r&&0===t.length)throw new Error(`Tried to calculate elements of an empty list with non-fully-defined elementShape: ${s}`);if(r&&t.forEach((e=>{s=lH(e.shape,s)})),!iH(s))throw new Error(`Non-fully-defined elementShape: ${s}`);return s}function lH(e,t){if("number"==typeof e)return t;if("number"==typeof t)return e;if(e.length!==t.length)throw new Error(`Incompatible ranks during merge: ${e} vs. ${t}`);const n=[];for(let s=0;s<e.length;++s){const r=e[s],a=t[s];if(r>=0&&a>=0&&r!==a)throw new Error(`Incompatible shape during merge: ${e} vs. ${t}`);n[s]=r>=0?r:a}return n}class uH{constructor(e,t,n,s,r,a,i){this.name=e,this.dtype=t,this.maxSize=n,this.elementShape=s,this.identicalElementShapes=r,this.dynamicSize=a,this.clearAfterRead=i,this.tensors=[],this.closed_=!1,this.idTensor=AP(0),JV(this.idTensor)}get id(){return this.idTensor.id}get closed(){return this.closed_}clearAndClose(e){this.tensors.forEach((t=>{null!=e&&e.has(t.tensor.id)||t.tensor.dispose()})),this.tensors=[],this.closed_=!0,this.idTensor.dispose()}size(){return this.tensors.length}read(e){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(e<0||e>=this.size())throw new Error(`Tried to read from index ${e}, but array size is: ${this.size()}`);const t=this.tensors[e];if(t.cleared)throw new Error(`TensorArray ${this.name}: Could not read index ${e} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);return this.clearAfterRead&&(t.cleared=!0),t.read=!0,t.tensor}readMany(e){return e.map((e=>this.read(e)))}write(e,t){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(e<0||!this.dynamicSize&&e>=this.maxSize)throw new Error(`Tried to write to index ${e}, but array is not resizeable and size is: ${this.maxSize}`);const n=this.tensors[e]||{};if(t.dtype!==this.dtype)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e},\n          because the value dtype is ${t.dtype}, but TensorArray dtype is ${this.dtype}.`);if(0!==this.size()||null!=this.elementShape&&0!==this.elementShape.length||(this.elementShape=t.shape),aH(this.elementShape,t.shape,`TensorArray ${this.name}: Could not write to TensorArray index ${e}.`),n.read)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e}, because it has already been read.`);if(n.written)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e}, because it has already been written.`);n.tensor=t,JV(t),n.written=!0,this.tensors[e]=n}writeMany(e,t){if(e.length!==t.length)throw new Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${e.length} is not the same as tensors size: ${t.length}.`);e.forEach(((e,n)=>this.write(e,t[n])))}gather(e,t){if(t&&t!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${t}`);if(e)e=e.slice(0,this.size());else{e=[];for(let t=0;t<this.size();t++)e.push(t)}if(0===e.length)return PL([],[0].concat(this.elementShape));const n=this.readMany(e);return aH(this.elementShape,n[0].shape,"TensorArray shape mismatch: "),AV(n,0)}concat(e){if(e&&e!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${e}`);if(0===this.size())return PL([],[0].concat(this.elementShape));const t=[];for(let e=0;e<this.size();e++)t.push(e);const n=this.readMany(t);return aH(this.elementShape,n[0].shape,`TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${n[0].shape})`),_B(n,0)}scatter(e,t){if(t.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t.dtype}`);if(e.length!==t.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${e.length} vs. ${t.shape[0]}`);const n=Math.max(...e);if(!this.dynamicSize&&n>=this.maxSize)throw new Error(`Max index must be < array size (${n}  vs. ${this.maxSize})`);this.writeMany(e,HV(t,0))}split(e,t){if(t.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t.dtype}`);let n=0;const s=e.map((e=>(n+=e,n)));if(n!==t.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${n}, and tensor's shape is: ${t.shape}`);if(!this.dynamicSize&&e.length!==this.maxSize)throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${e.length}), and the TensorArray is not marked as dynamically resizeable`);const r=0===n?0:t.size/n,a=[];YV((()=>{t=CB(t,[1,n,r]);for(let n=0;n<e.length;++n){const i=[0,0===n?0:s[n-1],0],o=[1,e[n],r];a[n]=CB(MB(t,i,o),this.elementShape)}return a}));const i=[];for(let t=0;t<e.length;t++)i[t]=t;this.writeMany(i,a)}}class cH{constructor(e,t,n,s=-1){this.tensors=e,this.elementShape=t,this.elementDtype=n,null!=e&&e.forEach((e=>{if(n!==e.dtype)throw new Error(`Invalid data types; op elements ${n}, but list elements ${e.dtype}`);aH(t,e.shape,"TensorList shape mismatch: "),JV(e)})),this.idTensor=AP(0),this.maxNumElements=s,JV(this.idTensor)}get id(){return this.idTensor.id}copy(){return new cH([...this.tensors],this.elementShape,this.elementDtype)}clearAndClose(e){this.tensors.forEach((t=>{null!=e&&e.has(t.id)||t.dispose()})),this.tensors.length=0,this.idTensor.dispose()}size(){return this.tensors.length}stack(e,t,n=-1){if(t!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);if(-1!==n&&this.tensors.length!==n)throw new Error(`Operation expected a list with ${n} elements but got a list with ${this.tensors.length} elements.`);aH(e,this.elementShape,"TensorList shape mismatch: ");const s=oH(this.elementShape,this.tensors,e);return YV((()=>{const e=this.tensors.map((e=>CB(e,s)));return AV(e,0)}))}popBack(e,t){if(t!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);if(0===this.size())throw new Error("Trying to pop from an empty list.");const n=oH(this.elementShape,this.tensors,e),s=this.tensors.pop();return s.kept=!1,aH(s.shape,e,"TensorList shape mismatch: "),CB(s,n)}pushBack(e){if(e.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e.dtype}, but list elements ${this.elementDtype}`);if(aH(e.shape,this.elementShape,"TensorList shape mismatch: "),this.maxNumElements===this.size())throw new Error("Trying to push element into a full list.");JV(e),this.tensors.push(e)}resize(e){if(e<0)throw new Error(`TensorListResize expects size to be non-negative. Got: ${e}`);if(-1!==this.maxNumElements&&e>this.maxNumElements)throw new Error(`TensorListResize input size ${e} is greater maxNumElement ${this.maxNumElements}.`);const t=new cH([],this.elementShape,this.elementDtype,this.maxNumElements);t.tensors.length=e;for(let n=0;n<Math.min(this.tensors.length,e);++n)t.tensors[n]=this.tensors[n];return t}getItem(e,t,n){if(n!==this.elementDtype)throw new Error(`Invalid data types; op elements ${n}, but list elements ${this.elementDtype}`);if(e<0||e>this.tensors.length)throw new Error(`Trying to access element ${e} in a list with ${this.tensors.length} elements.`);if(null==this.tensors[e])throw new Error(`element at index ${e} is null.`);aH(this.tensors[e].shape,t,"TensorList shape mismatch: ");const s=oH(this.elementShape,this.tensors,t);return CB(this.tensors[e],s)}setItem(e,t){if(t.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t.dtype}, but list elements ${this.elementDtype}`);if(e<0||-1!==this.maxNumElements&&e>=this.maxNumElements)throw new Error(`Trying to set element ${e} in a list with max ${this.maxNumElements} elements.`);aH(this.elementShape,t.shape,"TensorList shape mismatch: "),JV(t),null!=this.tensors[e]&&(this.tensors[e].kept=!1),this.tensors[e]=t}gather(e,t,n){if(t!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);aH(this.elementShape,n,"TensorList shape mismatch: "),e=e.slice(0,this.size());const s=oH(this.elementShape,this.tensors,n);return 0===e.length?PL([],[0].concat(s)):YV((()=>{const t=e.map((e=>CB(this.tensors[e],s)));return AV(t,0)}))}concat(e,t){if(e&&e!==this.elementDtype)throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${e}`);aH(this.elementShape,t,"TensorList shape mismatch: ");const n=oH(this.elementShape,this.tensors,t);return 0===this.size()?PL([],[0].concat(n)):YV((()=>{const e=this.tensors.map((e=>CB(e,n)));return _B(e,0)}))}}function hH(e,t,n){const[s,r]=yG("fusedOps",e,t,n),a="biasadd"===s,i=!a,o="prelu"===r,l="fusedbatchnorm"===s,u=yG("numArgs",e,t,n);if(a){if(o&&2!==u)throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");if(!o&&a&&1!==u)throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.")}if(l)throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported");const c=yG("strides",e,t,n),h=vG(e,t,n),p=yG("dataFormat",e,t,n).toUpperCase(),d=yG("dilations",e,t,n);let[f,m]=yG("args",e,t,n);return i&&(m=f,f=void 0),{stride:c,pad:h,dataFormat:p,dilations:d,biasArg:f,preluArg:m,activationFunc:r,leakyreluAlpha:yG("leakyreluAlpha",e,t,n)}}function pH(e,t,n){return{boxes:yG("boxes",e,t,n),scores:yG("scores",e,t,n),maxOutputSize:yG("maxOutputSize",e,t,n),iouThreshold:yG("iouThreshold",e,t,n),scoreThreshold:yG("scoreThreshold",e,t,n),softNmsSigma:yG("softNmsSigma",e,t,n)}}class dH{constructor(e,t){this.keyDType=e,this.valueDType=t,this.handle=AP(0),this.tensorMap=new Map,JV(this.handle)}get id(){return this.handle.id}clearAndClose(){this.tensorMap.forEach((e=>e.dispose())),this.tensorMap.clear(),this.handle.dispose()}size(){return this.tensorMap.size}tensorSize(){return AP(this.size(),"int32")}async import(e,t){this.checkKeyAndValueTensor(e,t);const n=await e.data();return this.tensorMap.forEach((e=>e.dispose())),this.tensorMap.clear(),YV((()=>{const e=HV(t),s=n.length,r=e.length;aM(s===r,(()=>`The number of elements doesn't match, keys has ${s} elements, the values has ${r} elements.`));for(let t=0;t<s;t++){const s=n[t],r=e[t];JV(r),this.tensorMap.set(s,r)}return this.handle}))}async find(e,t){this.checkKeyAndValueTensor(e,t);const n=await e.data();return YV((()=>{const e=[];for(let s=0;s<n.length;s++){const r=n[s],a=this.findWithDefault(r,t);e.push(a)}return AV(e)}))}findWithDefault(e,t){const n=this.tensorMap.get(e);return null!=n?n:t}checkKeyAndValueTensor(e,t){if(e.dtype!==this.keyDType)throw new Error(`Expect key dtype ${this.keyDType}, but got ${e.dtype}`);if(t.dtype!==this.valueDType)throw new Error(`Expect value dtype ${this.valueDType}, but got ${t.dtype}`)}}function fH(e,t,n,s,r=YV){const a=((e,t,n)=>{switch(e.category){case"arithmetic":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"BiasAdd":case"AddV2":case"Add":return[s.add(yG("a",e,t,n),yG("b",e,t,n))];case"AddN":return[s.addN(yG("tensors",e,t,n))];case"FloorMod":case"Mod":return[s.mod(yG("a",e,t,n),yG("b",e,t,n))];case"Mul":return[s.mul(yG("a",e,t,n),yG("b",e,t,n))];case"RealDiv":case"Div":return[s.div(yG("a",e,t,n),yG("b",e,t,n))];case"DivNoNan":return[s.divNoNan(yG("a",e,t,n),yG("b",e,t,n))];case"FloorDiv":return[s.floorDiv(yG("a",e,t,n),yG("b",e,t,n))];case"Sub":return[s.sub(yG("a",e,t,n),yG("b",e,t,n))];case"Minimum":return[s.minimum(yG("a",e,t,n),yG("b",e,t,n))];case"Maximum":return[s.maximum(yG("a",e,t,n),yG("b",e,t,n))];case"Pow":return[s.pow(yG("a",e,t,n),yG("b",e,t,n))];case"SquaredDifference":return[s.squaredDifference(yG("a",e,t,n),yG("b",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"basic_math":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"Abs":case"ComplexAbs":return[s.abs(yG("x",e,t,n))];case"Acos":return[s.acos(yG("x",e,t,n))];case"Acosh":return[s.acosh(yG("x",e,t,n))];case"Asin":return[s.asin(yG("x",e,t,n))];case"Asinh":return[s.asinh(yG("x",e,t,n))];case"Atan":return[s.atan(yG("x",e,t,n))];case"Atan2":return[s.atan2(yG("x",e,t,n),yG("y",e,t,n))];case"Atanh":return[s.atanh(yG("x",e,t,n))];case"Ceil":return[s.ceil(yG("x",e,t,n))];case"Complex":return[s.complex(yG("real",e,t,n),yG("imag",e,t,n))];case"Cos":return[s.cos(yG("x",e,t,n))];case"Cosh":return[s.cosh(yG("x",e,t,n))];case"Elu":return[s.elu(yG("x",e,t,n))];case"Erf":return[s.erf(yG("x",e,t,n))];case"Exp":return[s.exp(yG("x",e,t,n))];case"Expm1":return[s.expm1(yG("x",e,t,n))];case"Floor":return[s.floor(yG("x",e,t,n))];case"Log":return[s.log(yG("x",e,t,n))];case"Log1p":return[s.log1p(yG("x",e,t,n))];case"Imag":return[s.imag(yG("x",e,t,n))];case"Neg":return[s.neg(yG("x",e,t,n))];case"Reciprocal":return[s.reciprocal(yG("x",e,t,n))];case"Real":return[s.real(yG("x",e,t,n))];case"Relu":return[s.relu(yG("x",e,t,n))];case"Round":return[s.round(yG("x",e,t,n))];case"Selu":return[s.selu(yG("x",e,t,n))];case"Sigmoid":return[s.sigmoid(yG("x",e,t,n))];case"Sin":return[s.sin(yG("x",e,t,n))];case"Sign":return[s.sign(yG("x",e,t,n))];case"Sinh":return[s.sinh(yG("x",e,t,n))];case"Softplus":return[s.softplus(yG("x",e,t,n))];case"Sqrt":return[s.sqrt(yG("x",e,t,n))];case"Square":return[s.square(yG("x",e,t,n))];case"Tanh":return[s.tanh(yG("x",e,t,n))];case"Tan":return[s.tan(yG("x",e,t,n))];case"ClipByValue":return[s.clipByValue(yG("x",e,t,n),yG("clipValueMin",e,t,n),yG("clipValueMax",e,t,n))];case"Relu6":return[s.relu6(yG("x",e,t,n))];case"Rsqrt":return[s.rsqrt(bG(e.inputNames[0],t,n))];case"Prod":return[s.prod(yG("x",e,t,n),yG("axes",e,t,n))];case"LeakyRelu":return[s.leakyRelu(yG("x",e,t,n),yG("alpha",e,t,n))];case"Prelu":return[s.prelu(yG("x",e,t,n),yG("alpha",e,t,n))];case"IsNan":return[s.isNaN(bG(e.inputNames[0],t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"control":return(async(e,t,n)=>{switch(e.op){case"If":case"StatelessIf":{const s=yG("thenBranch",e,t,n),r=yG("elseBranch",e,t,n),a=yG("cond",e,t,n),i=yG("args",e,t,n);return(await a.data())[0]?n.functionMap[s].executeFunctionAsync(i,n.tensorArrayMap,n.tensorListMap):n.functionMap[r].executeFunctionAsync(i,n.tensorArrayMap,n.tensorListMap)}case"While":case"StatelessWhile":{const s=yG("body",e,t,n),r=yG("cond",e,t,n),a=yG("args",e,t,n),i=await n.functionMap[r].executeFunctionAsync(a,n.tensorArrayMap,n.tensorListMap),o=a.map((e=>e.id));let l=await i[0].data();i.forEach((e=>{e.kept||-1!==o.indexOf(e.id)||e.dispose()}));let u=a;for(;l[0];){const e=u;u=await n.functionMap[s].executeFunctionAsync(u,n.tensorArrayMap,n.tensorListMap);const t=u.map((e=>e.id));e.forEach((e=>{e.kept||-1!==o.indexOf(e.id)||-1!==t.indexOf(e.id)||e.dispose()}));const a=await n.functionMap[r].executeFunctionAsync(u,n.tensorArrayMap,n.tensorListMap);l=await a[0].data(),a.forEach((e=>{e.kept||-1!==o.indexOf(e.id)||-1!==t.indexOf(e.id)||e.dispose()}))}return u}case"LoopCond":return[IG(yG("pred",e,t,n))];case"Switch":{const s=yG("pred",e,t,n);let r=yG("data",e,t,n);return r.kept||(r=IG(r)),(await s.data())[0]?[void 0,r]:[r,void 0]}case"Merge":{const s=e.inputNames.find((e=>void 0!==bG(e,t,n)));return s?[IG(bG(s,t,n))]:void 0}case"Enter":{const s=yG("frameName",e,t,n),r=yG("tensor",e,t,n);return n.enterFrame(s),[IG(r)]}case"Exit":{const s=yG("tensor",e,t,n);return n.exitFrame(),[IG(s)]}case"NextIteration":{const s=yG("tensor",e,t,n);return n.nextIteration(),[IG(s)]}case"TensorArrayV3":{const s=yG("size",e,t,n),r=yG("dtype",e,t,n),a=yG("elementShape",e,t,n),i=yG("dynamicSize",e,t,n),o=yG("clearAfterRead",e,t,n),l=yG("identicalElementShapes",e,t,n),u=yG("name",e,t,n),c=new uH(u,r,s,a,l,i,o);return n.addTensorArray(c),[c.idTensor,AP(1)]}case"TensorArrayWriteV3":{const s=yG("tensorArrayId",e,t,n),r=yG("index",e,t,n),a=yG("tensor",e,t,n),i=n.getTensorArray(s.id);return i.write(r,a),[i.idTensor]}case"TensorArrayReadV3":{const s=yG("tensorArrayId",e,t,n),r=yG("index",e,t,n);return[n.getTensorArray(s.id).read(r)]}case"TensorArrayGatherV3":{const s=yG("tensorArrayId",e,t,n),r=yG("indices",e,t,n),a=yG("dtype",e,t,n);return[n.getTensorArray(s.id).gather(r,a)]}case"TensorArrayScatterV3":{const s=yG("tensorArrayId",e,t,n),r=yG("indices",e,t,n),a=yG("tensor",e,t,n),i=n.getTensorArray(s.id);return i.scatter(r,a),[i.idTensor]}case"TensorArrayConcatV3":{const s=yG("tensorArrayId",e,t,n),r=n.getTensorArray(s.id),a=yG("dtype",e,t,n);return[r.concat(a)]}case"TensorArraySplitV3":{const s=yG("tensorArrayId",e,t,n),r=yG("tensor",e,t,n),a=yG("lengths",e,t,n),i=n.getTensorArray(s.id);return i.split(a,r),[i.idTensor]}case"TensorArraySizeV3":{const s=yG("tensorArrayId",e,t,n);return[AP(n.getTensorArray(s.id).size(),"int32")]}case"TensorArrayCloseV3":{const s=yG("tensorArrayId",e,t,n),r=n.getTensorArray(s.id);return r.clearAndClose(),[r.idTensor]}case"TensorListSetItem":{const s=yG("tensorListId",e,t,n),r=yG("index",e,t,n),a=yG("tensor",e,t,n),i=n.getTensorList(s.id);return i.setItem(r,a),[i.idTensor]}case"TensorListGetItem":{const s=yG("tensorListId",e,t,n),r=yG("index",e,t,n),a=yG("elementShape",e,t,n),i=yG("elementDType",e,t,n);return[n.getTensorList(s.id).getItem(r,a,i)]}case"TensorListScatterV2":case"TensorListScatter":{const s=yG("indices",e,t,n),r=function(e,t,n,s){if(t.length!==e.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${t.length} vs. ${e.shape[0]}`);const r=Math.max(...t);if(null!=s&&-1!==s&&r>=s)throw new Error(`Max index must be < array size (${r}  vs. ${s})`);const a=new cH([],n,e.dtype,s),i=HV(e,0);return t.forEach(((e,t)=>{a.setItem(e,i[t])})),a}(yG("tensor",e,t,n),s,yG("elementShape",e,t,n),yG("numElements",e,t,n));return n.addTensorList(r),[r.idTensor]}case"TensorListReserve":case"EmptyTensorList":{const s=yG("elementShape",e,t,n),r=yG("elementDType",e,t,n);let a;a="TensorListReserve"===e.op?"numElements":"maxNumElements";const i=yG(a,e,t,n),o=function(e,t,n,s){return new cH([],e,t,s)}(s,r,0,"TensorListReserve"===e.op?-1:i);return n.addTensorList(o),[o.idTensor]}case"TensorListGather":{const s=yG("tensorListId",e,t,n),r=yG("indices",e,t,n),a=yG("elementShape",e,t,n),i=yG("elementDType",e,t,n);return[n.getTensorList(s.id).gather(r,i,a)]}case"TensorListStack":{const s=yG("tensorListId",e,t,n),r=yG("elementShape",e,t,n),a=yG("elementDType",e,t,n),i=yG("numElements",e,t,n);return[n.getTensorList(s.id).stack(r,a,i)]}case"TensorListFromTensor":{const s=function(e,t,n){const s=e.dtype;if(e.shape.length<1)throw new Error(`Tensor must be at least a vector, but saw shape: ${e.shape}`);if(e.dtype!==n)throw new Error(`Invalid data types; op elements ${e.dtype}, but list elements ${n}`);aH(e.shape.slice(1),t,"TensorList shape mismatch: ");const r=HV(e);return new cH(r,t,s)}(yG("tensor",e,t,n),yG("elementShape",e,t,n),yG("elementDType",e,t,n));return n.addTensorList(s),[s.idTensor]}case"TensorListConcat":case"TensorListConcatV2":{const s=yG("tensorListId",e,t,n),r=n.getTensorList(s.id),a=yG("dtype",e,t,n),i=yG("elementShape",e,t,n);return[r.concat(a,i)]}case"TensorListPushBack":{const s=yG("tensorListId",e,t,n),r=yG("tensor",e,t,n),a=n.getTensorList(s.id);return a.pushBack(r),[a.idTensor]}case"TensorListPopBack":{const s=yG("tensorListId",e,t,n),r=yG("elementShape",e,t,n),a=yG("elementDType",e,t,n);return[n.getTensorList(s.id).popBack(r,a)]}case"TensorListSplit":{const s=yG("tensor",e,t,n),r=yG("elementShape",e,t,n),a=function(e,t,n){let s=0;const r=t.map((e=>(s+=e,s)));if(s!==e.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${s}, and tensor's shape is: ${e.shape}`);const a=lH(e.shape.slice(1),n),i=0===s?0:e.size/s,o=YV((()=>{const n=[];e=CB(e,[1,s,i]);for(let s=0;s<t.length;++s){const o=[0,0===s?0:r[s-1],0],l=[1,t[s],i];n[s]=CB(MB(e,o,l),a)}return e.dispose(),n})),l=new cH([],n,e.dtype,t.length);for(let e=0;e<o.length;e++)l.setItem(e,o[e]);return l}(s,yG("lengths",e,t,n),r);return n.addTensorList(a),[a.idTensor]}case"TensorListLength":{const s=yG("tensorListId",e,t,n);return[AP(n.getTensorList(s.id).size(),"int32")]}case"TensorListResize":{const s=yG("tensorListId",e,t,n),r=yG("size",e,t,n),a=n.getTensorList(s.id).resize(r);return n.addTensorList(a),[a.idTensor]}default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n);case"convolution":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"Conv1D":{const r=yG("stride",e,t,n),a=yG("pad",e,t,n),i=yG("dataFormat",e,t,n).toUpperCase(),o=yG("dilation",e,t,n);return[s.conv1d(yG("x",e,t,n),yG("filter",e,t,n),r,a,i,o)]}case"Conv2D":{const r=yG("strides",e,t,n),a=vG(e,t,n),i=yG("dataFormat",e,t,n).toUpperCase(),o=yG("dilations",e,t,n);return[s.conv2d(yG("x",e,t,n),yG("filter",e,t,n),[r[1],r[2]],a,i,[o[1],o[2]])]}case"_FusedConv2D":{const{stride:r,pad:a,dataFormat:i,dilations:o,biasArg:l,preluArg:u,activationFunc:c,leakyreluAlpha:h}=hH(e,t,n);return[s.fused.conv2d({x:yG("x",e,t,n),filter:yG("filter",e,t,n),strides:[r[1],r[2]],pad:a,dataFormat:i,dilations:[o[1],o[2]],bias:l,activation:c,preluActivationWeights:u,leakyreluAlpha:h})]}case"FusedDepthwiseConv2dNative":{const{stride:r,pad:a,dataFormat:i,dilations:o,biasArg:l,preluArg:u,activationFunc:c,leakyreluAlpha:h}=hH(e,t,n);return[s.fused.depthwiseConv2d({x:yG("x",e,t,n),filter:yG("filter",e,t,n),strides:[r[1],r[2]],pad:a,dataFormat:i,dilations:[o[1],o[2]],bias:l,activation:c,preluActivationWeights:u,leakyreluAlpha:h})]}case"Conv2DBackpropInput":case"Conv2dTranspose":{const r=yG("outputShape",e,t,n),a=yG("strides",e,t,n),i=vG(e,t,n);return[s.conv2dTranspose(yG("x",e,t,n),yG("filter",e,t,n),r,[a[1],a[2]],i)]}case"DepthwiseConv2dNative":case"DepthwiseConv2d":{const r=yG("strides",e,t,n),a=vG(e,t,n),i=yG("dilations",e,t,n),o=yG("dataFormat",e,t,n).toUpperCase();return[s.depthwiseConv2d(yG("input",e,t,n),yG("filter",e,t,n),[r[1],r[2]],a,o,[i[1],i[2]])]}case"Conv3D":{const r=yG("strides",e,t,n),a=yG("pad",e,t,n),i=yG("dataFormat",e,t,n).toUpperCase(),o=yG("dilations",e,t,n);return[s.conv3d(yG("x",e,t,n),yG("filter",e,t,n),[r[1],r[2],r[3]],a,i,[o[1],o[2],o[3]])]}case"AvgPool":{const r=yG("strides",e,t,n),a=yG("pad",e,t,n),i=yG("kernelSize",e,t,n);return[s.avgPool(yG("x",e,t,n),[i[1],i[2]],[r[1],r[2]],a)]}case"MaxPool":{const r=yG("strides",e,t,n),a=yG("pad",e,t,n),i=yG("kernelSize",e,t,n);return[s.maxPool(yG("x",e,t,n),[i[1],i[2]],[r[1],r[2]],a)]}case"MaxPoolWithArgmax":{const r=yG("strides",e,t,n),a=yG("pad",e,t,n),i=yG("kernelSize",e,t,n),o=yG("includeBatchInIndex",e,t,n),{result:l,indexes:u}=s.maxPoolWithArgmax(yG("x",e,t,n),[i[1],i[2]],[r[1],r[2]],a,o);return[l,u]}case"AvgPool3D":{const r=yG("strides",e,t,n),a=yG("pad",e,t,n),i=yG("kernelSize",e,t,n);return[s.avgPool3d(yG("x",e,t,n),[i[1],i[2],i[3]],[r[1],r[2],r[3]],a)]}case"MaxPool3D":{const r=yG("strides",e,t,n),a=yG("pad",e,t,n),i=yG("kernelSize",e,t,n);return[s.maxPool3d(yG("x",e,t,n),[i[1],i[2],i[3]],[r[1],r[2],r[3]],a)]}case"Dilation2D":{const r=yG("strides",e,t,n),a=yG("pad",e,t,n),i=yG("dilations",e,t,n),o=r[1],l=r[2],u=i[1],c=i[2];return[s.dilation2d(yG("x",e,t,n),yG("filter",e,t,n),[o,l],a,[u,c],"NHWC")]}default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"creation":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"Fill":{const r=yG("shape",e,t,n),a=yG("dtype",e,t,n),i=yG("value",e,t,n);return[s.fill(r,i,a)]}case"LinSpace":{const r=yG("start",e,t,n),a=yG("stop",e,t,n),i=yG("num",e,t,n);return[s.linspace(r,a,i)]}case"Multinomial":{const r=yG("logits",e,t,n),a=yG("numSamples",e,t,n),i=yG("seed",e,t,n);return[s.multinomial(r,a,i)]}case"OneHot":{const r=yG("indices",e,t,n),a=yG("depth",e,t,n),i=yG("onValue",e,t,n),o=yG("offValue",e,t,n),l=yG("dtype",e,t,n);return[s.oneHot(r,a,i,o,l)]}case"Ones":return[s.ones(yG("shape",e,t,n),yG("dtype",e,t,n))];case"OnesLike":return[s.onesLike(yG("x",e,t,n))];case"RandomStandardNormal":return[s.randomStandardNormal(yG("shape",e,t,n),yG("dtype",e,t,n),yG("seed",e,t,n))];case"RandomUniform":return[s.randomUniform(yG("shape",e,t,n),yG("minval",e,t,n),yG("maxval",e,t,n),yG("dtype",e,t,n))];case"Range":{const r=yG("start",e,t,n),a=yG("stop",e,t,n),i=yG("step",e,t,n);return[s.range(r,a,i,yG("dtype",e,t,n))]}case"TruncatedNormal":{const r=yG("shape",e,t,n),a=yG("mean",e,t,n),i=yG("stdDev",e,t,n),o=yG("seed",e,t,n);return[s.truncatedNormal(r,a,i,yG("dtype",e,t,n),o)]}case"Zeros":return[s.zeros(yG("shape",e,t,n),yG("dtype",e,t,n))];case"ZerosLike":return[s.zerosLike(yG("x",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"dynamic":return(async(e,t,n,s,r=T)=>{switch(e.op){case"NonMaxSuppressionV5":{const{boxes:s,scores:a,maxOutputSize:i,iouThreshold:o,scoreThreshold:l,softNmsSigma:u}=pH(e,t,n),c=await r.image.nonMaxSuppressionWithScoreAsync(s,a,i,o,l,u);return[c.selectedIndices,c.selectedScores]}case"NonMaxSuppressionV4":{const{boxes:s,scores:a,maxOutputSize:i,iouThreshold:o,scoreThreshold:l}=pH(e,t,n),u=yG("padToMaxOutputSize",e,t,n),c=await r.image.nonMaxSuppressionPaddedAsync(s,a,i,o,l,u);return[c.selectedIndices,c.validOutputs]}case"NonMaxSuppressionV3":case"NonMaxSuppressionV2":{const{boxes:s,scores:a,maxOutputSize:i,iouThreshold:o,scoreThreshold:l}=pH(e,t,n);return[await r.image.nonMaxSuppressionAsync(s,a,i,o,l)]}case"Where":{const s=r.cast(yG("condition",e,t,n),"bool"),a=[await r.whereAsync(s)];return s.dispose(),a}case"ListDiff":return r.setdiff1dAsync(yG("x",e,t,n),yG("y",e,t,n));default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n);case"evaluation":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"LowerBound":{const r=yG("sortedSequence",e,t,n),a=yG("values",e,t,n);return[s.lowerBound(r,a)]}case"TopKV2":{const r=yG("x",e,t,n),a=yG("k",e,t,n),i=yG("sorted",e,t,n),o=s.topk(r,a,i);return[o.values,o.indices]}case"UpperBound":{const r=yG("sortedSequence",e,t,n),a=yG("values",e,t,n);return[s.upperBound(r,a)]}case"Unique":{const r=yG("x",e,t,n),a=s.unique(r);return[a.values,a.indices]}case"UniqueV2":{const r=yG("x",e,t,n),a=yG("axis",e,t,n),i=s.unique(r,a);return[i.values,i.indices]}default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"image":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"ResizeBilinear":{const r=yG("images",e,t,n),a=yG("size",e,t,n),i=yG("alignCorners",e,t,n),o=yG("halfPixelCenters",e,t,n);return[s.image.resizeBilinear(r,[a[0],a[1]],i,o)]}case"ResizeNearestNeighbor":{const r=yG("images",e,t,n),a=yG("size",e,t,n),i=yG("alignCorners",e,t,n),o=yG("halfPixelCenters",e,t,n);return[s.image.resizeNearestNeighbor(r,[a[0],a[1]],i,o)]}case"CropAndResize":{const r=yG("image",e,t,n),a=yG("boxes",e,t,n),i=yG("boxInd",e,t,n),o=yG("cropSize",e,t,n),l=yG("method",e,t,n),u=yG("extrapolationValue",e,t,n);return[s.image.cropAndResize(r,a,i,o,l,u)]}case"ImageProjectiveTransformV3":{const r=yG("images",e,t,n),a=yG("transforms",e,t,n),i=yG("outputShape",e,t,n),o=yG("fillValue",e,t,n),l=yG("interpolation",e,t,n),u=yG("fillMode",e,t,n);return[s.image.transform(r,a,l.toLowerCase(),u.toLowerCase(),o,i)]}default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"graph":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"Const":return t[e.name];case"PlaceholderWithDefault":const r=yG("default",e,t,n);return[bG(e.name,t,n)||r];case"Placeholder":return[bG(e.name,t,n)];case"Identity":case"StopGradient":case"FakeQuantWithMinMaxVars":case"Snapshot":return[IG(yG("x",e,t,n))];case"IdentityN":return yG("x",e,t,n).map((e=>IG(e)));case"Shape":return[s.tensor1d(yG("x",e,t,n).shape,"int32")];case"ShapeN":return yG("x",e,t,n).map((e=>s.tensor1d(e.shape)));case"Size":return[s.scalar(yG("x",e,t,n).size,"int32")];case"Rank":return[s.scalar(yG("x",e,t,n).rank,"int32")];case"NoOp":return[s.scalar(1)];case"Print":const a=yG("x",e,t,n),i=yG("data",e,t,n),o=yG("message",e,t,n),l=yG("summarize",e,t,n);console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance."),console.log(o);for(let e=0;e<i.length;e++)console.log(Array.prototype.slice.call(i[e].dataSync()).slice(0,l));return[a];default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"logical":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"Equal":return[s.equal(yG("a",e,t,n),yG("b",e,t,n))];case"NotEqual":return[s.notEqual(yG("a",e,t,n),yG("b",e,t,n))];case"Greater":return[s.greater(yG("a",e,t,n),yG("b",e,t,n))];case"GreaterEqual":return[s.greaterEqual(yG("a",e,t,n),yG("b",e,t,n))];case"Less":return[s.less(yG("a",e,t,n),yG("b",e,t,n))];case"LessEqual":return[s.lessEqual(yG("a",e,t,n),yG("b",e,t,n))];case"LogicalAnd":return[s.logicalAnd(yG("a",e,t,n),yG("b",e,t,n))];case"LogicalNot":return[s.logicalNot(yG("a",e,t,n))];case"LogicalOr":return[s.logicalOr(yG("a",e,t,n),yG("b",e,t,n))];case"Select":case"SelectV2":return[s.where(yG("condition",e,t,n),yG("a",e,t,n),yG("b",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"matrices":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"BatchMatMul":case"BatchMatMulV2":case"MatMul":return[s.matMul(yG("a",e,t,n),yG("b",e,t,n),yG("transposeA",e,t,n),yG("transposeB",e,t,n))];case"Einsum":return[s.einsum(yG("equation",e,t,n),...yG("tensors",e,t,n))];case"Transpose":return[s.transpose(yG("x",e,t,n),yG("perm",e,t,n))];case"_FusedMatMul":const[r,a]=yG("fusedOps",e,t,n),i="biasadd"===r,o="prelu"===a,l=yG("numArgs",e,t,n),u=yG("leakyreluAlpha",e,t,n);if(i){if(o&&2!==l)throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");if(!o&&1!==l)throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.")}const[c,h]=yG("args",e,t,n);return[s.fused.matMul({a:yG("a",e,t,n),b:yG("b",e,t,n),transposeA:yG("transposeA",e,t,n),transposeB:yG("transposeB",e,t,n),bias:c,activation:a,preluActivationWeights:h,leakyreluAlpha:u})];default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"normalization":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"EuclideanNorm":return[s.euclideanNorm(yG("x",e,t,n),yG("axis",e,t,n),yG("keepDims",e,t,n))];case"FusedBatchNorm":case"FusedBatchNormV2":case"FusedBatchNormV3":return[s.batchNorm(yG("x",e,t,n),yG("mean",e,t,n),yG("variance",e,t,n),yG("offset",e,t,n),yG("scale",e,t,n),yG("epsilon",e,t,n))];case"LRN":return[s.localResponseNormalization(yG("x",e,t,n),yG("radius",e,t,n),yG("bias",e,t,n),yG("alpha",e,t,n),yG("beta",e,t,n))];case"Softmax":return[s.softmax(yG("x",e,t,n))];case"LogSoftmax":return[s.logSoftmax(yG("x",e,t,n))];case"SparseToDense":return[s.sparseToDense(yG("sparseIndices",e,t,n),yG("outputShape",e,t,n),yG("sparseValues",e,t,n),yG("defaultValue",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"reduction":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"Max":{const r=yG("axis",e,t,n),a=yG("keepDims",e,t,n);return[s.max(yG("x",e,t,n),r,a)]}case"Mean":{const r=yG("axis",e,t,n),a=yG("keepDims",e,t,n);return[s.mean(yG("x",e,t,n),r,a)]}case"Min":{const r=yG("axis",e,t,n),a=yG("keepDims",e,t,n);return[s.min(yG("x",e,t,n),r,a)]}case"Sum":{const r=yG("axis",e,t,n),a=yG("keepDims",e,t,n);return[s.sum(yG("x",e,t,n),r,a)]}case"All":{const r=yG("axis",e,t,n),a=yG("keepDims",e,t,n);return[s.all(yG("x",e,t,n),r,a)]}case"Any":{const r=yG("axis",e,t,n),a=yG("keepDims",e,t,n);return[s.any(yG("x",e,t,n),r,a)]}case"ArgMax":{const r=yG("axis",e,t,n);return[s.argMax(yG("x",e,t,n),r)]}case"ArgMin":{const r=yG("axis",e,t,n);return[s.argMin(yG("x",e,t,n),r)]}case"Prod":{const r=yG("axis",e,t,n),a=yG("keepDims",e,t,n);return[s.prod(yG("x",e,t,n),r,a)]}case"Cumprod":{const r=yG("axis",e,t,n),a=yG("exclusive",e,t,n),i=yG("reverse",e,t,n);return[s.cumprod(yG("x",e,t,n),r,a,i)]}case"Cumsum":{const r=yG("axis",e,t,n),a=yG("exclusive",e,t,n),i=yG("reverse",e,t,n);return[s.cumsum(yG("x",e,t,n),r,a,i)]}case"Bincount":const r=yG("x",e,t,n),a=yG("weights",e,t,n),i=yG("size",e,t,n);return[s.bincount(r,a,i)];case"DenseBincount":{const r=yG("x",e,t,n),a=yG("weights",e,t,n),i=yG("size",e,t,n),o=yG("binaryOutput",e,t,n);return[s.denseBincount(r,a,i,o)]}default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"slice_join":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"ConcatV2":case"Concat":{const r=yG("n",e,t,n),a=yG("axis",e,t,n);let i=yG("tensors",e,t,n);return i=i.slice(0,r),[s.concat(i,a)]}case"Gather":{const r=yG("x",e,t,n),a=yG("indices",e,t,n);return[s.gather(r,s.cast(a,"int32"),0)]}case"GatherV2":{const r=yG("axis",e,t,n),a=yG("batchDims",e,t,n),i=yG("x",e,t,n),o=yG("indices",e,t,n);return[s.gather(i,s.cast(o,"int32"),r,a)]}case"Reverse":{const r=yG("dims",e,t,n),a=[];for(let e=0;e<r.length;e++)r[e]&&a.push(e);const i=yG("x",e,t,n);return[s.reverse(i,a)]}case"ReverseV2":{const r=yG("axis",e,t,n),a=yG("x",e,t,n);return[s.reverse(a,r)]}case"Slice":{const r=yG("begin",e,t,n),a=yG("size",e,t,n);return[s.slice(yG("x",e,t,n),r,a)]}case"StridedSlice":{const r=yG("begin",e,t,n),a=yG("end",e,t,n),i=yG("strides",e,t,n),o=yG("beginMask",e,t,n),l=yG("endMask",e,t,n),u=yG("ellipsisMask",e,t,n),c=yG("newAxisMask",e,t,n),h=yG("shrinkAxisMask",e,t,n),p=yG("x",e,t,n);return[s.stridedSlice(p,r,a,i,o,l,u,c,h)]}case"Pack":return YV((()=>{const r=yG("axis",e,t,n),a=yG("tensors",e,t,n),i=a[0].shape,o=s.squeeze(a[0]).shape,l=a.map((e=>{const t=cM(e.shape,i);if(!t&&!cM(s.squeeze(e).shape,o))throw new Error("the input tensors shape does not match");return t?e:s.reshape(e,i)}));return[s.stack(l,r)]}));case"Unpack":{const r=yG("axis",e,t,n),a=yG("tensor",e,t,n);return s.unstack(a,r)}case"Tile":{const r=yG("reps",e,t,n);return[s.tile(yG("x",e,t,n),r)]}case"Split":case"SplitV":{const r=yG("axis",e,t,n),a=yG("numOrSizeSplits",e,t,n),i=yG("x",e,t,n);return s.split(i,a,r)}case"ScatterNd":{const r=yG("indices",e,t,n),a=yG("values",e,t,n),i=yG("shape",e,t,n);return[s.scatterND(r,a,i)]}case"GatherNd":{const r=yG("x",e,t,n),a=yG("indices",e,t,n);return[s.gatherND(r,a)]}case"SparseToDense":{const r=yG("sparseIndices",e,t,n),a=yG("outputShape",e,t,n),i=yG("sparseValues",e,t,n),o=yG("defaultValue",e,t,n);return[s.sparseToDense(r,i,a,i.dtype===o.dtype?o:s.cast(o,i.dtype))]}default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"sparse":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"SparseFillEmptyRows":{const{outputIndices:r,outputValues:a,emptyRowIndicator:i,reverseIndexMap:o}=s.sparse.sparseFillEmptyRows(yG("indices",e,t,n),yG("values",e,t,n),yG("denseShape",e,t,n),yG("defaultValue",e,t,n));return[r,a,i,o]}case"SparseReshape":{const{outputIndices:r,outputShape:a}=s.sparse.sparseReshape(yG("inputIndices",e,t,n),yG("inputShape",e,t,n),yG("newShape",e,t,n));return[r,a]}case"SparseSegmentMean":return[s.sparse.sparseSegmentMean(yG("data",e,t,n),yG("indices",e,t,n),yG("segmentIds",e,t,n))];case"SparseSegmentSum":return[s.sparse.sparseSegmentSum(yG("data",e,t,n),yG("indices",e,t,n),yG("segmentIds",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"spectral":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"FFT":return[s.fft(yG("x",e,t,n))];case"IFFT":return[s.ifft(yG("x",e,t,n))];case"RFFT":return[s.rfft(yG("x",e,t,n))];case"IRFFT":return[s.irfft(yG("x",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"string":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"StringNGrams":{const{nGrams:r,nGramsSplits:a}=s.string.stringNGrams(yG("data",e,t,n),yG("dataSplits",e,t,n),yG("separator",e,t,n),yG("nGramWidths",e,t,n),yG("leftPad",e,t,n),yG("rightPad",e,t,n),yG("padWidth",e,t,n),yG("preserveShortSequences",e,t,n));return[r,a]}case"StringSplit":{const{indices:r,values:a,shape:i}=s.string.stringSplit(yG("input",e,t,n),yG("delimiter",e,t,n),yG("skipEmpty",e,t,n));return[r,a,i]}case"StringToHashBucketFast":return[s.string.stringToHashBucketFast(yG("input",e,t,n),yG("numBuckets",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"transformation":return r((()=>((e,t,n,s=T)=>{switch(e.op){case"Cast":return[s.cast(yG("x",e,t,n),yG("dtype",e,t,n))];case"ExpandDims":{const r=yG("axis",e,t,n);return[s.expandDims(yG("x",e,t,n),r)]}case"Squeeze":{const r=yG("axis",e,t,n);return[s.squeeze(yG("x",e,t,n),r)]}case"Reshape":return[s.reshape(yG("x",e,t,n),yG("shape",e,t,n))];case"MirrorPad":return[s.mirrorPad(yG("x",e,t,n),yG("padding",e,t,n),yG("mode",e,t,n))];case"PadV2":case"Pad":return[s.pad(yG("x",e,t,n),yG("padding",e,t,n),yG("constantValue",e,t,n))];case"SpaceToBatchND":{const r=yG("blockShape",e,t,n),a=yG("paddings",e,t,n);return[s.spaceToBatchND(yG("x",e,t,n),r,a)]}case"BatchToSpaceND":{const r=yG("blockShape",e,t,n),a=yG("crops",e,t,n);return[s.batchToSpaceND(yG("x",e,t,n),r,a)]}case"DepthToSpace":{const r=yG("blockSize",e,t,n),a=yG("dataFormat",e,t,n).toUpperCase();return[s.depthToSpace(yG("x",e,t,n),r,a)]}case"BroadcastTo":return[s.broadcastTo(yG("x",e,t,n),yG("shape",e,t,n))];case"BroadcastArgs":return[s.broadcastArgs(yG("s0",e,t,n),yG("s1",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n)));case"hash_table":return(async(e,t,n,s)=>{switch(e.op){case"HashTable":case"HashTableV2":{const r=yG("keyDType",e,t,n),a=yG("valueDType",e,t,n),i=new dH(r,a);return s.addHashTable(e.name,i),[i.handle]}case"LookupTableImport":case"LookupTableImportV2":{const r=yG("tableHandle",e,t,n,s),a=yG("keys",e,t,n),i=yG("values",e,t,n),o=s.getHashTableById(r.id);return[await o.import(a,i)]}case"LookupTableFind":case"LookupTableFindV2":{const r=yG("tableHandle",e,t,n,s),a=yG("keys",e,t,n),i=yG("defaultValue",e,t,n),o=s.getHashTableById(r.id);return[await o.find(a,i)]}case"LookupTableSize":case"LookupTableSizeV2":{const r=yG("tableHandle",e,t,n,s);return[s.getHashTableById(r.id).tensorSize()]}default:throw TypeError(`Node type ${e.op} is not implemented`)}})(e,t,n,s);case"custom":const a=gG(e.op);if(a&&a.customExecutor)return a.customExecutor(new rH(e,t,n));throw TypeError(`Custom op ${e.op} is not registered.`);default:throw TypeError(`Unknown op '${e.op}'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()`)}})(e,t,n);return SM(a)?a.then((e=>[].concat(e))):[].concat(a)}class mH{constructor(e={},t={},n={},s={}){this.weightMap=e,this.tensorArrayMap=t,this.tensorListMap=n,this.functionMap=s,this.rootContext={id:0,frameName:"",iterationId:0},this.contexts=[this.rootContext],this.lastId=0,this.generateCurrentContextIds()}newFrame(e,t){return{id:e,frameName:t,iterationId:0}}set currentContext(e){this.contexts!==e&&(this.contexts=e,this.generateCurrentContextIds())}get currentContext(){return this.contexts}get currentContextId(){return this._currentContextIds[0]}get currentContextIds(){return this._currentContextIds}generateCurrentContextIds(){const e=[];for(let t=0;t<this.contexts.length-1;t++){const n=this.contexts.slice(0,this.contexts.length-t);e.push(this.contextIdforContexts(n))}e.push(""),this._currentContextIds=e}contextIdforContexts(e){return e?e.map((e=>0===e.id&&0===e.iterationId?"":`${e.frameName}-${e.iterationId}`)).join("/"):""}enterFrame(e){this.contexts&&(this.lastId++,this.contexts=this.contexts.slice(),this.contexts.push(this.newFrame(this.lastId,e)),this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)))}exitFrame(){if(!(this.contexts&&this.contexts.length>1))throw new Error("Cannot exit frame, the context is empty");this.contexts=this.contexts.slice(),this.contexts.splice(-1),this.currentContextIds.shift()}nextIteration(){if(!(this.contexts&&this.contexts.length>0))throw new Error("Cannot increase frame iteration, the context is empty");{this.contexts=this.contexts.slice(),this.lastId++;const e=Object.assign({},this.contexts[this.contexts.length-1]);e.iterationId+=1,e.id=this.lastId,this.contexts.splice(-1,1,e),this._currentContextIds.splice(0,1,this.contextIdforContexts(this.contexts))}}getWeight(e){return this.weightMap[e]}addTensorArray(e){this.tensorArrayMap[e.id]=e}getTensorArray(e){return this.tensorArrayMap[e]}addTensorList(e){this.tensorListMap[e.id]=e}getTensorList(e){return this.tensorListMap[e]}dispose(e){for(const t in this.tensorArrayMap)this.tensorArrayMap[t].clearAndClose(e);for(const t in this.tensorListMap)this.tensorListMap[t].clearAndClose(e)}}function gH(e,t,n,s){const r=new Set,a=[];let i=null,o=null;const l=new Set,u=Object.keys(e).map((e=>kG(e)[0]));let c=[];null!=s&&(c=s.map((e=>kG(e.name)[0])));const h=[...t];for(;h.length>0;){const e=h.pop();(wH(e)||kH(e)||vH(e))&&null==i&&(i=e,o=i.children.map((e=>e.name)).filter((e=>r.has(e)))),r.add(e.name),null==n[e.name]&&-1===u.indexOf(e.name)&&-1===c.indexOf(e.name)&&(0!==e.inputs.length?e.inputs.forEach((e=>{l.has(e.name)||(l.add(e.name),h.push(e))})):a.push(e.name))}return{inputs:e,outputs:t,usedNodes:r,missingInputs:a,dynamicNode:i,syncInputs:o}}const yH=["Switch","Merge","Enter","Exit","NextIteration","StatelessIf","StatelessWhile","if","While"],bH=["NonMaxSuppressionV2","NonMaxSuppressionV3","NonMaxSuppressionV5","Where"],xH=["HashTable","HashTableV2","LookupTableImport","LookupTableImportV2","LookupTableFind","LookupTableFindV2","LookupTableSize","LookupTableSizeV2"];function wH(e){return yH.indexOf(e.op)>=0}function kH(e){return bH.indexOf(e.op)>=0}function vH(e){return xH.indexOf(e.op)>=0}class IH{constructor(e,t){this.graph=e,this.parent=t,this.compiledMap=new Map,this._weightMap={},this.SEPERATOR=",",this._functions={},this._functionExecutorMap={},this.intermediateTensors={},this.keepTensorForDebug=!1,this._outputs=e.outputs,this._inputs=e.inputs,this._initNodes=e.initNodes,this._signature=e.signature,this._functions=e.functions,null!=e.functions&&Object.keys(e.functions).forEach((t=>{this._functionExecutorMap[t]=new IH(e.functions[t],this)}))}get weightIds(){return this.parent?this.parent.weightIds:this._weightIds}get functionExecutorMap(){return this.parent?this.parent.functionExecutorMap:this._functionExecutorMap}get weightMap(){return this.parent?this.parent.weightMap:this._weightMap}set weightMap(e){const t=Object.keys(e).map((t=>e[t].map((e=>e.id))));this._weightIds=[].concat(...t),this._weightMap=e}set resourceManager(e){this._resourceManager=e}get inputs(){return this._inputs.map((e=>({name:e.name,shape:e.attrParams.shape?e.attrParams.shape.value:void 0,dtype:e.attrParams.dtype?e.attrParams.dtype.value:void 0})))}get outputs(){return this._outputs.map((e=>({name:e.name,shape:e.attrParams.shape?e.attrParams.shape.value:void 0,dtype:e.attrParams.dtype?e.attrParams.dtype.value:void 0})))}get inputNodes(){return this._inputs.map((e=>e.signatureKey||e.name))}get outputNodes(){return this._outputs.map((e=>{const t=e.signatureKey||e.name;return e.defaultOutput?`${t}:${e.defaultOutput}`:t}))}get functions(){return Object.keys(this._functions).reduce(((e,t)=>(e[t]=this._functions[t].signature,e)),{})}getCompilationKey(e,t){const n=e.map((e=>e.name)).sort(),s=t.map((e=>e.name)).sort();return n.join(this.SEPERATOR)+"--"+s.join(this.SEPERATOR)}compile(e,t){const n=gH(e,t,this.weightMap,this._initNodes),{missingInputs:s,dynamicNode:r,syncInputs:a}=n;if(null!=r)throw new Error(`This execution contains the node '${r.name}', which has the dynamic op '${r.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${a}]`);if(s.length>0){const n=t.map((e=>e.name)),r=Object.keys(e);throw new Error(`Cannot compute the outputs [${n}] from the provided inputs [${r}]. Missing the following inputs: [${s}]`)}return function(e,t,n){const{usedNodes:s,inputs:r}=n,a=[],i=Object.keys(r).map((e=>kG(e)[0])).map((t=>e.nodes[t])),o=e.initNodes;i.forEach((e=>{s.has(e.name)&&a.push(e)})),e.weights.forEach((e=>{s.has(e.name)&&a.push(e)})),null!=o&&o.forEach((e=>{s.has(e.name)&&a.push(e)}));const l=new Set,u=[];for(;a.length>0;){const e=a.pop();l.add(e.name),t[e.name]||u.push(e),e.children.forEach((e=>{!l.has(e.name)&&s.has(e.name)&&e.inputs.every((e=>l.has(e.name)))&&a.push(e)}))}return u}(this.graph,this.weightMap,n)}execute(e,t){e=this.mapInputs(e);const n=Object.keys(e).sort();this.checkInputs(e),this.checkInputShapeAndType(e),t=this.mapOutputs(t),this.checkOutputs(t);const s=n.map((e=>this.graph.nodes[kG(e)[0]])),r=t.map((e=>kG(e)[0]));let a=r.map((e=>this.graph.nodes[e]));this.resetIntermediateTensors(),0===a.length&&(a=this._outputs);const i=this.getCompilationKey(s,a);let o=this.compiledMap.get(i);null==o&&(o=this.compile(e,a),this.compiledMap.set(i,o));const l={},u={};return YV((()=>{const n=new mH(this.weightMap,l,u,this.functionExecutorMap),s=Object.assign({},this.weightMap);Object.keys(e).forEach((t=>{const[n,r]=kG(t),a=[];a[r]=e[t],s[n]=a}));const a=this.getFrozenTensorIds(s),i={};for(let e=0;e<o.length;e++){const t=o[e];if(!s[t.name]){const e=fH(t,s,n,this._resourceManager);if(SM(e))throw new Error(`The execution of the op '${t.op}' returned a promise. Please use model.executeAsync() instead.`);s[t.name]=e,this.checkTensorForDisposal(t.name,t,s,n,a,r,i)}}return null==this.parent&&n.dispose(a),t.map((e=>bG(e,s,n)))}))}getFrozenTensorIds(e){const t=[].concat.apply([],Object.keys(e).map((t=>e[t])).map((e=>e.map((e=>e.id)))));return new Set(t)}checkTensorForDisposal(e,t,n,s,r,a,i){"control"!==t.category&&-1===a.indexOf(e)&&(n[e].forEach((e=>{null!=e&&(i[e.id]=(i[e.id]||0)+t.children.length)})),t.inputs.forEach((e=>{if("control"!==e.category){const a=function(e,t,n){return t[wG(e,n.currentContextId)]}(e.name,n,s);null!=a&&a.forEach((e=>{if(e&&!e.kept&&!r.has(e.id)){const n=i[e.id];if(1===n){if(this.keepTensorForDebug){const[n,r]=xG(t.name,s);this.intermediateTensors[n]||(this.intermediateTensors[n]=[]),this.intermediateTensors[n][r]=e}else e.dispose();delete i[e.id]}else null!=n&&i[e.id]--}}))}})))}async executeAsync(e,t){return this._executeAsync(e,t)}disposeIntermediateTensors(){this.intermediateTensors&&(Object.keys(this.intermediateTensors).forEach((e=>this.intermediateTensors[e].forEach((e=>e.dispose())))),this.disposeTensorsMap())}disposeTensorsMap(){this.tensorsMap&&Object.keys(this.tensorsMap).forEach((e=>{this.tensorsMap[e].forEach((e=>{!e||e.kept||e.isDisposed||this.keepIds.has(e.id)||e.dispose()}))}))}getIntermediateTensors(){return this.tensorsMap}resetIntermediateTensors(){for(const e in this.intermediateTensors)this.intermediateTensors[e].forEach((e=>e.dispose())),delete this.intermediateTensors[e]}async _executeAsync(e,t,n=!1,s={},r={}){n||(e=this.mapInputs(e),this.checkInputs(e),this.checkInputShapeAndType(e),t=this.mapOutputs(t),this.checkOutputs(t));try{this.keepTensorForDebug=CM().getBool("KEEP_INTERMEDIATE_TENSORS")}catch(e){console.warn(e.message)}this.resetIntermediateTensors();const a=new mH(this.weightMap,s,r,this.functionExecutorMap);this.tensorsMap=await this.executeWithControlFlow(e,a,t,n);const i=t.map((e=>bG(e,this.tensorsMap,a))),o=i.map((e=>e.id)),l=Object.keys(e).map((t=>e[t].id));return this.keepIds=new Set([...o,...l,...this.weightIds]),this.keepTensorForDebug||this.disposeTensorsMap(),null==this.parent&&a.dispose(this.keepIds),i}async executeFunctionAsync(e,t,n){const s=e.reduce(((e,t,n)=>(e[this.inputs[n].name]=t,e)),{});return this._executeAsync(s,this.outputNodes,!0,t,n)}async executeWithControlFlow(e,t,n,s){const r=Object.keys(e),a=r.map((e=>this.graph.nodes[kG(e)[0]])),i=n.map((e=>kG(e)[0]));let o=i.map((e=>this.graph.nodes[e]));0===o.length&&(o=this._outputs);const{usedNodes:l,missingInputs:u,dynamicNode:c,syncInputs:h}=gH(e,o,this.weightMap,this._initNodes),p=[...a,...this.graph.weights,...this._initNodes||[]].map((e=>({node:e,contexts:t.currentContext}))),d=Object.assign({},this.weightMap);Object.keys(e).forEach((t=>{const[n,s]=kG(t),r=[];r[s]=e[t],d[n]=r}));const f={},m=this.getFrozenTensorIds(d),g={};for(;p.length>0;){const e=this.processStack(a,p,t,d,g,m,i,f,l);await Promise.all(e)}null!=c||s||console.warn("This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.");const y=o.filter((e=>!wH(e)&&!bG(e.name,d,t))).map((e=>e.name));if(y.length>0){let e="";throw null!=c&&(e=`Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${h}]`),new Error(`Cannot compute the outputs [${y}] from the provided inputs [${r}]. Consider providing the following inputs: [${u}]. ${e}`)}return d}processStack(e,t,n,s,r,a,i,o,l){const u=[];for(;t.length>0;){const e=t.pop();n.currentContext=e.contexts;let c="";if("Enter"===e.node.op&&yG("isConstant",e.node,s,n)&&([c]=xG(e.node.name,n)),null==s[e.node.name]){const h=fH(e.node,s,n,this._resourceManager);c||([c]=xG(e.node.name,n));const p=n.currentContext;SM(h)?u.push(h.then((u=>(s[c]=u,n.currentContext=p,this.checkTensorForDisposal(c,e.node,s,n,a,i,o),this.processChildNodes(e.node,t,n,s,r,l),u)))):(s[c]=h,this.checkTensorForDisposal(c,e.node,s,n,a,i,o),this.processChildNodes(e.node,t,n,s,r,l))}else this.processChildNodes(e.node,t,n,s,r,l)}return u}processChildNodes(e,t,n,s,r,a){e.children.forEach((e=>{const[i]=xG(e.name,n);!r[i]&&a.has(e.name)&&("Merge"===e.op?e.inputNames.some((e=>!!bG(e,s,n)))&&(r[i]=!0,t.push({contexts:n.currentContext,node:e})):e.inputNames.every((e=>!!bG(e,s,n)))&&(r[i]=!0,t.push({contexts:n.currentContext,node:e})))}))}dispose(){Object.keys(this.weightMap).forEach((e=>this.weightMap[e].forEach((e=>e.dispose()))))}checkInputShapeAndType(e){Object.keys(e).forEach((t=>{const n=e[t],[s]=kG(t),r=this.graph.nodes[s];if(r.attrParams.shape&&r.attrParams.shape.value){const e=r.attrParams.shape.value;aM(e.length===n.shape.length&&n.shape.every(((t,n)=>-1===e[n]||e[n]===t)),(()=>`The shape of dict['${r.name}'] provided in model.execute(dict) must be [${e}], but was [${n.shape}]`))}r.attrParams.dtype&&r.attrParams.dtype.value&&aM(n.dtype===r.attrParams.dtype.value,(()=>`The dtype of dict['${r.name}'] provided in model.execute(dict) must be ${r.attrParams.dtype.value}, but was ${n.dtype}`))}))}mapInputs(e){const t={};for(const n in e)null!=this._signature&&null!=this._signature.inputs&&null!=this._signature.inputs[n]?t[this._signature.inputs[n].name]=e[n]:t[n]=e[n];return t}checkInputs(e){const t=Object.keys(e).filter((e=>{const[t]=kG(e);return null==this.graph.nodes[t]}));if(t.length>0)throw new Error(`The dict provided in model.execute(dict) has keys: [${t}] that are not part of graph`)}mapOutputs(e){return e.map((e=>null!=this._signature&&null!=this._signature.outputs&&null!=this._signature.outputs[e]?this._signature.outputs[e].name:e),{})}checkOutputs(e){e.forEach((e=>{const[t]=kG(e);if(!this.graph.nodes[t])throw new Error(`The output '${e}' is not found in the graph`)}))}}class NH{constructor(e={},t={}){this.hashTableNameToHandle=e,this.hashTableMap=t}addHashTable(e,t){this.hashTableNameToHandle[e]=t.handle,this.hashTableMap[t.id]=t}getHashTableHandleByName(e){return this.hashTableNameToHandle[e]}getHashTableById(e){return this.hashTableMap[e]}dispose(){for(const e in this.hashTableMap)this.hashTableMap[e].clearAndClose(),delete this.hashTableMap[e];for(const e in this.hashTableNameToHandle)this.hashTableNameToHandle[e].dispose(),delete this.hashTableNameToHandle[e]}}class SH{constructor(e,t={},n=a){this.modelUrl=e,this.loadOptions=t,this.version="n/a",this.io=n,null==t&&(this.loadOptions={}),this.resourceManager=new NH}get modelVersion(){return this.version}get inputNodes(){return this.executor.inputNodes}get outputNodes(){return this.executor.outputNodes}get inputs(){return this.executor.inputs}get outputs(){return this.executor.outputs}get weights(){return this.executor.weightMap}get metadata(){return this.artifacts.userDefinedMetadata}get modelSignature(){return this.signature}get modelStructuredOutputKeys(){return this.structuredOutputKeys}findIOHandler(){const e=this.modelUrl;if(null!=e.load)this.handler=e;else if(null!=this.loadOptions.requestInit)this.handler=this.io.browserHTTPRequest(e,this.loadOptions);else{const t=this.io.getLoadHandlers(e,this.loadOptions);if(0===t.length)t.push(this.io.browserHTTPRequest(e,this.loadOptions));else if(t.length>1)throw new Error(`Found more than one (${t.length}) load handlers for URL '${[e]}'`);this.handler=t[0]}}load(){if(this.findIOHandler(),null==this.handler.load)throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const e=this.handler.load();return SM(e)?e.then((e=>this.loadSync(e))):this.loadSync(e)}loadSync(e){this.artifacts=e;const t=this.artifacts.modelTopology;let n=this.artifacts.signature;if(null!=this.artifacts.userDefinedMetadata){const e=this.artifacts.userDefinedMetadata;null!=e.signature&&(n=e.signature),null!=e.structuredOutputKeys&&(this.structuredOutputKeys=e.structuredOutputKeys)}this.signature=n,this.version=`${t.versions.producer}.${t.versions.minConsumer}`;const s=this.io.decodeWeights(this.artifacts.weightData,this.artifacts.weightSpecs);if(this.executor=new IH(UG.Instance.transformGraph(t,this.signature)),this.executor.weightMap=this.convertTensorMapToTensorsMap(s),this.executor.resourceManager=this.resourceManager,null!=e.modelInitializer&&null!=e.modelInitializer.node){const t=UG.Instance.transformGraph(e.modelInitializer);this.initializer=new IH(t),this.initializer.weightMap=this.executor.weightMap,this.initializer.resourceManager=this.resourceManager,this.initializer.executeAsync({},[])}return!0}async save(e,t){if("string"==typeof e){const t=this.io.getSaveHandlers(e);if(0===t.length)throw new Error(`Cannot find any save handlers for URL '${e}'`);if(t.length>1)throw new Error(`Found more than one (${t.length}) save handlers for URL '${e}'`);e=t[0]}if(null==e.save)throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");return e.save(this.artifacts)}predict(e,t){const n=this.execute(e,this.outputNodes);if(this.structuredOutputKeys){const e={};return(n instanceof dL?[n]:n).forEach(((t,n)=>e[this.structuredOutputKeys[n]]=t)),e}return n}normalizeInputs(e){if(!(e instanceof dL||Array.isArray(e)))return e;if((e=Array.isArray(e)?e:[e]).length!==this.inputNodes.length)throw new Error(`Input tensor count mismatch,the graph model has ${this.inputNodes.length} placeholders, while there are ${e.length} input tensors.`);return this.inputNodes.reduce(((t,n,s)=>(t[n]=e[s],t)),{})}normalizeOutputs(e){return e=e||this.outputNodes,Array.isArray(e)?e:[e]}execute(e,t){e=this.normalizeInputs(e),t=this.normalizeOutputs(t);const n=this.executor.execute(e,t);return n.length>1?n:n[0]}async executeAsync(e,t){e=this.normalizeInputs(e),t=this.normalizeOutputs(t);const n=await this.executor.executeAsync(e,t);return n.length>1?n:n[0]}getIntermediateTensors(){return this.executor.getIntermediateTensors()}disposeIntermediateTensors(){this.executor.disposeIntermediateTensors()}convertTensorMapToTensorsMap(e){return Object.keys(e).reduce(((t,n)=>(t[n]=[e[n]],t)),{})}dispose(){this.executor.dispose(),this.initializer&&this.initializer.dispose(),this.resourceManager.dispose()}}async function TH(e,t={},n=a){if(null==e)throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");null==t&&(t={}),t.fromTFHub&&"string"==typeof e&&(e=function(e){return e.endsWith("/")||(e+="/"),`${e}model.json?tfjs-format=file`}(e));const s=new SH(e,t,n);return await s.load(),s}function $H(e,t,n,s){return new(n||(n=Promise))((function(r,a){function i(e){try{l(s.next(e))}catch(e){a(e)}}function o(e){try{l(s.throw(e))}catch(e){a(e)}}function l(e){var t;e.done?r(e.value):(t=e.value,t instanceof n?t:new n((function(e){e(t)}))).then(i,o)}l((s=s.apply(e,t||[])).next())}))}function EH(e,t){var n,s,r,a,i={label:0,sent:function(){if(1&r[0])throw r[1];return r[1]},trys:[],ops:[]};return a={next:o(0),throw:o(1),return:o(2)},"function"==typeof Symbol&&(a[Symbol.iterator]=function(){return this}),a;function o(a){return function(o){return function(a){if(n)throw new TypeError("Generator is already executing.");for(;i;)try{if(n=1,s&&(r=2&a[0]?s.return:a[0]?s.throw||((r=s.return)&&r.call(s),0):s.next)&&!(r=r.call(s,a[1])).done)return r;switch(s=0,r&&(a=[2&a[0],r.value]),a[0]){case 0:case 1:r=a;break;case 4:return i.label++,{value:a[1],done:!1};case 5:i.label++,s=a[1],a=[0];continue;case 7:a=i.ops.pop(),i.trys.pop();continue;default:if(!(r=(r=i.trys).length>0&&r[r.length-1])&&(6===a[0]||2===a[0])){i=0;continue}if(3===a[0]&&(!r||a[1]>r[0]&&a[1]<r[3])){i.label=a[1];break}if(6===a[0]&&i.label<r[1]){i.label=r[1],r=a;break}if(r&&i.label<r[2]){i.label=r[2],i.ops.push(a);break}r[2]&&i.ops.pop(),i.trys.pop();continue}a=t.call(e,i)}catch(e){a=[6,e],s=0}finally{n=r=0}if(5&a[0])throw a[1];return{value:a[0]?a[1]:void 0,done:!0}}([a,o])}}}var CH=function(e){for(var t=[],n=0,s=e;n<s.length;n++){var r=s[n];t.push(r)}return t},RH=function(){this.parent=null,this.children={},this.end=!1,this.word=[[],0,0]},AH=function(){function e(){this.root=new RH}return e.prototype.insert=function(e,t,n){for(var s=this.root,r=CH(e),a=0;a<r.length;a++)s.children[r[a]]||(s.children[r[a]]=new RH,s.children[r[a]].parent=s,s.children[r[a]].word[0]=s.word[0].concat(r[a])),s=s.children[r[a]],a===r.length-1&&(s.end=!0,s.word[1]=t,s.word[2]=n)},e.prototype.commonPrefixSearch=function(e){for(var t=[],n=this.root.children[e[0]],s=0;s<e.length&&n;s++)n.end&&t.push(n.word),n=n.children[e[s+1]];return t.length||t.push([[e[0]],0,0]),t},e}(),_H=function(){function e(e,t){void 0===t&&(t=6),this.vocabulary=e,this.reservedSymbolsCount=t,this.trie=new AH;for(var n=this.reservedSymbolsCount;n<this.vocabulary.length;n++)this.trie.insert(this.vocabulary[n][0],this.vocabulary[n][1],n)}return e.prototype.encode=function(e){var t=[],n=[],s=[];e=function(e){var t=e.normalize("NFKC");return t.length>0?"▁"+t.replace(/ /g,"▁"):t}(e);for(var r=CH(e),a=0;a<=r.length;a++)t.push({}),n.push(0),s.push(0);for(a=0;a<r.length;a++)for(var i=this.trie.commonPrefixSearch(r.slice(a)),o=0;o<i.length;o++){var l=i[o],u={key:l[0],score:l[1],index:l[2]};null==t[a+(c=l[0].length)][a]&&(t[a+c][a]=[]),t[a+c][a].push(u)}for(var c=0;c<=r.length;c++)for(var h in t[c]){var p=t[c][h];for(o=0;o<p.length;o++){var d=p[o],f=d.score+s[c-d.key.length];(0===s[c]||f>=s[c])&&(s[c]=f,n[c]=p[o].index)}}for(var m=[],g=n.length-1;g>0;)m.push(n[g]),g-=this.vocabulary[n[g]][0].length;var y=[],b=!1;for(a=0;a<m.length;a++){var x=m[a];b&&0===x||y.push(x),b=0===x}return y.reverse()},e}();function DH(e){return $H(this,void 0,void 0,(function(){return EH(this,(function(t){switch(t.label){case 0:return[4,(n=e,CM().platform.fetch(n,undefined))];case 1:return[2,t.sent().json()]}var n}))}))}var FH="https://tfhub.dev/google/tfjs-model/universal-sentence-encoder-qa-ondevice/1",OH=[0,1,2],MH=192;!function(){function e(){}e.prototype.loadModel=function(){return $H(this,void 0,void 0,(function(){return EH(this,(function(e){return[2,TH(FH,{fromTFHub:!0})]}))}))},e.prototype.load=function(){return $H(this,void 0,void 0,(function(){var e,t,n;return EH(this,(function(s){switch(s.label){case 0:return[4,Promise.all([this.loadModel(),DH(FH+"/vocab.json?tfjs-format=file")])];case 1:return e=s.sent(),t=e[0],n=e[1],this.model=t,this.tokenizer=new _H(n,3),[2]}}))}))},e.prototype.embed=function(e){var t=this,n=YV((function(){var n=t.tokenizeStrings(e.queries,MH),s=t.tokenizeStrings(e.responses,MH);if(null!=e.contexts&&e.contexts.length!==e.responses.length)throw new Error("The length of response strings and context strings need to match.");var r=e.contexts||[];null==e.contexts&&(r.length=e.responses.length,r.fill(""));var a=t.tokenizeStrings(r,MH),i={};return i.input_inp_text=n,i.input_res_text=s,i.input_res_context=a,t.model.execute(i,["Final/EncodeQuery/mul","Final/EncodeResult/mul"])}));return{queryEmbedding:n[0],responseEmbedding:n[1]}},e.prototype.tokenizeStrings=function(e,t){var n=this;return MV(e.map((function(e){return n.shiftTokens(n.tokenizer.encode(e),MH)})),[e.length,MH],"int32")},e.prototype.shiftTokens=function(e,t){e.unshift(1);for(var n=0;n<t;n++)n>=e.length?e[n]=2:OH.includes(e[n])||(e[n]+=3);return e.slice(0,t)}}();var LH=function(){function e(){}return e.prototype.loadModel=function(e){return $H(this,void 0,void 0,(function(){return EH(this,(function(t){return[2,e?TH(e):TH("https://tfhub.dev/tensorflow/tfjs-model/universal-sentence-encoder-lite/1/default/1",{fromTFHub:!0})]}))}))},e.prototype.load=function(e){return void 0===e&&(e={}),$H(this,void 0,void 0,(function(){var t,n,s;return EH(this,(function(r){switch(r.label){case 0:return[4,Promise.all([this.loadModel(e.modelUrl),DH(e.vocabUrl||"https://storage.googleapis.com/tfjs-models/savedmodel/universal_sentence_encoder/vocab.json")])];case 1:return t=r.sent(),n=t[0],s=t[1],this.model=n,this.tokenizer=new _H(s),[2]}}))}))},e.prototype.embed=function(e){return $H(this,void 0,void 0,(function(){var t,n,s,r,a,i,o,l,u=this;return EH(this,(function(c){switch(c.label){case 0:for("string"==typeof e&&(e=[e]),t=e.map((function(e){return u.tokenizer.encode(e)})),n=t.map((function(e,t){return e.map((function(e,n){return[t,n]}))})),s=[],r=0;r<n.length;r++)s=s.concat(n[r]);return a=MV(s,[s.length,2],"int32"),i=OV(lM(t),"int32"),o={indices:a,values:i},[4,this.model.executeAsync(o)];case 1:return l=c.sent(),a.dispose(),i.dispose(),[2,l]}}))}))},e}();"undefined"==typeof browser&&(globalThis.window=globalThis.window||globalThis);const zH="undefined"!=typeof browser?browser:chrome;let BH,PH=null;const WH=new Map;async function VH(e){if(!BH){if(!e)return PH||(PH=function(){return $H(this,void 0,void 0,(function(){var e;return EH(this,(function(t){switch(t.label){case 0:return[4,(e=new LH).load(undefined)];case 1:return t.sent(),[2,e]}}))}))}().then((e=>(BH=e,PH=null,console.log("Modèle chargé !"),BH))).catch((e=>{throw PH=null,e}))),PH;try{return BH=await dy("model_tfjs/model.json"),console.log("Model loaded successfully!"),print("model.predict(gros fils de pute)",BH.predict("gros fils de pute")),BH}catch(e){console.error("Erreur lors du chargement du modèle :",e),alert("Une erreur est survenue lors du chargement du modèle. Veuillez vérifier le chemin ou la connexion.")}}return BH}async function UH(e){await VH(!0);const t=[],n=[];for(const s of e)WH.has(s)?t.push(WH.get(s)):n.push(s);if(n.length>0){const e=n.map((e=>ql(e.split(" ")))),s=(await BH.predict(e)).arraySync();n.forEach(((e,n)=>{WH.set(e,s[n]),t.push(s[n])}))}return t}function GH(e,t){console.log("vecA.length",e.length),console.log("vecB.length",t.length);return e.reduce(((e,n,s)=>e+n*t[s]),0)/(Math.sqrt(e.reduce(((e,t)=>e+t*t),0))*Math.sqrt(t.reduce(((e,t)=>e+t*t),0)))}VH(!0),zH.runtime.onMessage.addListener((function(e,t,n){if("analyzeText"===e.type&&e.sentence&&Array.isArray(e.keywords))return console.log("Handle MEssageeeeeeeeeeeeeeeeeeeeeeeee!!! => "+e.sentence),async function(e,t,n=.7){try{const s=await UH([e]),r=await UH(t);console.log("OKi embedding");const a=s[0],i=r;console.log("wordEmbeddings",e,a),console.log("keywordEmbeddings",t,i);let o=0;for(const s of i){const r=GH(a,s);if(console.log("Similarité avec",t[o],e,":",r),r>n)return!0;o++}return!1}catch(e){return console.log(e),!1}}(e.sentence,e.keywords,e.threshold).then((e=>{n({isAboveThreshold:e})})).catch((e=>{console.error(e),n({isAboveThreshold:!1})})),!0}))})()})();